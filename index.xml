<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>fgg blog</title><link>https://fgg100y.github.io/</link><description>fgg blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Wed, 22 May 2024 11:15:40 +0800</lastBuildDate><atom:link href="https://fgg100y.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>FAISS-IVFPQ</title><link>https://fgg100y.github.io/posts/faiss101/</link><pubDate>Wed, 22 May 2024 11:15:40 +0800</pubDate><guid>https://fgg100y.github.io/posts/faiss101/</guid><description>&lt;h2 id="plain-and-simple-indexflatl2" >
&lt;div>
&lt;a href="#plain-and-simple-indexflatl2">
#
&lt;/a>
Plain and Simple: IndexFlatL2
&lt;/div>
&lt;/h2>&lt;blockquote>
&lt;p>Given a set of vectors, we can index them using Faiss — then using another vector (the query vector), we search for the most similar vectors within the index.
Now, Faiss not only allows us to build an index and search — but it also speeds up search times to ludicrous performance levels.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>IndexFlatL2: simple but not scalable&lt;/li>
&lt;li>Partitioning the index: for speed when scale up&lt;/li>
&lt;li>Quantization: for more speed&lt;/li>
&lt;/ul>
&lt;h2 id="inverted-file-index-ivf-index" >
&lt;div>
&lt;a href="#inverted-file-index-ivf-index">
#
&lt;/a>
Inverted File Index (IVF) index
&lt;/div>
&lt;/h2>&lt;p>The Inverted File Index (IVF) index consists of search scope reduction through clustering.&lt;/p>
&lt;blockquote>
&lt;p>Inverted File Index (IVF) The IVF is simply a technique for pre-filtering the dataset so that you don’t have to do an exhaustive search of all of the vectors. It’s pretty straightforward–you cluster the dataset ahead of time with k-means clustering to produce a large number (e.g., 100) of dataset partitions. Then, at query time, you compare your query vector to the partition centroids to find, e.g., the 10 closest clusters, and then you search against only the vectors in those partitions.&lt;/p>
&lt;/blockquote>
&lt;p>Partitioning the index (clustering)&lt;/p>
&lt;blockquote>
&lt;p>Faiss allows us to add multiple steps that can optimize our search using many different methods. A popular approach is to partition the index into Voronoi cells.
We can imagine our vectors as each being contained within a Voronoi cell — when we introduce a new query vector, we first measure its distance between centroids, then restrict our search scope to that centroid’s cell.
But there is a problem if our query vector lands near the edge of a cell — there’s a good chance that its closest other datapoint is contained within a neighboring cell.&lt;/p>
&lt;/blockquote>
&lt;p>what we can do to mitigate this issue and increase search-quality is increase an index parameter known as the nprobe value. With nprobe we can set the number of cells to search. I.e., Increasing nprobe increases our search scope.&lt;/p>
&lt;p>进行聚类的结果，一方面可以极大提升查询速度，但另一方面，可能会造成落在聚类簇边缘的“query向量”只在本聚类簇内查找匹配的结果（实际上，它可能与邻近的聚类簇的其他向量更靠近），从而导致匹配质量的降低。
一个缓解这个问题的方法是：调整参数 nprobe. 通过增加 nprobe (增加用于匹配查询向量的邻近聚类簇数量）来提升匹配质量。（同时，也会增加查询耗时）&lt;/p>
&lt;h2 id="product-quantization" >
&lt;div>
&lt;a href="#product-quantization">
#
&lt;/a>
Product Quantization
&lt;/div>
&lt;/h2>&lt;blockquote>
&lt;p>All of our indexes so far have stored our vectors as full (eg Flat) vectors. Now, in very large datasets this can quickly become a problem.
Fortunately, Faiss comes with the ability to compress our vectors using Product Quantization (PQ).
But, what is PQ? Well, we can view it as an additional approximation step with a similar outcome to our use of IVF. Where IVF allowed us to approximate by reducing the scope of our search, PQ approximates the distance/similarity calculation instead.
PQ achieves this approximated similarity operation by compressing the vectors themselves, which consists of three steps.&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>Original vector&lt;/li>
&lt;li>Sliced sub-vector&lt;/li>
&lt;li>slice clustering&lt;/li>
&lt;li>centroid ID vector&lt;/li>
&lt;/ol>
&lt;p>PQ（乘积量化）不是对嵌入向量空间进行降维，而是对向量本身进行压缩：&lt;/p>
&lt;ul>
&lt;li>01 向量分段，例如：1024 -&amp;gt; 128x8 (8个片段)；&lt;/li>
&lt;li>02 如果数据量是50k，则从单个50k x 1024 的矩阵，变成 8个 50k x 128 的矩阵；&lt;/li>
&lt;li>03 然后分别用k=256的k-means进行聚类，得到8组256个centroids；则每个原始向量可以用长度为8的向量进行表征（8组与各个向量片段最近的centroid的ID）；&lt;/li>
&lt;li>04 查询向量（query）同样进行片段化，并找到各组的centroids，然后计算片段向量与centroid的距离，并保存为距离表（partial query subvector-to-centroid distances table)；&lt;/li>
&lt;li>05 查询向量与数据向量的距离？将数据向量的centroid-ID向量，用于 partial-query-distance-table 的表查询（table lookup），就能得到对应的一系列距离，然后计算其总和L2距离；&lt;/li>
&lt;li>06 将查询向量与所有数据向量的距离计算出来，排序，即可得到 top-k 最近距离，亦即 top-k 最近似结果 （实际就是 KNN 算法）。&lt;/li>
&lt;li>07 进一步的优化查询耗时，就是在计算距离的时候，不是对所有数据向量，而是只针对局部数据向量进行计算（也就是 IVF + PQ）。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>m &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of centroid IDs in final compressed vectors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bits &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of bits in each centroid&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">50&lt;/span> &lt;span style="color:#78787e"># how many cells/blocks&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d) &lt;span style="color:#78787e"># we keep the same L2 distance flat index&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFPQ(quantizer, d, nlist, m, bits)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>train(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>add(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>nprobe &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">10&lt;/span> &lt;span style="color:#78787e"># align to previous IndexIVFFlat nprobe value&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># %%time # jupyterlab cell magic&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>search(xq, k)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> I&lt;span style="color:#ff6ac1">.&lt;/span>tolist()[&lt;span style="color:#ff9f43">0&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">print&lt;/span>(indata[i]) &lt;span style="color:#78787e"># sample of original texts/sentences&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>tech interview prepare (for my resume)</title><link>https://fgg100y.github.io/posts/notes4resume/</link><pubDate>Sat, 27 Apr 2024 22:35:53 +0800</pubDate><guid>https://fgg100y.github.io/posts/notes4resume/</guid><description>&lt;h1 id="自我介绍" >
&lt;div>
&lt;a href="#%e8%87%aa%e6%88%91%e4%bb%8b%e7%bb%8d">
##
&lt;/a>
自我介绍
&lt;/div>
&lt;/h1>&lt;blockquote>
&lt;p>在自我介绍时，确保你提到的项目和技能与你申请的职位紧密相关，这样可以更好地展示你的专业
能力和对职位的适应性。同时，保持自信和热情，让面试官感受到你对工作和团队的承诺。&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;p>尊敬的面试官，您好！&lt;/p>
&lt;p>我叫范明华，拥有6年在机器学习领域的工作经验。我于2017年硕士毕业于中山大学，专业是生态学，
这为我在实验设计、统计分析以及数据挖掘方面打下了扎实的基础。在过去的6年中，我一直致力于
将机器学习技术应用于实际问题，并取得了一些的成果。&lt;/p>
&lt;p>我在目前公司担任高级数据挖掘工程师，期间我主导了多个机器学习项目的开发和交付，包括时序预
测模型， 图像识别/目标检测模型，以及基于大数据挖掘的普通机器学习模型等，并预研NLP以及语
音识别方面的技术, 同时也取得了授权的发明专利、软件著作、地方标准等成果。在这些项目的实战
中，不仅提升了我的技术深度，也锻炼了代码管理和团队领导能力。&lt;/p>
&lt;p>在技术层面，我比较擅长结合业务流程开展半监督学习，并且有丰富的实践经验（包括在普通机器学
习和NLP领域）。我熟悉整个机器学习项目的开发流程，从项目调研、数据预处理、特征工程到模型
训练和部署，我都有深入的理解和实践。&lt;/p>
&lt;p>除了技术专长，我还是一个注重团队合作和务实负责的人。我相信，我的专业技能和丰富经验，能够为贵公司带来直接的价值。&lt;/p>
&lt;p>我对贵公司在机器学习/大模型应用/自然语言处理方面等方面的工作非常感兴趣，并且我相信我的背景和技能可以为贵公司的发展做出贡献。
我期待能够加入贵公司，并与团队一起解决更多有趣的技术挑战。&lt;/p>
&lt;p>感谢您给我这次面试的机会，我期待在接下来的讨论中分享更多我的经验和想法。谢谢！&lt;/p>
&lt;hr>
&lt;h1 id="project-01----nlp" >
&lt;div>
&lt;a href="#project-01----nlp">
##
&lt;/a>
Project 01 &amp;ndash; NLP
&lt;/div>
&lt;/h1>&lt;h2 id="sklearn-randomforest-model" >
&lt;div>
&lt;a href="#sklearn-randomforest-model">
#
&lt;/a>
sklearn randomforest model
&lt;/div>
&lt;/h2>&lt;p>当谈到随机森林时，我们需要理解它的基础算法：决策树。随机森林是基于决策树的集成学习方法。所以，让我们首先来了解决策树的基本算法，然后再深入探讨随机森林。&lt;/p>
&lt;h3 id="1-决策树算法" >
&lt;div>
&lt;a href="#1-%e5%86%b3%e7%ad%96%e6%a0%91%e7%ae%97%e6%b3%95">
##
&lt;/a>
1. 决策树算法:
&lt;/div>
&lt;/h3>&lt;h4 id="11-cart算法-classification-and-regression-trees" >
&lt;div>
&lt;a href="#11-cart%e7%ae%97%e6%b3%95-classification-and-regression-trees">
###
&lt;/a>
1.1 CART算法 (Classification and Regression Trees):
&lt;/div>
&lt;/h4>&lt;p>CART算法是一种用于构建分类和回归树的决策树算法。它通过对数据集递归地进行二分来构建决策树。具体步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>特征选择&lt;/strong>：对于分类问题，通常使用基尼指数（Gini index）或信息增益（Information Gain）来选择最佳的特征进行分裂；对于回归问题，通常使用平方误差来选择最佳的特征。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>节点分裂&lt;/strong>：根据选择的特征，将数据集分成两部分，使得每个子集的样本属于同一类别（对于分类问题）或具有相似的回归值（对于回归问题）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>递归&lt;/strong>：对每个子集重复上述过程，直到满足停止条件，如达到最大深度、节点中样本数小于某个阈值或其他预定义条件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>剪枝&lt;/strong>：为了避免过拟合，可以对生成的树进行剪枝，即移除一些节点来简化树的结构。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="2-随机森林算法" >
&lt;div>
&lt;a href="#2-%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97%e7%ae%97%e6%b3%95">
##
&lt;/a>
2. 随机森林算法:
&lt;/div>
&lt;/h3>&lt;h4 id="21-构建随机森林" >
&lt;div>
&lt;a href="#21-%e6%9e%84%e5%bb%ba%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97">
###
&lt;/a>
2.1 构建随机森林:
&lt;/div>
&lt;/h4>&lt;p>随机森林是通过构建多棵决策树并将它们集成起来来完成的。具体步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>随机抽样&lt;/strong>：从原始训练集中随机选择一部分样本（有放回抽样）来构建每棵决策树的训练集。这样可以保证每棵树的训练集略有差异，增加了模型的多样性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>随机特征选择&lt;/strong>：对于每棵树的每个节点，在选择分割特征时，随机选择一部分特征来进行评估。这样可以确保每棵树的分裂过程也有所差异。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>独立构建&lt;/strong>：每棵树都是独立构建的，没有任何关联。这意味着可以并行地构建多棵树，提高了训练效率。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="22-集成决策树" >
&lt;div>
&lt;a href="#22-%e9%9b%86%e6%88%90%e5%86%b3%e7%ad%96%e6%a0%91">
###
&lt;/a>
2.2 集成决策树:
&lt;/div>
&lt;/h4>&lt;p>构建多棵决策树后，随机森林采用不同的方式来集成它们的预测结果：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>分类任务&lt;/strong>：采用投票的方式，即每棵树投票选择最终的类别。&lt;/li>
&lt;li>&lt;strong>回归任务&lt;/strong>：采用平均值的方式，即多棵树的预测结果取平均值。&lt;/li>
&lt;/ul>
&lt;h3 id="总结" >
&lt;div>
&lt;a href="#%e6%80%bb%e7%bb%93">
##
&lt;/a>
总结:
&lt;/div>
&lt;/h3>&lt;p>随机森林是一种强大的机器学习方法，基于决策树的集成学习。通过利用决策树的随机性和集成策略，随机森林能够有效地应对分类和回归问题，并在许多实际应用中表现优异。&lt;/p>
&lt;p>在 CART (Classification and Regression Trees) 算法中，节点的分裂依据是基于贪心算法。CART 算法通过贪心地选择每次分裂时能够最大程度减少不纯度（对于分类问题）或者最小化误差（对于回归问题）的特征来进行节点的分裂。这种贪心策略保证了在每个节点分裂时都选择了最优的特征来进行分裂。&lt;/p>
&lt;h3 id="节点分裂的依据" >
&lt;div>
&lt;a href="#%e8%8a%82%e7%82%b9%e5%88%86%e8%a3%82%e7%9a%84%e4%be%9d%e6%8d%ae">
##
&lt;/a>
节点分裂的依据：
&lt;/div>
&lt;/h3>&lt;h4 id="对于分类问题" >
&lt;div>
&lt;a href="#%e5%af%b9%e4%ba%8e%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98">
###
&lt;/a>
对于分类问题：
&lt;/div>
&lt;/h4>&lt;p>在分类问题中，CART 算法通常使用以下两种方法作为节点分裂的依据：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>基尼指数 (Gini index)&lt;/strong>：基尼指数衡量了从一个数据集中随机抽取两个样本，它们类别不一致的概率。具体地，对于一个节点 $t$，基尼指数可以计算为：&lt;/p>
&lt;p>[ Gini(t) = 1 - \sum_{i=1}^{c} p(i|t)^2 ]&lt;/p>
&lt;p>其中，$c$ 是类别的数量，$p(i|t)$ 是在节点 $t$ 中属于类别 $i$ 的样本的比例。选择能够最大程度降低基尼指数的特征来进行节点分裂。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>信息增益 (Information Gain)&lt;/strong>：信息增益衡量了在某个特征的条件下，将数据集分为不同类别后，带来的不确定性减少的程度。具体地，对于一个节点 $t$ 和一个特征 $A$，信息增益可以计算为：&lt;/p>
&lt;p>[ IG(t, A) = H(t) - \sum_{v \in Values(A)} \frac{|t_v|}{|t|} \cdot H(t_v) ]&lt;/p>
&lt;p>其中，$H(t)$ 是节点 $t$ 的熵，$Values(A)$ 是特征 $A$ 的取值集合，$t_v$ 是在特征 $A$ 上取值为 $v$ 的样本集合，$H(t_v)$ 是样本集合 $t_v$ 的熵。选择能够最大化信息增益的特征来进行节点分裂。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="对于回归问题" >
&lt;div>
&lt;a href="#%e5%af%b9%e4%ba%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98">
###
&lt;/a>
对于回归问题：
&lt;/div>
&lt;/h4>&lt;p>在回归问题中，CART 算法通常使用平方误差 (Mean Squared Error, MSE) 作为节点分裂的依据。选择能够最小化节点分裂后样本的平方误差的特征来进行分裂。&lt;/p>
&lt;h3 id="总结-1" >
&lt;div>
&lt;a href="#%e6%80%bb%e7%bb%93-1">
##
&lt;/a>
总结：
&lt;/div>
&lt;/h3>&lt;p>CART 算法在节点分裂时采用贪心算法，选择能够最大程度减少不纯度（分类问题）或者最小化误差（回归问题）的特征来进行分裂。这种贪心策略保证了每次分裂都选择了最优的特征，以构建出尽可能简单且有效的决策树。&lt;/p>
&lt;p>当谈到基于决策树的集成学习时，除了随机森林，还有一种重要的方法是提升树（Boosting）。提升树是一种迭代的集成学习方法，通过串行地构建一系列决策树来逐步提升模型的性能。下面我会详细介绍提升树的原理和实现方式。&lt;/p>
&lt;h3 id="提升树的原理" >
&lt;div>
&lt;a href="#%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%8e%9f%e7%90%86">
##
&lt;/a>
提升树的原理：
&lt;/div>
&lt;/h3>&lt;h4 id="1-基本思想" >
&lt;div>
&lt;a href="#1-%e5%9f%ba%e6%9c%ac%e6%80%9d%e6%83%b3">
###
&lt;/a>
1. 基本思想：
&lt;/div>
&lt;/h4>&lt;p>提升树的基本思想是通过训练一系列弱学习器（通常是决策树），然后将它们组合起来构成一个更强大的模型。每个弱学习器都专注于纠正之前模型的错误，因此在构建过程中会关注之前模型预测错误的样本。&lt;/p>
&lt;h4 id="2-算法流程" >
&lt;div>
&lt;a href="#2-%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b">
###
&lt;/a>
2. 算法流程：
&lt;/div>
&lt;/h4>&lt;p>提升树的算法流程如下：&lt;/p>
&lt;ol>
&lt;li>初始化模型为一个常数值，通常为目标变量的均值（对于回归问题）或者是类别的先验概率（对于分类问题）。&lt;/li>
&lt;li>迭代地训练决策树，每次训练都会生成一个新的弱学习器。在每次迭代中，算法会计算当前模型的残差（对于回归问题）或者梯度（对于分类问题），然后训练一个新的决策树来拟合这些残差或者梯度。&lt;/li>
&lt;li>将新生成的决策树加到模型中，通常使用一个较小的学习率来缓解每棵树的影响。&lt;/li>
&lt;li>重复迭代步骤2和步骤3，直到达到预先设定的迭代次数或者模型的性能达到某个阈值为止。&lt;/li>
&lt;/ol>
&lt;h4 id="3-加法模型" >
&lt;div>
&lt;a href="#3-%e5%8a%a0%e6%b3%95%e6%a8%a1%e5%9e%8b">
###
&lt;/a>
3. 加法模型：
&lt;/div>
&lt;/h4>&lt;p>提升树的最终模型是一个加法模型，即多个弱学习器的加权求和。通过迭代训练，每个弱学习器都会对模型进行一定的修正，最终组合起来构成一个更强大的模型。&lt;/p>
&lt;h3 id="实现" >
&lt;div>
&lt;a href="#%e5%ae%9e%e7%8e%b0">
##
&lt;/a>
实现：
&lt;/div>
&lt;/h3>&lt;p>提升树的实现通常采用梯度提升算法（Gradient Boosting），其中最常见的是梯度提升决策树（Gradient Boosting Decision Trees，GBDT）。&lt;/p>
&lt;p>GBDT 算法的关键步骤包括计算残差或者梯度、训练决策树以拟合残差或者梯度、确定学习率等。GBDT 通过不断地迭代训练决策树来逐步优化模型，直到达到一定的迭代次数或者达到一定的性能指标。&lt;/p>
&lt;h3 id="总结-2" >
&lt;div>
&lt;a href="#%e6%80%bb%e7%bb%93-2">
##
&lt;/a>
总结：
&lt;/div>
&lt;/h3>&lt;p>提升树是一种基于决策树的集成学习方法，通过迭代训练一系列决策树来逐步提升模型的性能。相较于随机森林，提升树通常会产生更加精确的预测，但需要更长的训练时间，并且对异常值和噪声数据更敏感。&lt;/p>
&lt;h2 id="mlp-model" >
&lt;div>
&lt;a href="#mlp-model">
#
&lt;/a>
MLP model
&lt;/div>
&lt;/h2>&lt;p>MLP，即多层感知器（Multilayer Perceptron），是一种基本的人工神经网络模型。它由多层神经元组成，每一层都与下一层全连接。MLP是一种前馈神经网络，意味着信息只能从输入层向输出层传递，不会存在循环连接。&lt;/p>
&lt;p>下面是MLP的一些基本原理：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>神经元（Perceptron）&lt;/strong>：
在MLP中，每个神经元都是一个简单的计算单元。它接收来自前一层的输入信号，将这些信号加权求和，并通过激活函数产生输出。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>多层结构&lt;/strong>：
MLP由多个层组成，典型的MLP包括输入层、至少一个隐藏层和输出层。输入层接收原始数据，隐藏层对输入数据进行特征提取和转换，输出层生成最终的预测结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>权重和偏置&lt;/strong>：
在MLP中，每个连接都有一个相关联的权重，用于控制信号传递的强度和方向。此外，每个神经元还有一个偏置，用于调整神经元的激活阈值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>激活函数&lt;/strong>：
在神经元中，激活函数决定了神经元输出的非线性关系。常用的激活函数包括Sigmoid、ReLU（Rectified Linear Unit）、tanh等，它们在不同情况下具有不同的优势。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>前向传播&lt;/strong>：
在MLP中，数据从输入层开始传播，经过一系列的加权求和和激活函数处理，一直传播到输出层，生成最终的预测结果。这个过程称为前向传播。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>反向传播&lt;/strong>：
反向传播是MLP中用于训练模型的关键步骤。它利用梯度下降算法，通过计算损失函数对每个参数（权重和偏置）的梯度，并沿着梯度的反方向更新参数，从而最小化损失函数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>损失函数&lt;/strong>：
损失函数用于衡量模型预测结果与真实标签之间的差异。常见的损失函数包括均方误差（MSE）、交叉熵等，选择适当的损失函数取决于具体的问题类型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>优化算法&lt;/strong>：
在反向传播过程中，需要选择合适的优化算法来更新模型参数。常用的优化算法包括随机梯度下降（SGD）、Adam、RMSprop等。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>总的来说，MLP通过多层的非线性变换来学习输入数据的复杂特征表示，通过反向传播算法不断调整模型参数以最小化损失函数，从而实现对数据的分类、回归等任务。&lt;/p>
&lt;p>反向传播算法是用于训练神经网络的关键算法之一，它通过计算损失函数对每个参数的梯度来更新模型参数，从而使得模型能够逐渐优化以达到最佳性能。下面我将介绍反向传播算法的计算过程，以及链式法则如何用来计算梯度。&lt;/p>
&lt;h3 id="反向传播算法的计算过程" >
&lt;div>
&lt;a href="#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e7%ae%97%e6%b3%95%e7%9a%84%e8%ae%a1%e7%ae%97%e8%bf%87%e7%a8%8b">
##
&lt;/a>
反向传播算法的计算过程：
&lt;/div>
&lt;/h3>&lt;ol>
&lt;li>
&lt;p>&lt;strong>前向传播&lt;/strong>：
首先，通过前向传播计算模型的输出。将输入数据输入到网络中，按照网络结构逐层计算每个神经元的输出，并将输出传递给下一层，直至生成最终的预测结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>计算损失&lt;/strong>：
使用损失函数计算模型的预测值与真实标签之间的差异，得到损失值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>反向传播&lt;/strong>：
从输出层开始，利用链式法则逐层计算每个参数的梯度。梯度表示了损失函数对参数的变化率，它告诉我们如何调整参数才能使损失函数最小化。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>参数更新&lt;/strong>：
根据计算得到的梯度，利用优化算法（如随机梯度下降）来更新模型参数。通常，参数更新的步长（学习率）是一个超参数，需要根据实际情况进行调整。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="链式法则如何用来计算梯度" >
&lt;div>
&lt;a href="#%e9%93%be%e5%bc%8f%e6%b3%95%e5%88%99%e5%a6%82%e4%bd%95%e7%94%a8%e6%9d%a5%e8%ae%a1%e7%ae%97%e6%a2%af%e5%ba%a6">
##
&lt;/a>
链式法则如何用来计算梯度：
&lt;/div>
&lt;/h3>&lt;p>链式法则是微积分中的基本原理，用于计算复合函数的导数。在反向传播算法中，我们利用链式法则来计算损失函数对模型参数的梯度，从而实现参数的更新。&lt;/p>
&lt;p>假设有一个复合函数 (z = f(g(x)))，其中 (x) 是输入，(g(x)) 是一个函数，(f(x)) 是另一个函数。根据链式法则，(z) 对 (x) 的导数可以表示为：&lt;/p>
&lt;p>[
\frac{dz}{dx} = \frac{dz}{dg} \cdot \frac{dg}{dx}
]&lt;/p>
&lt;p>在神经网络中，我们可以将损失函数 (L) 视为 (z)，模型的参数视为 (x)，前向传播过程中的每一层输出视为 (g)，激活函数视为 (f)。利用链式法则，我们可以逐层计算损失函数对每个参数的梯度，然后根据优化算法更新参数，使得损失函数逐渐减小。&lt;/p>
&lt;p>总的来说，反向传播算法通过利用链式法则计算损失函数对参数的梯度，实现了高效的神经网络训练过程，使得模型能够自动学习复杂的数据表示。&lt;/p>
&lt;p>交叉熵（Cross-Entropy）是在分类任务中常用的损失函数，特别是在多分类任务中。它的原理和为什么有用可以通过以下几点进行详细解释：&lt;/p>
&lt;h3 id="1-损失函数的作用" >
&lt;div>
&lt;a href="#1-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e7%9a%84%e4%bd%9c%e7%94%a8">
##
&lt;/a>
1. 损失函数的作用：
&lt;/div>
&lt;/h3>&lt;p>损失函数用于衡量模型预测结果与真实标签之间的差异。优化模型的目标是最小化损失函数，使得模型能够产生与真实标签相匹配的预测结果。&lt;/p>
&lt;h3 id="2-交叉熵的定义" >
&lt;div>
&lt;a href="#2-%e4%ba%a4%e5%8f%89%e7%86%b5%e7%9a%84%e5%ae%9a%e4%b9%89">
##
&lt;/a>
2. 交叉熵的定义：
&lt;/div>
&lt;/h3>&lt;p>对于多分类任务，交叉熵损失函数的数学定义如下：&lt;/p>
&lt;p>[
\text{Cross-Entropy}(y, \hat{y}) = -\sum_{i=1}^{N} y_i \log(\hat{y}_i)
]&lt;/p>
&lt;p>其中，(y) 是真实标签的概率分布（通常是一个one-hot编码的向量），(\hat{y}) 是模型预测的概率分布，(N) 是类别的数量。该损失函数用于衡量真实标签与模型预测结果之间的差异。&lt;/p>
&lt;h3 id="3-原理解释" >
&lt;div>
&lt;a href="#3-%e5%8e%9f%e7%90%86%e8%a7%a3%e9%87%8a">
##
&lt;/a>
3. 原理解释：
&lt;/div>
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>&lt;strong>信息论角度&lt;/strong>：
交叉熵损失函数源自信息论中的信息熵概念。信息熵用于衡量一个随机变量的不确定性，而交叉熵则衡量两个概率分布之间的差异。当真实标签和模型预测的分布越接近时，交叉熵越小。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>梯度下降优化&lt;/strong>：
交叉熵损失函数在梯度下降优化过程中具有良好的性质。它的导数相对简单，计算起来更加高效，而且当模型的预测结果与真实标签的差异较大时，梯度也会变得更大，从而加速模型参数的更新。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>适用于多分类任务&lt;/strong>：
交叉熵损失函数特别适用于多分类任务，因为它能够有效地衡量多个类别之间的差异，并且在模型优化过程中能够引导模型更快地收敛到最优解。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="4-为什么有用" >
&lt;div>
&lt;a href="#4-%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e7%94%a8">
##
&lt;/a>
4. 为什么有用：
&lt;/div>
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>&lt;strong>梯度信息&lt;/strong>：
交叉熵损失函数提供了丰富的梯度信息，使得模型可以更快地学习到正确的预测结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>适用性广泛&lt;/strong>：
交叉熵损失函数适用于多分类任务，并且在实际应用中表现良好，因此成为了许多分类任务的首选损失函数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>与概率相关&lt;/strong>：
交叉熵损失函数直接与概率分布相关，更符合任务的本质，能够更好地指导模型学习数据的分布情况。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>总的来说，交叉熵损失函数通过衡量模型预测结果与真实标签之间的差异，提供了有效的优化目标，并在梯度下降优化过程中起到重要作用，因此被广泛应用于分类任务中。&lt;/p>
&lt;h2 id="bertroberta-model" >
&lt;div>
&lt;a href="#bertroberta-model">
#
&lt;/a>
BERT/RoBERTa model
&lt;/div>
&lt;/h2>&lt;p>BERT:&lt;/p>
&lt;pre>&lt;code>BERT是一种双向的（Bidirectional）模型，这意味着它能够同时考虑到一个单词左边和右边的上下文信息。这使得BERT在理解句子语境时比之前的模型更为强大。
BERT模型的预训练过程是通过掩盖输入文本中的一部分词汇（Masked Language Model，MLM）和预测句子是否连续（Next Sentence Prediction，NSP）来完成的。
BERT以“transformer”为基础，这是一种自注意力（self-attention）机制的神经网络结构，它能够在考虑到输入序列的所有位置之间建立关联，从而更好地理解上下文。
&lt;/code>&lt;/pre>
&lt;p>RoBERTa是Facebook AI提出的一种改进的预训练自然语言处理（NLP）模型，它在很大程度上建立在BERT的基础上，但通过一系列的改进，使其在多个NLP任务上表现更优秀。&lt;/p>
&lt;p>RoBERTa的主要改进包括：&lt;/p>
&lt;pre>&lt;code>动态掩码策略（Dynamic Masking）：RoBERTa在预训练时采用了动态掩码策略，即在每个训练迭代中对输入句子进行随机化处理，而不是固定地在句子中随机掩码。这使得模型更好地学习句子中的上下文信息。
更长的训练时间和更大的批次大小：RoBERTa使用了更大的批次大小和更长的训练时间，以提高模型的泛化能力和性能。
去除NSP（Next Sentence Prediction）任务：RoBERTa不再使用BERT中的NSP任务，而是专注于MLM（Masked Language Model）任务，这使得模型更好地理解输入文本。
更多的训练数据：RoBERTa使用了更多的文本数据来进行预训练，这有助于提高模型的泛化能力。
&lt;/code>&lt;/pre>
&lt;p>总的来说，RoBERTa是对BERT模型的一种优化和改进，它在多个NLP任务上都取得了比BERT更好的性能。&lt;/p>
&lt;h2 id="faiss-indexivfpq" >
&lt;div>
&lt;a href="#faiss-indexivfpq">
#
&lt;/a>
FAISS (indexIVFPQ)
&lt;/div>
&lt;/h2>&lt;h2 id="bertopic" >
&lt;div>
&lt;a href="#bertopic">
#
&lt;/a>
BERTopic
&lt;/div>
&lt;/h2>&lt;ul>
&lt;li>clustering&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>UMAP/PCA&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>c-TF-IDF&lt;/li>
&lt;/ul>
&lt;p>BERTopic 是一个基于BERT（Bidirectional Encoder Representations from Transformers）的自然语言处理工具，用于主题建模任务。BERTopic结合了BERT的强大表示学习能力和主题建模的思想，能够在大规模文本数据上快速、准确地提取主题信息。&lt;/p>
&lt;p>BERTopic的工作原理如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>文本向量化&lt;/strong>：首先，BERTopic使用预训练的BERT模型来将输入文本转换为高维向量表示。这些向量捕捉了输入文本的语义信息，并且通常能够更好地反映文本之间的语义相似度。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>主题发现&lt;/strong>：接下来，BERTopic使用聚类算法（例如DBSCAN或HDBSCAN）对文本向量进行聚类，以发现潜在的主题。聚类算法将文本向量分组为具有相似主题的簇。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>主题关键词提取&lt;/strong>：对于每个发现的主题簇，BERTopic还可以提取关键词来描述该主题。这些关键词通常是簇中最具代表性的词语，帮助用户理解主题的内容。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>主题可视化&lt;/strong>：最后，BERTopic可以将发现的主题可视化，使用户能够直观地了解文本数据中的主题结构。通常，可视化结果会以簇的形式展示，每个簇代表一个主题，簇内的文本则表示该主题的具体内容。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>关于最佳实践，以下是一些建议：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>调整模型参数&lt;/strong>：根据任务需求和数据特点，调整BERTopic的参数，例如聚类算法的参数、主题数量等，以获得更好的结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>预处理文本数据&lt;/strong>：在使用BERTopic之前，对文本数据进行适当的预处理是很重要的，例如去除停用词、进行词干化或词形还原等，以减少噪音对主题建模的影响。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>理解主题结果&lt;/strong>：对于每个发现的主题，仔细查看主题簇中的文本，并考虑它们之间的相似性和共性，以确保主题的合理性和可解释性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>与领域知识结合&lt;/strong>：在解释和利用主题结果时，结合领域知识会更有帮助。通过深入了解领域专业术语和相关概念，可以更准确地理解和解释主题的含义。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>通过合理地使用BERTopic工具，并结合适当的数据预处理和模型调优，可以有效地完成基于自然语言的主题建模任务。&lt;/p>
&lt;p>当然，让我更详细地解释一下这些技术。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>UMAP（Uniform Manifold Approximation and Projection）&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>UMAP是一种非线性降维算法，旨在将高维数据映射到低维空间以进行可视化或进一步分析。&lt;/li>
&lt;li>UMAP相对于传统的降维技术（如t-SNE）具有更好的可扩展性和保持全局数据结构的能力。它能够保持更多的局部结构，同时在大规模数据上的计算效率更高。&lt;/li>
&lt;li>在BERTopic中，UMAP常用于对BERT向量化的文本数据进行降维，以便进行更好的可视化或进一步的分析。降维后的数据可以更容易地被人类理解和解释。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>c-TF-IDF（Class-based TF-IDF）&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>c-TF-IDF是一种改进的TF-IDF（Term Frequency-Inverse Document Frequency）方法，用于从文本数据中提取关键词。&lt;/li>
&lt;li>与传统的TF-IDF相比，c-TF-IDF考虑了单词在不同主题中的重要性，而不仅仅是在整个文本集合中的重要性。这使得c-TF-IDF能够更好地捕捉文本中的主题相关信息。&lt;/li>
&lt;li>在BERTopic中，c-TF-IDF常用于从每个发现的主题簇中提取关键词，以描述该主题的内容。这些关键词通常是簇中最具代表性的词语，帮助用户理解主题的含义和内容。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>HDBSCAN（Hierarchical Density-Based Spatial Clustering of Applications with Noise）&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>HDBSCAN是一种密度聚类算法，旨在发现数据中的高密度区域，并将它们组合成簇。&lt;/li>
&lt;li>与传统的基于距离的聚类算法（如K均值）不同，HDBSCAN不需要预先指定簇的数量，因此更适用于发现具有不同大小和形状的簇的数据。&lt;/li>
&lt;li>在BERTopic中，HDBSCAN通常与UMAP一起使用，用于对BERT向量化的文本数据进行聚类。HDBSCAN能够识别出具有不同主题的文本簇，从而帮助用户发现文本数据中的主题结构。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>综上所述，UMAP用于将高维文本向量降维到低维空间，以便于可视化和分析；c-TF-IDF用于从每个主题簇中提取关键词以描述主题内容；HDBSCAN用于发现文本数据中的潜在主题簇。这些技术的结合使得BERTopic能够有效地进行自然语言主题建模，并从文本数据中提取有意义的主题信息。&lt;/p>
&lt;h1 id="project-02----ml" >
&lt;div>
&lt;a href="#project-02----ml">
##
&lt;/a>
Project 02 &amp;ndash; ML
&lt;/div>
&lt;/h1>&lt;h2 id="self-training--gausianmixtruemodels" >
&lt;div>
&lt;a href="#self-training--gausianmixtruemodels">
#
&lt;/a>
self-training &amp;amp; GausianMixtrueModels
&lt;/div>
&lt;/h2>&lt;p>半监督学习是一种机器学习方法，它利用有标签和无标签的数据来进行模型训练。相比于只使用有标签数据进行训练，半监督学习可以利用更多的无标签数据，从而提高模型的性能。&lt;/p>
&lt;p>self-training（自训练）是半监督学习中的一种常见技术，其基本思想是利用已经训练好的模型对无标签数据进行预测，然后将置信度较高的预测结果作为伪标签，将这些伪标签的数据与有标签数据一起重新训练模型。&lt;/p>
&lt;p>具体来说，self-training的步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>利用有标签数据训练一个初始模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用该模型对无标签数据进行预测，并选取置信度较高的预测结果作为伪标签。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将伪标签的数据与原有的有标签数据合并，重新训练模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>重复步骤2和步骤3，直到满足停止条件（比如达到最大迭代次数、模型性能不再提升等）。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>self-training的关键在于如何选择置信度较高的预测结果作为伪标签。一般来说，可以通过设置一个阈值来筛选置信度较高的预测结果，也可以使用模型的输出概率来作为置信度的度量。&lt;/p>
&lt;p>使用self-training技术可以帮助扩充样本，提高模型的泛化能力，特别是在标记数据有限的情况下。但需要注意的是，自训练过程中可能会引入噪声，因此需要仔细调节参数和监控模型性能，以避免过拟合和性能下降的问题。&lt;/p>
&lt;p>如果聚类簇内的标签并不一致，而且类别数目较为相同，这种情况可能会导致一些混乱，因为无法简单地选择一个代表性的标签来为整个聚类簇的样本打标签。在这种情况下，可以考虑以下几种处理方式：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>投票机制&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>对于每个聚类簇，可以采用投票机制来选择标签。即，统计聚类簇中样本的真实标签或者已有的伪标签，选择出现频率最高的标签作为整个聚类簇的标签。&lt;/li>
&lt;li>如果有多个标签出现频率相同，可以随机选择其中一个或者采用一些其他的策略来解决冲突。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>标签融合&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>对于聚类簇内的样本，可以将其真实标签或者已有的伪标签进行融合。例如，可以计算聚类簇中每个类别的权重，然后根据权重对多个标签进行加权平均，得到一个综合的标签。&lt;/li>
&lt;li>这种方法可以在一定程度上解决标签冲突的问题，但需要谨慎设计权重计算的方法，以避免给不太准确的标签过多的权重。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>进一步分析&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>对于那些标签冲突较为严重的聚类簇，可以进一步分析其样本特征或者数据分布，尝试找到更合适的标签选择策略。&lt;/li>
&lt;li>可以考虑使用一些数据挖掘技术或者领域知识来帮助解决这个问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>半监督学习方法&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>除了高斯混合聚类，还可以尝试其他半监督学习方法，如图半监督学习（Graph-based Semi-Supervised Learning）、标签传播算法（Label Propagation）、自训练（Self-training）等。&lt;/li>
&lt;li>这些方法可能会更有效地处理标签冲突的问题，因为它们可以更好地利用数据之间的相似性和关联性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>在实际应用中，可以根据具体情况选择适合的方法来处理标签冲突问题，同时需要注意监控模型的性能和效果，及时调整和优化算法。&lt;/p>
&lt;h2 id="xgboost" >
&lt;div>
&lt;a href="#xgboost">
#
&lt;/a>
XGBoost
&lt;/div>
&lt;/h2>&lt;p>XGBoost，全称为“eXtreme Gradient Boosting”，是一种高效的集成学习算法，属于梯度提升树（Gradient Boosting Tree）的一种实现。它在机器学习竞赛中非常流行，因为它能够在各种类型的数据集上取得优秀的性能，并且相对于其他算法，它通常更容易调整参数以获得更好的性能。&lt;/p>
&lt;p>以下是 XGBoost 模型的一些关键特点和优势：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>集成学习&lt;/strong>：XGBoost 是一种集成学习算法，它通过组合多个弱学习器（通常是决策树）来构建一个强大的模型。每个决策树都是根据前一个树的错误进行训练，以逐步减少模型的残差。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>梯度提升算法&lt;/strong>：XGBoost 使用梯度提升算法来训练模型。该算法通过最小化损失函数的梯度来优化模型，从而使模型在每一步都更加贴近真实值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>正则化&lt;/strong>：XGBoost 提供了对模型进行正则化的选项，包括 L1 和 L2 正则化，以及控制树的复杂度的参数。这有助于减少过拟合，提高模型的泛化能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>支持并行化&lt;/strong>：XGBoost 可以有效地利用并行计算资源进行训练，因此在大规模数据集上也能够快速地训练模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>特征重要性评估&lt;/strong>：XGBoost 可以计算特征的重要性，从而帮助用户了解哪些特征对模型的预测最为关键。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>灵活性&lt;/strong>：XGBoost 可以用于分类问题、回归问题以及排序问题，并且可以在不同类型的数据集上进行应用。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>总的来说，XGBoost 是一种强大且灵活的机器学习算法，适用于各种类型的问题，并且在实践中表现出色。&lt;/p>
&lt;p>梯度提升算法（Gradient Boosting Algorithm）是一种集成学习方法，通过将多个弱学习器（通常是决策树）串联起来，逐步减少模型的残差来构建一个强大的预测模型。梯度提升算法通过梯度下降的思想，不断优化模型以最小化损失函数。&lt;/p>
&lt;p>下面是梯度提升算法的基本步骤：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>初始化模型&lt;/strong>：梯度提升算法通常从一个简单的模型开始，例如用一个常数来拟合数据的平均值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>迭代优化&lt;/strong>：接下来，算法迭代地执行以下步骤：&lt;/p>
&lt;ul>
&lt;li>计算残差：使用当前模型对训练数据进行预测，并计算实际值与预测值之间的残差。&lt;/li>
&lt;li>拟合残差：构建一个新的弱学习器（如决策树），以拟合残差。这意味着新的学习器会尝试纠正上一个模型的错误。&lt;/li>
&lt;li>更新模型：将新的学习器与前面的模型组合起来，形成一个更强大的模型。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>停止条件&lt;/strong>：当达到预先设定的迭代次数，或者当模型的性能满足某个特定的标准时，停止迭代。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>与梯度下降算法的关系在于，梯度提升算法也利用了梯度的信息来优化模型。但两者之间的关键区别在于优化的对象和优化方向。在梯度下降算法中，优化的对象是损失函数本身，而优化的方向是沿着损失函数梯度的反方向。而在梯度提升算法中，优化的对象是损失函数的残差，优化的方向是使残差最小化的方向。&lt;/p>
&lt;p>总的来说，梯度提升算法是一种强大的集成学习方法，通过不断迭代优化模型以减少残差，从而构建一个强大的预测模型。它利用了梯度信息来指导优化过程，但与梯度下降算法相比，它的优化目标和优化方向有所不同。&lt;/p>
&lt;h2 id="onnx-dockerpodman-and-restful-api" >
&lt;div>
&lt;a href="#onnx-dockerpodman-and-restful-api">
#
&lt;/a>
ONNX, Docker/Podman, and restful-api
&lt;/div>
&lt;/h2>&lt;p>当你希望使用 Docker 来部署服务，并且构建 Flask RESTful API 来提供对 ONNX 模型的推理服务时，你可以按照以下步骤进行：&lt;/p>
&lt;h3 id="1-准备-flask-restful-api-代码" >
&lt;div>
&lt;a href="#1-%e5%87%86%e5%a4%87-flask-restful-api-%e4%bb%a3%e7%a0%81">
##
&lt;/a>
1. 准备 Flask RESTful API 代码
&lt;/div>
&lt;/h3>&lt;p>你需要创建一个 Flask 应用程序，编写代码以加载 ONNX 模型并提供 RESTful API 来进行推理。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> flask &lt;span style="color:#ff6ac1">import&lt;/span> Flask, request
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> flask_restful &lt;span style="color:#ff6ac1">import&lt;/span> Api, Resource
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> numpy &lt;span style="color:#ff6ac1">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> onnxruntime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>app &lt;span style="color:#ff6ac1">=&lt;/span> Flask(__name__)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>api &lt;span style="color:#ff6ac1">=&lt;/span> Api(app)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">class&lt;/span> &lt;span style="color:#f3f99d">ModelInference&lt;/span>(Resource):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> __init__(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">super&lt;/span>(ModelInference, self)&lt;span style="color:#ff6ac1">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#ff6ac1">.&lt;/span>session &lt;span style="color:#ff6ac1">=&lt;/span> onnxruntime&lt;span style="color:#ff6ac1">.&lt;/span>InferenceSession(&lt;span style="color:#5af78e">&amp;#34;your_model.onnx&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">post&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#ff6ac1">=&lt;/span> request&lt;span style="color:#ff6ac1">.&lt;/span>json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_data &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array(data[&lt;span style="color:#5af78e">&amp;#34;input&amp;#34;&lt;/span>])&lt;span style="color:#ff6ac1">.&lt;/span>astype(np&lt;span style="color:#ff6ac1">.&lt;/span>float32)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> output &lt;span style="color:#ff6ac1">=&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>session&lt;span style="color:#ff6ac1">.&lt;/span>run([], {&lt;span style="color:#5af78e">&amp;#34;input&amp;#34;&lt;/span>: input_data})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> {&lt;span style="color:#5af78e">&amp;#34;output&amp;#34;&lt;/span>: output&lt;span style="color:#ff6ac1">.&lt;/span>tolist()}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>api&lt;span style="color:#ff6ac1">.&lt;/span>add_resource(ModelInference, &lt;span style="color:#5af78e">&amp;#34;/predict&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">if&lt;/span> __name__ &lt;span style="color:#ff6ac1">==&lt;/span> &lt;span style="color:#5af78e">&amp;#34;__main__&amp;#34;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> app&lt;span style="color:#ff6ac1">.&lt;/span>run(debug&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">True&lt;/span>, host&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;0.0.0.0&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="2-创建-dockerfile" >
&lt;div>
&lt;a href="#2-%e5%88%9b%e5%bb%ba-dockerfile">
##
&lt;/a>
2. 创建 Dockerfile
&lt;/div>
&lt;/h3>&lt;p>创建一个 Dockerfile 来构建 Docker 镜像。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-Dockerfile" data-lang="Dockerfile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">FROM&lt;/span>&lt;span style="color:#5af78e"> python:3.9-slim&lt;/span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">WORKDIR&lt;/span>&lt;span style="color:#5af78e"> /app&lt;/span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">COPY&lt;/span> requirements.txt .&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">RUN&lt;/span> pip install --no-cache-dir -r requirements.txt&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">COPY&lt;/span> . .&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">CMD&lt;/span> [ &lt;span style="color:#5af78e">&amp;#34;python&amp;#34;&lt;/span>, &lt;span style="color:#5af78e">&amp;#34;app.py&amp;#34;&lt;/span> ]&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-构建-docker-镜像" >
&lt;div>
&lt;a href="#3-%e6%9e%84%e5%bb%ba-docker-%e9%95%9c%e5%83%8f">
##
&lt;/a>
3. 构建 Docker 镜像
&lt;/div>
&lt;/h3>&lt;p>在包含 Dockerfile 的目录下执行以下命令来构建 Docker 镜像。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker build -t your_image_name .
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="4-运行-docker-容器" >
&lt;div>
&lt;a href="#4-%e8%bf%90%e8%a1%8c-docker-%e5%ae%b9%e5%99%a8">
##
&lt;/a>
4. 运行 Docker 容器
&lt;/div>
&lt;/h3>&lt;p>使用以下命令来运行你的 Docker 容器。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -p 5000:5000 your_image_name
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="5-测试-api" >
&lt;div>
&lt;a href="#5-%e6%b5%8b%e8%af%95-api">
##
&lt;/a>
5. 测试 API
&lt;/div>
&lt;/h3>&lt;p>使用任何 HTTP 客户端工具或 Python 应用程序来测试你的 API。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> requests
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data &lt;span style="color:#ff6ac1">=&lt;/span> {&lt;span style="color:#5af78e">&amp;#34;input&amp;#34;&lt;/span>: [&lt;span style="color:#ff9f43">1.0&lt;/span>, &lt;span style="color:#ff9f43">2.0&lt;/span>, &lt;span style="color:#ff9f43">3.0&lt;/span>]} &lt;span style="color:#78787e"># 示例输入数据&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#ff6ac1">=&lt;/span> requests&lt;span style="color:#ff6ac1">.&lt;/span>post(&lt;span style="color:#5af78e">&amp;#34;http://localhost:5000/predict&amp;#34;&lt;/span>, json&lt;span style="color:#ff6ac1">=&lt;/span>data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(response&lt;span style="color:#ff6ac1">.&lt;/span>json())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="总结-3" >
&lt;div>
&lt;a href="#%e6%80%bb%e7%bb%93-3">
##
&lt;/a>
总结
&lt;/div>
&lt;/h3>&lt;p>这就是一个简单的部署流程。你可以根据你的具体需求进行调整和扩展，比如添加模型预处理、后处理逻辑，以及对 API 的身份验证和访问控制等功能。&lt;/p>
&lt;h1 id="project-03----cv" >
&lt;div>
&lt;a href="#project-03----cv">
##
&lt;/a>
Project 03 &amp;ndash; CV
&lt;/div>
&lt;/h1>&lt;h2 id="yolo-model" >
&lt;div>
&lt;a href="#yolo-model">
#
&lt;/a>
YOLO model
&lt;/div>
&lt;/h2>&lt;p>好的，让我来详细介绍一下YOLO（You Only Look Once）目标检测模型的原理和实现。&lt;/p>
&lt;h3 id="1-yolo-模型的原理" >
&lt;div>
&lt;a href="#1-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%8e%9f%e7%90%86">
##
&lt;/a>
1. YOLO 模型的原理：
&lt;/div>
&lt;/h3>&lt;h4 id="11-单阶段检测" >
&lt;div>
&lt;a href="#11-%e5%8d%95%e9%98%b6%e6%ae%b5%e6%a3%80%e6%b5%8b">
###
&lt;/a>
1.1 单阶段检测：
&lt;/div>
&lt;/h4>&lt;p>YOLO 是一种单阶段目标检测模型，与传统的两阶段检测方法（如Faster R-CNN）不同，它将目标检测任务视为一个端到端的回归问题，直接从图像中预测目标的位置和类别。&lt;/p>
&lt;h4 id="12-网络结构" >
&lt;div>
&lt;a href="#12-%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84">
###
&lt;/a>
1.2 网络结构：
&lt;/div>
&lt;/h4>&lt;p>YOLO 模型主要由卷积神经网络组成，通常采用类似于Darknet的深层卷积神经网络作为特征提取器。&lt;/p>
&lt;h4 id="13-网络输出" >
&lt;div>
&lt;a href="#13-%e7%bd%91%e7%bb%9c%e8%be%93%e5%87%ba">
###
&lt;/a>
1.3 网络输出：
&lt;/div>
&lt;/h4>&lt;p>YOLO 将图像划分为固定大小的网格，并为每个网格预测多个边界框和对应的类别概率。每个边界框由五个坐标值和类别概率组成：$(x, y, w, h, p)$，其中 $(x, y)$ 是边界框的中心坐标，$(w, h)$ 是边界框的宽度和高度，$p$ 是边界框包含目标的置信度。&lt;/p>
&lt;h4 id="14-损失函数" >
&lt;div>
&lt;a href="#14-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0">
###
&lt;/a>
1.4 损失函数：
&lt;/div>
&lt;/h4>&lt;p>YOLO 模型使用组合损失函数来同时优化边界框位置的准确性和类别的预测精度。该损失函数包括位置误差、置信度误差和类别误差。&lt;/p>
&lt;h3 id="2-yolo-模型的实现" >
&lt;div>
&lt;a href="#2-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%ae%9e%e7%8e%b0">
##
&lt;/a>
2. YOLO 模型的实现：
&lt;/div>
&lt;/h3>&lt;h4 id="21-训练阶段" >
&lt;div>
&lt;a href="#21-%e8%ae%ad%e7%bb%83%e9%98%b6%e6%ae%b5">
###
&lt;/a>
2.1 训练阶段：
&lt;/div>
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>数据准备&lt;/strong>：收集和标记训练数据集，包括图像和对应的目标边界框。&lt;/li>
&lt;li>&lt;strong>网络结构&lt;/strong>：选择适当的网络结构，通常使用预训练的Darknet网络或其变种。&lt;/li>
&lt;li>&lt;strong>损失函数&lt;/strong>：定义和实现组合损失函数，用于优化网络参数。&lt;/li>
&lt;li>&lt;strong>训练过程&lt;/strong>：使用训练数据集对模型进行训练，通过反向传播算法更新网络参数，以最小化损失函数。&lt;/li>
&lt;/ul>
&lt;h4 id="22-推理阶段" >
&lt;div>
&lt;a href="#22-%e6%8e%a8%e7%90%86%e9%98%b6%e6%ae%b5">
###
&lt;/a>
2.2 推理阶段：
&lt;/div>
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>前向传播&lt;/strong>：将待检测的图像输入到训练好的模型中，通过前向传播算法获取每个边界框的预测结果。&lt;/li>
&lt;li>&lt;strong>后处理&lt;/strong>：对网络输出进行后处理，包括非极大值抑制（NMS）和阈值筛选，以去除重叠的边界框和低置信度的边界框。&lt;/li>
&lt;li>&lt;strong>目标框绘制&lt;/strong>：根据最终的边界框结果，将目标框绘制在原始图像上，并标记类别。&lt;/li>
&lt;/ul>
&lt;h3 id="3-yolo-模型的优势" >
&lt;div>
&lt;a href="#3-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e4%bc%98%e5%8a%bf">
##
&lt;/a>
3. YOLO 模型的优势：
&lt;/div>
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>速度快&lt;/strong>：YOLO 是一种高效的目标检测模型，能够实时处理图像和视频流。&lt;/li>
&lt;li>&lt;strong>端到端&lt;/strong>：YOLO 将目标检测视为一个端到端的回归问题，简化了检测流程。&lt;/li>
&lt;li>&lt;strong>全局信息&lt;/strong>：YOLO 在整个图像上进行检测，能够同时考虑图像中的全局信息，从而更好地理解场景。&lt;/li>
&lt;/ul>
&lt;h3 id="4-总结" >
&lt;div>
&lt;a href="#4-%e6%80%bb%e7%bb%93">
##
&lt;/a>
4. 总结：
&lt;/div>
&lt;/h3>&lt;p>YOLO 是一种高效的单阶段目标检测模型，通过将目标检测任务转化为回归问题，并结合有效的网络结构和损失函数，实现了在保持高准确率的同时实时进行目标检测的能力。&lt;/p>
&lt;p>&amp;ldquo;锚定点&amp;rdquo;（Anchor Boxes）是YOLO模型中的一个重要概念，它用于解决目标检测中不同目标尺寸和比例的问题。在YOLO中，每个网格单元都负责预测一组固定数量和固定大小的边界框（即锚定点），以便检测不同尺寸和比例的目标。&lt;/p>
&lt;h3 id="1-锚定点的概念" >
&lt;div>
&lt;a href="#1-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%a6%82%e5%bf%b5">
##
&lt;/a>
1. 锚定点的概念：
&lt;/div>
&lt;/h3>&lt;h4 id="11-问题" >
&lt;div>
&lt;a href="#11-%e9%97%ae%e9%a2%98">
###
&lt;/a>
1.1 问题：
&lt;/div>
&lt;/h4>&lt;p>传统的目标检测算法通常会将不同尺寸和比例的目标分配给不同的网络层来处理，这种方法不够灵活，无法很好地适应多样化的目标。&lt;/p>
&lt;h4 id="12-解决方法" >
&lt;div>
&lt;a href="#12-%e8%a7%a3%e5%86%b3%e6%96%b9%e6%b3%95">
###
&lt;/a>
1.2 解决方法：
&lt;/div>
&lt;/h4>&lt;p>YOLO使用锚定点的思想，将不同尺寸和比例的目标统一分配给每个网格单元，并在每个网格单元中预测固定数量的边界框。这样可以增加模型的灵活性，使其能够检测不同尺寸和比例的目标。&lt;/p>
&lt;h3 id="2-锚定点的思想" >
&lt;div>
&lt;a href="#2-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%80%9d%e6%83%b3">
##
&lt;/a>
2. 锚定点的思想：
&lt;/div>
&lt;/h3>&lt;h4 id="21-预定义大小和比例" >
&lt;div>
&lt;a href="#21-%e9%a2%84%e5%ae%9a%e4%b9%89%e5%a4%a7%e5%b0%8f%e5%92%8c%e6%af%94%e4%be%8b">
###
&lt;/a>
2.1 预定义大小和比例：
&lt;/div>
&lt;/h4>&lt;p>在YOLO中，锚定点是一组预定义的大小和比例的边界框。这些边界框通常是在训练数据集上通过聚类等方法得到的，以确保涵盖了大部分目标的大小和比例。&lt;/p>
&lt;h4 id="22-单元格内多个边界框" >
&lt;div>
&lt;a href="#22-%e5%8d%95%e5%85%83%e6%a0%bc%e5%86%85%e5%a4%9a%e4%b8%aa%e8%be%b9%e7%95%8c%e6%a1%86">
###
&lt;/a>
2.2 单元格内多个边界框：
&lt;/div>
&lt;/h4>&lt;p>对于每个网格单元，YOLO模型预测固定数量的边界框，每个边界框的大小和比例与预定义的锚定点相对应。这样，每个网格单元可以同时检测多个不同尺寸和比例的目标。&lt;/p>
&lt;h3 id="3-锚定点的技术实现" >
&lt;div>
&lt;a href="#3-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%8a%80%e6%9c%af%e5%ae%9e%e7%8e%b0">
##
&lt;/a>
3. 锚定点的技术实现：
&lt;/div>
&lt;/h3>&lt;h4 id="31-预训练锚定点" >
&lt;div>
&lt;a href="#31-%e9%a2%84%e8%ae%ad%e7%bb%83%e9%94%9a%e5%ae%9a%e7%82%b9">
###
&lt;/a>
3.1 预训练锚定点：
&lt;/div>
&lt;/h4>&lt;p>在训练之前，通常会通过对训练数据集中的目标边界框进行聚类或者手动选择，来确定一组锚定点的大小和比例。&lt;/p>
&lt;h4 id="32-模型预测" >
&lt;div>
&lt;a href="#32-%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b">
###
&lt;/a>
3.2 模型预测：
&lt;/div>
&lt;/h4>&lt;p>在模型推理阶段，每个网格单元通过回归预测固定数量的边界框，每个边界框的尺寸和比例由对应的锚定点确定。&lt;/p>
&lt;h4 id="33-边界框调整" >
&lt;div>
&lt;a href="#33-%e8%be%b9%e7%95%8c%e6%a1%86%e8%b0%83%e6%95%b4">
###
&lt;/a>
3.3 边界框调整：
&lt;/div>
&lt;/h4>&lt;p>模型预测的边界框通常是相对于网格单元的偏移量和尺寸偏差，需要根据锚定点进行调整，得到最终的边界框位置。&lt;/p>
&lt;h3 id="4-总结-1" >
&lt;div>
&lt;a href="#4-%e6%80%bb%e7%bb%93-1">
##
&lt;/a>
4. 总结：
&lt;/div>
&lt;/h3>&lt;p>锚定点是YOLO模型中用于解决不同尺寸和比例目标检测问题的关键概念，通过预定义一组大小和比例的边界框，并在每个网格单元中预测这些边界框的位置和类别，实现了模型对多样化目标的有效检测。&lt;/p>
&lt;h2 id="transfer-learning" >
&lt;div>
&lt;a href="#transfer-learning">
#
&lt;/a>
transfer-learning
&lt;/div>
&lt;/h2>&lt;p>迁移学习是一种通过将已学习的知识从一个任务或领域应用到另一个任务或领域的机器学习技术。在目标检测任务中，迁移学习可以通过利用预训练的模型或特征来提升模型性能。以下是一些常用的迁移学习方法：&lt;/p>
&lt;h3 id="1-微调fine-tuning" >
&lt;div>
&lt;a href="#1-%e5%be%ae%e8%b0%83fine-tuning">
##
&lt;/a>
1. 微调（Fine-tuning）：
&lt;/div>
&lt;/h3>&lt;p>微调是迁移学习中最常见的方法之一，它通常包括以下步骤：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>预训练模型选择&lt;/strong>：选择一个在大规模数据集上预训练好的模型，例如 ImageNet 上的预训练模型。&lt;/li>
&lt;li>&lt;strong>模型冻结&lt;/strong>：将预训练模型的部分或全部层冻结，即不更新它们的权重。&lt;/li>
&lt;li>&lt;strong>顶层替换&lt;/strong>：替换预训练模型的顶层（通常是全连接层）或者添加新的全连接层，以适应新的目标检测任务。&lt;/li>
&lt;li>&lt;strong>微调训练&lt;/strong>：在目标检测数据集上对整个模型进行训练，包括更新顶层和部分或全部解冻的层。&lt;/li>
&lt;/ul>
&lt;h3 id="2-特征提取feature-extraction" >
&lt;div>
&lt;a href="#2-%e7%89%b9%e5%be%81%e6%8f%90%e5%8f%96feature-extraction">
##
&lt;/a>
2. 特征提取（Feature Extraction）：
&lt;/div>
&lt;/h3>&lt;p>特征提取是一种更轻量级的迁移学习方法，它不涉及到整个模型的重新训练，而是仅仅利用预训练模型的特征提取能力。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>预训练模型选择&lt;/strong>：同样选择一个在大规模数据集上预训练好的模型。&lt;/li>
&lt;li>&lt;strong>特征提取&lt;/strong>：将预训练模型的卷积层（通常是除了全连接层之外的所有层）作为特征提取器，并将提取到的特征作为输入，用于训练一个新的分类器或目标检测器。&lt;/li>
&lt;/ul>
&lt;h3 id="3-领域自适应domain-adaptation" >
&lt;div>
&lt;a href="#3-%e9%a2%86%e5%9f%9f%e8%87%aa%e9%80%82%e5%ba%94domain-adaptation">
##
&lt;/a>
3. 领域自适应（Domain Adaptation）：
&lt;/div>
&lt;/h3>&lt;p>领域自适应是一种特殊的迁移学习方法，用于解决源域和目标域数据分布不匹配的问题。在目标检测任务中，可以通过在源域和目标域之间进行域适应来提高模型的泛化能力。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>域适应方法&lt;/strong>：常见的域适应方法包括对抗训练、领域对齐等，通过调整模型的训练策略，使得模型在目标域上表现更好。&lt;/li>
&lt;/ul>
&lt;h3 id="4-知识蒸馏knowledge-distillation" >
&lt;div>
&lt;a href="#4-%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8fknowledge-distillation">
##
&lt;/a>
4. 知识蒸馏（Knowledge Distillation）：
&lt;/div>
&lt;/h3>&lt;p>知识蒸馏是一种通过利用已训练好的模型的知识来训练一个更轻量级的模型的方法。在目标检测任务中，可以利用一个大型模型的知识来训练一个小型模型，以降低模型的复杂度和计算成本。&lt;/p>
&lt;p>以上是一些常用的迁移学习方法，可以根据具体的任务需求和情况选择合适的方法来提升目标检测模型的性能。&lt;/p>
&lt;h2 id="图像识别长尾分布问题" >
&lt;div>
&lt;a href="#%e5%9b%be%e5%83%8f%e8%af%86%e5%88%ab%e9%95%bf%e5%b0%be%e5%88%86%e5%b8%83%e9%97%ae%e9%a2%98">
#
&lt;/a>
图像识别长尾分布问题
&lt;/div>
&lt;/h2>&lt;p>处理训练数据集中的长尾分布是一个常见的问题，在目标检测任务中也同样存在。长尾分布意味着有些类别的样本数量非常少，而另一些类别的样本数量非常多。解决这个问题的方法包括：&lt;/p>
&lt;h3 id="1-数据增强data-augmentation" >
&lt;div>
&lt;a href="#1-%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%badata-augmentation">
##
&lt;/a>
1. 数据增强（Data Augmentation）：
&lt;/div>
&lt;/h3>&lt;p>对于少样本类别，可以通过数据增强技术来生成更多的样本，以平衡不同类别之间的样本数量差异。常用的数据增强技术包括随机旋转、裁剪、缩放、平移、颜色变换等。&lt;/p>
&lt;h3 id="2-类别加权class-weighting" >
&lt;div>
&lt;a href="#2-%e7%b1%bb%e5%88%ab%e5%8a%a0%e6%9d%83class-weighting">
##
&lt;/a>
2. 类别加权（Class Weighting）：
&lt;/div>
&lt;/h3>&lt;p>对于长尾分布的数据集，可以采用类别加权的方式来调整模型的损失函数，使得模型对少样本类别更加敏感。可以根据类别出现的频率来设置不同类别的权重，使得损失函数更平衡。&lt;/p>
&lt;h3 id="3-重新采样resampling" >
&lt;div>
&lt;a href="#3-%e9%87%8d%e6%96%b0%e9%87%87%e6%a0%b7resampling">
##
&lt;/a>
3. 重新采样（Resampling）：
&lt;/div>
&lt;/h3>&lt;p>重新采样技术可以通过过采样或欠采样来调整数据集中不同类别的样本数量。对于少样本类别，可以采用过采样的方法增加样本数量，或者采用欠采样的方法减少样本数量。&lt;/p>
&lt;h3 id="4-弱监督学习weakly-supervised-learning" >
&lt;div>
&lt;a href="#4-%e5%bc%b1%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0weakly-supervised-learning">
##
&lt;/a>
4. 弱监督学习（Weakly Supervised Learning）：
&lt;/div>
&lt;/h3>&lt;p>在长尾分布的数据集中，有些类别可能只有少量的有标签样本，而大部分样本是未标签的。可以利用弱监督学习的方法，例如使用无监督或半监督学习技术，从未标签的数据中学习有用的特征。&lt;/p>
&lt;h3 id="5-多任务学习multi-task-learning" >
&lt;div>
&lt;a href="#5-%e5%a4%9a%e4%bb%bb%e5%8a%a1%e5%ad%a6%e4%b9%a0multi-task-learning">
##
&lt;/a>
5. 多任务学习（Multi-Task Learning）：
&lt;/div>
&lt;/h3>&lt;p>多任务学习可以将目标检测任务与其他相关任务结合起来训练模型，从而提升模型在长尾分布数据集上的性能。例如，可以将目标检测任务与图像分类、语义分割等任务结合起来进行训练，从而利用额外的信息来提升模型性能。&lt;/p>
&lt;h3 id="6-异常检测anomaly-detection" >
&lt;div>
&lt;a href="#6-%e5%bc%82%e5%b8%b8%e6%a3%80%e6%b5%8banomaly-detection">
##
&lt;/a>
6. 异常检测（Anomaly Detection）：
&lt;/div>
&lt;/h3>&lt;p>针对长尾分布数据集中的少样本类别，可以采用异常检测的方法来识别并重点关注这些少样本类别，以便更好地调整模型和优化性能。&lt;/p>
&lt;p>通过以上方法，可以有效地处理训练数据集中的长尾分布问题，并提升模型在不同类别上的性能。在实践中，通常需要根据具体的数据集和任务需求选择合适的方法进行处理。&lt;/p>
&lt;h2 id="auto-encoder-model" >
&lt;div>
&lt;a href="#auto-encoder-model">
#
&lt;/a>
Auto-encoder model
&lt;/div>
&lt;/h2>&lt;p>领域自适应是一种将知识从一个域（源域）迁移到另一个域（目标域）的迁移学习方法，用于解决源域和目标域数据分布不匹配的问题。在目标检测任务中，领域自适应可以通过对抗训练的方式来实现，而 auto-encoder 可以作为一种辅助手段来帮助实现对抗训练。以下是具体的思路和细节：&lt;/p>
&lt;h3 id="1-对抗训练的基本思路" >
&lt;div>
&lt;a href="#1-%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%80%9d%e8%b7%af">
##
&lt;/a>
1. 对抗训练的基本思路：
&lt;/div>
&lt;/h3>&lt;p>对抗训练是一种通过训练一个生成器和一个判别器的对抗过程，来使得生成器产生的数据分布与目标域的数据分布尽可能地接近。在目标检测任务中，可以通过对抗训练来调整模型，使得模型在目标域上表现更好。&lt;/p>
&lt;h3 id="2-auto-encoder-在对抗训练中的作用" >
&lt;div>
&lt;a href="#2-auto-encoder-%e5%9c%a8%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8">
##
&lt;/a>
2. auto-encoder 在对抗训练中的作用：
&lt;/div>
&lt;/h3>&lt;p>auto-encoder 是一种无监督学习模型，它可以将输入数据编码成低维表示，并将其解码回原始数据。在对抗训练中，auto-encoder 可以作为一个生成器，用于生成与目标域数据分布相似的数据样本。通过训练 auto-encoder，可以学习到目标域数据的特征表示，从而帮助实现对抗训练。&lt;/p>
&lt;h3 id="3-具体实现步骤" >
&lt;div>
&lt;a href="#3-%e5%85%b7%e4%bd%93%e5%ae%9e%e7%8e%b0%e6%ad%a5%e9%aa%a4">
##
&lt;/a>
3. 具体实现步骤：
&lt;/div>
&lt;/h3>&lt;h4 id="31-模型选择" >
&lt;div>
&lt;a href="#31-%e6%a8%a1%e5%9e%8b%e9%80%89%e6%8b%a9">
###
&lt;/a>
3.1 模型选择：
&lt;/div>
&lt;/h4>&lt;ul>
&lt;li>选择一个预训练的模型作为基础模型，例如在源域上训练好的目标检测模型。&lt;/li>
&lt;/ul>
&lt;h4 id="32-auto-encoder-训练" >
&lt;div>
&lt;a href="#32-auto-encoder-%e8%ae%ad%e7%bb%83">
###
&lt;/a>
3.2 auto-encoder 训练：
&lt;/div>
&lt;/h4>&lt;ul>
&lt;li>在目标域上收集一部分数据，并使用这些数据来训练 auto-encoder。auto-encoder 的输入为目标域的图像数据，输出为重构的图像数据。通过训练 auto-encoder，可以学习到目标域数据的特征表示。&lt;/li>
&lt;/ul>
&lt;h4 id="33-对抗训练" >
&lt;div>
&lt;a href="#33-%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83">
###
&lt;/a>
3.3 对抗训练：
&lt;/div>
&lt;/h4>&lt;ul>
&lt;li>将训练好的 auto-encoder 作为生成器，将基础模型（源域上预训练的模型）作为判别器。&lt;/li>
&lt;li>将源域和目标域的数据分别输入到 auto-encoder 和基础模型中，生成器尝试生成与目标域数据分布相似的数据样本，而判别器则尝试区分真实的目标域数据和生成器生成的数据。&lt;/li>
&lt;li>通过对抗训练的过程，调整生成器和判别器的参数，使得生成器生成的数据分布与目标域的数据分布尽可能地接近。&lt;/li>
&lt;/ul>
&lt;h3 id="4-进一步细化" >
&lt;div>
&lt;a href="#4-%e8%bf%9b%e4%b8%80%e6%ad%a5%e7%bb%86%e5%8c%96">
##
&lt;/a>
4. 进一步细化：
&lt;/div>
&lt;/h3>&lt;ul>
&lt;li>可以考虑使用带有重建损失的对抗生成网络（Adversarial Auto-Encoder, AAE）来进行训练，以加强 auto-encoder 的特征学习能力和生成能力。&lt;/li>
&lt;li>可以通过调整训练策略和超参数来进一步优化对抗训练的效果，例如学习率、训练轮数等。&lt;/li>
&lt;/ul>
&lt;p>通过以上步骤，可以利用 auto-encoder 和对抗训练的方法来实现领域自适应，从而提升目标检测模型在目标域上的性能。&lt;/p>
&lt;h2 id="目标检测的评估指标map_50" >
&lt;div>
&lt;a href="#%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b%e7%9a%84%e8%af%84%e4%bc%b0%e6%8c%87%e6%a0%87map_50">
#
&lt;/a>
目标检测的评估指标（$mAP_{50}$）
&lt;/div>
&lt;/h2>&lt;p>mAP_50 是目标检测任务中常用的评估指标之一，它表示在 IoU 阈值为 0.5 时的平均精确率（mAP，Mean Average Precision）。让我解释一下这个指标：&lt;/p>
&lt;h3 id="1-平均精确率-average-precision-ap" >
&lt;div>
&lt;a href="#1-%e5%b9%b3%e5%9d%87%e7%b2%be%e7%a1%ae%e7%8e%87-average-precision-ap">
##
&lt;/a>
1. 平均精确率 (Average Precision, AP)：
&lt;/div>
&lt;/h3>&lt;ul>
&lt;li>平均精确率是 Precision-Recall 曲线下的面积，用于衡量模型在不同 Recall 下的平均精确率。在目标检测任务中，AP 表示模型对单个类别的检测性能。&lt;/li>
&lt;/ul>
&lt;h3 id="2-iou-阈值为-05" >
&lt;div>
&lt;a href="#2-iou-%e9%98%88%e5%80%bc%e4%b8%ba-05">
##
&lt;/a>
2. IoU 阈值为 0.5：
&lt;/div>
&lt;/h3>&lt;ul>
&lt;li>IoU（Intersection over Union）是真实边界框和预测边界框的交集与并集之比。在计算 mAP 时，通常需要指定一个 IoU 阈值来判断一个检测结果是否是真正的检测结果。常用的 IoU 阈值之一是 0.5，表示当预测边界框与真实边界框的 IoU 大于等于 0.5 时，认为该预测边界框是正确的检测结果。&lt;/li>
&lt;/ul>
&lt;h3 id="3-map_50-的含义" >
&lt;div>
&lt;a href="#3-map_50-%e7%9a%84%e5%90%ab%e4%b9%89">
##
&lt;/a>
3. mAP_50 的含义：
&lt;/div>
&lt;/h3>&lt;ul>
&lt;li>mAP_50 表示在 IoU 阈值为 0.5 时的平均精确率，即模型在检测目标时，当预测边界框与真实边界框的 IoU 大于等于 0.5 时的平均精确率。&lt;/li>
&lt;/ul>
&lt;h3 id="4-使用场景" >
&lt;div>
&lt;a href="#4-%e4%bd%bf%e7%94%a8%e5%9c%ba%e6%99%af">
##
&lt;/a>
4. 使用场景：
&lt;/div>
&lt;/h3>&lt;ul>
&lt;li>mAP_50 是目标检测任务中常用的评估指标之一，它可以衡量模型在检测目标时的准确率和召回率，尤其在要求检测结果准确度较高的情况下，是一个重要的评价指标。&lt;/li>
&lt;/ul>
&lt;h3 id="5-其他-iou-阈值" >
&lt;div>
&lt;a href="#5-%e5%85%b6%e4%bb%96-iou-%e9%98%88%e5%80%bc">
##
&lt;/a>
5. 其他 IoU 阈值：
&lt;/div>
&lt;/h3>&lt;p>除了常用的 IoU 阈值 0.5 外，还可以使用其他 IoU 阈值来计算不同阈值下的 mAP，比如 mAP_75 表示在 IoU 阈值为 0.75 时的平均精确率，以此类推。不同的 IoU 阈值反映了不同的检测精度要求，可以根据具体任务的需求选择合适的 IoU 阈值来评估模型性能。&lt;/p>
&lt;h1 id="project-04----tsa" >
&lt;div>
&lt;a href="#project-04----tsa">
##
&lt;/a>
Project 04 &amp;ndash; TSA
&lt;/div>
&lt;/h1>&lt;h2 id="k-means" >
&lt;div>
&lt;a href="#k-means">
#
&lt;/a>
K-means
&lt;/div>
&lt;/h2>&lt;h2 id="arima-model" >
&lt;div>
&lt;a href="#arima-model">
#
&lt;/a>
ARIMA model
&lt;/div>
&lt;/h2>&lt;h2 id="b-spline" >
&lt;div>
&lt;a href="#b-spline">
#
&lt;/a>
B-spline
&lt;/div>
&lt;/h2>&lt;h2 id="general-additive-models" >
&lt;div>
&lt;a href="#general-additive-models">
#
&lt;/a>
General Additive Models
&lt;/div>
&lt;/h2>&lt;h2 id="时序预测模型评估指标-apemape" >
&lt;div>
&lt;a href="#%e6%97%b6%e5%ba%8f%e9%a2%84%e6%b5%8b%e6%a8%a1%e5%9e%8b%e8%af%84%e4%bc%b0%e6%8c%87%e6%a0%87-apemape">
#
&lt;/a>
时序预测模型评估指标 (APE/MAPE)
&lt;/div>
&lt;/h2>&lt;h1 id="others" >
&lt;div>
&lt;a href="#others">
##
&lt;/a>
Others
&lt;/div>
&lt;/h1>&lt;h2 id="web-scraping" >
&lt;div>
&lt;a href="#web-scraping">
#
&lt;/a>
web-scraping
&lt;/div>
&lt;/h2>&lt;h2 id="bpewordpiecesentence-piece" >
&lt;div>
&lt;a href="#bpewordpiecesentence-piece">
#
&lt;/a>
BPE/wordpiece/sentence-piece
&lt;/div>
&lt;/h2></description></item><item><title>About Me: 大道如青天，我独不得出</title><link>https://fgg100y.github.io/about/</link><pubDate>Sat, 27 Apr 2024 19:58:25 +0800</pubDate><guid>https://fgg100y.github.io/about/</guid><description>&lt;p>大道如青天，我独不得出。&lt;/p>
&lt;p>羞逐长安社中儿，赤鸡白雉赌梨栗。&lt;/p>
&lt;p>弹剑作歌奏苦声，曳裾王门不称情。&lt;/p>
&lt;p>淮阴市井笑韩信，汉朝公卿忌贾生。&lt;/p>
&lt;p>君不见昔时燕家重郭隗，拥篲折节无嫌猜。&lt;/p>
&lt;p>剧辛乐毅感恩分，输肝剖胆效英才。&lt;/p>
&lt;p>昭王白骨萦蔓草，谁人更扫黄金台？&lt;/p>
&lt;p>行路难，归去来！&lt;/p>
&lt;p>&lt;a href="https://so.gushiwen.cn/shiwenv_95834b2324cc.aspx">唐代 · 李白《行路难 · 其二》&lt;/a>&lt;/p></description></item><item><title>LLMs_interview_faq</title><link>https://fgg100y.github.io/posts/post_llms_faq/</link><pubDate>Fri, 26 Apr 2024 11:04:16 +0800</pubDate><guid>https://fgg100y.github.io/posts/post_llms_faq/</guid><description>&lt;h2 id="01简述gpt和bert的区别" >
&lt;div>
&lt;a href="#01%e7%ae%80%e8%bf%b0gpt%e5%92%8cbert%e7%9a%84%e5%8c%ba%e5%88%ab">
#
&lt;/a>
01:简述GPT和BERT的区别
&lt;/div>
&lt;/h2>&lt;p>GPT (Decoder-only) 和 BERT (Encoder-only) 都是基于 Transformer 架构的自然语言处理模型，它们在设计上有一些显著区别：&lt;/p>
&lt;ul>
&lt;li>任务类型
&lt;ul>
&lt;li>GPT 以生成文本为主要任务，其目标是生成与输入文本连贯和相关的文本。因此，GPT 通
常用于生成文本 (如：摘要总结，文本补充和chatbot)。&lt;/li>
&lt;li>BERT 以理解文本为主要任务，其目标是从输入文本中提取语义信息。因此适用于各种文
本理解任务，如：情感分析、 文本分类、命名实体识别等下游任务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>预训练目标
&lt;ul>
&lt;li>GPT：单向语言建模。GPT通过自左向右的注意力机制来预测下一个单词，即根据上下文预
测下一个单词/词元是什么。&lt;/li>
&lt;li>BERT：双向语言建模。BERT使用掩码语言建模（MLM）和下一句预测（NSP）两个任务，前
者在MLM任务中随机遮掩输入中的一些词语，模型需要预测这些被掩盖的词语是什么；
NSP的任务是判断两个句子是否在原文中是前后连接的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>结构特点
&lt;ul>
&lt;li>GPT：Transformer-decoder的堆叠，仅使用自注意力机制&lt;/li>
&lt;li>BERT：Transformer-encoder的堆叠，包含多层双向Transformer-encoder。在预训练阶段，
BERT同时使用了自注意力机制和前馈神经网络。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>模型微调
&lt;ul>
&lt;li>GPT：由于其生成式的特点，GPT在微调时通常将整个模型作为单独的序列生成任务进行微
调。&lt;/li>
&lt;li>BERT：由于其双向表示的特点，BERT在微调时通常用于各种文本理解任务，微调时可以在
模型顶层添加适当的输出层来适应下游特定任务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="02llm中的因果语言建模与掩码语言建模有什么区别" >
&lt;div>
&lt;a href="#02llm%e4%b8%ad%e7%9a%84%e5%9b%a0%e6%9e%9c%e8%af%ad%e8%a8%80%e5%bb%ba%e6%a8%a1%e4%b8%8e%e6%8e%a9%e7%a0%81%e8%af%ad%e8%a8%80%e5%bb%ba%e6%a8%a1%e6%9c%89%e4%bb%80%e4%b9%88%e5%8c%ba%e5%88%ab">
#
&lt;/a>
02:LLM中的因果语言建模与掩码语言建模有什么区别？
&lt;/div>
&lt;/h2>&lt;p>因果语言建模（Causal Language Modeling）&lt;/p>
&lt;pre>&lt;code>在因果语言建模中，模型被要求根据输入序列的左侧内容来预测右侧的下一个词或标记。也就是
说，模型只能看到输入序列中已经生成的部分，而不能看到后续的内容。这种训练方式有助于模
型学习生成连贯和合理的文本，因为模型需要在生成每个词语时考虑上下文的信息，同时不能依
赖于未来的信息。GPT（Generative Pre-trained Transformer）就是以因果语言建模为基础的
模型。
&lt;/code>&lt;/pre>
&lt;p>掩码语言建模（Masked Language Modeling）：&lt;/p>
&lt;pre>&lt;code>在掩码语言建模中，模型被要求预测输入序列中一些被随机掩盖或掩码的词语。模型需要基于上
下文来预测这些被掩盖的词语是什么。
这种训练方式通常用于双向的语言理解任务，因为模型需要考虑上下文中的所有信息来预测被掩盖的词语。
BERT（Bidirectional Encoder Representations from Transformers）就是以掩码语言建模为基础的模型。
&lt;/code>&lt;/pre>
&lt;h2 id="03请简述transformer基本原理" >
&lt;div>
&lt;a href="#03%e8%af%b7%e7%ae%80%e8%bf%b0transformer%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86">
#
&lt;/a>
03:请简述Transformer基本原理
&lt;/div>
&lt;/h2>&lt;p>Transformer 是一种用于处理序列数据的深度学习模型，由谷歌团队于2017年提出，其主要原理包括
自注意力机制和位置编码。&lt;/p>
&lt;h3 id="自注意力机制" >
&lt;div>
&lt;a href="#%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6">
##
&lt;/a>
自注意力机制：
&lt;/div>
&lt;/h3>&lt;pre>&lt;code>允许模型在序列的任意两个位置间直接建立依赖关系，而不考虑它们之间的距离。具体就是将词
元线性转换为三个向量Q,K,V，然后将Q和K用来计算内积(相似度分数)并进行注意力缩放（scaled
dot-product)，然后通过softmax归一化，得到每个词元相对于其他词元的注意力权重，然后用
注意力权重对向量V进行加权和计算得到“上下文向量”(context vector)，然后将上下文向量用
前馈网络（FFNN）进行变换，就得到编码器隐层输出。注意：自注意力机制中，每个输入词元的
context vector 以及后续的 hidden state，可以看成是相应的 Q 向量的函数，其他的如 K，V，
以及自注意力机制的参数对所有的 Q 都是恒定值。
+ 多头注意力：
在多头注意力中，注意力机制被复制多次，并且每个注意力头都学习到一组不同的Q,K,V的
表示，然后将它们的输出拼接起来，再通过FFNN进行维度对齐。
- 复制注意力机制：原始输入序列会被用来计算多个注意力头（例如8个或16个头）
- 独立学习：每个注意力头都会独立地学习一组Q，K，V的表示，也就是：每个注意力头都
有自己的权重矩阵，将输入序列转换为Q,K,V向量。
- 注意力计算：每个注意力头像单头注意力机制那样计算注意力分数和注意力权重。
- 拼接输出：将所有注意力头的输出拼接成一个向量，形成多头注意力的最终输出。这意味
着每个词元都会得到来自多个不同视角的表示，从而提高模型对输入序列的理解。
- 线性变换：拼接后的输出通过FFNN进行处理，维持输出维度以及融合不同注意力头的信息。
+ narrow attn：Each attention head will get a chunk of the transformed data points
(projections) to work with. This is a details of utmost importance: The
attention heads DO NOT use chunks of the original data points, but rather those
of their projections. It computes the projections first and then chunks them
later, so that each value in the projection is a linear combination of all
features in the data point.
&lt;/code>&lt;/pre>
&lt;h3 id="位置编码" >
&lt;div>
&lt;a href="#%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81">
##
&lt;/a>
位置编码：
&lt;/div>
&lt;/h3>&lt;pre>&lt;code>位置编码通常是通过将一个与位置相关的向量添加到输入嵌入（input embeddings）
中来实现的。这个向量为序列中的每个位置提供了一个唯一的表示，从而使模型能够
区分不同的单词顺序。
特别是基于 transformer 架构的模型，由于自注意力机制无法捕捉词元顺序，因此必
须通过加入位置编码来获取输入序列中各个词元的位置信息。
尽管自注意力机制（Self-Attention Mechanism）确实可以捕捉序列中元素之间的关
系，但它主要依赖于元素之间的交互和权重计算，而不是它们的绝对位置信息。位置
编码的作用是补充自注意力机制，提供序列中元素顺序的额外信息，使得模型能够更
好地理解序列的结构。
+ 正弦/余弦函数组合编码 (偶数位用 sin(), 奇数位用 cos())
它们为序列中的每个位置提供了一个唯一的、与位置直接相关的编码。这种编码
方式能够明确地告诉模型每个单词在序列中的绝对位置。
绝对位置编码的一个潜在缺点是它们是静态的，不会随着模型训练的进行而改变。
这意味着它们可能不足以捕捉长序列中复杂的依赖关系，特别是在模型需要动态
地调整位置信息以适应输入序列的变化时。
信息的局限性：固定的位置编码仅提供了位置的绝对信息，而没有考虑序列中元
素之间的相对关系。在长序列中，元素之间的相对位置和距离可能更为重要。
+ 旋转位置编码：旋转位置编码的核心思想是将每个位置的编码表示为一个旋转矩阵，
该矩阵可以应用于输入嵌入。旋转矩阵是动态生成的，这意味着它们可以根据输入
序列的内容进行调整，从而更好地捕捉长距离依赖。
&lt;/code>&lt;/pre>
&lt;h3 id="残差连接与层归一化" >
&lt;div>
&lt;a href="#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e4%b8%8e%e5%b1%82%e5%bd%92%e4%b8%80%e5%8c%96">
##
&lt;/a>
残差连接与层归一化：
&lt;/div>
&lt;/h3>&lt;pre>&lt;code>+ 残差连接：将每个子层的输入与其输出相加，然后传递给下一层。这使得模型在学
习过程中，能更容易地学习到残差（输入于输出之差），从而缓解梯度消失问题；
提高训练稳定性；允许更深的网络结构；以及提高模型性能。
+ 层归一化：在每个层的输入之后都应用归一化，即对每个特征维度进行归一化操作，
使得它们均值为0，标准差为1，有助于缓解梯度消失和梯度爆炸的问题，从而使
模型训练更加稳定，也提高其泛化能力。
- “批次归一化”（Batch Norm）：
The mean and variance statistics used for normalization are calculated
across all elements of all instances in a batch, for each feature
independently.
即：均值和方差是通过对一个批次里所有实例（序列）的所有元素（词元）的某
个特征进行统计的。
- “层归一化”（Layer Norm）：
For layernorm, the statistics are calculated across the feature
dimension, for each element and instance independently.
即：均值和方差是通过对某个实例（序列）中的某个元素（词元）的所有特征进
行统计的。
NOTE By &amp;quot;element&amp;quot; and &amp;quot;instance,&amp;quot; I mean &amp;quot;word&amp;quot; and &amp;quot;sentence&amp;quot;
respectively for an NLP task, and &amp;quot;pixel&amp;quot; and &amp;quot;image&amp;quot; for a CV task.
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="images/LLMs_layerNorm_batchNorm.png" alt="IMG: LayerNorm &amp;amp; BatchNorm">&lt;/p>
&lt;h2 id="04-注意力机制的改良版本们" >
&lt;div>
&lt;a href="#04-%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6%e7%9a%84%e6%94%b9%e8%89%af%e7%89%88%e6%9c%ac%e4%bb%ac">
#
&lt;/a>
04: 注意力机制的改良版本们
&lt;/div>
&lt;/h2>&lt;p>MHA，GQA，MQA三种注意力机制的区别是什么？&lt;/p>
&lt;p>注意力机制在自然语言处理和机器学习领域有多种不同的实现方式，其中常见的包括多头自注意力
（Multi-Head Self-Attention，MHA）、全局注意力（Global Attention，GQA）和多头查询注意力
（Multi-Query Attention，MQA）。这些不同的实现方式在机制和应用上有一些区别：&lt;/p>
&lt;pre>&lt;code>多头自注意力（MHA）：
机制：MHA将输入序列中的每个位置的表示都作为查询（Query）、键（Key）和值（Value），
通过计算查询与所有键的相似度，然后将相似度作为权重对值进行加权求和，从而获得每个
位置的注意力输出。
特点：MHA允许模型在不同的表示空间上进行多头并行计算，通过多头机制，可以学习到不同的关注点和表示。
应用：MHA常用于Transformer等模型中，用于捕捉输入序列中不同位置之间的依赖关系。
全局注意力（GQA）：
机制：GQA将所有的输入位置都作为查询，与所有的键计算相似度，然后将所有位置的值根
据相似度进行加权求和，得到一个全局的输出。
特点：GQA考虑了序列中所有位置的关系，但在处理长序列时可能会受到计算资源的限制，
因为需要计算所有位置之间的相似度。
应用：GQA常用于对整个输入序列进行全局的信息聚合，例如在图像分类任务中。
多头查询注意力（MQA）：
机制：MQA与MHA类似，但在每个头的注意力计算中，使用不同的查询向量，而不是所有头都共享相同的查询向量。
特点：MQA允许模型为每个头学习不同的查询模式，增强了模型的灵活性和表达能力。
应用：MQA常用于需要根据不同的查询来获取注意力信息的任务，如问答系统或需要针对不同问题进行推理的场景
&lt;/code>&lt;/pre>
&lt;h2 id="05-attention的改良版本们" >
&lt;div>
&lt;a href="#05-attention%e7%9a%84%e6%94%b9%e8%89%af%e7%89%88%e6%9c%ac%e4%bb%ac">
#
&lt;/a>
05: Attention的改良版本们
&lt;/div>
&lt;/h2>&lt;ul>
&lt;li>&lt;strong>简述一下 FlashAttention 的原理&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>Flash Attention是一种新型的注意力算法，旨在解决传统Transformer模型中自注意力机制的计
算和内存效率问题。由于自注意力机制的时间和存储复杂度与序列长度成二次方关系，这使得处
理长序列数据时面临巨大挑战。Flash Attention通过精心设计，显著减少了对高带宽内存（HBM）
的读写次数，从而加快了运行速度并降低了内存占用。&lt;/p>
&lt;h3 id="flash-attention的核心原理和技术" >
&lt;div>
&lt;a href="#flash-attention%e7%9a%84%e6%a0%b8%e5%bf%83%e5%8e%9f%e7%90%86%e5%92%8c%e6%8a%80%e6%9c%af">
##
&lt;/a>
Flash Attention的核心原理和技术：
&lt;/div>
&lt;/h3>&lt;pre>&lt;code>平铺（Tiling）：Flash Attention将输入分割成小块，并在每个块上执行注意力操作。这种方法减少了对高带宽内存的访问次数，因为不需要一次性将整个大矩阵加载到内存中。
重新计算（Recomputation）：在后向传播过程中，Flash Attention避免了存储大型中间矩阵（如S和P矩阵），而是利用前向传播中的统计量来快速重新计算这些矩阵，从而减少了内存消耗。
在线Softmax：为了处理Softmax操作，Flash Attention采用了在线Softmax技术，它允许分块计算softmax，并通过适当的归一化因子来确保最终结果的正确性。
内存层次结构意识（IO-Awareness）：Flash Attention考虑了GPU内存层次结构，优化了不同层级内存之间的数据访问，如在GPU的SRAM和HBM之间。
&lt;/code>&lt;/pre>
&lt;h3 id="flash-attention-2" >
&lt;div>
&lt;a href="#flash-attention-2">
##
&lt;/a>
Flash Attention-2：
&lt;/div>
&lt;/h3>&lt;p>在Flash Attention的基础上，研究人员进一步提出了Flash Attention-2，它通过改进工作分配和并行化策略，进一步提高了计算速度。Flash Attention-2的优化包括：&lt;/p>
&lt;pre>&lt;code>减少非矩阵乘法（non-matmul）的浮点运算次数（FLOPs）。
通过在不同的线程块上并行化注意力计算，提高了GPU的占用率。
在每个线程块内，将工作分配给不同的warp，以减少通过共享内存的通信。
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;strong>PagedAttention的原理是什么，解决了LLM中的什么问题？&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>Paged Attention（PA）技术是一种用于优化大型语言模型（LLM）推理性能的方法，特别是在处理自
回归生成任务时对内存使用效率的显著提升。这项技术的核心思想是借鉴操作系统中虚拟内存和分页
的技术，将传统的注意力机制中的键值对（Key-Value pairs，简称K-V pairs）缓存以分页的形式存
储和管理。&lt;/p>
&lt;p>在自回归解码过程中，模型为每个输入令牌生成注意力键和值，这些键值对被存储在GPU的显存中以
预测下一个令牌。由于这些缓存的键值对大小是动态变化的，并且可能会占用大量的显存空间，因此
有效管理这些缓存成为一个挑战。传统的注意力算法在处理时会受限于显存的大小，这限制了模型的
批处理能力和整体的吞吐量。&lt;/p>
&lt;h2 id="06llm微调与量化" >
&lt;div>
&lt;a href="#06llm%e5%be%ae%e8%b0%83%e4%b8%8e%e9%87%8f%e5%8c%96">
#
&lt;/a>
06:LLM微调与量化
&lt;/div>
&lt;/h2>&lt;p>30.参数高效的微调（PEFT）有哪些方法？
31.LORA微调相比于微调适配器或前缀微调有什么优势？
32.有了解过什么是稀疏微调吗？
33.训练后量化（PTQ）和量化感知训练（QAT）与什么区别？
34.LLMs中，量化权重和量化激活的区别是什么？
35.AWQ量化的步骤是什么？&lt;/p>
&lt;h2 id="07嵌入向量模型" >
&lt;div>
&lt;a href="#07%e5%b5%8c%e5%85%a5%e5%90%91%e9%87%8f%e6%a8%a1%e5%9e%8b">
#
&lt;/a>
07:嵌入向量模型
&lt;/div>
&lt;/h2>&lt;p>40.自前主流的中文嵌入向量模型有哪些？&lt;/p>
&lt;h2 id="其他" >
&lt;div>
&lt;a href="#%e5%85%b6%e4%bb%96">
#
&lt;/a>
其他
&lt;/div>
&lt;/h2>&lt;p>45.DeepSpeed推理对算子融合做了哪些优化？
48.请介绍一下微软的ZeRO优化器&lt;/p>
&lt;p>3.为什么现在的大模型大多是decoder-only的架构？
4.讲一下生成式语言模型的工作机理
5.哪些因素会导致LLM的偏见？
7.如何减轻LLM中的幻觉现象？
8.解释ChatGPT的零样本和少样本学习的概念
10.如何评估大语言模型（LLMs）的性能？
11.如何缓解LLMs重复读问题？
16.Wordpiece与BPE之间的区别是什么？
17.有哪些常见的优化LLMs输出的技术？
18.GPT-3拥有的1750亿参数，是怎么算出来的？
19.温度系数和top-p，top-k参数有什么区别？
21.介绍-下postlayernorm和prelayernorm的区别
22.什么是思维链（CoT）提示？
23.你觉得什么样的任务或领域适合用思维链提示？
24.你了解ReAct吗，它有什么优点？
25.解释一下langchainAgent的概念
26.langchain有哪些替代方案？
27.langchaintoken计数有什么问题？如何解决？
28.LLM预训练阶段有哪几个关键步骤？
29.RLHF模型为什么会表现比SFT更好？
36.介绍一下GPipe推理框架
37.矩阵乘法如何做张量并行？
38.请简述下PPO算法流程，它跟TRPO的区别是什么？
39.什么是检索增强生成（RAG）？
41.为什么LLM的知识更新很困难？
42.RAG和微调的区别是什么？
43.大模型一般评测方法及基准是什么？
50.什么是投机采样技术，请举例说明？&lt;/p></description></item><item><title>Tokenization: BPE, Unigram and more</title><link>https://fgg100y.github.io/posts/llm_tokenization/</link><pubDate>Mon, 22 Apr 2024 15:41:56 +0800</pubDate><guid>https://fgg100y.github.io/posts/llm_tokenization/</guid><description>&lt;h1 id="there-is-more-than-one-way-to-tokenize-a-sentence" >
&lt;div>
&lt;a href="#there-is-more-than-one-way-to-tokenize-a-sentence">
##
&lt;/a>
There is more than one way to tokenize a sentence
&lt;/div>
&lt;/h1>&lt;ul>
&lt;li>
&lt;p>word-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>A big vocabulary is needed&lt;/li>
&lt;li>We combine words: what exactly constitutes a word (&amp;ldquo;bachelor of science&amp;rdquo;, or
isolated words)&lt;/li>
&lt;li>Abbreviated words: &amp;ldquo;LOL&amp;rdquo;, &amp;ldquo;IMO&amp;rdquo;, are these collections of words or new words?&lt;/li>
&lt;li>Languages that don&amp;rsquo;t segment by spaces&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>character-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>Lack of meaning: Unlike words, characters don&amp;rsquo;t have any inherent meaning, model
may lose the semantic-specific feature of words.&lt;/li>
&lt;li>Increased input computation&lt;/li>
&lt;li>Limits netword+k choices: It&amp;rsquo;s difficult to use architectures which process input
sequentially since the input sequences will be much longer.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Subword-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>We want a tokenization scheme that deals with an infinite potential vocabulary via
a finite list of known words. Make up the word “unfortunately” via “un” + “for”+
“tun” + “ate” + “ly”.&lt;/li>
&lt;li>Subword tokenisation will break the text into chunks based on the word frequency.
In practice what happens is that common words will be tokenized generally as
whole words, e.g. “the”, “at”, “and”, etc., while rarer words will be broken
into smaller chunks and can be used to create the rest of the words in the
relevant dataset.&lt;/li>
&lt;li>BPE(Byte Pair Encoding): One popular algorithm for subword tokenisation which
follows the above approach is BPE. BPE was originally used to help compress data
by finding common byte pair combinations. It can also be applied to NLP to find
the most efficient way of representing text.
&lt;ul>
&lt;li>What is merging?
The main goal of the BPE subword algorithm is to find a way to represent
your entire text dataset with the least amount of tokens. Similar to a
compression algorithm, you want to find the best way to represent your image,
text or whatever you are encoding, which uses the least amount of data, or
in our case tokens. In the BPE algorithm merging is the way we try and
“compress” the text into subword units.&lt;/li>
&lt;li>There are a few steps to these merging actions:
&lt;ol>
&lt;li>Get the word &lt;strong>count&lt;/strong> frequency&lt;/li>
&lt;li>Get the &lt;strong>initial token count&lt;/strong> and frequency (i.e., how many times each
character occurs)&lt;/li>
&lt;li>Merge the &lt;strong>most common byte pairing&lt;/strong>&lt;/li>
&lt;li>Add this to the list of tokens and &lt;strong>recalculate the frequency count&lt;/strong>
for each token (this will change with each merging step)&lt;/li>
&lt;li>&lt;strong>Rinse and repeat&lt;/strong> until get reached pre-defined token limits (vocab
size) or a set of number of iterations&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Greedy algorithm: BPE ensures that the most common words will be represented in
the new vocabulary as a single token, while less common words will be broken
down into two or more subword tokens. To achieve this, BPE will go through every
potential option at each step and pick the tokens to merge based on the highest
frequency.One downside of BPE’s greedy approach is it can result in a potentially
ambiguous final token vocabulary.
For instance GPT has a vocabulary size of 40,478 since they have 478 base
characters and chose to stop training after 40,000 merges.&lt;/li>
&lt;li>BBPE(byte-level PBE): A base vocabulary that includes all possible base characters
can be quite large if e.g. all unicode characters are considered as base
characters. To have a better base vocabulary, GPT-2 uses bytes as the base
vocabulary, which is a clever trick to force the base vocabulary to be of size
256 while ensuring that every base character is included in the vocabulary. With
some additional rules to deal with punctuation, the GPT2’s tokenizer can
tokenize every text without the need for the &lt;unk> symbol. GPT-2 has a
vocabulary size of 50,257, which corresponds to the 256 bytes base tokens, a
special end-of-text token and the symbols learned with 50,000 merges.
&lt;a href="https://huggingface.co/docs/transformers/en/tokenizer_summary#byte-pair-encoding-bpe">from hf doc&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="probabilistic-subword-tokenization" >
&lt;div>
&lt;a href="#probabilistic-subword-tokenization">
##
&lt;/a>
Probabilistic Subword Tokenization
&lt;/div>
&lt;/h1>&lt;p>Using the frequency of subword patterns for tokenization can result in ambiguous final
encodings. The problem is that we have no way to predict which particular token is more
likely to be the best one when encoding any new input text.
Luckily, needing to predict the most likely sequence of text is not a unique problem to
tokenization. We can leverage this knowledge to build a better tokenizer.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Unigram Subword Tokenization&lt;/p>
&lt;ul>
&lt;li>The goal for a subword model, however, is different from a LM that is trying to
predict a full sentence. We only want something that generates unambiguous
tokenization.&lt;/li>
&lt;li>The unigram approach differs from BPE in that it attempts to choose the most
likely option rather than the best option at each iteration. To generate a
unigram subword token set you need to first define the desired final size of
your token set and also a starting seed subword token set.&lt;/li>
&lt;li>You can choose the seed subword token set in a similar way to BPE and choose
the most frequently occurring substrings. Once you have this in place then
you need to:
&lt;ol>
&lt;li>Work out the probability for each subword token&lt;/li>
&lt;li>Work out a loss value which would result if each subwork token were to be
dropped. The loss is worked out via Expectation Maximization algorithm.&lt;/li>
&lt;li>Drop the tokens which have the largest loss value (e.g., the bottom 10%
or 20% of subword tokens based on their loss calculations).&lt;/li>
&lt;li>Repeat these steps until reach the desired final vocabulary size or there
is no change in token numbers after successive iterations.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>WordPiece (greedy approach tokenzier, BERT partner)
Think of WordPiece as an intermediary between the BPE approach and the unigram approach.&lt;/p>
&lt;ul>
&lt;li>BPE, if you remember, takes two tokens, looks at the frequency of each pair and then
merges the pairs that have the highest combined frequency count. It only considers
the most frequent pair combinations at each step, nothing else.&lt;/li>
&lt;li>An alternate approach is to check the potential impact of merging that particular
pair. You can do this using the probabilistic LM approach. At each iterative step,
choose the character pair which will result in the largest increase in likelihood
once merged. This is the difference between the probability of the new meged pair
occurring minus the probability of both individual tokens occurring individually.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>The main difference is that WordPiece is a greedy approach. It still tries to build a
tokenizer from the bottom up, picking the best pair at each iteration to merge.
WordPiece uses the likelihood rather than count frequency but otherwise it is a similar
approach. Unigram in contrast is a fully probabilistic approach which uses probability
to both choose the pairs to merge and whether to merge them or not. It also removes
tokens based on the fact that they add the least to the overall likelihood of the
unigram model.&lt;/p>
&lt;h1 id="briefly-summarize" >
&lt;div>
&lt;a href="#briefly-summarize">
##
&lt;/a>
briefly summarize:
&lt;/div>
&lt;/h1>&lt;ul>
&lt;li>
&lt;p>BPE: Just uses the frequency of occurrences to identify the best match at every
iteration until it reaches the predefined vocabulary size.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>WordPiece: Similar to BPE and uses frequency occurrences to identify potential
merges but makes the final decision based on the likelihood of the merged token&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Unigram: A fully probabilistic model which does not use frequency
occurrences. Instead, it trains a LM using a probabilistic model, removing
the token which improves the overall likelihood the least and then starting
over until it reaches the final token limit.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="sentencepiece" >
&lt;div>
&lt;a href="#sentencepiece">
##
&lt;/a>
SentencePiece
&lt;/div>
&lt;/h1>&lt;p>SentencePiece basically tries to bring all the subword tokenization tools and techniques
under one banner. It’s kind of like the Swiss Army knife for subword tokenization. To be
a Swiss Army-like tool something has to be capable of solving multiple problems. So what
problems is SentencePiece addressing:&lt;/p>
&lt;ol>
&lt;li>All other models assume input is already tokenized: BPE and Unigram are great model
but they share one big disadvantage: they both need to have their input already
tokenized. SentencePiece deals with this by simply taking in an input in raw text and
then doing everything needed on that input to perform subword tokenization.&lt;/li>
&lt;li>Language agnostic: Since all other subword algorithms need to have their input
pre-tokenized, it limits their applicability to many languages.&lt;/li>
&lt;li>Decoding is difficult: Another problem which is caused by model like BPE and unigram
requiring already tokenized inputs is that you do not know what encoding rules were
used. For example, how were spaces encoded in the tokens? So you cannot decode the
input and return it to is original format.&lt;/li>
&lt;li>No end to end solution: You cannot just plug in a raw input to BPE (or Unigram) and
get an output.&lt;/li>
&lt;/ol>
&lt;p>Some of the techniques SentencePiece uses to address the above shortcomings:&lt;/p>
&lt;ol>
&lt;li>Encode everything as unicode: SentencePiece first converts all the input into unicode
characters. This makes it a language agnostic tool.&lt;/li>
&lt;li>&amp;ldquo;space&amp;rdquo; encoded as &amp;ldquo;_&amp;quot;(U+2581): To get around the word segmenting issues.&lt;/li>
&lt;li>And it&amp;rsquo;s faster: One of the issues preventing other subword algorithms from being used
to tokenize raw sentences as part of model training was that there lack of speed. If
you processed input in real time and performed your tokenization on the raw input it
would be too slow. SentencePiece addresses this by using a priority queue for the BPE
algorithm to speed it up so that you can use it as part of an end-to-end solution.&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>&lt;a href="https://www.openteams.com/tokenizers-how-machines-read/">https://www.openteams.com/tokenizers-how-machines-read/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>TODO: 补充中文&lt;/p></description></item></channel></rss>