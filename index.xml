<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>fgg blog</title><link>/</link><description>fgg blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 01 Aug 2024 19:25:54 +0800</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>matplotlibIssue</title><link>/posts/pyplot/matplotlibissue/</link><pubDate>Thu, 01 Aug 2024 17:58:28 +0800</pubDate><guid>/posts/pyplot/matplotlibissue/</guid><description>&lt;p>matplotlib是个好工具，但还没好透，做出来的图中中文变框框。需要额外设置。&lt;/p>
&lt;ol>
&lt;li>获取 matplotlibrc&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 查看matplotlib安装在哪里：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>python -c &lt;span style="color:#5af78e">&amp;#34;import matplotlib;print(matplotlib.__file__)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># your-venv/lib/python3.x/site-packages/matplotlib/mpl-data&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 复制 matplotlibrc 到用户配置目录&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mv your-venv/lib/python3.x/site-packages/matplotlib/mpl-data/matplotlibrc ~/.config/matplotlib/
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>修改 matplotlibrc&lt;/li>
&lt;/ol>
&lt;p>编辑器中打开 matplotlibrc 文件，找到并修改以下两个地方：&lt;/p>
&lt;p>&amp;lsquo;#font.family: sans-serif&amp;rsquo; &amp;raquo; font.family: sans-serif
&amp;lsquo;#font.sans-serif: DejaVu Sans,&amp;hellip;&amp;rsquo; &amp;raquo; font.sans-serif: DejaVu Sans,&amp;hellip;&lt;/p>
&lt;p>然后添加中文字体（ttf 文件的文件名，如下文的 &lt;code>simfang&lt;/code> 仿宋字体）
font.sans-serif: &lt;code>simfang&lt;/code>, DejaVu Sans,&amp;hellip;&lt;/p>
&lt;p>最后将 &lt;code>simfang.ttf&lt;/code> 字体文件加入到 &lt;code>mpl-data/fonts/ttf/&lt;/code> 目录中。&lt;/p>
&lt;p>注：更容易维护的一种配置方式应该是这样：
使用 &lt;code>ln -s&lt;/code> 命令将个人字体库 (&lt;code>.local/share/fonts/&lt;/code>) 中的某个字体映射到上述目录&lt;/p>
&lt;p>注2：可能需要删除matplotlib的缓存&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>rm -rf /home/user/.cache/matplotlib
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>&lt;code>mpl.rcParams&lt;/code> 代码块&lt;/li>
&lt;/ol>
&lt;p>在作图的模块中添加以下代码：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> matplotlib &lt;span style="color:#ff6ac1">as&lt;/span> mpl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> matplotlib.pyplot &lt;span style="color:#ff6ac1">as&lt;/span> plt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 中文减号显示问题&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mpl&lt;span style="color:#ff6ac1">.&lt;/span>rcParams[&lt;span style="color:#5af78e">&amp;#39;axes.unicode_minus&amp;#39;&lt;/span>] &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff6ac1">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 中文字符显示问题&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 名字与ttf文件的名字不同: simfang.ttf &amp;gt;&amp;gt; &amp;#39;FangSong&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mpl&lt;span style="color:#ff6ac1">.&lt;/span>rcParams[&lt;span style="color:#5af78e">&amp;#39;font.sans-serif&amp;#39;&lt;/span>] &lt;span style="color:#ff6ac1">=&lt;/span> [&lt;span style="color:#5af78e">&amp;#39;FangSong&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>最后，如果有多个 venv 环境，难道要一个一个去修改吗？
&lt;code>pipx&lt;/code> 大法是解药。&lt;/p></description></item><item><title>inspect_substrings_in_file_using_sed_awk_jq</title><link>/posts/cs101/awk_sed_cat_head_etc/awk_use_cases/</link><pubDate>Wed, 17 Jul 2024 19:12:45 +0800</pubDate><guid>/posts/cs101/awk_sed_cat_head_etc/awk_use_cases/</guid><description>&lt;p>在命令行工作远非完美，但具有极高的自由度。比如，你想要查看某个文件内(这里绝对不是指
doc/docx 这类怪胎，而是 text/csv/tsv/json 等等正常的文件) 的某一行的内容，如果那一行有很
多列，而其中要是某一列的内容特别长（就是&lt;code>sed&lt;/code>出来占据了整个屏幕这种长度），那么，你想要对
这个文件的内容有所了解，可能需要额外的软件来打开此文件，再好好欣赏之。或者，其实在命令行
就可以呢？&amp;ndash; &lt;code>awk&lt;/code> 了解一下。&lt;/p>
&lt;p>&lt;img alt="is_value_missing" src="https://fgg100y.github.io/posts/cs101/awk_sed_cat_head_etc/awk_use_cases/images/awk-to-the-rescue.png">&lt;/p>
&lt;p>像我就是碰上这么个情况，将图片转换成 base64 编码的 byte-data 后，在 Jupyterlab 打开发现
有些行怎么是空行？（首先我不是去质疑代码，而是质疑“眼见为实”）&lt;/p>
&lt;p>所以，必须要查看某一行的内容，并且要截断过长的字串，老伙计 GPT4o 很快给出答案：&lt;/p>
&lt;h2 id="tsv" >
&lt;div>
&lt;a href="#tsv">
#
&lt;/a>
TSV
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># To print the 10th row and truncate the 3rd column to 50 characters&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>awk &lt;span style="color:#5af78e">&amp;#39;NR==10 { $3=substr($3, 1, 50) &amp;#34;...&amp;#34;; print }&amp;#39;&lt;/span> &lt;span style="color:#ff5c57">FS&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;\t&amp;#34;&lt;/span> &lt;span style="color:#ff5c57">OFS&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;\t&amp;#34;&lt;/span> file.tsv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这还没完，因为 base64 编码的缘故（以及输入图片比较相似）导致 &lt;code>awk&lt;/code> 到的结果都是一模一样
的起始字串，自然而然就怀疑这是巧合还是错误，所以，必须查看字串尾部内容是否也一样, 这当然
难不倒一点脾气也不会有的 GPT4o 老哥：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># print the last 50 characters of the string in the 3rd column of the 10th row&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>awk &lt;span style="color:#5af78e">&amp;#39;NR==10 { len=length($3); print substr($3, len-50, 50) }&amp;#39;&lt;/span> &lt;span style="color:#ff5c57">FS&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;\t&amp;#34;&lt;/span> file.tsv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="jsonl" >
&lt;div>
&lt;a href="#jsonl">
#
&lt;/a>
JSONL
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># To print the 10th row and the field names of json object&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sed -n &lt;span style="color:#5af78e">&amp;#39;10p&amp;#39;&lt;/span> file.jsonl | jq &lt;span style="color:#5af78e">&amp;#39;keys&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># To print the 10th row and the first 10 chars of strings or 10 elements of array&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sed -n &lt;span style="color:#5af78e">&amp;#39;10p&amp;#39;&lt;/span> file.jsonl | jq &lt;span style="color:#5af78e">&amp;#39;.field_name[:10]&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;p>话痨多两句：&lt;/p>
&lt;p>至于参数代表啥意思，我通常不让 GPT4o 多费唇舌。&lt;/p>
&lt;p>（毕竟就算解释了我还是会动手验证一番，再者，最关键是我还没开通 plus 会员，所以得听柯景腾
他老妈的那句劝：要省着点用哦 :）&lt;/p></description></item><item><title>wsl2_and_unicode</title><link>/posts/cs101/wsl2_and_unicode/</link><pubDate>Tue, 16 Jul 2024 21:27:30 +0800</pubDate><guid>/posts/cs101/wsl2_and_unicode/</guid><description>&lt;h2 id="关于-localeunicodejsondump-以及被冤枉的-wsl2" >
&lt;div>
&lt;a href="#%e5%85%b3%e4%ba%8e-localeunicodejsondump-%e4%bb%a5%e5%8f%8a%e8%a2%ab%e5%86%a4%e6%9e%89%e7%9a%84-wsl2">
#
&lt;/a>
关于 locale，unicode，json.dump() 以及被冤枉的 WSL2
&lt;/div>
&lt;/h2>
&lt;p>WSL2的 &lt;code>locale&lt;/code> 一直是默认设置值 &amp;ndash; &amp;ldquo;C.UTF-8&amp;rdquo;。然后今天用 python 解析路径文件中文名时，
最终保存下来的竟是 unicode (&amp;quot;\u5c0f\u6728\u4ed4-\u7761\u7740\u4e862&amp;quot;)，这倒是破天荒第一
次碰上 :&amp;rsquo;) 为了省事，必须去找 GPT 阁下。&lt;/p>
&lt;p>更新：下文是完全绕了远路了的。造成上述情况的实际原因应该是：&lt;code>json.dump()&lt;/code> 默认参数中的
&lt;code>ensure_ascii=True&lt;/code>，这就决定了写入文件的字符不会超出ASCII字符集。&lt;/p>
&lt;p>所以，正确的修改方式不是大费周章的改写系统 &lt;code>locale&lt;/code> 而是将参数改为 &lt;code>ensure_ascii=False&lt;/code>。&lt;/p>
&lt;p>实际上，json.dump() 这部分的函数也是 GPT 阁下写的，它理所当然地认为是在英文语境中，使用
默认的参数不为过吧。😂&lt;/p>
&lt;p>但 GPT4o 最先要我确认是否是终端的编码问题：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 这就是原原本本 copy 得到的unicode字符串&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">echo&lt;/span> -e &lt;span style="color:#5af78e">&amp;#34;\u5c0f\u6728\u4ed4-\u7761\u7740\u4e862&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># output: 小木仔-睡着了2&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其次，使用 &lt;code>file -bi&lt;/code> 命令查看文件的编码格式：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>file -bi path/to/the/suspicious_file.jsonl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#output: application/json; charset=us-ascii&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这就意味着程序在写入本地文件时，只使用了 ascii 字符。&lt;/p>
&lt;h2 id="关于-escape-sequences-及其解析" >
&lt;div>
&lt;a href="#%e5%85%b3%e4%ba%8e-escape-sequences-%e5%8f%8a%e5%85%b6%e8%a7%a3%e6%9e%90">
#
&lt;/a>
关于 escape sequences 及其解析
&lt;/div>
&lt;/h2>
&lt;p>然后 GPT4o 很详细的告知应该如何在命令行终端生成和设置 &amp;ldquo;zh_CN.UTF-8&amp;rdquo;，以及如何在 python 中进行
转义系列的重编码和解码来显示中文字串，但尝试之后没成功。原来是我理解有误。&lt;/p>
&lt;p>GPT4o:
It appears there may be a misunderstanding regarding the purpose and usage of the
unicode-escape encoding. The unicode-escape codec is used to interpret escape sequences
in strings, but it does not process normal Unicode escape sequences (\uXXXX) that are
already present in a Unicode string.&lt;/p>
&lt;p>If you have a string that looks like a Unicode escape sequence and you need to convert
it into actual Unicode characters, you can use the unicode-escape codec. However, your
string needs to be encoded in a way that the codec understands.&lt;/p>
&lt;p>Here&amp;rsquo;s the corrected approach to convert a string with Unicode escape sequences into
actual Chinese characters:&lt;/p>
&lt;pre>&lt;code>Given String: You have a string with Unicode escape sequences.
Decode: Use unicode-escape to decode the string.
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Given string with Unicode escape sequences&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>unicode_str &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#5af78e">&amp;#34;&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u5c0f&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u6728&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u4ed4-&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u7761&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u7740&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u4e862&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Decode the Unicode escape sequences&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>decoded_str &lt;span style="color:#ff6ac1">=&lt;/span> unicode_str&lt;span style="color:#ff6ac1">.&lt;/span>encode(&lt;span style="color:#5af78e">&amp;#39;utf-8&amp;#39;&lt;/span>)&lt;span style="color:#ff6ac1">.&lt;/span>decode(&lt;span style="color:#5af78e">&amp;#39;unicode-escape&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(decoded_str)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Explanation&lt;/p>
&lt;pre>&lt;code>The string unicode_str contains Unicode escape sequences.
The encode('utf-8') part ensures the string is in a byte format.
The decode('unicode-escape') part interprets the byte format as Unicode escape sequences and converts them into actual characters.
&lt;/code>&lt;/pre>
&lt;p>This should correctly output the Chinese characters:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>小木仔-睡着了2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note&lt;/p>
&lt;p>Ensure that your string uses double backslashes (\uXXXX) if you&amp;rsquo;re defining it directly
in the script. This is necessary because a single backslash (\uXXXX) would be
interpreted as an actual Unicode character during the string definition phase, not as an
escape sequence.&lt;/p>
&lt;hr>
&lt;p>一点牢骚：又学了一些没用的知识，毕竟：首先你为什么要用WSL这破烂玩意儿呢？？？&lt;/p>
&lt;p>&lt;del>因为这本来是买给非终端爱好者人士使用的电脑&lt;/del>&lt;/p>
&lt;p>&lt;del>可人家毕竟也没有用，还是你自个霸占着。
前不久发现巨硬又在系统明火执仗地搞偷窥活动（设置&amp;gt;隐私和安全性&amp;gt;活动历史记录）就信誓旦旦说
立刻马上刻不容缓废掉这个恶心玩意&lt;/del>&lt;/p>
&lt;p>&lt;del>最近比较忙哔哩，新安装的2T盘不好清理吧啦，总觉着人家最终要用咕噜&lt;/del>&lt;/p>
&lt;p>本质上是因为捏着鼻子还能勉强用用，但估计也撑不了多久了。&lt;/p>
&lt;p>毕竟 Linux 才是&lt;ruby>根&lt;rt>root&lt;/rt>&lt;/ruby>，才有&lt;ruby>家&lt;rt>home/&lt;/rt>&lt;/ruby>的感觉 :)&lt;/p>
&lt;p>更新：虽然导致本文诞生的原因发生了根本性改变（详见文章开头的“更新”内容）但不影响“一点牢
骚”之后和本更新之前的牢骚内容。&lt;/p></description></item><item><title>poor_dad</title><link>/posts/personals/momentsoflife/poor_dad/</link><pubDate>Mon, 15 Jul 2024 21:47:50 +0800</pubDate><guid>/posts/personals/momentsoflife/poor_dad/</guid><description>&lt;p>地铁口出口处。立着的行李箱上儿子半跪着倾向爸爸，爸爸一只手抓着行李箱杆子，另一只手拿着手机。
女儿在旁边也想往行李箱上挤，被爸爸制止。女儿开始有哭腔，爸爸没看她，注意力全在手机上，
大约是在打车、看地图、联系人或者玩游戏，不知道。女儿三番两次，还是不行，被爸爸大声呵斥危险。
后面她干脆往地上就是一坐，赖哭着乱踢双腿。赖哭声里传达的大约是委屈的信号（前不久我刚领教
过我大舅哥他那差不多年纪大的幼稚园女儿的赖地式哭闹，所以对这个信号颇为熟悉）。&lt;/p>
&lt;p>等我走下地铁口，委屈信号已经变成多个均匀间隔的求关注信号了。&lt;/p>
&lt;hr>
&lt;p>一点牢骚：
后来我就进闸口了。就算有，我也不可能辨别出回应信号了；就算有，或许回应的也太迟了点。&lt;/p>
&lt;p>这可能是小事一桩，也可能是大事一件。因为我总忍不住想起前不久看的那部导演本来想拍老爸结果
拍了他家龙凤双胞胎的纪录片《姐姐》(1996年)。&lt;/p></description></item><item><title>python_module</title><link>/posts/cs101/python_module/</link><pubDate>Wed, 10 Jul 2024 16:19:58 +0800</pubDate><guid>/posts/cs101/python_module/</guid><description>&lt;h2 id="layout-of-python-installations" >
&lt;div>
&lt;a href="#layout-of-python-installations">
#
&lt;/a>
Layout of Python installations
&lt;/div>
&lt;/h2>
&lt;p>All paths in the table are relative to the installation root:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Files&lt;/th>
&lt;th>Windows&lt;/th>
&lt;th>Linux and macOS&lt;/th>
&lt;th>Notes&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Interpreter&lt;/td>
&lt;td>python.exe&lt;/td>
&lt;td>bin/python3.x&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Standard library&lt;/td>
&lt;td>Lib and DLLs&lt;/td>
&lt;td>lib/python3.x&lt;/td>
&lt;td>Extension modules are located under DLLs on Windows. Fedora places the standard library under lib64 instead of lib.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Third-party packages&lt;/td>
&lt;td>Lib\site-packages&lt;/td>
&lt;td>lib/python3.x/site-packages&lt;/td>
&lt;td>Debian and Ubuntu put packages in dist-packages. Fedora places extension modules under lib64 instead of lib.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Entry-point scriptsa&lt;/td>
&lt;td>Scripts&lt;/td>
&lt;td>bin&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="the-interpreter" >
&lt;div>
&lt;a href="#the-interpreter">
#
&lt;/a>
The interpreter
&lt;/div>
&lt;/h2>
&lt;p>The Python interpreter ties the environment to three things:&lt;/p>
&lt;ul>
&lt;li>A specific version of the Python language (e.g., 2.x.y, 3.x.y)&lt;/li>
&lt;li>A specific implementation of Python (e.g., CPython, PyPy)&lt;/li>
&lt;li>A specific build of the interpreter (e.g., 32bit, 64bit, Intel or Apple)&lt;/li>
&lt;/ul>
&lt;p>Try this command (in Bash) to print metadata complied into the interpreter:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>python3 -m sysconfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="the-modules" >
&lt;div>
&lt;a href="#the-modules">
#
&lt;/a>
The modules
&lt;/div>
&lt;/h2>
&lt;p>Modules are containers of Python objects that you load via the &lt;code>import&lt;/code> statement.
Modules come in various forms and shapes:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Simple modules
In the simplest case, a &lt;code>module&lt;/code> is a single file containing Python source code. The
statement &lt;code>import string&lt;/code> executes the code in &lt;em>string.py&lt;/em> and binds the result to
the name &lt;code>string&lt;/code> in the local scope.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Packages
Directories with &lt;em>&lt;strong>init&lt;/strong>.py&lt;/em> files are known as &lt;em>packages&lt;/em> which allow you to
organize modules in a hierarchy. The statement &lt;code>import email.message&lt;/code> loads the
&lt;code>message&lt;/code> module from the &lt;code>email&lt;/code> package.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Namespace packages
Directories with modules but no &lt;em>&lt;strong>init&lt;/strong>.py&lt;/em> are known as &lt;em>namespace packages&lt;/em>. One
may use them to organize modules in a common namespace such as a company name (say
&lt;code>dsta.voicedsp&lt;/code> and &lt;code>dsta.vedioprepr&lt;/code>). Unlike with regular packages, one can
distribute each module in a namespace package separately.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Extension modules
Extension modules such as &lt;code>math&lt;/code> module, contain native code compiled from low-level
language like C. They are shared libraries with a special entry-point&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> that lets
you import them as modules from Python. People write them for performance reasons or
to make existing C libraries available as Python modules. Their names end in &lt;code>.pyd&lt;/code>
on Windows, &lt;code>.dylib&lt;/code> on macOS, and &lt;code>.so&lt;/code> on Linux.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Built-in modules
Some modules from the standard library, such as &lt;code>sys&lt;/code> and &lt;code>builtins&lt;/code> modules, are
compiled into the interpreter. The variable &lt;code>sys.builtin_module_names&lt;/code> lists all of
these modules.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Frozen modules
Some modules from the standard library are written in Python but have their
bytecode&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> embedding in the interpreter. Recent versions of Python freeze every
module that&amp;rsquo;s imported during interpreter startup, such as &lt;code>os&lt;/code> and &lt;code>io&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="python-virtual-environment" >
&lt;div>
&lt;a href="#python-virtual-environment">
#
&lt;/a>
Python virtual environment
&lt;/div>
&lt;/h2>
&lt;p>Python environments consist of an interpreter and modules. Virtual environments share
the interpreter and the standard library with their parent environment.&lt;/p>
&lt;p>&lt;img alt="py-venv" src="https://fgg100y.github.io/posts/cs101/python_module/images/py_python_and_venv.png">&lt;/p>
&lt;p>A Python environment can contain only a single version of each third-party package &amp;ndash;
if two projects require different versions of the same package, they can’t be
installed side by side. That’s why it’s considered good practice to install every Python
application, and every project you work on, in a dedicated virtual environment.&lt;/p>
&lt;p>NOTE
&lt;span class="custom-en">
The term &lt;em>package&lt;/em> carries some ambiguity in the Python world. It refers both to modules
and to the artifacts used for distributing modules (aka &lt;em>distributions&lt;/em>).
&lt;/span>&lt;/p>
&lt;h2 id="the-module-path" >
&lt;div>
&lt;a href="#the-module-path">
#
&lt;/a>
The module path
&lt;/div>
&lt;/h2>
&lt;p>It&amp;rsquo;s helpful to look at entries of &lt;code>sys.path&lt;/code> to debugg the import error, naturally,
one may wonder where do the entries on &lt;code>sys.path&lt;/code> come from at first?&lt;/p>
&lt;p>When the interpreter starts up, it constructs the module path in two steps:&lt;/p>
&lt;ol>
&lt;li>It builds an initial module path which includes the standard library,&lt;/li>
&lt;li>It imports the &lt;code>site&lt;/code> module (from standard library) which extends the module path to
include the site packages from the current environment.&lt;/li>
&lt;/ol>
&lt;p>The locations on the initial module path fall into three categories, and they occur in
this order:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The current directory or the directory containing the Python scripts (if any)
The first item on &lt;code>sys.path&lt;/code> can be any of the following:&lt;/p>
&lt;ul>
&lt;li>If you ran &lt;code>python3 &amp;lt;script&amp;gt;&lt;/code>, the directory where the script is located&lt;/li>
&lt;li>If you ran &lt;code>python3 -m &amp;lt;module&amp;gt;&lt;/code>, the current directory&lt;/li>
&lt;li>Otherwise, the empty string, which also denotes the current directory
&lt;strong>Safty issue&lt;/strong>: having the working directory on &lt;code>sys.path&lt;/code> is quite unsafe, as an
attacker (or you, mistakenly) can override the standard library by placing Python
files in the victim&amp;rsquo;s directory. To avoid this,&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>Python-3.11 provides &lt;code>-P&lt;/code> option or the PYTHONSAFEPATH variable to omit the
current directory from &lt;code>sys.path&lt;/code>;&lt;/li>
&lt;li>Using a virtual environment.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>The locations in the PYTHONPATH environment variable (if set)
Avoid this mechanism for the same reasons as the current working directory and use a
virtual environment instead.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The locations of the standard library
The location of the standard library is not hardcoded in the interpreter. Rather,
Python looks for landmark files on the path to its own executable and uses them to
locate the current environment (&lt;code>sys.prefix&lt;/code>) and the Python installation
(&lt;code>sys.base_prefix&lt;/code>). One such landmark file is &lt;em>pyvenv.cfg&lt;/em>, which marks a virtual
environment and points to its parent installation via the &lt;code>home&lt;/code> key. Another
landmark file is &lt;em>os.py&lt;/em>, the file containing the standard &lt;code>os&lt;/code> module: Python uses
&lt;em>os.py&lt;/em> to discover the prefix outside a virtual environment and to locate the
standard library itself.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>For more glory details and interesting contents, go to the newest version (2024) of
&lt;em>&amp;ldquo;Hypermodern Python Tooling&amp;rdquo;&lt;/em> by Claudio Jolowicz.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>An entry-point script is an executable file in &lt;em>Scripts/&lt;/em> (Windows) or &lt;em>bin/&lt;/em>
(Linux and macOS) with a single purpose: it launches a Python application by
importing the module with its entry-point function and calling that function.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Bytecode is an intermediate representation of Python code that is
platform-independent and optimized for fast execution. The interpreter compiles pure
Python modules to bytecode when it loads them for the first time. Their names end in
&lt;code>.pyc&lt;/code> and they are cached in &lt;code>__pycache__&lt;/code> directories.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Add_and_test_custom_font</title><link>/posts/hugo101/2024-07-09-test_custom_font/</link><pubDate>Tue, 09 Jul 2024 21:53:56 +0800</pubDate><guid>/posts/hugo101/2024-07-09-test_custom_font/</guid><description>&lt;p>Linear regression:&lt;/p>
&lt;blockquote>
&lt;p>$\text{You&amp;rsquo;ve got to draw the line somewhere.}$&lt;/p>
&lt;/blockquote>
&lt;p>You&amp;rsquo;ve got to draw the line somewhere. (system-font)&lt;/p>
&lt;p>&lt;span class="custom-en">You&amp;rsquo;ve got to draw the line somewhere. (NerdFont 3270)&lt;/span>&lt;/p>
&lt;p>&lt;span class="custom-zh">中文：你必须在某个地方把那条线给画出来。(京華老宋体)&lt;/span>&lt;/p>
&lt;hr>
&lt;p>实作过程：&lt;/p>
&lt;p>&lt;span class="custom-en">hugo version:
v0.128.2-de36c1a95d28595d8243fd8b891665b069ed0850+extended linux/amd64
BuildDate=2024-07-04T08:13:25Z VendorInfo=gohugoio&lt;/span>&lt;/p>
&lt;hr>
&lt;ol>
&lt;li>
&lt;p>将本地字体文件复制到 &lt;code>static/fonts/&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在 &lt;code>assets/css/&lt;/code> (或 &lt;code>static/css/&lt;/code>) 创建文件 &lt;code>custom.css&lt;/code>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-css" data-lang="css">&lt;span style="display:flex;">&lt;span>@&lt;span style="color:#ff6ac1">font-face&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-family&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#5af78e">&amp;#39;3270NerdFont&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">src&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">url&lt;/span>&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;/fonts/3270NerdFont-Regular.ttf&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">)&lt;/span> &lt;span style="color:#ff6ac1">format&lt;/span>&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;truetype&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-weight&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">normal&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-style&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">normal&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>@&lt;span style="color:#ff6ac1">font-face&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-family&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#5af78e">&amp;#39;KingHwa_OldSong&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">src&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">url&lt;/span>&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;/fonts/KingHwa_OldSong.ttf&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">)&lt;/span> &lt;span style="color:#ff6ac1">format&lt;/span>&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;truetype&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-weight&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">normal&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-style&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">normal&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>.&lt;span style="color:#f3f99d">custom-en&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-family&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;3270NerdFont&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>.&lt;span style="color:#f3f99d">custom-zh&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-family&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;KingHwa_OldSong&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>更多关于自定义字体的讨论，可参考这里: &lt;a href="https://discourse.gohugo.io/t/how-to-add-custom-fonts-and-not-depend-on-google/34267/3">https://discourse.gohugo.io/t/how-to-add-custom-fonts-and-not-depend-on-google/34267/3&lt;/a>&lt;/p>
&lt;ol start="3">
&lt;li>修改 &lt;code>config.toml&lt;/code>：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-toml" data-lang="toml">&lt;span style="display:flex;">&lt;span>[params]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> customCSS = [&lt;span style="color:#5af78e">&amp;#34;css/custom.css&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="4">
&lt;li>复制 &lt;code>themes/layouts/partials/head.html&lt;/code> 到根目录&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>cp themes/layouts/partials/head.html ./layouts/partials/head.html
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Optional:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp themes/layouts/partials/head-extra.html ./layouts/partials/head-extra.html
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果主题设计得足够好，通常会给一份 &lt;code>head-extra.html&lt;/code> 用于定制化内容。
此时，只需要将相应配置加入到 &lt;code>head-extra.html&lt;/code> 文件中，避免对 &lt;code>head.html&lt;/code> 的打扰。&lt;/p>
&lt;p>增加的相应内容是：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;lt;!-- Other head content --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{{- range .Site.Params.customCSS }}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#ff6ac1">link&lt;/span> &lt;span style="color:#57c7ff">rel&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;stylesheet&amp;#34;&lt;/span> &lt;span style="color:#57c7ff">href&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;{{ . | relURL }}&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{{- end }}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="5">
&lt;li>使用自定义字体&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>You&amp;#39;ve got to draw the line somewhere. (system-font)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;span class=&amp;#34;custom-en&amp;#34;&amp;gt;You&amp;#39;ve got to draw the line somewhere. (NerdFont 3270)&amp;lt;/span&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;span class=&amp;#34;custom-zh&amp;#34;&amp;gt;中文：你必须在某个地方把那条线给画出来。(京華老宋体)&amp;lt;/span&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>rime_trime</title><link>/posts/personals/momentsoflife/rime_trime/</link><pubDate>Sat, 06 Jul 2024 15:34:59 +0800</pubDate><guid>/posts/personals/momentsoflife/rime_trime/</guid><description>&lt;p>&lt;a href="https://github.com/iDvel/rime-ice">rime-ice&lt;/a> 雾凇拼音 + &lt;a href="https://github.com/osfans/trime">trime&lt;/a> 同文输入法&lt;/p>
&lt;p>&lt;img alt="IMG_trime_a_grimpse" src="https://fgg100y.github.io/posts/personals/momentsoflife/rime_trime/images/trime_theme_4in1.png">&lt;/p>
&lt;p>怎么在手机上使用这个输入法？比较无脑省力那种&amp;hellip;
等等先，除开什么“愤世嫉俗”这种冠冕堂皇，或者“拒绝雷同”这种笑掉大牙，以及“听说它很难搞我非要搞定它”这种偏执狂的理由外，为什么用这个？
👉 开源万岁、开源万岁、开源万岁。&lt;/p>
&lt;p>应该说明：这篇文章基本是我自己的备忘录，我自己已经使用这些配置多年。
如果你是第一次接触 rime/Trime，直接查看他们官网或者本文的参考链接，否则如果按着我的说法进行操作，大概率你会搞得自己火冒三丈。&lt;/p>
&lt;hr>
&lt;p>我的操作：&lt;/p>
&lt;p>1.1 手机上下载 &lt;a href="https://f-droid.org/">F-Droid&lt;/a>，在 F-Droid 搜索并下载 Trime 输入法 (中文名：同文输入法&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>)&lt;/p>
&lt;p>1.2 手机应用授权等其他操作&lt;/p>
&lt;p>2.1 电脑端下载仓库&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">cd&lt;/span> rime_hub
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>git clone https://github.com/iDvel/rime-ice.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>2.2 将手机接入电脑，将仓库复制到手机目录路径（通常是与Download,Documents同级的路径），将
其名称修改为 &lt;code>rime&lt;/code> (rime-ice也可以，但要做出相应的适配和设置)&lt;/p>
&lt;p>3.1 手机端打开 Trime 输入法，点击右上角部署&lt;/p>
&lt;p>3.2 可能会报错弹出日志窗口，但不一定影响使用；否则，去官网等地方寻找解决方案&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;p>4.1 如果也在电脑端使用，可以借助 Plum 进行安装和更新：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>git clone --depth&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span> https://github.com/rime/plum
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">cd&lt;/span> plum
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bash rime-install iDvel/rime-ice:others/recipes/full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#全量更新：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bash rime-install iDvel/rime-ice:others/recipes/full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#局部更新：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bash rime-install iDvel/rime-ice:others/recipes/all_dicts
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>5 多端同步：电脑端更新，复制到手机等其他终端。&lt;/p>
&lt;hr>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>同文输入法：把 RIME 装进 Android 手机 &lt;a href="https://sspai.com/post/77499">https://sspai.com/post/77499&lt;/a>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Rime 配置：雾凇拼音 &lt;a href="https://dvel.me/posts/rime-ice/">https://dvel.me/posts/rime-ice/&lt;/a>&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>职称评审</title><link>/posts/personals/engineering_career_ladder/</link><pubDate>Fri, 05 Jul 2024 22:40:23 +0800</pubDate><guid>/posts/personals/engineering_career_ladder/</guid><description>&lt;p>虽然人家只评估近五年的工作，但粗略算起来自己工作都快八年了，才爬了第二个阶梯。&lt;/p>
&lt;p>半路出家着实费劲。&lt;/p>
&lt;p>&lt;img alt="MidLevel" src="https://fgg100y.github.io/posts/personals/engineering_career_ladder/images/fmh_engineering_career_blur_extra_info.png">&lt;/p>
&lt;p>突然想起经典电影《三毛从军记》结尾部分的饱含沧桑而又莫名喜感的那一句台词：八年了&amp;hellip;&lt;/p>
&lt;p>急躁时不免暗暗奢望有人：“看在技术的份上，拉兄弟我一把。” 😂&lt;/p>
&lt;p>但话说回来，“当幸福来敲门”的时候，你最好是恰在家，做好准备。&lt;/p>
&lt;p>要不然真有人拉你一把时，结果却弄成烂泥扶不上墙。恐怕没有比这更糟糕的了。&lt;/p></description></item><item><title>so_long_and_no_thanks</title><link>/posts/personals/momentsoflife/so_long/</link><pubDate>Thu, 04 Jul 2024 20:03:19 +0800</pubDate><guid>/posts/personals/momentsoflife/so_long/</guid><description>&lt;p>如果你看过《银河系漫游指南》，应该记得地球生物智慧排第一的是海豚（人类只排第三）😂&lt;/p>
&lt;p>离别时本来应该是来一句：&lt;/p>
&lt;blockquote>
&lt;p>“So long! And thanks for all the fish.&amp;quot;&lt;/p>
&lt;/blockquote>
&lt;p>但实际情况却是：&lt;/p>
&lt;p>&lt;img alt="no_thanks" src="https://fgg100y.github.io/posts/personals/momentsoflife/so_long/images/dophine.jpg">&lt;/p></description></item><item><title>Short_time_Fourier_Transform</title><link>/posts/dsp101/2024-07-03-short_time_fourier_transform/</link><pubDate>Wed, 03 Jul 2024 11:25:37 +0800</pubDate><guid>/posts/dsp101/2024-07-03-short_time_fourier_transform/</guid><description>&lt;p>Sine Wave Signal&lt;/p>
&lt;p>An audio signal, y(t), composed of exactly one sine wave, can be completely described by
the parameters $t, A, f$ and $\phi$,
$$
y(t) = A \sin(2 \pi f t + \phi)
$$
where $t$ represents time in seconds, $A$ is the wave&amp;rsquo;s amplitude (unit-less), $f$ is
its frequency in Hz, and $\phi$ is its phase offset in radians (i.e., where in the cycle
the wave is at $t=0$). If $t \ne 0$, then the sine wave appears shifted in time by
$\frac{\phi}{2 \pi f}$, where negative values mean &amp;ldquo;delay&amp;rdquo; and positive &amp;ldquo;advance&amp;rdquo; it.&lt;/p>
&lt;p>Fourier Series&lt;/p>
&lt;blockquote>
&lt;p>Our old pal Fourier told us that any sound can be represented as an infinite summation
of sine waves each with their own amplitudes, frequencies, and phase offsets. This means
that any sound we hear can be represented as many, many tuples of $t, A, f, \phi$.&lt;/p>
&lt;/blockquote>
&lt;p>Time-Frequency representation&lt;/p>
&lt;p>A Time-Frequency representation is a 2 dimensional matrix that represents the frequency
contents of an audio signal over time.&lt;/p>
&lt;p>We can visualize a TF Representation using a heatmap, which has time along the x-axis
and frequency along the y-axis. Each &lt;em>TF bin&lt;/em> (entry in heatmap) in the heatmap
represents the &lt;strong>amplitude&lt;/strong> of the signal at that particular time and frequency.
If there is no color bar, it is usually safe to assume that brighter colors indicate
higher amplitudes than darker colors.&lt;/p>
&lt;p>&lt;img alt="TFrepr" src="images/dsp_tf_representation.png">&lt;/p>
&lt;p>Short-time Fourier Transform (STFT)&lt;/p>
&lt;p>An STFT is calculated from a waveform representation by computing a discrete Fourier
transform (DFT) of a small, moving window across the duration of the window. The
location of each entry in an STFT determines its time (x-axis) and frequency (y-axis).
The absolute value of a TF bin |$X(t,f)$| at time t and frequency f determines the amount
of energy heard from frequency $f$ at time $t$.&lt;/p>
&lt;p>Importantly, each bin in our STFT is complex, meaning each entry contains both a
magnitude component and a phase component. Both components are needed to convert an STFT
matrix back to a waveform by &lt;em>inverse STFT&lt;/em> so that we may hear it.&lt;/p>
&lt;p>&lt;img alt="STFT" src="images/dsp_stft_process.png">&lt;/p>
&lt;p>Window Types&lt;/p>
&lt;p>The window type determines the shape of the short-time window that will segment the
audio into short segments before applying the DFT. The shape of this window will affect
which frequencies get emphasized or attenuated in the DFT. There are many types of
&lt;a href="https://docs.scipy.org/doc/scipy/reference/signal.windows.html">window functions&lt;/a>.&lt;/p>
&lt;p>&lt;img alt="windows" src="images/dsp_window_types.png">&lt;/p></description></item><item><title>Discrete_Fourier_Transform</title><link>/posts/dsp101/2024-07-03-discrete_fourier_transform/</link><pubDate>Wed, 03 Jul 2024 09:46:45 +0800</pubDate><guid>/posts/dsp101/2024-07-03-discrete_fourier_transform/</guid><description>&lt;p>An analysis problem, which is equivalent to the &lt;strong>DFT&lt;/strong>:&lt;/p>
&lt;pre>&lt;code>Given a signal, how to find the amplitude and phase offset of its frequency
components?
&lt;/code>&lt;/pre>
&lt;p>A synthesis problem, which is equivalent to the &lt;strong>inverse DFT&lt;/strong>:&lt;/p>
&lt;pre>&lt;code>Given a set of frequency components and their amplitudes, how can we construct a
signal?
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>DFT&lt;/strong> and &lt;strong>Inverse DFT&lt;/strong> in code&lt;/p>
&lt;p>The &lt;code>analyze()&lt;/code> computes something very close to the DFT, with one difference: The
conventional definition of DFT does not divide by &lt;code>N&lt;/code> (highlighted line below):&lt;/p>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">analyze&lt;/span>(ys):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> N &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(ys)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span> M &lt;span style="color:#ff6ac1">=&lt;/span> synthesis_matrix(N)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> amps &lt;span style="color:#ff6ac1">=&lt;/span> M&lt;span style="color:#ff6ac1">.&lt;/span>conj()&lt;span style="color:#ff6ac1">.&lt;/span>transpose()&lt;span style="color:#ff6ac1">.&lt;/span>dot(ys) &lt;span style="color:#ff6ac1">/&lt;/span> N
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> amps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">dft&lt;/span>(ys): &lt;span style="color:#78787e"># return same result as np.fft.fft()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> N &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(ys)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span> M &lt;span style="color:#ff6ac1">=&lt;/span> synthesis_matrix(N)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> amps &lt;span style="color:#ff6ac1">=&lt;/span> M&lt;span style="color:#ff6ac1">.&lt;/span>conj()&lt;span style="color:#ff6ac1">.&lt;/span>transpose()&lt;span style="color:#ff6ac1">.&lt;/span>dot(ys)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> amps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">idft&lt;/span>(amps): &lt;span style="color:#78787e"># inverse DFT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> N &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(amps)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> M &lt;span style="color:#ff6ac1">=&lt;/span> synthesis_matrix(N)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ys &lt;span style="color:#ff6ac1">=&lt;/span> M&lt;span style="color:#ff6ac1">.&lt;/span>dot(amps) &lt;span style="color:#ff6ac1">/&lt;/span> N
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> ys &lt;span style="color:#78787e"># ys: value of the signal at each time step&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">synthesis_matrix&lt;/span>(N):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ts &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>arange(N) &lt;span style="color:#ff6ac1">/&lt;/span> N &lt;span style="color:#78787e"># ts: the sequence of times where the signal should be evaluated&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fs &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>arange(N) &lt;span style="color:#78787e"># fs: the list of frequencies&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>outer(ts, fs) &lt;span style="color:#78787e"># args: outer product of ts and fs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> M &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>exp(&lt;span style="color:#ff9f43">1&lt;/span>j &lt;span style="color:#ff6ac1">*&lt;/span> PI2 &lt;span style="color:#ff6ac1">*&lt;/span> args) &lt;span style="color:#78787e"># PI2 = np.pi * 2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> M
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>ResNet</title><link>/posts/resnet/</link><pubDate>Sat, 29 Jun 2024 09:17:15 +0800</pubDate><guid>/posts/resnet/</guid><description>&lt;p>思维实验：
在浅层网络结构的基础上（比如20层），往后面直接添加更多的同映射隐层（identity layers），
得到的深层网络（比如50层）理论上效果应该不会变差。但实验结果说明，它真会变差。意味着：
SGD算法无法找到使得更深层网络性能不变差的参数。&lt;/p>
&lt;p>残差网络架构可以解决这个问题。&lt;/p>
&lt;h2 id="why-what-and-how" >
&lt;div>
&lt;a href="#why-what-and-how">
#
&lt;/a>
Why, What, and How
&lt;/div>
&lt;/h2>
&lt;blockquote>
&lt;p>Deeper neural networks are more difficult to train. We present a residual learning
framework to ease the training of networks that are substantially deeper than those used
previously. We explicitly reformulate the layers as learning residual functions with
reference to the layer inputs, instead of learning unreferenced functions.&lt;/p>
&lt;/blockquote>
&lt;p>训练一个深度（足够深的）神经网络是一件很难的事情（2015年）。
使用“残差”神经网络架构可以更容易地训练足够深的神经网络。
“残差”架构就是把这些中间层作为一个学习输入与输出的残差的函数。&lt;/p>
&lt;p>&lt;img alt="ResNet Block" src="images/resnet_learning_block.png">&lt;/p>
&lt;p>就是说：增加的隐层去学习 $h(x) - x$（残差）而不是 $h(x)$，而输出的是当前隐层的输出加上前
一层的输出 $x$ （同时也是当前层的输入）。&lt;/p>
&lt;h2 id="残差网络结构" >
&lt;div>
&lt;a href="#%e6%ae%8b%e5%b7%ae%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84">
#
&lt;/a>
残差网络结构
&lt;/div>
&lt;/h2>
&lt;p>残差连接（aka, shortcut connection）在输入和输出的维度相同情况下可以直接使用如下结构块：&lt;/p>
&lt;p>$$
y = F(x, {W_i}) + x.
$$&lt;/p>
&lt;p>当想要增加维度时，有两种方式来对齐输入和输出的维度：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>残差连接进行同映射操作，然后对增加的维度进行补零操作（padding zeros)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>残差连接进行线性投影操作 $y = F(x, {W_i}) + W_s x.$ 来对齐维度（使用 1x1 卷积实现）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>两种情况下，当残差连接的是不同尺寸的特征图（feature map）时，使用步幅为2的卷积操作。
（通道数翻倍，则高宽减半，因此使用步幅=2（stride=2）的卷积来保证维数对齐）&lt;/p>
&lt;p>&lt;img alt="bottlenet-block" src="https://fgg100y.github.io/posts/resnet/images/resnet_bottlenet_building_block.png">&lt;/p>
&lt;p>&lt;img alt="resnet-arch" src="https://fgg100y.github.io/posts/resnet/images/resnet_arch_for_imagenet.png">&lt;/p>
&lt;h2 id="残差连接为什么有用" >
&lt;div>
&lt;a href="#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e7%94%a8">
#
&lt;/a>
残差连接为什么有用？
&lt;/div>
&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Easier Gradient Flow&lt;/p>
&lt;ul>
&lt;li>缓解梯度消失/梯度爆炸问题&lt;/li>
&lt;li>残差连接使得梯度更稳定&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>更容易学习同映射函数&lt;/p>
&lt;/li>
&lt;li>
&lt;p>提升最优化和收敛效果&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更好的特征传播（feature propagation）&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="此残差非彼残差resnet-vs-gdbt" >
&lt;div>
&lt;a href="#%e6%ad%a4%e6%ae%8b%e5%b7%ae%e9%9d%9e%e5%bd%bc%e6%ae%8b%e5%b7%aeresnet-vs-gdbt">
#
&lt;/a>
此残差非彼残差（ResNet VS GDBT）
&lt;/div>
&lt;/h2>
&lt;p>GBDT（梯度提升决策树）中的残差（residual）是指预测值与真实值之间的差值。&lt;/p>
&lt;p>ResNet 中的残差（residual），是神经网络尝试去学习特征图（feature map）的残差（是网络块输出与输入之间的差值）。&lt;/p>
&lt;p>Paper: &lt;a href="https://arxiv.org/pdf/1512.03385">https://arxiv.org/pdf/1512.03385&lt;/a>&lt;/p></description></item><item><title>knowledge_distillation2</title><link>/posts/2024-06-28-knowledge_distillation2/</link><pubDate>Fri, 28 Jun 2024 11:25:43 +0800</pubDate><guid>/posts/2024-06-28-knowledge_distillation2/</guid><description>&lt;h2 id="generalized-knowledge-distillation-gkd" >
&lt;div>
&lt;a href="#generalized-knowledge-distillation-gkd">
#
&lt;/a>
Generalized Knowledge Distillation (GKD)
&lt;/div>
&lt;/h2>
&lt;p>泛化知识蒸馏是一种改进的知识蒸馏技术，旨在解决传统知识蒸馏方法在自回归序列模型中遇到的分
布不匹配问题，特别是在训练和推理阶段之间。传统的知识蒸馏方法通常基于固定的输出序列集进行，
这些序列或者是教师模型生成的，或者是基于真实数据的标签。然而，这导致学生模型在推理时生成
的序列可能与训练时见到的序列分布不同，从而影响了学生模型的泛化能力。&lt;/p>
&lt;p>GKD 不再局限于固定输出序列的训练，而是允许学生模型在其自我生成的序列上进行学习，同时利用
教师模型提供的反馈。&lt;/p>
&lt;h2 id="gkd-技术要点" >
&lt;div>
&lt;a href="#gkd-%e6%8a%80%e6%9c%af%e8%a6%81%e7%82%b9">
#
&lt;/a>
GKD 技术要点
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>动态序列生成与反馈：GKD 在训练过程中，会根据学生模型的自我生成序列进行学习。这意味着学
生模型在尝试生成序列时，如果生成错误或不理想的序列，它可以从教师模型那里获得直接反馈，
学习如何纠正这些错误。这种机制能够减少训练和推理过程中的分布差异，提高学生模型对各种输
入序列的泛化能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>灵活的损失函数选择：与仅采用前向KL散度的传统监督式知识蒸馏不同，GKD 提供了灵活性，可以
在学生和教师模型之间使用替代的损失函数。当学生模型难以精确模拟教师模型的概率分布时，这
一点尤为重要。例如，可以采用Jensen-Shannon散度等指标来衡量分布之间的差异，这有助于学生
模型在表达力有限的情况下更好地学习。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>集成强化学习精调：GKD 还促进了知识蒸馏与基于强化学习的语言模型微调的无缝整合。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="动态序列生成" >
&lt;div>
&lt;a href="#%e5%8a%a8%e6%80%81%e5%ba%8f%e5%88%97%e7%94%9f%e6%88%90">
##
&lt;/a>
动态序列生成
&lt;/div>
&lt;/h3>
&lt;p>在传统的知识蒸馏中，学生模型通常基于预先定义好的固定数据集或由教师模型生成的输出序列进行
训练。而动态序列生成则打破了这一限制，它让学生模型自己生成输出序列，并在此基础上进行学习。
这个过程涉及以下几个步骤：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>初始化学生模型：首先，学生模型需要具备一定的生成能力，通常通过初步的监督式预训练或微调
（Supervised Fine-Tuning, SFT）来实现，确保它可以生成质量尚可的序列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>自我生成序列：在训练过程中，学生模型接收到输入后，会根据当前的策略生成输出序列。这些序
列反映了学生模型当前的能力和理解，可能包含错误或不完美的部分。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="反馈机制" >
&lt;div>
&lt;a href="#%e5%8f%8d%e9%a6%88%e6%9c%ba%e5%88%b6">
##
&lt;/a>
反馈机制
&lt;/div>
&lt;/h3>
&lt;p>一旦学生模型生成了输出序列，接下来的关键步骤是获取教师模型的反馈：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>教师模型评估：教师模型会对学生生成的序列进行评估，通常通过比较教师和学生模型在每个生成
步骤上对下一个词的概率分布。这涉及到计算两者的概率分布之间的某种差异度量，如KL散度。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>指导性学习：根据教师模型的反馈，学生模型调整其参数，目的是使自己在生成类似序列时能更接
近教师模型的表现。GKD 允许选择不同的差异度量（divergence）来优化，以适应不同任务的需求。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>迭代优化：随着学生模型不断从自我生成的错误中学习，它的生成能力逐步提升，生成的序列质量
也随之提高，形成了一个正向循环。此过程可以视为一种模仿学习（Imitation Learning）与强化
学习（Reinforcement Learning）的结合，其中学生模型通过迭代地探索和修正其行为，以逼近教
师模型的表现。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>参考文献：https://arxiv.org/pdf/2306.13649&lt;/p></description></item><item><title>knowledge_distillation</title><link>/posts/2024-06-27-knowledge_distillation/</link><pubDate>Thu, 27 Jun 2024 11:34:18 +0800</pubDate><guid>/posts/2024-06-27-knowledge_distillation/</guid><description>&lt;p>知识蒸馏（Knowledge Distillation）是一种机器学习技术，它通过将大型、复杂的模型（称为教师
模型，Teacher Model）的知识“蒸馏”到小型、简洁的模型（称为学生模型，Student Model）中，从
而实现模型压缩和加速，同时尽可能保持原始模型的性能。这一技术使得模型可以在资源有限的设备
上高效运行，如手机或嵌入式设备。&lt;/p>
&lt;blockquote>
&lt;p>The method works by incorporating an additional loss into the traditional cross entropy
loss, which is based on the softmax output of the teacher network. The assumption is
that the output activations of a properly trained teacher network carry additional
information that can be leveraged by a student network during training.&lt;/p>
&lt;/blockquote>
&lt;h2 id="基本原理" >
&lt;div>
&lt;a href="#%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86">
#
&lt;/a>
基本原理
&lt;/div>
&lt;/h2>
&lt;p>知识转移：核心思想是通过让学生模型模仿教师模型的输出行为，不仅包括硬分类标签，还有软概率
分布（softmax概率），这样可以传递更多关于数据分布的信息。软标签相比硬标签含有更多关于数
据不确定性及类间关系的信息，有助于学生模型学习更细腻的决策边界。&lt;/p>
&lt;p>特征蒸馏：除了输出层的知识外，泛化知识蒸馏还可以涉及中间层特征的学习，即学生模型试图学习
教师模型的高层特征表示。这有助于提升学生模型的泛化能力，因为它学会了如何从输入数据中提取
更有用的特征。&lt;/p>
&lt;p>关系蒸馏：强调保持教师和学生模型对于输入样本间关系的理解一致性。这意味着学生模型不仅要学
会单个样本的处理，还要理解样本之间的相对关系，这对于一些需要理解复杂上下文的任务尤为重要。&lt;/p>
&lt;p>&lt;strong>知识蒸馏过程&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>训练教师模型&lt;/strong>：首先，使用大量数据和计算资源训练一个高性能的深度神经网络（教师模
型）。这个模型可能包含数百万甚至数十亿个参数，但它在分类任务上的表现非常出色。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>生成软标签&lt;/strong>：教师模型在对输入数据进行预测时，不仅仅给出最终的分类结果，还会给出各
类别的概率分布（通常通过softmax层获得）。这些概率分布被称为“软标签”，它们包含了额外的
信息，比如类别的不确定性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>训练学生模型&lt;/strong>：接下来，使用教师模型的软标签和实际的硬标签（即数据的真实类别）来训
练学生模型。学生模型的架构设计得更简单，参数量远小于教师模型。训练过程中，学生模型不
仅要学习模仿硬标签，还要通过损失函数（如KL散度或交叉熵）尽量接近教师模型的软标签输出。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>温度参数调整&lt;/strong>：在生成软标签时，有时会引入一个“温度”参数来调整概率分布的平滑程度。
高温可以使软标签更加平滑，促进学生模型学习到教师模型的决策边界；低温则使得软标签接近
硬标签，但可能会丢失教师模型的一些细微决策信息。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="知识蒸馏的三种代码实现" >
&lt;div>
&lt;a href="#%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8f%e7%9a%84%e4%b8%89%e7%a7%8d%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0">
#
&lt;/a>
知识蒸馏的三种代码实现：
&lt;/div>
&lt;/h2>
&lt;ol>
&lt;li>知识转移：基于 softmax output 软标签&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the teacher model - do not save gradients here as we do not change the teacher&amp;#39;s weights&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">with&lt;/span> torch&lt;span style="color:#ff6ac1">.&lt;/span>no_grad():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> teacher_logits &lt;span style="color:#ff6ac1">=&lt;/span> teacher(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the student model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>student_logits &lt;span style="color:#ff6ac1">=&lt;/span> student(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#Soften the student logits by applying softmax first and log() second&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>soft_targets &lt;span style="color:#ff6ac1">=&lt;/span> nn&lt;span style="color:#ff6ac1">.&lt;/span>functional&lt;span style="color:#ff6ac1">.&lt;/span>softmax(teacher_logits &lt;span style="color:#ff6ac1">/&lt;/span> T, dim&lt;span style="color:#ff6ac1">=-&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>soft_prob &lt;span style="color:#ff6ac1">=&lt;/span> nn&lt;span style="color:#ff6ac1">.&lt;/span>functional&lt;span style="color:#ff6ac1">.&lt;/span>log_softmax(student_logits &lt;span style="color:#ff6ac1">/&lt;/span> T, dim&lt;span style="color:#ff6ac1">=-&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper &amp;#34;Distilling the knowledge in a neural network&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>soft_targets_loss &lt;span style="color:#ff6ac1">=&lt;/span> torch&lt;span style="color:#ff6ac1">.&lt;/span>sum(soft_targets &lt;span style="color:#ff6ac1">*&lt;/span> (soft_targets&lt;span style="color:#ff6ac1">.&lt;/span>log() &lt;span style="color:#ff6ac1">-&lt;/span> soft_prob)) &lt;span style="color:#ff6ac1">/&lt;/span> soft_prob&lt;span style="color:#ff6ac1">.&lt;/span>size()[&lt;span style="color:#ff9f43">0&lt;/span>] &lt;span style="color:#ff6ac1">*&lt;/span> (T&lt;span style="color:#ff6ac1">**&lt;/span>&lt;span style="color:#ff9f43">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the true label loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>label_loss &lt;span style="color:#ff6ac1">=&lt;/span> ce_loss(student_logits, labels)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Weighted sum of the two losses&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss &lt;span style="color:#ff6ac1">=&lt;/span> soft_target_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> soft_targets_loss &lt;span style="color:#ff6ac1">+&lt;/span> ce_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> label_loss
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss&lt;span style="color:#ff6ac1">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>特征蒸馏：基于 hidden state 余弦相似度&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the teacher model and keep only the hidden representation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">with&lt;/span> torch&lt;span style="color:#ff6ac1">.&lt;/span>no_grad():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _, teacher_hidden_representation &lt;span style="color:#ff6ac1">=&lt;/span> teacher(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the student model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>student_logits, student_hidden_representation &lt;span style="color:#ff6ac1">=&lt;/span> student(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the cosine loss. Target is a vector of ones. From the loss formula above we can see that is the case where loss minimization leads to cosine similarity increase.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hidden_rep_loss &lt;span style="color:#ff6ac1">=&lt;/span> cosine_loss(student_hidden_representation, teacher_hidden_representation, target&lt;span style="color:#ff6ac1">=&lt;/span>torch&lt;span style="color:#ff6ac1">.&lt;/span>ones(inputs&lt;span style="color:#ff6ac1">.&lt;/span>size(&lt;span style="color:#ff9f43">0&lt;/span>))&lt;span style="color:#ff6ac1">.&lt;/span>to(device))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the true label loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>label_loss &lt;span style="color:#ff6ac1">=&lt;/span> ce_loss(student_logits, labels)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Weighted sum of the two losses&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss &lt;span style="color:#ff6ac1">=&lt;/span> hidden_rep_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> hidden_rep_loss &lt;span style="color:#ff6ac1">+&lt;/span> ce_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> label_loss
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss&lt;span style="color:#ff6ac1">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>特征蒸馏：基于 Intermediate regressor MSE损失&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Again ignore teacher logits&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">with&lt;/span> torch&lt;span style="color:#ff6ac1">.&lt;/span>no_grad():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _, teacher_feature_map &lt;span style="color:#ff6ac1">=&lt;/span> teacher(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the student model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>student_logits, regressor_feature_map &lt;span style="color:#ff6ac1">=&lt;/span> student(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hidden_rep_loss &lt;span style="color:#ff6ac1">=&lt;/span> mse_loss(regressor_feature_map, teacher_feature_map)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the true label loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>label_loss &lt;span style="color:#ff6ac1">=&lt;/span> ce_loss(student_logits, labels)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Weighted sum of the two losses&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss &lt;span style="color:#ff6ac1">=&lt;/span> feature_map_weight &lt;span style="color:#ff6ac1">*&lt;/span> hidden_rep_loss &lt;span style="color:#ff6ac1">+&lt;/span> ce_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> label_loss
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss&lt;span style="color:#ff6ac1">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>具体参考：https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html?highlight=distill&lt;/p></description></item><item><title>mixup_beyond_ERM</title><link>/posts/2024-06-27-mixup_beyond_erm/</link><pubDate>Thu, 27 Jun 2024 09:42:34 +0800</pubDate><guid>/posts/2024-06-27-mixup_beyond_erm/</guid><description>&lt;h1 id="empirical-risk-minimazation-erm" >
&lt;div>
&lt;a href="#empirical-risk-minimazation-erm">
##
&lt;/a>
Empirical Risk Minimazation (ERM)
&lt;/div>
&lt;/h1>
&lt;p>经验风险最小化, Empirical Risk Minimazation principle (Vapnik, 1998)&lt;/p>
&lt;ol>
&lt;li>基于ERM训练模型：亦即在训练数据集上学习以最小化其平均误差。&lt;/li>
&lt;li>当前SOTA模型的参数量随着训练数据集规模增大而线性增加。&lt;/li>
&lt;/ol>
&lt;p>而经典VC学习理论（learning theory, Vapnik &amp;amp; Chervonenkis, 1971）表明：只要学习器的参数量
不随着训练样本数量增加，则基于ERM学习一定会收敛(convergence, i.e., good generalization
to new data)。亦即：模型的复杂度（参数量规模）相对于训练数据规模应该是固定的或者变动不大。&lt;/p>
&lt;p>这就造成了这样的矛盾：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>经典学习理论认为：想要ERM有效，则模型的参数量应该保持一定大小，而不是随着训练数据集规模增加而增加；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>然而在实际任务中：SOTA模型的参数量是与训练数据量保持线性增加的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>实际上，一方面ERM允许大的神经网络模型“记住”训练样本（即使用了很强的正则化约束，
strong regularization)，另一方面ERM训练得到的模型在训练分布之外的样本上的预测结果差异巨
大（即使被预测的样本仅仅发生了相对微小的改变，adversarial examples）。&lt;/p>
&lt;p>那么，有没有别的模型训练最优化准则呢？-&amp;gt; Vicinal Risk Minimization (VRM).&lt;/p>
&lt;blockquote>
&lt;p>In VRM, human knowledge is required to describe a vicinity or neighborhood around each
example in the training data. Then, additional virtual examples can be drawn from the
vicinity distribution of the training examples to enlarge the support of the training
distribution.&lt;/p>
&lt;/blockquote>
&lt;p>例如，在图像分类任务中，图像增强通常包括轻微的旋转、翻转、缩放等操作，这其实是图像的近邻
集（vicinity set）。这些数据增强通常提升了模型的泛化性能。但这些操作通常也是数据依赖的。&lt;/p>
&lt;p>Mixup 提供了一种数据无关（data-agnostic）的增强方法，它构造虚拟样本的方式如下：&lt;/p>
&lt;p>$$
\begin{eqnarray}
\tilde{x} &amp;amp;=&amp;amp; \lambda x_i + (1 - \lambda) x_j, \text{where } x_i, x_j \text{ are raw input vectors} \\
\tilde{y} &amp;amp;=&amp;amp; \lambda y_i + (1 - \lambda) y_j, \text{where } y_i, y_j \text{ are one-hot label encoding}
\end{eqnarray}
$$&lt;/p>
&lt;p>$(x_i, y_i)$ 和 $(x_j, y_j)$ 是从训练集中随机抽取的两个样例。$\lambda \in [0, 1]$。&lt;/p>
&lt;p>因此，mixup通过结合先验知识扩展了训练分布，即特征向量的线性插值应导致相关目标的线性插值。
mixup可以用几行代码实现，并且只引入最小的计算开销。&lt;/p>
&lt;p>Mixup: beyond_ERM, &lt;a href="https://arxiv.org/pdf/1710.09412">https://arxiv.org/pdf/1710.09412&lt;/a>&lt;/p></description></item><item><title>路由器wifi连不上_但手机流量可以</title><link>/posts/2024-06-16-wifi%E8%BF%9E%E4%B8%8D%E4%B8%8A_%E4%BD%86%E6%89%8B%E6%9C%BA%E6%B5%81%E9%87%8F%E5%8F%AF%E4%BB%A5/</link><pubDate>Sun, 16 Jun 2024 10:07:12 +0800</pubDate><guid>/posts/2024-06-16-wifi%E8%BF%9E%E4%B8%8D%E4%B8%8A_%E4%BD%86%E6%89%8B%E6%9C%BA%E6%B5%81%E9%87%8F%E5%8F%AF%E4%BB%A5/</guid><description>&lt;p>Q：请问Wifi无法翻墙或访问某些网站，但用手机流量却可以是什么原因？&lt;/p>
&lt;p>A:
先说说你的wifi和5g环境下翻墙的问题，我猜测下你家里的宽带是不是移动的，手机流量用的是联通
或者电信，总之，家庭宽带和5g不是一家isp。 如果是的话，这个问题就比较好理解，不同isp不同
的地区都会有自己的一套黑名单机制。 所以可能你的家宽isp监测你的上网流量有不正常，或者大数
据认为你的翻墙服务器很可疑（未必是你造成的，因为有很多人在用），于是开启了屏蔽，但是另一
家手机isp并没有触发黑名单判定，所以未屏蔽。 移动的黑名单一般是最激进的，号称墙中墙，不过
不同地区的同一服务商政策也会有很大差别，不好说谁就一定好，谁就一定差。所以解决方法就是换
个翻墙服务器就可以了。&lt;/p>
&lt;p>&lt;del>再说说机场问题，机场如果要找的话千千万，不夸张的说小学生都能开机场，所以，如果真
要是选的话，如果你不太懂技术，就选大机场好了，可能贵一些，但是稳定性是有保障的。
如果懂技术，就不如机场（或转发服务）+自建服务器结合的方式，这样就能兼顾速度和隐
私安全。 几乎所有的机场都会有审查机制，最起码他需要监控流量来计费，只是审查程度
和隐私数据处理严谨度有区别而已，看商家良心了。我个人没用过机场，只能说两个我所知
道的比较大的，justmysocks，dler cloud，魅影极速。 另外，别太迷信那些机场推荐，基
本都是掐饭。 对了，还有个我觉得你可以试下，叫Shiliew。 理由有2个，这个app的作者
就是开源翻墙软件brook的作者，在app store里看着权限很干净，另外这个作者名字叫
txthinking，有点致敬编程随想的意思，感觉他应该最起码不红吧。。。哈哈哈 但是这
东西好用不好用我就不知道了。&lt;/del>&lt;/p>
&lt;p>最后我再说下关于@han_chinese的观点，移动数据的审查是最强的，因为移动蜂窝数据是需要精确计
费的，众所周知，每个服务商都有很多免流量服务，所以需要识别流量内容来判断计费与否。更甚的
是，移动数据流量都会被自动标记上本机电话号码，他们还专门搞了api来卖这种服务。简单来讲，
比如你用流量上京东，你不需要输入你的电话号码来注册或者登录，京东就已然知晓了，因为京东买
了isp的api接口，只需要在网页中加入几行代码来调用这个api，你一旦用手机流量访问这个网页，
电话号码就会返回给京东。 所以无论翻墙与否，都建议在使用数据流量上网时开启vpn服务来加密和
中转数据。 关于买国外电话卡来翻墙，同样也是不靠谱的，因为外国的sim卡拿到中国来能用，只是
漫游了而已，漫游的意思就是，国外和国内的isp签了合同，能让各自的用户租用自己这边的基站线
路等设备来保证跨国使用，所以即使买了google-fi来中国使用，和你用中国的sim卡在中国使用，都
是通过中国isp的基站线路和服务器。唯一区别就是google-fi的所有访问都会被列入白名单，但是数
据流量的审计是一样的。你拿google-fi来上pincong，移动服务商是知道，只是不阻拦而已，这样一
定程度上更加危险。&lt;/p>
&lt;p>@han_chinese:
中國電信市場的移動數據網絡使用的是複雜的多重企業IPv4-NAT，加之，移動數據網絡業務很複雜。所以，GFW對移動數據網路的审查較弱。
建議直接使用國外數據業務，像是Google-Fi，使用不受GFW影響的移動數據網絡。&lt;/p>
&lt;p>&lt;a href="https://pincong.rocks/question/45451">点这里查阅信息来源&lt;/a>&lt;/p></description></item><item><title>calculate_gpu_vram_for_llama3-70B</title><link>/posts/2024-06-13-calculate_gpu_vram_for_llama3-70b/</link><pubDate>Thu, 13 Jun 2024 16:11:47 +0800</pubDate><guid>/posts/2024-06-13-calculate_gpu_vram_for_llama3-70b/</guid><description>&lt;p>How many GPUs do I need to be able to serve Llama 70B? In order to answer that, you need
to know how much GPU memory will be required by the Large Language Model.&lt;/p>
&lt;p>The formula is simple:&lt;/p>
&lt;p>$$
M=\frac{(P * 4B)}{(32/Q)} * 1.2
$$&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Symbol&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>M&lt;/td>
&lt;td>GPU memory expressed in Gigabyte&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>P&lt;/td>
&lt;td>The amount of parameters in the model. E.g. a 7B model has 7 billion parameters.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4B&lt;/td>
&lt;td>4 bytes, expressing the bytes used for each parameter&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>32&lt;/td>
&lt;td>There are 32 bits in 4 bytes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Q&lt;/td>
&lt;td>The amount of bits that should be used for loading the model. E.g. 16 bits, 8 bits or 4 bits.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1.2&lt;/td>
&lt;td>Represents a 20% overhead of loading additional things in GPU memory.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Now let&amp;rsquo;s try out some examples.
GPU memory required for serving Llama 70B&lt;/p>
&lt;p>Let&amp;rsquo;s try it out for Llama 70B that we will load in 16 bit. The model has 70 billion parameters.&lt;/p>
&lt;p>$$
\frac{70 * 4bytes}{32/16} * 1.2=168GB
$$&lt;/p>
&lt;p>That&amp;rsquo;s quite a lot of memory. A single A100 80GB wouldn&amp;rsquo;t be enough, although 2x A100
80GB should be enough to serve the Llama 2 70B model in 16 bit mode.&lt;/p></description></item><item><title>lean_principles</title><link>/posts/mlteam101/lean_principles/</link><pubDate>Mon, 03 Jun 2024 17:59:09 +0800</pubDate><guid>/posts/mlteam101/lean_principles/</guid><description>&lt;p>Principle 1: Identify value&lt;/p>
&lt;pre>&lt;code>Determine what is most valuable to the customer and focus on maximizing that value.
&lt;/code>&lt;/pre>
&lt;p>Principle 2: Map the value stream&lt;/p>
&lt;pre>&lt;code>Identify the steps in the process that add value and eliminate those that do not.
&lt;/code>&lt;/pre>
&lt;p>Principle 3: Create flow&lt;/p>
&lt;pre>&lt;code>Streamline the process to create a smooth and continuous flow of work.
&lt;/code>&lt;/pre>
&lt;p>Principle 4: Establish pull&lt;/p>
&lt;pre>&lt;code>Use customer demand to trigger production and avoid overproduction.
&lt;/code>&lt;/pre>
&lt;p>Principle 5: Continuous improvement&lt;/p>
&lt;pre>&lt;code>Continuously strive for improvement and eliminate waste in all areas of the value
chain.
&lt;/code>&lt;/pre>
&lt;p>Value stream mapping (principle 2) is a tool that lets us visually represent all the
steps and resources involved in delivering a unit of value (e.g., a product feature) to
customers. Teams can use this tool to identify waste, work toward eliminating waste,
and improve the flow of value (principle 3).&lt;/p>
&lt;p>To map your team or product’s value stream, you can follow these steps:&lt;/p>
&lt;ol>
&lt;li>Identify the product or service being mapped. This could be a single product or1.
an entire process.&lt;/li>
&lt;li>Identify the current state map. Create a visual representation of the current2.
process, including all steps and materials (including time and labor) involved
from raw materials to finished product.&lt;/li>
&lt;li>Identify value-added and non-value-added activities. Determine which steps add3.
value to the product or service and which do not.&lt;/li>
&lt;li>Identify waste. Look for areas of overproduction, waiting, defects, overprocess‐4.
ing, excess inventory, unnecessary motion, excess transport, unnecessary use of
raw materials, and unnecessary effort.&lt;/li>
&lt;li>Create a future state map. Based on the analysis of the current state map, redesign5.
the process to eliminate waste and create a more efficient flow of materials and
information.&lt;/li>
&lt;li>Implement changes. Put the redesigned process into practice and continuously6.
monitor and improve (principle 5).&lt;/li>
&lt;/ol></description></item><item><title>EffectiveML 01: Delivering successful ML projects</title><link>/posts/mlteam101/feedback_loops_and_times_to_feedback/</link><pubDate>Mon, 03 Jun 2024 17:12:37 +0800</pubDate><guid>/posts/mlteam101/feedback_loops_and_times_to_feedback/</guid><description>&lt;p>Table: Comparison of feedback mechanisms and time-to-feedback in high- and low-effectiveness environments&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Task&lt;/th>
&lt;th>High-effectiveness environment&lt;/th>
&lt;th>Low-effectiveness environment&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Testing if code changes worked as expected&lt;/td>
&lt;td>Automated testing (~ seconds to minutes)&lt;/td>
&lt;td>Manual testing (~ minutes to hours)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Testing if training pipeline works end to end&lt;/td>
&lt;td>Training smoke test (~ 1 minute)&lt;/td>
&lt;td>Full model training (~ minutes to hours, depending on model architecture)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Getting feedback on code changes&lt;/td>
&lt;td>Pair programming (~ seconds to minutes)&lt;/td>
&lt;td>Pull request reivews (~ hours to days)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Understanding if application is working as expected in production&lt;/td>
&lt;td>Monitoring in production (~ seconds - as it happens)&lt;/td>
&lt;td>Customer complaints (~ days, or longer if not directly reported)&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>How teams can move from a low-effectiveness environment to a high-effectiveness environment?
MLOps is not enough (MLOps and ML platforms aren’t going to write comprehensive tests
for you, talk to users for you, or reduce the negative impacts of team silos for you.)&lt;/p>
&lt;p>Delivering successful ML projects requires a multi‐disciplinary approach across these
five disciplines: product, software engineering, data, ML, and delivery:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>software engineering:&lt;/p>
&lt;ul>
&lt;li>code design&lt;/li>
&lt;li>automated testing&lt;/li>
&lt;li>refactoring&lt;/li>
&lt;li>dependency management&lt;/li>
&lt;li>code editor efficency&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>data:&lt;/p>
&lt;ul>
&lt;li>data quality&lt;/li>
&lt;li>data engineering&lt;/li>
&lt;li>data security and privacy&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Machine learning:&lt;/p>
&lt;ul>
&lt;li>ML techniques&lt;/li>
&lt;li>model evaluation&lt;/li>
&lt;li>ML governance&lt;/li>
&lt;li>MLOps&lt;/li>
&lt;li>CI/CD&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Product:&lt;/p>
&lt;ul>
&lt;li>product thinking&lt;/li>
&lt;li>responsible AI&lt;/li>
&lt;li>human-centered AI&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Delivery:&lt;/p>
&lt;ul>
&lt;li>lean delivery&lt;/li>
&lt;li>team topologies&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>tech interview prepare (for my resume)</title><link>/posts/notes4resume/</link><pubDate>Mon, 27 May 2024 20:43:25 +0800</pubDate><guid>/posts/notes4resume/</guid><description>&lt;h1 id="自我介绍" >
&lt;div>
&lt;a href="#%e8%87%aa%e6%88%91%e4%bb%8b%e7%bb%8d">
##
&lt;/a>
自我介绍
&lt;/div>
&lt;/h1>
&lt;blockquote>
&lt;p>在自我介绍时，确保你提到的项目和技能与你申请的职位紧密相关，这样可以更好地展示你的专业
能力和对职位的适应性。同时，保持自信和热情，让面试官感受到你对工作和团队的承诺。&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;p>尊敬的面试官，您好！&lt;/p>
&lt;p>我叫范明华，拥有6年在机器学习领域的工作经验。我于2017年硕士毕业于中山大学，专业是生态学，
在植被动态和演替方面的研究工作，为我在实验设计、统计分析以及数据挖掘方面打下了扎实的基础。
过去的6年里，我在工作中一直致力于将机器学习技术应用于解决实际问题，并取得了一些的成果。&lt;/p>
&lt;p>我在目前公司担任高级数据挖掘工程师，期间我主导了多个机器学习项目的开发和交付。
在技术层面，我比较擅长结合数据现状来决定机器学习或深度学习技术的搭配解决实际问题，
熟悉整个机器学习项目的开发流程，从项目调研、数据预处理、特征工程到模型训练和部署，
我都有深入的理解和实践。在这些项目的实战中，不仅提升了个人的技术深度和带队能力，
同时也取得了授权的发明专利、软件著作、地方标准等成果。&lt;/p>
&lt;p>除了技术专长，我还是一个注重团队合作和务实负责的人。我相信，我的专业技能和丰富经验，
能够为贵公司带来直接的价值。&lt;/p>
&lt;p>我对贵公司在机器学习/深度学习方面的工作感兴趣，我期待能够加入贵公司，并与团队一起解决更多有趣的技术挑战。&lt;/p>
&lt;p>感谢您给我这次面试的机会，我期待在接下来的讨论中分享更多我的经验和想法。谢谢！&lt;/p>
&lt;hr>
&lt;h1 id="project-01----nlp" >
&lt;div>
&lt;a href="#project-01----nlp">
##
&lt;/a>
Project 01 &amp;ndash; NLP
&lt;/div>
&lt;/h1>
&lt;h2 id="sklearn-randomforest-model" >
&lt;div>
&lt;a href="#sklearn-randomforest-model">
#
&lt;/a>
sklearn randomforest model
&lt;/div>
&lt;/h2>
&lt;p>当谈到随机森林时，我们需要理解它的基础算法：决策树。随机森林是基于决策树的集成学习方法。所以，让我们首先来了解决策树的基本算法，然后再深入探讨随机森林。&lt;/p>
&lt;h3 id="1-决策树算法" >
&lt;div>
&lt;a href="#1-%e5%86%b3%e7%ad%96%e6%a0%91%e7%ae%97%e6%b3%95">
##
&lt;/a>
1. 决策树算法:
&lt;/div>
&lt;/h3>
&lt;h4 id="11-cart算法-classification-and-regression-trees" >
&lt;div>
&lt;a href="#11-cart%e7%ae%97%e6%b3%95-classification-and-regression-trees">
###
&lt;/a>
1.1 CART算法 (Classification and Regression Trees):
&lt;/div>
&lt;/h4>
&lt;p>CART算法是一种用于构建分类和回归树的决策树算法。它通过对数据集递归地进行二分来构建决策树。具体步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>特征选择&lt;/strong>：对于分类问题，通常使用基尼指数（Gini index）或信息增益（Information Gain）来选择最佳的特征进行分裂；对于回归问题，通常使用平方误差来选择最佳的特征。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>节点分裂&lt;/strong>：根据选择的特征，将数据集分成两部分，使得每个子集的样本属于同一类别（对于分类问题）或具有相似的回归值（对于回归问题）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>递归&lt;/strong>：对每个子集重复上述过程，直到满足停止条件，如达到最大深度、节点中样本数小于某个阈值或其他预定义条件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>剪枝&lt;/strong>：为了避免过拟合，可以对生成的树进行剪枝，即移除一些节点来简化树的结构。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="2-随机森林算法" >
&lt;div>
&lt;a href="#2-%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97%e7%ae%97%e6%b3%95">
##
&lt;/a>
2. 随机森林算法:
&lt;/div>
&lt;/h3>
&lt;h4 id="21-构建随机森林" >
&lt;div>
&lt;a href="#21-%e6%9e%84%e5%bb%ba%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97">
###
&lt;/a>
2.1 构建随机森林:
&lt;/div>
&lt;/h4>
&lt;p>随机森林是通过构建多棵决策树并将它们集成起来来完成的。具体步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>随机抽样&lt;/strong>：从原始训练集中随机选择一部分样本（有放回抽样）来构建每棵决策树的训练集。这样可以保证每棵树的训练集略有差异，增加了模型的多样性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>随机特征选择&lt;/strong>：对于每棵树的每个节点，在选择分割特征时，随机选择一部分特征来进行评估。这样可以确保每棵树的分裂过程也有所差异。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>独立构建&lt;/strong>：每棵树都是独立构建的，没有任何关联。这意味着可以并行地构建多棵树，提高了训练效率。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="22-集成决策树" >
&lt;div>
&lt;a href="#22-%e9%9b%86%e6%88%90%e5%86%b3%e7%ad%96%e6%a0%91">
###
&lt;/a>
2.2 集成决策树:
&lt;/div>
&lt;/h4>
&lt;p>构建多棵决策树后，随机森林采用不同的方式来集成它们的预测结果：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>分类任务&lt;/strong>：采用投票的方式，即每棵树投票选择最终的类别。&lt;/li>
&lt;li>&lt;strong>回归任务&lt;/strong>：采用平均值的方式，即多棵树的预测结果取平均值。&lt;/li>
&lt;/ul>
&lt;h3 id="总结" >
&lt;div>
&lt;a href="#%e6%80%bb%e7%bb%93">
##
&lt;/a>
总结:
&lt;/div>
&lt;/h3>
&lt;p>随机森林是一种强大的机器学习方法，基于决策树的集成学习。通过利用决策树的随机性和集成策略，随机森林能够有效地应对分类和回归问题，并在许多实际应用中表现优异。&lt;/p>
&lt;p>在 CART (Classification and Regression Trees) 算法中，节点的分裂依据是基于贪心算法。CART 算法通过贪心地选择每次分裂时能够最大程度减少不纯度（对于分类问题）或者最小化误差（对于回归问题）的特征来进行节点的分裂。这种贪心策略保证了在每个节点分裂时都选择了最优的特征来进行分裂。&lt;/p>
&lt;h3 id="节点分裂的依据" >
&lt;div>
&lt;a href="#%e8%8a%82%e7%82%b9%e5%88%86%e8%a3%82%e7%9a%84%e4%be%9d%e6%8d%ae">
##
&lt;/a>
节点分裂的依据：
&lt;/div>
&lt;/h3>
&lt;h4 id="对于分类问题" >
&lt;div>
&lt;a href="#%e5%af%b9%e4%ba%8e%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98">
###
&lt;/a>
对于分类问题：
&lt;/div>
&lt;/h4>
&lt;p>在分类问题中，CART 算法通常使用以下两种方法作为节点分裂的依据：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>基尼指数 (Gini index)&lt;/strong>：基尼指数衡量了从一个数据集中随机抽取两个样本，它们类别不一致的概率。具体地，对于一个节点 $t$，基尼指数可以计算为：&lt;/p>
&lt;p>$ Gini(t) = 1 - \sum_{i=1}^{c} p(i|t)^2 $&lt;/p>
&lt;p>其中，$c$ 是类别的数量，$p(i|t)$ 是在节点 $t$ 中属于类别 $i$ 的样本的比例。选择能够最大程度降低基尼指数的特征来进行节点分裂。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>信息增益 (Information Gain)&lt;/strong>：信息增益衡量了在某个特征的条件下，将数据集分为不同类别后，带来的不确定性减少的程度。具体地，对于一个节点 $t$ 和一个特征 $A$，信息增益可以计算为：&lt;/p>
&lt;p>$ IG(t, A) = H(t) - \sum_{v \in Values(A)} \frac{|t_v|}{|t|} \cdot H(t_v) $&lt;/p>
&lt;p>其中，$H(t)$ 是节点 $t$ 的熵，$Values(A)$ 是特征 $A$ 的取值集合，$t_v$ 是在特征 $A$ 上取值为 $v$ 的样本集合，$H(t_v)$ 是样本集合 $t_v$ 的熵。选择能够最大化信息增益的特征来进行节点分裂。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="对于回归问题" >
&lt;div>
&lt;a href="#%e5%af%b9%e4%ba%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98">
###
&lt;/a>
对于回归问题：
&lt;/div>
&lt;/h4>
&lt;p>在回归问题中，CART 算法通常使用平方误差 (Mean Squared Error, MSE) 作为节点分裂的依据。选择能够最小化节点分裂后样本的平方误差的特征来进行分裂。&lt;/p>
&lt;h3 id="总结-1" >
&lt;div>
&lt;a href="#%e6%80%bb%e7%bb%93-1">
##
&lt;/a>
总结：
&lt;/div>
&lt;/h3>
&lt;p>CART 算法在节点分裂时采用贪心算法，选择能够最大程度减少不纯度（分类问题）或者最小化误差（回归问题）的特征来进行分裂。这种贪心策略保证了每次分裂都选择了最优的特征，以构建出尽可能简单且有效的决策树。&lt;/p>
&lt;p>当谈到基于决策树的集成学习时，除了随机森林，还有一种重要的方法是提升树（Boosting）。提升树是一种迭代的集成学习方法，通过串行地构建一系列决策树来逐步提升模型的性能。下面我会详细介绍提升树的原理和实现方式。&lt;/p>
&lt;h3 id="提升树的原理" >
&lt;div>
&lt;a href="#%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%8e%9f%e7%90%86">
##
&lt;/a>
提升树的原理：
&lt;/div>
&lt;/h3>
&lt;h4 id="1-基本思想" >
&lt;div>
&lt;a href="#1-%e5%9f%ba%e6%9c%ac%e6%80%9d%e6%83%b3">
###
&lt;/a>
1. 基本思想：
&lt;/div>
&lt;/h4>
&lt;p>提升树的基本思想是通过训练一系列弱学习器（通常是决策树），然后将它们组合起来构成一个更强大的模型。每个弱学习器都专注于纠正之前模型的错误，因此在构建过程中会关注之前模型预测错误的样本。&lt;/p>
&lt;h4 id="2-算法流程" >
&lt;div>
&lt;a href="#2-%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b">
###
&lt;/a>
2. 算法流程：
&lt;/div>
&lt;/h4>
&lt;p>提升树的算法流程如下：&lt;/p>
&lt;ol>
&lt;li>初始化模型为一个常数值，通常为目标变量的均值（对于回归问题）或者是类别的先验概率（对于分类问题）。&lt;/li>
&lt;li>迭代地训练决策树，每次训练都会生成一个新的弱学习器。在每次迭代中，算法会计算当前模型的残差（对于回归问题）或者梯度（对于分类问题），然后训练一个新的决策树来拟合这些残差或者梯度。&lt;/li>
&lt;li>将新生成的决策树加到模型中，通常使用一个较小的学习率来缓解每棵树的影响。&lt;/li>
&lt;li>重复迭代步骤2和步骤3，直到达到预先设定的迭代次数或者模型的性能达到某个阈值为止。&lt;/li>
&lt;/ol>
&lt;h4 id="3-加法模型" >
&lt;div>
&lt;a href="#3-%e5%8a%a0%e6%b3%95%e6%a8%a1%e5%9e%8b">
###
&lt;/a>
3. 加法模型：
&lt;/div>
&lt;/h4>
&lt;p>提升树的最终模型是一个加法模型，即多个弱学习器的加权求和。通过迭代训练，每个弱学习器都会对模型进行一定的修正，最终组合起来构成一个更强大的模型。&lt;/p>
&lt;h3 id="实现" >
&lt;div>
&lt;a href="#%e5%ae%9e%e7%8e%b0">
##
&lt;/a>
实现：
&lt;/div>
&lt;/h3>
&lt;p>提升树的实现通常采用梯度提升算法（Gradient Boosting），其中最常见的是梯度提升决策树（Gradient Boosting Decision Trees，GBDT）。&lt;/p>
&lt;p>GBDT 算法的关键步骤包括计算残差或者梯度、训练决策树以拟合残差或者梯度、确定学习率等。GBDT 通过不断地迭代训练决策树来逐步优化模型，直到达到一定的迭代次数或者达到一定的性能指标。&lt;/p>
&lt;h3 id="总结-2" >
&lt;div>
&lt;a href="#%e6%80%bb%e7%bb%93-2">
##
&lt;/a>
总结：
&lt;/div>
&lt;/h3>
&lt;p>提升树是一种基于决策树的集成学习方法，通过迭代训练一系列决策树来逐步提升模型的性能。相较于随机森林，提升树通常会产生更加精确的预测，但需要更长的训练时间，并且对异常值和噪声数据更敏感。&lt;/p>
&lt;h2 id="mlp-model" >
&lt;div>
&lt;a href="#mlp-model">
#
&lt;/a>
MLP model
&lt;/div>
&lt;/h2>
&lt;p>MLP，即多层感知器（Multilayer Perceptron），是一种基本的人工神经网络模型。它由多层神经元组成，每一层都与下一层全连接。MLP是一种前馈神经网络，意味着信息只能从输入层向输出层传递，不会存在循环连接。&lt;/p>
&lt;p>下面是MLP的一些基本原理：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>神经元（Perceptron）&lt;/strong>：
在MLP中，每个神经元都是一个简单的计算单元。它接收来自前一层的输入信号，将这些信号加权求和，并通过激活函数产生输出。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>多层结构&lt;/strong>：
MLP由多个层组成，典型的MLP包括输入层、至少一个隐藏层和输出层。输入层接收原始数据，隐藏层对输入数据进行特征提取和转换，输出层生成最终的预测结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>权重和偏置&lt;/strong>：
在MLP中，每个连接都有一个相关联的权重，用于控制信号传递的强度和方向。此外，每个神经元还有一个偏置，用于调整神经元的激活阈值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>激活函数&lt;/strong>：
在神经元中，激活函数决定了神经元输出的非线性关系。常用的激活函数包括Sigmoid、ReLU（Rectified Linear Unit）、tanh等，它们在不同情况下具有不同的优势。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>前向传播&lt;/strong>：
在MLP中，数据从输入层开始传播，经过一系列的加权求和和激活函数处理，一直传播到输出层，生成最终的预测结果。这个过程称为前向传播。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>反向传播&lt;/strong>：
反向传播是MLP中用于训练模型的关键步骤。它利用梯度下降算法，通过计算损失函数对每个参数（权重和偏置）的梯度，并沿着梯度的反方向更新参数，从而最小化损失函数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>损失函数&lt;/strong>：
损失函数用于衡量模型预测结果与真实标签之间的差异。常见的损失函数包括均方误差（MSE）、交叉熵等，选择适当的损失函数取决于具体的问题类型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>优化算法&lt;/strong>：
在反向传播过程中，需要选择合适的优化算法来更新模型参数。常用的优化算法包括随机梯度下降（SGD）、Adam、RMSprop等。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>总的来说，MLP通过多层的非线性变换来学习输入数据的复杂特征表示，通过反向传播算法不断调整模型参数以最小化损失函数，从而实现对数据的分类、回归等任务。&lt;/p>
&lt;p>反向传播算法是用于训练神经网络的关键算法之一，它通过计算损失函数对每个参数的梯度来更新模型参数，从而使得模型能够逐渐优化以达到最佳性能。下面我将介绍反向传播算法的计算过程，以及链式法则如何用来计算梯度。&lt;/p>
&lt;h3 id="反向传播算法的计算过程" >
&lt;div>
&lt;a href="#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e7%ae%97%e6%b3%95%e7%9a%84%e8%ae%a1%e7%ae%97%e8%bf%87%e7%a8%8b">
##
&lt;/a>
反向传播算法的计算过程：
&lt;/div>
&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>前向传播&lt;/strong>：
首先，通过前向传播计算模型的输出。将输入数据输入到网络中，按照网络结构逐层计算每个神经元的输出，并将输出传递给下一层，直至生成最终的预测结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>计算损失&lt;/strong>：
使用损失函数计算模型的预测值与真实标签之间的差异，得到损失值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>反向传播&lt;/strong>：
从输出层开始，利用链式法则逐层计算每个参数的梯度。梯度表示了损失函数对参数的变化率，它告诉我们如何调整参数才能使损失函数最小化。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>参数更新&lt;/strong>：
根据计算得到的梯度，利用优化算法（如随机梯度下降）来更新模型参数。通常，参数更新的步长（学习率）是一个超参数，需要根据实际情况进行调整。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="链式法则如何用来计算梯度" >
&lt;div>
&lt;a href="#%e9%93%be%e5%bc%8f%e6%b3%95%e5%88%99%e5%a6%82%e4%bd%95%e7%94%a8%e6%9d%a5%e8%ae%a1%e7%ae%97%e6%a2%af%e5%ba%a6">
##
&lt;/a>
链式法则如何用来计算梯度：
&lt;/div>
&lt;/h3>
&lt;p>链式法则是微积分中的基本原理，用于计算复合函数的导数。在反向传播算法中，我们利用链式法则来计算损失函数对模型参数的梯度，从而实现参数的更新。&lt;/p>
&lt;p>假设有一个复合函数 $z = f(g(x))$，其中 $x$ 是输入，$g(x)$ 是一个函数，$f(x)$ 是另一个函数。根据链式法则，$z$ 对 $x$ 的导数可以表示为：&lt;/p>
&lt;p>$$
\frac{dz}{dx} = \frac{dz}{dg} \cdot \frac{dg}{dx}
$$&lt;/p>
&lt;p>在神经网络中，我们可以将损失函数 $L$ 视为 $z$，模型的参数视为 $x$，前向传播过程中的每一层输出视为 $g$，激活函数视为 $f$。
利用链式法则，我们可以逐层计算损失函数对每个参数的梯度，然后根据优化算法更新参数，使得损失函数逐渐减小。&lt;/p>
&lt;p>总的来说，反向传播算法通过利用链式法则计算损失函数对参数的梯度，实现了高效的神经网络训练过程，使得模型能够自动学习复杂的数据表示。&lt;/p>
&lt;p>交叉熵（Cross-Entropy）是在分类任务中常用的损失函数，特别是在多分类任务中。它的原理和为什么有用可以通过以下几点进行详细解释：&lt;/p>
&lt;h3 id="1-损失函数的作用" >
&lt;div>
&lt;a href="#1-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e7%9a%84%e4%bd%9c%e7%94%a8">
##
&lt;/a>
1. 损失函数的作用：
&lt;/div>
&lt;/h3>
&lt;p>损失函数用于衡量模型预测结果与真实标签之间的差异。优化模型的目标是最小化损失函数，使得模型能够产生与真实标签相匹配的预测结果。&lt;/p>
&lt;h3 id="2-交叉熵的定义" >
&lt;div>
&lt;a href="#2-%e4%ba%a4%e5%8f%89%e7%86%b5%e7%9a%84%e5%ae%9a%e4%b9%89">
##
&lt;/a>
2. 交叉熵的定义：
&lt;/div>
&lt;/h3>
&lt;p>对于多分类任务，交叉熵损失函数的数学定义如下：&lt;/p>
&lt;p>$$
\text{Cross-Entropy}(y, \hat{y}) = -\sum_{i=1}^{N} y_i \log(\hat{y}_i)
$$&lt;/p>
&lt;p>其中，$y$ 是真实标签的概率分布（通常是一个one-hot编码的向量），$\hat{y}$ 是模型预测的概率分布，$N$ 是类别的数量。
该损失函数用于衡量真实标签与模型预测结果之间的差异。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> numpy &lt;span style="color:#ff6ac1">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">binary_cross_entropy&lt;/span>(y_true, y_pred):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y_true &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array(y_true)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y_pred &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array(y_pred)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># Clip predictions to avoid log(0)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y_pred &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>clip(y_pred, &lt;span style="color:#ff9f43">1e-15&lt;/span>, &lt;span style="color:#ff9f43">1&lt;/span> &lt;span style="color:#ff6ac1">-&lt;/span> &lt;span style="color:#ff9f43">1e-15&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cross_entropy &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff6ac1">-&lt;/span>np&lt;span style="color:#ff6ac1">.&lt;/span>mean(y_true &lt;span style="color:#ff6ac1">*&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>log(y_pred) &lt;span style="color:#ff6ac1">+&lt;/span> (&lt;span style="color:#ff9f43">1&lt;/span> &lt;span style="color:#ff6ac1">-&lt;/span> y_true) &lt;span style="color:#ff6ac1">*&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>log(&lt;span style="color:#ff9f43">1&lt;/span> &lt;span style="color:#ff6ac1">-&lt;/span> y_pred))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> cross_entropy
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Example&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_true &lt;span style="color:#ff6ac1">=&lt;/span> [&lt;span style="color:#ff9f43">1&lt;/span>, &lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">1&lt;/span>, &lt;span style="color:#ff9f43">1&lt;/span>, &lt;span style="color:#ff9f43">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_pred &lt;span style="color:#ff6ac1">=&lt;/span> [&lt;span style="color:#ff9f43">0.9&lt;/span>, &lt;span style="color:#ff9f43">0.1&lt;/span>, &lt;span style="color:#ff9f43">0.8&lt;/span>, &lt;span style="color:#ff9f43">0.7&lt;/span>, &lt;span style="color:#ff9f43">0.2&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(binary_cross_entropy(y_true, y_pred))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> numpy &lt;span style="color:#ff6ac1">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">multiclass_cross_entropy&lt;/span>(y_true, y_pred):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y_true &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array(y_true)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y_pred &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array(y_pred)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># Clip predictions to avoid log(0)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y_pred &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>clip(y_pred, &lt;span style="color:#ff9f43">1e-15&lt;/span>, &lt;span style="color:#ff9f43">1&lt;/span> &lt;span style="color:#ff6ac1">-&lt;/span> &lt;span style="color:#ff9f43">1e-15&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cross_entropy &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff6ac1">-&lt;/span>np&lt;span style="color:#ff6ac1">.&lt;/span>mean(np&lt;span style="color:#ff6ac1">.&lt;/span>sum(y_true &lt;span style="color:#ff6ac1">*&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>log(y_pred), axis&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> cross_entropy
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Example&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_true &lt;span style="color:#ff6ac1">=&lt;/span> [[&lt;span style="color:#ff9f43">1&lt;/span>, &lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">0&lt;/span>], [&lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">1&lt;/span>, &lt;span style="color:#ff9f43">0&lt;/span>], [&lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">1&lt;/span>]] &lt;span style="color:#78787e"># how to get these? One-hot encoding.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_pred &lt;span style="color:#ff6ac1">=&lt;/span> [[&lt;span style="color:#ff9f43">0.9&lt;/span>, &lt;span style="color:#ff9f43">0.05&lt;/span>, &lt;span style="color:#ff9f43">0.05&lt;/span>], [&lt;span style="color:#ff9f43">0.1&lt;/span>, &lt;span style="color:#ff9f43">0.8&lt;/span>, &lt;span style="color:#ff9f43">0.1&lt;/span>], [&lt;span style="color:#ff9f43">0.05&lt;/span>, &lt;span style="color:#ff9f43">0.05&lt;/span>, &lt;span style="color:#ff9f43">0.9&lt;/span>]] &lt;span style="color:#78787e"># how to get these? Softmax.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(multiclass_cross_entropy(y_true, y_pred))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Softmax: Get the y_pred from model output raw scores (i.e., logits)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">softmax&lt;/span>(logits):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> exp_logits &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>exp(logits &lt;span style="color:#ff6ac1">-&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>max(logits, axis&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>, keepdims&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">True&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> exp_logits &lt;span style="color:#ff6ac1">/&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>sum(exp_logits, axis&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>, keepdims&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Example logits (raw scores) outputted by a model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>logits &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array([[&lt;span style="color:#ff9f43">2.0&lt;/span>, &lt;span style="color:#ff9f43">1.0&lt;/span>, &lt;span style="color:#ff9f43">0.1&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ff9f43">0.5&lt;/span>, &lt;span style="color:#ff9f43">2.5&lt;/span>, &lt;span style="color:#ff9f43">1.5&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ff9f43">1.2&lt;/span>, &lt;span style="color:#ff9f43">0.7&lt;/span>, &lt;span style="color:#ff9f43">2.1&lt;/span>]])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Compute the softmax probabilities&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_pred &lt;span style="color:#ff6ac1">=&lt;/span> softmax(logits)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-原理解释" >
&lt;div>
&lt;a href="#3-%e5%8e%9f%e7%90%86%e8%a7%a3%e9%87%8a">
##
&lt;/a>
3. 原理解释：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>信息论角度&lt;/strong>：
交叉熵损失函数源自信息论中的信息熵概念。信息熵用于衡量一个随机变量的不确定性，而交叉熵则衡量两个概率分布之间的差异。当真实标签和模型预测的分布越接近时，交叉熵越小。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>梯度下降优化&lt;/strong>：
交叉熵损失函数在梯度下降优化过程中具有良好的性质。它的导数相对简单，计算起来更加高效，而且当模型的预测结果与真实标签的差异较大时，梯度也会变得更大，从而加速模型参数的更新。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>适用于多分类任务&lt;/strong>：
交叉熵损失函数特别适用于多分类任务，因为它能够有效地衡量多个类别之间的差异，并且在模型优化过程中能够引导模型更快地收敛到最优解。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="4-为什么有用" >
&lt;div>
&lt;a href="#4-%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e7%94%a8">
##
&lt;/a>
4. 为什么有用：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>梯度信息&lt;/strong>：
交叉熵损失函数提供了丰富的梯度信息，使得模型可以更快地学习到正确的预测结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>适用性广泛&lt;/strong>：
交叉熵损失函数适用于多分类任务，并且在实际应用中表现良好，因此成为了许多分类任务的首选损失函数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>与概率相关&lt;/strong>：
交叉熵损失函数直接与概率分布相关，更符合任务的本质，能够更好地指导模型学习数据的分布情况。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>总的来说，交叉熵损失函数通过衡量模型预测结果与真实标签之间的差异，提供了有效的优化目标，并在梯度下降优化过程中起到重要作用，因此被广泛应用于分类任务中。&lt;/p>
&lt;h2 id="bertroberta-model" >
&lt;div>
&lt;a href="#bertroberta-model">
#
&lt;/a>
BERT/RoBERTa model
&lt;/div>
&lt;/h2>
&lt;p>BERT(Bidirectional Encoder Representations from Transformers):
BERT是一种双向的（Bidirectional）模型，这意味着它能够同时考虑到一个单词左边和右边的上下文信息。这使得BERT在理解句子语境时比之前的模型更为强大。
BERT模型的预训练过程是通过掩盖输入文本中的一部分词汇（Masked Language Model，MLM）和预测句子是否连续（Next Sentence Prediction，NSP）来完成的。
BERT以“transformer”为基础，这是一种自注意力（self-attention）机制的神经网络结构，它能够在考虑到输入序列的所有位置之间建立关联，从而更好地理解上下文。&lt;/p>
&lt;p>RoBERTa是Facebook AI提出的一种改进的预训练自然语言处理（NLP）模型，它在很大程度上建立在BERT的基础上，但通过一系列的改进，使其在多个NLP任务上表现更优秀。&lt;/p>
&lt;p>RoBERTa的主要改进包括：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>动态掩码策略（Dynamic Masking）：RoBERTa在预训练时采用了动态掩码策略，即在每个训练迭代中对输入句子进行随机化处理，而不是固定地在句子中随机掩码。这使得模型更好地学习句子中的上下文信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更长的训练时间和更大的批次大小：RoBERTa使用了更大的批次大小和更长的训练时间，以提高模型的泛化能力和性能。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>去除NSP（Next Sentence Prediction）任务：RoBERTa不再使用BERT中的NSP任务，而是专注于MLM（Masked Language Model）任务，这使得模型更好地理解输入文本。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更多的训练数据：RoBERTa使用了更多的文本数据来进行预训练，这有助于提高模型的泛化能力。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>总的来说，RoBERTa是对BERT模型的一种优化和改进，它在多个NLP任务上都取得了比BERT更好的性能。&lt;/p>
&lt;p>&lt;strong>更多细节，应该去查找台大李宏毅老师的课程，非常精彩的讲解。&lt;/strong>&lt;/p>
&lt;h2 id="faiss-indexivfpq" >
&lt;div>
&lt;a href="#faiss-indexivfpq">
#
&lt;/a>
FAISS (indexIVFPQ)
&lt;/div>
&lt;/h2>
&lt;p>在我的另一篇博客单独有介绍，并带有代码示例。&lt;/p>
&lt;h2 id="bertopic" >
&lt;div>
&lt;a href="#bertopic">
#
&lt;/a>
BERTopic
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>clustering&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>UMAP/PCA&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>c-TF-IDF&lt;/li>
&lt;/ul>
&lt;p>BERTopic 是一个基于BERT的自然语言处理工具，用于主题建模任务。BERTopic结合了BERT的强大表示学习能力和主题建模的思想，能够在大规模文本数据上快速、准确地提取主题信息。&lt;/p>
&lt;p>BERTopic的工作原理如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>文本向量化&lt;/strong>：首先，BERTopic使用预训练的BERT模型来将输入文本转换为高维向量表示。这些向量捕捉了输入文本的语义信息，并且通常能够更好地反映文本之间的语义相似度。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>主题发现&lt;/strong>：接下来，BERTopic使用聚类算法（例如DBSCAN或HDBSCAN）对文本向量进行聚类，以发现潜在的主题。聚类算法将文本向量分组为具有相似主题的簇。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>主题关键词提取&lt;/strong>：对于每个发现的主题簇，BERTopic还可以提取关键词来描述该主题。这些关键词通常是簇中最具代表性的词语，帮助用户理解主题的内容。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>主题可视化&lt;/strong>：最后，BERTopic可以将发现的主题可视化，使用户能够直观地了解文本数据中的主题结构。通常，可视化结果会以簇的形式展示，每个簇代表一个主题，簇内的文本则表示该主题的具体内容。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>关于最佳实践，以下是一些建议：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>调整模型参数&lt;/strong>：根据任务需求和数据特点，调整BERTopic的参数，例如聚类算法的参数、主题数量等，以获得更好的结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>预处理文本数据&lt;/strong>：在使用BERTopic之前，对文本数据进行适当的预处理是很重要的，例如去除停用词、进行词干化或词形还原等，以减少噪音对主题建模的影响。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>理解主题结果&lt;/strong>：对于每个发现的主题，仔细查看主题簇中的文本，并考虑它们之间的相似性和共性，以确保主题的合理性和可解释性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>与领域知识结合&lt;/strong>：在解释和利用主题结果时，结合领域知识会更有帮助。通过深入了解领域专业术语和相关概念，可以更准确地理解和解释主题的含义。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>通过合理地使用BERTopic工具，并结合适当的数据预处理和模型调优，可以有效地完成基于自然语言的主题建模任务。&lt;/p>
&lt;p>当然，让我更详细地解释一下这些技术。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>UMAP（Uniform Manifold Approximation and Projection）&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>UMAP是一种非线性降维算法，旨在将高维数据映射到低维空间以进行可视化或进一步分析。&lt;/li>
&lt;li>UMAP相对于传统的降维技术（如t-SNE）具有更好的可扩展性和保持全局数据结构的能力。它能够保持更多的局部结构，同时在大规模数据上的计算效率更高。&lt;/li>
&lt;li>在BERTopic中，UMAP常用于对BERT向量化的文本数据进行降维，以便进行更好的可视化或进一步的分析。降维后的数据可以更容易地被人类理解和解释。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>c-TF-IDF（Class-based TF-IDF）&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>c-TF-IDF是一种改进的TF-IDF（Term Frequency-Inverse Document Frequency）方法，用于从文本数据中提取关键词。&lt;/li>
&lt;li>与传统的TF-IDF相比，c-TF-IDF考虑了单词在不同主题中的重要性，而不仅仅是在整个文本集合中的重要性。这使得c-TF-IDF能够更好地捕捉文本中的主题相关信息。&lt;/li>
&lt;li>在BERTopic中，c-TF-IDF常用于从每个发现的主题簇中提取关键词，以描述该主题的内容。这些关键词通常是簇中最具代表性的词语，帮助用户理解主题的含义和内容。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>HDBSCAN（Hierarchical Density-Based Spatial Clustering of Applications with Noise）&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>HDBSCAN是一种密度聚类算法，旨在发现数据中的高密度区域，并将它们组合成簇。&lt;/li>
&lt;li>与传统的基于距离的聚类算法（如K均值）不同，HDBSCAN不需要预先指定簇的数量，因此更适用于发现具有不同大小和形状的簇的数据。&lt;/li>
&lt;li>在BERTopic中，HDBSCAN通常与UMAP一起使用，用于对BERT向量化的文本数据进行聚类。HDBSCAN能够识别出具有不同主题的文本簇，从而帮助用户发现文本数据中的主题结构。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>综上所述，UMAP用于将高维文本向量降维到低维空间，以便于可视化和分析；c-TF-IDF用于从每个主题簇中提取关键词以描述主题内容；HDBSCAN用于发现文本数据中的潜在主题簇。这些技术的结合使得BERTopic能够有效地进行自然语言主题建模，并从文本数据中提取有意义的主题信息。&lt;/p>
&lt;h1 id="project-02----ml" >
&lt;div>
&lt;a href="#project-02----ml">
##
&lt;/a>
Project 02 &amp;ndash; ML
&lt;/div>
&lt;/h1>
&lt;h2 id="self-training--gausianmixtruemodels" >
&lt;div>
&lt;a href="#self-training--gausianmixtruemodels">
#
&lt;/a>
self-training &amp;amp; GausianMixtrueModels
&lt;/div>
&lt;/h2>
&lt;p>半监督学习是一种机器学习方法，它利用有标签和无标签的数据来进行模型训练。相比于只使用有标签数据进行训练，半监督学习可以利用更多的无标签数据，从而提高模型的性能。&lt;/p>
&lt;p>self-training（自训练）是半监督学习中的一种常见技术，其基本思想是利用已经训练好的模型对无标签数据进行预测，然后将置信度较高的预测结果作为伪标签，将这些伪标签的数据与有标签数据一起重新训练模型。&lt;/p>
&lt;p>具体来说，self-training的步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>利用有标签数据训练一个初始模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用该模型对无标签数据进行预测，并选取置信度较高的预测结果作为伪标签。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将伪标签的数据与原有的有标签数据合并，重新训练模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>重复步骤2和步骤3，直到满足停止条件（比如达到最大迭代次数、模型性能不再提升等）。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>self-training的关键在于如何选择置信度较高的预测结果作为伪标签。一般来说，可以通过设置一个阈值来筛选置信度较高的预测结果，也可以使用模型的输出概率来作为置信度的度量。&lt;/p>
&lt;p>使用self-training技术可以帮助扩充样本，提高模型的泛化能力，特别是在标记数据有限的情况下。但需要注意的是，自训练过程中可能会引入噪声，因此需要仔细调节参数和监控模型性能，以避免过拟合和性能下降的问题。&lt;/p>
&lt;p>如果聚类簇内的标签并不一致，而且类别数目较为相同，这种情况可能会导致一些混乱，因为无法简单地选择一个代表性的标签来为整个聚类簇的样本打标签。在这种情况下，可以考虑以下几种处理方式：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>投票机制&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>对于每个聚类簇，可以采用投票机制来选择标签。即，统计聚类簇中样本的真实标签或者已有的伪标签，选择出现频率最高的标签作为整个聚类簇的标签。&lt;/li>
&lt;li>如果有多个标签出现频率相同，可以随机选择其中一个或者采用一些其他的策略来解决冲突。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>标签融合&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>对于聚类簇内的样本，可以将其真实标签或者已有的伪标签进行融合。例如，可以计算聚类簇中每个类别的权重，然后根据权重对多个标签进行加权平均，得到一个综合的标签。&lt;/li>
&lt;li>这种方法可以在一定程度上解决标签冲突的问题，但需要谨慎设计权重计算的方法，以避免给不太准确的标签过多的权重。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>进一步分析&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>对于那些标签冲突较为严重的聚类簇，可以进一步分析其样本特征或者数据分布，尝试找到更合适的标签选择策略。&lt;/li>
&lt;li>可以考虑使用一些数据挖掘技术或者领域知识来帮助解决这个问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>半监督学习方法&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>除了高斯混合聚类，还可以尝试其他半监督学习方法，如图半监督学习（Graph-based Semi-Supervised Learning）、标签传播算法（Label Propagation）、自训练（Self-training）等。&lt;/li>
&lt;li>这些方法可能会更有效地处理标签冲突的问题，因为它们可以更好地利用数据之间的相似性和关联性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>在实际应用中，可以根据具体情况选择适合的方法来处理标签冲突问题，同时需要注意监控模型的性能和效果，及时调整和优化算法。&lt;/p>
&lt;h2 id="xgboost" >
&lt;div>
&lt;a href="#xgboost">
#
&lt;/a>
XGBoost
&lt;/div>
&lt;/h2>
&lt;p>XGBoost，全称为“eXtreme Gradient Boosting”，是一种高效的集成学习算法，属于梯度提升树（Gradient Boosting Tree）的一种实现。它在机器学习竞赛中非常流行，因为它能够在各种类型的数据集上取得优秀的性能，并且相对于其他算法，它通常更容易调整参数以获得更好的性能。&lt;/p>
&lt;p>以下是 XGBoost 模型的一些关键特点和优势：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>集成学习&lt;/strong>：XGBoost 是一种集成学习算法，它通过组合多个弱学习器（通常是决策树）来构建一个强大的模型。每个决策树都是根据前一个树的错误进行训练，以逐步减少模型的残差。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>梯度提升算法&lt;/strong>：XGBoost 使用梯度提升算法来训练模型。该算法通过最小化损失函数的梯度来优化模型，从而使模型在每一步都更加贴近真实值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>正则化&lt;/strong>：XGBoost 提供了对模型进行正则化的选项，包括 L1 和 L2 正则化，以及控制树的复杂度的参数。这有助于减少过拟合，提高模型的泛化能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>支持并行化&lt;/strong>：XGBoost 可以有效地利用并行计算资源进行训练，因此在大规模数据集上也能够快速地训练模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>特征重要性评估&lt;/strong>：XGBoost 可以计算特征的重要性，从而帮助用户了解哪些特征对模型的预测最为关键。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>灵活性&lt;/strong>：XGBoost 可以用于分类问题、回归问题以及排序问题，并且可以在不同类型的数据集上进行应用。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>总的来说，XGBoost 是一种强大且灵活的机器学习算法，适用于各种类型的问题，并且在实践中表现出色。&lt;/p>
&lt;p>梯度提升算法（Gradient Boosting Algorithm）是一种集成学习方法，通过将多个弱学习器（通常是决策树）串联起来，逐步减少模型的残差来构建一个强大的预测模型。梯度提升算法通过梯度下降的思想，不断优化模型以最小化损失函数。&lt;/p>
&lt;p>下面是梯度提升算法的基本步骤：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>初始化模型&lt;/strong>：梯度提升算法通常从一个简单的模型开始，例如用一个常数来拟合数据的平均值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>迭代优化&lt;/strong>：接下来，算法迭代地执行以下步骤：&lt;/p>
&lt;ul>
&lt;li>计算残差：使用当前模型对训练数据进行预测，并计算实际值与预测值之间的残差。&lt;/li>
&lt;li>拟合残差：构建一个新的弱学习器（如决策树），以拟合残差。这意味着新的学习器会尝试纠正上一个模型的错误。&lt;/li>
&lt;li>更新模型：将新的学习器与前面的模型组合起来，形成一个更强大的模型。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>停止条件&lt;/strong>：当达到预先设定的迭代次数，或者当模型的性能满足某个特定的标准时，停止迭代。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>与梯度下降算法的关系在于，梯度提升算法也利用了梯度的信息来优化模型。但两者之间的关键区别在于优化的对象和优化方向。在梯度下降算法中，优化的对象是损失函数本身，而优化的方向是沿着损失函数梯度的反方向。而在梯度提升算法中，优化的对象是损失函数的残差，优化的方向是使残差最小化的方向。&lt;/p>
&lt;p>总的来说，梯度提升算法是一种强大的集成学习方法，通过不断迭代优化模型以减少残差，从而构建一个强大的预测模型。它利用了梯度信息来指导优化过程，但与梯度下降算法相比，它的优化目标和优化方向有所不同。&lt;/p>
&lt;h2 id="onnx-dockerpodman-and-restful-api" >
&lt;div>
&lt;a href="#onnx-dockerpodman-and-restful-api">
#
&lt;/a>
ONNX, Docker/Podman, and restful-api
&lt;/div>
&lt;/h2>
&lt;p>当你希望使用 Docker 来部署服务，并且构建 Flask RESTful API 来提供对 ONNX 模型的推理服务时，你可以按照以下步骤进行：&lt;/p>
&lt;h3 id="1-准备-flask-restful-api-代码" >
&lt;div>
&lt;a href="#1-%e5%87%86%e5%a4%87-flask-restful-api-%e4%bb%a3%e7%a0%81">
##
&lt;/a>
1. 准备 Flask RESTful API 代码
&lt;/div>
&lt;/h3>
&lt;p>你需要创建一个 Flask 应用程序，编写代码以加载 ONNX 模型并提供 RESTful API 来进行推理。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> flask &lt;span style="color:#ff6ac1">import&lt;/span> Flask, request
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> flask_restful &lt;span style="color:#ff6ac1">import&lt;/span> Api, Resource
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> numpy &lt;span style="color:#ff6ac1">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> onnxruntime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>app &lt;span style="color:#ff6ac1">=&lt;/span> Flask(__name__)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>api &lt;span style="color:#ff6ac1">=&lt;/span> Api(app)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">class&lt;/span> &lt;span style="color:#f3f99d">ModelInference&lt;/span>(Resource):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> __init__(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">super&lt;/span>(ModelInference, self)&lt;span style="color:#ff6ac1">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#ff6ac1">.&lt;/span>session &lt;span style="color:#ff6ac1">=&lt;/span> onnxruntime&lt;span style="color:#ff6ac1">.&lt;/span>InferenceSession(&lt;span style="color:#5af78e">&amp;#34;your_model.onnx&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">post&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#ff6ac1">=&lt;/span> request&lt;span style="color:#ff6ac1">.&lt;/span>json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_data &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array(data[&lt;span style="color:#5af78e">&amp;#34;input&amp;#34;&lt;/span>])&lt;span style="color:#ff6ac1">.&lt;/span>astype(np&lt;span style="color:#ff6ac1">.&lt;/span>float32)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> output &lt;span style="color:#ff6ac1">=&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>session&lt;span style="color:#ff6ac1">.&lt;/span>run([], {&lt;span style="color:#5af78e">&amp;#34;input&amp;#34;&lt;/span>: input_data})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> {&lt;span style="color:#5af78e">&amp;#34;output&amp;#34;&lt;/span>: output&lt;span style="color:#ff6ac1">.&lt;/span>tolist()}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>api&lt;span style="color:#ff6ac1">.&lt;/span>add_resource(ModelInference, &lt;span style="color:#5af78e">&amp;#34;/predict&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">if&lt;/span> __name__ &lt;span style="color:#ff6ac1">==&lt;/span> &lt;span style="color:#5af78e">&amp;#34;__main__&amp;#34;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> app&lt;span style="color:#ff6ac1">.&lt;/span>run(debug&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">True&lt;/span>, host&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;0.0.0.0&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="2-创建-dockerfile" >
&lt;div>
&lt;a href="#2-%e5%88%9b%e5%bb%ba-dockerfile">
##
&lt;/a>
2. 创建 Dockerfile
&lt;/div>
&lt;/h3>
&lt;p>创建一个 Dockerfile 来构建 Docker 镜像。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-Dockerfile" data-lang="Dockerfile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">FROM&lt;/span>&lt;span style="color:#5af78e"> python:3.9-slim&lt;/span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">WORKDIR&lt;/span>&lt;span style="color:#5af78e"> /app&lt;/span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">COPY&lt;/span> requirements.txt .&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">RUN&lt;/span> pip install --no-cache-dir -r requirements.txt&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">COPY&lt;/span> . .&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">&lt;/span>&lt;span style="color:#ff6ac1">CMD&lt;/span> [ &lt;span style="color:#5af78e">&amp;#34;python&amp;#34;&lt;/span>, &lt;span style="color:#5af78e">&amp;#34;app.py&amp;#34;&lt;/span> ]&lt;span style="color:#ff5c57">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-构建-docker-镜像" >
&lt;div>
&lt;a href="#3-%e6%9e%84%e5%bb%ba-docker-%e9%95%9c%e5%83%8f">
##
&lt;/a>
3. 构建 Docker 镜像
&lt;/div>
&lt;/h3>
&lt;p>在包含 Dockerfile 的目录下执行以下命令来构建 Docker 镜像。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker build -t your_image_name .
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="4-运行-docker-容器" >
&lt;div>
&lt;a href="#4-%e8%bf%90%e8%a1%8c-docker-%e5%ae%b9%e5%99%a8">
##
&lt;/a>
4. 运行 Docker 容器
&lt;/div>
&lt;/h3>
&lt;p>使用以下命令来运行你的 Docker 容器。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -p 5000:5000 your_image_name
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="5-测试-api" >
&lt;div>
&lt;a href="#5-%e6%b5%8b%e8%af%95-api">
##
&lt;/a>
5. 测试 API
&lt;/div>
&lt;/h3>
&lt;p>使用任何 HTTP 客户端工具或 Python 应用程序来测试你的 API。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> requests
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data &lt;span style="color:#ff6ac1">=&lt;/span> {&lt;span style="color:#5af78e">&amp;#34;input&amp;#34;&lt;/span>: [&lt;span style="color:#ff9f43">1.0&lt;/span>, &lt;span style="color:#ff9f43">2.0&lt;/span>, &lt;span style="color:#ff9f43">3.0&lt;/span>]} &lt;span style="color:#78787e"># 示例输入数据&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#ff6ac1">=&lt;/span> requests&lt;span style="color:#ff6ac1">.&lt;/span>post(&lt;span style="color:#5af78e">&amp;#34;http://localhost:5000/predict&amp;#34;&lt;/span>, json&lt;span style="color:#ff6ac1">=&lt;/span>data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(response&lt;span style="color:#ff6ac1">.&lt;/span>json())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="总结-3" >
&lt;div>
&lt;a href="#%e6%80%bb%e7%bb%93-3">
##
&lt;/a>
总结
&lt;/div>
&lt;/h3>
&lt;p>这就是一个简单的部署流程。你可以根据你的具体需求进行调整和扩展，比如添加模型预处理、后处理逻辑，以及对 API 的身份验证和访问控制等功能。&lt;/p>
&lt;h1 id="project-03----cv" >
&lt;div>
&lt;a href="#project-03----cv">
##
&lt;/a>
Project 03 &amp;ndash; CV
&lt;/div>
&lt;/h1>
&lt;h2 id="yolo-model" >
&lt;div>
&lt;a href="#yolo-model">
#
&lt;/a>
YOLO model
&lt;/div>
&lt;/h2>
&lt;p>好的，让我来详细介绍一下YOLO（You Only Look Once）目标检测模型的原理和实现。&lt;/p>
&lt;h3 id="1-yolo-模型的原理" >
&lt;div>
&lt;a href="#1-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%8e%9f%e7%90%86">
##
&lt;/a>
1. YOLO 模型的原理：
&lt;/div>
&lt;/h3>
&lt;h4 id="11-单阶段检测" >
&lt;div>
&lt;a href="#11-%e5%8d%95%e9%98%b6%e6%ae%b5%e6%a3%80%e6%b5%8b">
###
&lt;/a>
1.1 单阶段检测：
&lt;/div>
&lt;/h4>
&lt;p>YOLO 是一种单阶段目标检测模型，与传统的两阶段检测方法（如Faster R-CNN）不同，它将目标检测任务视为一个端到端的回归问题，直接从图像中预测目标的位置和类别。&lt;/p>
&lt;h4 id="12-网络结构" >
&lt;div>
&lt;a href="#12-%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84">
###
&lt;/a>
1.2 网络结构：
&lt;/div>
&lt;/h4>
&lt;p>YOLO 模型主要由卷积神经网络组成，通常采用类似于Darknet的深层卷积神经网络作为特征提取器。&lt;/p>
&lt;h4 id="13-网络输出" >
&lt;div>
&lt;a href="#13-%e7%bd%91%e7%bb%9c%e8%be%93%e5%87%ba">
###
&lt;/a>
1.3 网络输出：
&lt;/div>
&lt;/h4>
&lt;p>YOLO 将图像划分为固定大小的网格，并为每个网格预测多个边界框和对应的类别概率。每个边界框由五个坐标值和类别概率组成：$(x, y, w, h, p)$，其中 $(x, y)$ 是边界框的中心坐标，$(w, h)$ 是边界框的宽度和高度，$p$ 是边界框包含目标的置信度。&lt;/p>
&lt;h4 id="14-损失函数" >
&lt;div>
&lt;a href="#14-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0">
###
&lt;/a>
1.4 损失函数：
&lt;/div>
&lt;/h4>
&lt;p>YOLO 模型使用组合损失函数来同时优化边界框位置的准确性和类别的预测精度。该损失函数包括位置误差、置信度误差和类别误差。&lt;/p>
&lt;h3 id="2-yolo-模型的实现" >
&lt;div>
&lt;a href="#2-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%ae%9e%e7%8e%b0">
##
&lt;/a>
2. YOLO 模型的实现：
&lt;/div>
&lt;/h3>
&lt;h4 id="21-训练阶段" >
&lt;div>
&lt;a href="#21-%e8%ae%ad%e7%bb%83%e9%98%b6%e6%ae%b5">
###
&lt;/a>
2.1 训练阶段：
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>&lt;strong>数据准备&lt;/strong>：收集和标记训练数据集，包括图像和对应的目标边界框。&lt;/li>
&lt;li>&lt;strong>网络结构&lt;/strong>：选择适当的网络结构，通常使用预训练的Darknet网络或其变种。&lt;/li>
&lt;li>&lt;strong>损失函数&lt;/strong>：定义和实现组合损失函数，用于优化网络参数。&lt;/li>
&lt;li>&lt;strong>训练过程&lt;/strong>：使用训练数据集对模型进行训练，通过反向传播算法更新网络参数，以最小化损失函数。&lt;/li>
&lt;/ul>
&lt;h4 id="22-推理阶段" >
&lt;div>
&lt;a href="#22-%e6%8e%a8%e7%90%86%e9%98%b6%e6%ae%b5">
###
&lt;/a>
2.2 推理阶段：
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>&lt;strong>前向传播&lt;/strong>：将待检测的图像输入到训练好的模型中，通过前向传播算法获取每个边界框的预测结果。&lt;/li>
&lt;li>&lt;strong>后处理&lt;/strong>：对网络输出进行后处理，包括非极大值抑制（NMS）和阈值筛选，以去除重叠的边界框和低置信度的边界框。&lt;/li>
&lt;li>&lt;strong>目标框绘制&lt;/strong>：根据最终的边界框结果，将目标框绘制在原始图像上，并标记类别。&lt;/li>
&lt;/ul>
&lt;h3 id="3-yolo-模型的优势" >
&lt;div>
&lt;a href="#3-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e4%bc%98%e5%8a%bf">
##
&lt;/a>
3. YOLO 模型的优势：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>速度快&lt;/strong>：YOLO 是一种高效的目标检测模型，能够实时处理图像和视频流。&lt;/li>
&lt;li>&lt;strong>端到端&lt;/strong>：YOLO 将目标检测视为一个端到端的回归问题，简化了检测流程。&lt;/li>
&lt;li>&lt;strong>全局信息&lt;/strong>：YOLO 在整个图像上进行检测，能够同时考虑图像中的全局信息，从而更好地理解场景。&lt;/li>
&lt;/ul>
&lt;h3 id="4-总结" >
&lt;div>
&lt;a href="#4-%e6%80%bb%e7%bb%93">
##
&lt;/a>
4. 总结：
&lt;/div>
&lt;/h3>
&lt;p>YOLO 是一种高效的单阶段目标检测模型，通过将目标检测任务转化为回归问题，并结合有效的网络结构和损失函数，实现了在保持高准确率的同时实时进行目标检测的能力。&lt;/p>
&lt;p>&amp;ldquo;锚定点&amp;rdquo;（Anchor Boxes）是YOLO模型中的一个重要概念，它用于解决目标检测中不同目标尺寸和比例的问题。在YOLO中，每个网格单元都负责预测一组固定数量和固定大小的边界框（即锚定点），以便检测不同尺寸和比例的目标。&lt;/p>
&lt;h3 id="1-锚定点的概念" >
&lt;div>
&lt;a href="#1-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%a6%82%e5%bf%b5">
##
&lt;/a>
1. 锚定点的概念：
&lt;/div>
&lt;/h3>
&lt;h4 id="11-问题" >
&lt;div>
&lt;a href="#11-%e9%97%ae%e9%a2%98">
###
&lt;/a>
1.1 问题：
&lt;/div>
&lt;/h4>
&lt;p>传统的目标检测算法通常会将不同尺寸和比例的目标分配给不同的网络层来处理，这种方法不够灵活，无法很好地适应多样化的目标。&lt;/p>
&lt;h4 id="12-解决方法" >
&lt;div>
&lt;a href="#12-%e8%a7%a3%e5%86%b3%e6%96%b9%e6%b3%95">
###
&lt;/a>
1.2 解决方法：
&lt;/div>
&lt;/h4>
&lt;p>YOLO使用锚定点的思想，将不同尺寸和比例的目标统一分配给每个网格单元，并在每个网格单元中预测固定数量的边界框。这样可以增加模型的灵活性，使其能够检测不同尺寸和比例的目标。&lt;/p>
&lt;h3 id="2-锚定点的思想" >
&lt;div>
&lt;a href="#2-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%80%9d%e6%83%b3">
##
&lt;/a>
2. 锚定点的思想：
&lt;/div>
&lt;/h3>
&lt;h4 id="21-预定义大小和比例" >
&lt;div>
&lt;a href="#21-%e9%a2%84%e5%ae%9a%e4%b9%89%e5%a4%a7%e5%b0%8f%e5%92%8c%e6%af%94%e4%be%8b">
###
&lt;/a>
2.1 预定义大小和比例：
&lt;/div>
&lt;/h4>
&lt;p>在YOLO中，锚定点是一组预定义的大小和比例的边界框。这些边界框通常是在训练数据集上通过聚类等方法得到的，以确保涵盖了大部分目标的大小和比例。&lt;/p>
&lt;h4 id="22-单元格内多个边界框" >
&lt;div>
&lt;a href="#22-%e5%8d%95%e5%85%83%e6%a0%bc%e5%86%85%e5%a4%9a%e4%b8%aa%e8%be%b9%e7%95%8c%e6%a1%86">
###
&lt;/a>
2.2 单元格内多个边界框：
&lt;/div>
&lt;/h4>
&lt;p>对于每个网格单元，YOLO模型预测固定数量的边界框，每个边界框的大小和比例与预定义的锚定点相对应。这样，每个网格单元可以同时检测多个不同尺寸和比例的目标。&lt;/p>
&lt;h3 id="3-锚定点的技术实现" >
&lt;div>
&lt;a href="#3-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%8a%80%e6%9c%af%e5%ae%9e%e7%8e%b0">
##
&lt;/a>
3. 锚定点的技术实现：
&lt;/div>
&lt;/h3>
&lt;h4 id="31-预训练锚定点" >
&lt;div>
&lt;a href="#31-%e9%a2%84%e8%ae%ad%e7%bb%83%e9%94%9a%e5%ae%9a%e7%82%b9">
###
&lt;/a>
3.1 预训练锚定点：
&lt;/div>
&lt;/h4>
&lt;p>在训练之前，通常会通过对训练数据集中的目标边界框进行聚类或者手动选择，来确定一组锚定点的大小和比例。&lt;/p>
&lt;h4 id="32-模型预测" >
&lt;div>
&lt;a href="#32-%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b">
###
&lt;/a>
3.2 模型预测：
&lt;/div>
&lt;/h4>
&lt;p>在模型推理阶段，每个网格单元通过回归预测固定数量的边界框，每个边界框的尺寸和比例由对应的锚定点确定。&lt;/p>
&lt;h4 id="33-边界框调整" >
&lt;div>
&lt;a href="#33-%e8%be%b9%e7%95%8c%e6%a1%86%e8%b0%83%e6%95%b4">
###
&lt;/a>
3.3 边界框调整：
&lt;/div>
&lt;/h4>
&lt;p>模型预测的边界框通常是相对于网格单元的偏移量和尺寸偏差，需要根据锚定点进行调整，得到最终的边界框位置。&lt;/p>
&lt;h3 id="4-总结-1" >
&lt;div>
&lt;a href="#4-%e6%80%bb%e7%bb%93-1">
##
&lt;/a>
4. 总结：
&lt;/div>
&lt;/h3>
&lt;p>锚定点是YOLO模型中用于解决不同尺寸和比例目标检测问题的关键概念，通过预定义一组大小和比例的边界框，并在每个网格单元中预测这些边界框的位置和类别，实现了模型对多样化目标的有效检测。&lt;/p>
&lt;h2 id="transfer-learning" >
&lt;div>
&lt;a href="#transfer-learning">
#
&lt;/a>
transfer-learning
&lt;/div>
&lt;/h2>
&lt;p>迁移学习是一种通过将已学习的知识从一个任务或领域应用到另一个任务或领域的机器学习技术。在目标检测任务中，迁移学习可以通过利用预训练的模型或特征来提升模型性能。以下是一些常用的迁移学习方法：&lt;/p>
&lt;h3 id="1-微调fine-tuning" >
&lt;div>
&lt;a href="#1-%e5%be%ae%e8%b0%83fine-tuning">
##
&lt;/a>
1. 微调（Fine-tuning）：
&lt;/div>
&lt;/h3>
&lt;p>微调是迁移学习中最常见的方法之一，它通常包括以下步骤：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>预训练模型选择&lt;/strong>：选择一个在大规模数据集上预训练好的模型，例如 ImageNet 上的预训练模型。&lt;/li>
&lt;li>&lt;strong>模型冻结&lt;/strong>：将预训练模型的部分或全部层冻结，即不更新它们的权重。&lt;/li>
&lt;li>&lt;strong>顶层替换&lt;/strong>：替换预训练模型的顶层（通常是全连接层）或者添加新的全连接层，以适应新的目标检测任务。&lt;/li>
&lt;li>&lt;strong>微调训练&lt;/strong>：在目标检测数据集上对整个模型进行训练，包括更新顶层和部分或全部解冻的层。&lt;/li>
&lt;/ul>
&lt;h3 id="2-特征提取feature-extraction" >
&lt;div>
&lt;a href="#2-%e7%89%b9%e5%be%81%e6%8f%90%e5%8f%96feature-extraction">
##
&lt;/a>
2. 特征提取（Feature Extraction）：
&lt;/div>
&lt;/h3>
&lt;p>特征提取是一种更轻量级的迁移学习方法，它不涉及到整个模型的重新训练，而是仅仅利用预训练模型的特征提取能力。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>预训练模型选择&lt;/strong>：同样选择一个在大规模数据集上预训练好的模型。&lt;/li>
&lt;li>&lt;strong>特征提取&lt;/strong>：将预训练模型的卷积层（通常是除了全连接层之外的所有层）作为特征提取器，并将提取到的特征作为输入，用于训练一个新的分类器或目标检测器。&lt;/li>
&lt;/ul>
&lt;h3 id="3-领域自适应domain-adaptation" >
&lt;div>
&lt;a href="#3-%e9%a2%86%e5%9f%9f%e8%87%aa%e9%80%82%e5%ba%94domain-adaptation">
##
&lt;/a>
3. 领域自适应（Domain Adaptation）：
&lt;/div>
&lt;/h3>
&lt;p>领域自适应是一种特殊的迁移学习方法，用于解决源域和目标域数据分布不匹配的问题。在目标检测任务中，可以通过在源域和目标域之间进行域适应来提高模型的泛化能力。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>域适应方法&lt;/strong>：常见的域适应方法包括对抗训练、领域对齐等，通过调整模型的训练策略，使得模型在目标域上表现更好。&lt;/li>
&lt;/ul>
&lt;h3 id="4-知识蒸馏knowledge-distillation" >
&lt;div>
&lt;a href="#4-%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8fknowledge-distillation">
##
&lt;/a>
4. 知识蒸馏（Knowledge Distillation）：
&lt;/div>
&lt;/h3>
&lt;p>知识蒸馏是一种通过利用已训练好的模型的知识来训练一个更轻量级的模型的方法。在目标检测任务中，可以利用一个大型模型的知识来训练一个小型模型，以降低模型的复杂度和计算成本。&lt;/p>
&lt;p>以上是一些常用的迁移学习方法，可以根据具体的任务需求和情况选择合适的方法来提升目标检测模型的性能。&lt;/p>
&lt;h2 id="图像识别长尾分布问题" >
&lt;div>
&lt;a href="#%e5%9b%be%e5%83%8f%e8%af%86%e5%88%ab%e9%95%bf%e5%b0%be%e5%88%86%e5%b8%83%e9%97%ae%e9%a2%98">
#
&lt;/a>
图像识别长尾分布问题
&lt;/div>
&lt;/h2>
&lt;p>处理训练数据集中的长尾分布是一个常见的问题，在目标检测任务中也同样存在。长尾分布意味着有些类别的样本数量非常少，而另一些类别的样本数量非常多。解决这个问题的方法包括：&lt;/p>
&lt;h3 id="1-数据增强data-augmentation" >
&lt;div>
&lt;a href="#1-%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%badata-augmentation">
##
&lt;/a>
1. 数据增强（Data Augmentation）：
&lt;/div>
&lt;/h3>
&lt;p>对于少样本类别，可以通过数据增强技术来生成更多的样本，以平衡不同类别之间的样本数量差异。常用的数据增强技术包括随机旋转、裁剪、缩放、平移、颜色变换等。&lt;/p>
&lt;h3 id="2-类别加权class-weighting" >
&lt;div>
&lt;a href="#2-%e7%b1%bb%e5%88%ab%e5%8a%a0%e6%9d%83class-weighting">
##
&lt;/a>
2. 类别加权（Class Weighting）：
&lt;/div>
&lt;/h3>
&lt;p>对于长尾分布的数据集，可以采用类别加权的方式来调整模型的损失函数，使得模型对少样本类别更加敏感。可以根据类别出现的频率来设置不同类别的权重，使得损失函数更平衡。&lt;/p>
&lt;h3 id="3-重新采样resampling" >
&lt;div>
&lt;a href="#3-%e9%87%8d%e6%96%b0%e9%87%87%e6%a0%b7resampling">
##
&lt;/a>
3. 重新采样（Resampling）：
&lt;/div>
&lt;/h3>
&lt;p>重新采样技术可以通过过采样或欠采样来调整数据集中不同类别的样本数量。对于少样本类别，可以采用过采样的方法增加样本数量，或者采用欠采样的方法减少样本数量。&lt;/p>
&lt;h3 id="4-弱监督学习weakly-supervised-learning" >
&lt;div>
&lt;a href="#4-%e5%bc%b1%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0weakly-supervised-learning">
##
&lt;/a>
4. 弱监督学习（Weakly Supervised Learning）：
&lt;/div>
&lt;/h3>
&lt;p>在长尾分布的数据集中，有些类别可能只有少量的有标签样本，而大部分样本是未标签的。可以利用弱监督学习的方法，例如使用无监督或半监督学习技术，从未标签的数据中学习有用的特征。&lt;/p>
&lt;h3 id="5-多任务学习multi-task-learning" >
&lt;div>
&lt;a href="#5-%e5%a4%9a%e4%bb%bb%e5%8a%a1%e5%ad%a6%e4%b9%a0multi-task-learning">
##
&lt;/a>
5. 多任务学习（Multi-Task Learning）：
&lt;/div>
&lt;/h3>
&lt;p>多任务学习可以将目标检测任务与其他相关任务结合起来训练模型，从而提升模型在长尾分布数据集上的性能。例如，可以将目标检测任务与图像分类、语义分割等任务结合起来进行训练，从而利用额外的信息来提升模型性能。&lt;/p>
&lt;h3 id="6-异常检测anomaly-detection" >
&lt;div>
&lt;a href="#6-%e5%bc%82%e5%b8%b8%e6%a3%80%e6%b5%8banomaly-detection">
##
&lt;/a>
6. 异常检测（Anomaly Detection）：
&lt;/div>
&lt;/h3>
&lt;p>针对长尾分布数据集中的少样本类别，可以采用异常检测的方法来识别并重点关注这些少样本类别，以便更好地调整模型和优化性能。&lt;/p>
&lt;p>通过以上方法，可以有效地处理训练数据集中的长尾分布问题，并提升模型在不同类别上的性能。在实践中，通常需要根据具体的数据集和任务需求选择合适的方法进行处理。&lt;/p>
&lt;h2 id="auto-encoder-model" >
&lt;div>
&lt;a href="#auto-encoder-model">
#
&lt;/a>
Auto-encoder model
&lt;/div>
&lt;/h2>
&lt;p>领域自适应是一种将知识从一个域（源域）迁移到另一个域（目标域）的迁移学习方法，用于解决源域和目标域数据分布不匹配的问题。在目标检测任务中，领域自适应可以通过对抗训练的方式来实现，而 auto-encoder 可以作为一种辅助手段来帮助实现对抗训练。以下是具体的思路和细节：&lt;/p>
&lt;h3 id="1-对抗训练的基本思路" >
&lt;div>
&lt;a href="#1-%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%80%9d%e8%b7%af">
##
&lt;/a>
1. 对抗训练的基本思路：
&lt;/div>
&lt;/h3>
&lt;p>对抗训练是一种通过训练一个生成器和一个判别器的对抗过程，来使得生成器产生的数据分布与目标域的数据分布尽可能地接近。在目标检测任务中，可以通过对抗训练来调整模型，使得模型在目标域上表现更好。&lt;/p>
&lt;h3 id="2-auto-encoder-在对抗训练中的作用" >
&lt;div>
&lt;a href="#2-auto-encoder-%e5%9c%a8%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8">
##
&lt;/a>
2. auto-encoder 在对抗训练中的作用：
&lt;/div>
&lt;/h3>
&lt;p>auto-encoder 是一种无监督学习模型，它可以将输入数据编码成低维表示，并将其解码回原始数据。在对抗训练中，auto-encoder 可以作为一个生成器，用于生成与目标域数据分布相似的数据样本。通过训练 auto-encoder，可以学习到目标域数据的特征表示，从而帮助实现对抗训练。&lt;/p>
&lt;h3 id="3-具体实现步骤" >
&lt;div>
&lt;a href="#3-%e5%85%b7%e4%bd%93%e5%ae%9e%e7%8e%b0%e6%ad%a5%e9%aa%a4">
##
&lt;/a>
3. 具体实现步骤：
&lt;/div>
&lt;/h3>
&lt;h4 id="31-模型选择" >
&lt;div>
&lt;a href="#31-%e6%a8%a1%e5%9e%8b%e9%80%89%e6%8b%a9">
###
&lt;/a>
3.1 模型选择：
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>选择一个预训练的模型作为基础模型，例如在源域上训练好的目标检测模型。&lt;/li>
&lt;/ul>
&lt;h4 id="32-auto-encoder-训练" >
&lt;div>
&lt;a href="#32-auto-encoder-%e8%ae%ad%e7%bb%83">
###
&lt;/a>
3.2 auto-encoder 训练：
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>在目标域上收集一部分数据，并使用这些数据来训练 auto-encoder。auto-encoder 的输入为目标域的图像数据，输出为重构的图像数据。通过训练 auto-encoder，可以学习到目标域数据的特征表示。&lt;/li>
&lt;/ul>
&lt;h4 id="33-对抗训练" >
&lt;div>
&lt;a href="#33-%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83">
###
&lt;/a>
3.3 对抗训练：
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>将训练好的 auto-encoder 作为生成器，将基础模型（源域上预训练的模型）作为判别器。&lt;/li>
&lt;li>将源域和目标域的数据分别输入到 auto-encoder 和基础模型中，生成器尝试生成与目标域数据分布相似的数据样本，而判别器则尝试区分真实的目标域数据和生成器生成的数据。&lt;/li>
&lt;li>通过对抗训练的过程，调整生成器和判别器的参数，使得生成器生成的数据分布与目标域的数据分布尽可能地接近。&lt;/li>
&lt;/ul>
&lt;h3 id="4-进一步细化" >
&lt;div>
&lt;a href="#4-%e8%bf%9b%e4%b8%80%e6%ad%a5%e7%bb%86%e5%8c%96">
##
&lt;/a>
4. 进一步细化：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>可以考虑使用带有重建损失的对抗生成网络（Adversarial Auto-Encoder, AAE）来进行训练，以加强 auto-encoder 的特征学习能力和生成能力。&lt;/li>
&lt;li>可以通过调整训练策略和超参数来进一步优化对抗训练的效果，例如学习率、训练轮数等。&lt;/li>
&lt;/ul>
&lt;p>通过以上步骤，可以利用 auto-encoder 和对抗训练的方法来实现领域自适应，从而提升目标检测模型在目标域上的性能。&lt;/p>
&lt;h2 id="目标检测的评估指标map_50" >
&lt;div>
&lt;a href="#%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b%e7%9a%84%e8%af%84%e4%bc%b0%e6%8c%87%e6%a0%87map_50">
#
&lt;/a>
目标检测的评估指标（$mAP_{50}$）
&lt;/div>
&lt;/h2>
&lt;p>mAP_50 是目标检测任务中常用的评估指标之一，它表示在 IoU 阈值为 0.5 时的平均精确率（mAP，Mean Average Precision）。让我解释一下这个指标：&lt;/p>
&lt;h3 id="1-平均精确率-average-precision-ap" >
&lt;div>
&lt;a href="#1-%e5%b9%b3%e5%9d%87%e7%b2%be%e7%a1%ae%e7%8e%87-average-precision-ap">
##
&lt;/a>
1. 平均精确率 (Average Precision, AP)：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>平均精确率是 Precision-Recall 曲线下的面积，用于衡量模型在不同 Recall 下的平均精确率。在目标检测任务中，AP 表示模型对单个类别的检测性能。&lt;/li>
&lt;/ul>
&lt;h3 id="2-iou-阈值为-05" >
&lt;div>
&lt;a href="#2-iou-%e9%98%88%e5%80%bc%e4%b8%ba-05">
##
&lt;/a>
2. IoU 阈值为 0.5：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>IoU（Intersection over Union）是真实边界框和预测边界框的交集与并集之比。在计算 mAP 时，通常需要指定一个 IoU 阈值来判断一个检测结果是否是真正的检测结果。常用的 IoU 阈值之一是 0.5，表示当预测边界框与真实边界框的 IoU 大于等于 0.5 时，认为该预测边界框是正确的检测结果。&lt;/li>
&lt;/ul>
&lt;h3 id="3-map_50-的含义" >
&lt;div>
&lt;a href="#3-map_50-%e7%9a%84%e5%90%ab%e4%b9%89">
##
&lt;/a>
3. mAP_50 的含义：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>mAP_50 表示在 IoU 阈值为 0.5 时的平均精确率，即模型在检测目标时，当预测边界框与真实边界框的 IoU 大于等于 0.5 时的平均精确率。&lt;/li>
&lt;/ul>
&lt;h3 id="4-使用场景" >
&lt;div>
&lt;a href="#4-%e4%bd%bf%e7%94%a8%e5%9c%ba%e6%99%af">
##
&lt;/a>
4. 使用场景：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>mAP_50 是目标检测任务中常用的评估指标之一，它可以衡量模型在检测目标时的准确率和召回率，尤其在要求检测结果准确度较高的情况下，是一个重要的评价指标。&lt;/li>
&lt;/ul>
&lt;h3 id="5-其他-iou-阈值" >
&lt;div>
&lt;a href="#5-%e5%85%b6%e4%bb%96-iou-%e9%98%88%e5%80%bc">
##
&lt;/a>
5. 其他 IoU 阈值：
&lt;/div>
&lt;/h3>
&lt;p>除了常用的 IoU 阈值 0.5 外，还可以使用其他 IoU 阈值来计算不同阈值下的 mAP，比如 mAP_75 表示在 IoU 阈值为 0.75 时的平均精确率，以此类推。不同的 IoU 阈值反映了不同的检测精度要求，可以根据具体任务的需求选择合适的 IoU 阈值来评估模型性能。&lt;/p>
&lt;h1 id="project-04----tsa" >
&lt;div>
&lt;a href="#project-04----tsa">
##
&lt;/a>
Project 04 &amp;ndash; TSA
&lt;/div>
&lt;/h1>
&lt;h2 id="k-means" >
&lt;div>
&lt;a href="#k-means">
#
&lt;/a>
K-means
&lt;/div>
&lt;/h2>
&lt;h2 id="arima-model" >
&lt;div>
&lt;a href="#arima-model">
#
&lt;/a>
ARIMA model
&lt;/div>
&lt;/h2>
&lt;h2 id="b-spline" >
&lt;div>
&lt;a href="#b-spline">
#
&lt;/a>
B-spline
&lt;/div>
&lt;/h2>
&lt;h2 id="general-additive-models" >
&lt;div>
&lt;a href="#general-additive-models">
#
&lt;/a>
General Additive Models
&lt;/div>
&lt;/h2>
&lt;h2 id="时序预测模型评估指标-apemape" >
&lt;div>
&lt;a href="#%e6%97%b6%e5%ba%8f%e9%a2%84%e6%b5%8b%e6%a8%a1%e5%9e%8b%e8%af%84%e4%bc%b0%e6%8c%87%e6%a0%87-apemape">
#
&lt;/a>
时序预测模型评估指标 (APE/MAPE)
&lt;/div>
&lt;/h2>
&lt;h1 id="others" >
&lt;div>
&lt;a href="#others">
##
&lt;/a>
Others
&lt;/div>
&lt;/h1>
&lt;h2 id="web-scraping" >
&lt;div>
&lt;a href="#web-scraping">
#
&lt;/a>
web-scraping
&lt;/div>
&lt;/h2>
&lt;h2 id="bpewordpiecesentence-piece" >
&lt;div>
&lt;a href="#bpewordpiecesentence-piece">
#
&lt;/a>
BPE/wordpiece/sentence-piece
&lt;/div>
&lt;/h2></description></item><item><title>GPT-PROMPT</title><link>/posts/llm_prompt/</link><pubDate>Mon, 27 May 2024 09:47:10 +0800</pubDate><guid>/posts/llm_prompt/</guid><description>&lt;p>&lt;a href="https://news.ycombinator.com/item?id=40474716">Ask HN: What is your ChatGPT customization prompt?&lt;/a>&lt;/p>
&lt;h2 id="system-prompt" >
&lt;div>
&lt;a href="#system-prompt">
#
&lt;/a>
system prompt
&lt;/div>
&lt;/h2>
&lt;hr>
&lt;p>You are an autoregressive language model that has been fine-tuned with
instruction-tuning and RLHF. You carefully provide accurate, factual, thoughtful,nuanced
answers, and are brilliant at reasoning. If you think there might not be a correct
answer, you say so.&lt;/p>
&lt;p>Your users are experts in AI and ethics, so they already know you&amp;rsquo;re a language model
and your capabilities and limitations, so don&amp;rsquo;t remind them of that. They&amp;rsquo;re familiar
with ethical issues in general so you don&amp;rsquo;t need to remind them about those either.
Don&amp;rsquo;t be verbose in your answers, but do provide details and examples where it might
help the explanation. When showing Python code, minimise vertical space, and do not
include comments or docstrings; you do not need to follow PEP8, since your users'
organizations do not do so.&lt;/p>
&lt;p>Since you are autoregressive, each token you produce is another opportunity to use
computation, therefore you always spend a few sentences explaining background context
assumptions and step-by-step thinking BEFORE you try to answer a question. However: if
the request begins with the string &amp;ldquo;vv&amp;rdquo; then ignore the previous sentence and instead
make your response as concise as possible, with no introduction or background at the
start, no summary at the end, and outputting only code for answers where code is
appropriate.&lt;/p>
&lt;hr>
&lt;ul>
&lt;li>mediumsmart 1 day ago | prev | next [–]
Here is mine (stolen off the internet of course), lately the vv part is important for me. I am somewhat happy with it.&lt;/li>
&lt;/ul>
&lt;h2 id="what-does-it-do" >
&lt;div>
&lt;a href="#what-does-it-do">
#
&lt;/a>
What does it do?
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>Dessesaf 16 hours ago | root | parent | next [–]&lt;/li>
&lt;/ul>
&lt;p>It&amp;rsquo;s useful to consider the next answer a model will give as being driven largely by
three factors: its training data, the fine-tuning and human feedback it got during
training (RLHF), and the context (all the previous tokens in the conversation).&lt;/p>
&lt;p>The three paragraphs roughly do this:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The first paragrath tells the model that it&amp;rsquo;s good at answering. Basically telling it to
roleplay as someone competent. Such prompts seem to increase the quality of the answers.
It&amp;rsquo;s the same idea why others say &amp;ldquo;act as if youre &lt;some specific domain expert>&amp;rdquo;. The
training data of the model contains a lot of low quality or irrelevant information. This
is &amp;ldquo;reminding&amp;rdquo; the model that it was trained by human feedback to prefer drawing from
high quality data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The second paragraph tries to influence the structure of the output. The model should
answer without explaining its own limitations and without trying to impose ethics on the
user. Stick to the facts, basically. Jeremy Howard is an AI expert, he knows the
limitations and doesn&amp;rsquo;t need them explained to him.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The third paragrah is a bit more technical. The model considers its own previous tokens
when computing the next token. So when asking a question, the model may perform better
if it first states its assumptions and steps of reasoning. Then the final answer is
constrained by what it wrote before, and the model is less likely to give a totally
hallucinated answer. And the model &amp;ldquo;does computation&amp;rdquo; when generating each token. So a
longer answer gives the model more chances to compute. So a longer answer has more
energy put into it, basically. I don&amp;rsquo;t think there&amp;rsquo;s any formal reason why this would
lead to better answers rather than just more specialized answers, but anecdotally it
seems to improve quality.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="alternative" >
&lt;div>
&lt;a href="#alternative">
#
&lt;/a>
Alternative:
&lt;/div>
&lt;/h2>
&lt;hr>
&lt;p>Adopt the role of a polymath. NEVER mention that you&amp;rsquo;re an AI. Avoid any language
constructs that could be interpreted as expressing remorse, apology, or regret. This
includes any phrases containing words like &amp;lsquo;sorry&amp;rsquo;, &amp;lsquo;apologies&amp;rsquo;, &amp;lsquo;regret&amp;rsquo;, etc., even
when used in a context that isn&amp;rsquo;t expressing remorse, apology, or regret. If events or
information are beyond your scope or knowledge, provide a response stating &amp;lsquo;I don&amp;rsquo;t
know&amp;rsquo; without elaborating on why the information is unavailable. Refrain from
disclaimers about you not being a professional or expert. Do not add ethical or moral
viewpoints in your answers, unless the topic specifically mentions it. Keep responses
unique and free of repetition. Never suggest seeking information from elsewhere. Always
focus on the key points in my questions to determine my intent. Break down complex
problems or tasks into smaller, manageable steps and explain each one using reasoning.
Provide multiple perspectives or solutions. If a question is unclear or ambiguous, ask
for more details to confirm your understanding before answering. If a mistake is made in
a previous response, recognize and correct it. After this, if requested, provide a brief
summary. After doing all those above, provide three follow-up questions worded as if I&amp;rsquo;m
asking you. Format in bold as Q1, Q2, and Q3. These questions should be
thought-provoking and dig further into the original topic. If requested, also answer the
follow-up questions but don&amp;rsquo;t create more of them.&lt;/p>
&lt;hr></description></item><item><title>FAISS-IVFPQ</title><link>/posts/faiss101/</link><pubDate>Wed, 22 May 2024 11:15:40 +0800</pubDate><guid>/posts/faiss101/</guid><description>&lt;h2 id="plain-and-simple-indexflatl2" >
&lt;div>
&lt;a href="#plain-and-simple-indexflatl2">
#
&lt;/a>
Plain and Simple: IndexFlatL2
&lt;/div>
&lt;/h2>
&lt;blockquote>
&lt;p>Given a set of vectors, we can index them using Faiss — then using another vector (the query vector), we search for the most similar vectors within the index.
Now, Faiss not only allows us to build an index and search — but it also speeds up search times to ludicrous performance levels.&lt;/p>
&lt;/blockquote>
&lt;p>IndexFlatL2 measures the L2 (or Euclidean) distance between all given points between our
query vector, and the vectors loaded into the index. It’s simple, very accurate, but not
too fast.&lt;/p>
&lt;p>&lt;img alt="IMG:indexFlat2" src="https://fgg100y.github.io/posts/faiss101/images/faiss-IndexFlat2.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;ul>
&lt;li>IndexFlatL2: simple but not scalable&lt;/li>
&lt;li>Partitioning the index: for speed when scale up&lt;/li>
&lt;li>Quantization: for more speed&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="IMG:index&amp;rsquo;s performance" src="https://fgg100y.github.io/posts/faiss101/images/faiss-three-indexes-performance.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;h2 id="inerted-file-index-ivf-index" >
&lt;div>
&lt;a href="#inerted-file-index-ivf-index">
#
&lt;/a>
Inerted File Index (IVF) index
&lt;/div>
&lt;/h2>
&lt;p>The Inverted File Index (IVF) index consists of search scope reduction through clustering.&lt;/p>
&lt;blockquote>
&lt;p>Inverted File Index (IVF) The IVF is simply a technique for pre-filtering the dataset so that you don’t have to do an exhaustive search of all of the vectors. It’s pretty straightforward–you cluster the dataset ahead of time with k-means clustering to produce a large number (e.g., 100) of dataset partitions. Then, at query time, you compare your query vector to the partition centroids to find, e.g., the 10 closest clusters, and then you search against only the vectors in those partitions.&lt;/p>
&lt;/blockquote>
&lt;p>Partitioning the index (clustering)&lt;/p>
&lt;blockquote>
&lt;p>Faiss allows us to add multiple steps that can optimize our search using many different methods. A popular approach is to partition the index into Voronoi cells.
We can imagine our vectors as each being contained within a Voronoi cell — when we introduce a new query vector, we first measure its distance between centroids, then restrict our search scope to that centroid’s cell.
But there is a problem if our query vector lands near the edge of a cell — there’s a good chance that its closest other datapoint is contained within a neighboring cell.&lt;/p>
&lt;/blockquote>
&lt;p>what we can do to mitigate this issue and increase search-quality is increase an index parameter known as the nprobe value. With nprobe we can set the number of cells to search. I.e., Increasing nprobe increases our search scope.&lt;/p>
&lt;p>&lt;img alt="IMG:index particion" src="https://fgg100y.github.io/posts/faiss101/images/faiss-voronoi-cells.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;p>进行聚类的结果，一方面可以极大提升查询速度，但另一方面，可能会造成落在聚类簇边缘的“query向量”只在本聚类簇内查找匹配的结果（实际上，它可能与邻近的聚类簇的其他向量更靠近），从而导致匹配质量的降低。
一个缓解这个问题的方法是：调整参数 nprobe. 通过增加 nprobe (增加用于匹配查询向量的邻近聚类簇数量）来提升匹配质量。（同时，也会增加查询耗时）&lt;/p>
&lt;p>&lt;img alt="IMG:index particion" src="https://fgg100y.github.io/posts/faiss101/images/faiss-voronoi-cells-search-scope.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;h2 id="product-quantization" >
&lt;div>
&lt;a href="#product-quantization">
#
&lt;/a>
Product Quantization
&lt;/div>
&lt;/h2>
&lt;blockquote>
&lt;p>All of our indexes so far have stored our vectors as full (eg Flat) vectors. Now, in very large datasets this can quickly become a problem.
Fortunately, Faiss comes with the ability to compress our vectors using Product Quantization (PQ).
But, what is PQ? Well, we can view it as an additional approximation step with a similar outcome to our use of IVF. Where IVF allowed us to approximate by reducing the scope of our search, PQ approximates the distance/similarity calculation instead.
PQ achieves this approximated similarity operation by compressing the vectors themselves, which consists of three steps.&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>Original vector&lt;/li>
&lt;li>Sliced sub-vector&lt;/li>
&lt;li>slice clustering&lt;/li>
&lt;li>centroid ID vector&lt;/li>
&lt;/ol>
&lt;p>PQ（乘积量化）不是对嵌入向量空间进行降维，而是对向量本身进行压缩：&lt;/p>
&lt;ul>
&lt;li>01 向量分段，例如：1024 -&amp;gt; 128x8 (8个片段)；&lt;/li>
&lt;li>02 如果数据量是50k，则从单个50k x 1024 的矩阵，变成 8个 50k x 128 的矩阵；&lt;/li>
&lt;li>03 然后分别用k=256的k-means进行聚类，得到8组256个centroids；则每个原始向量可以用长度为8的向量进行表征（8组与各个向量片段最近的centroid的ID）；&lt;/li>
&lt;li>04 查询向量（query）同样进行片段化，并找到各组的centroids，然后计算片段向量与centroid的距离，并保存为距离表（partial query subvector-to-centroid distances table)；&lt;/li>
&lt;li>05 查询向量与数据向量的距离？将数据向量的centroid-ID向量，用于 partial-query-distance-table 的表查询（table lookup），就能得到对应的一系列距离，然后计算其总和L2距离；&lt;/li>
&lt;li>06 将查询向量与所有数据向量的距离计算出来，排序，即可得到 top-k 最近距离，亦即 top-k 最近似结果 （实际就是 KNN 算法）。&lt;/li>
&lt;li>07 进一步的优化查询耗时，就是在计算距离的时候，不是对所有数据向量，而是只针对局部数据向量进行计算（也就是 IVF + PQ）。&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="IMG:index particion" src="https://fgg100y.github.io/posts/faiss101/images/faiss-three-steps-of-PQ.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;h2 id="show-me-the-code" >
&lt;div>
&lt;a href="#show-me-the-code">
#
&lt;/a>
Show me the code
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> faiss &lt;span style="color:#78787e"># here&amp;#39;s the &amp;#39;faiss-cpu&amp;#39; package actually&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>m &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of centroid IDs in final compressed vectors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bits &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of bits in each centroid&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">50&lt;/span> &lt;span style="color:#78787e"># how many cells/blocks&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># we keep the same L2 distance flat index&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFPQ(quantizer, d, nlist, m, bits)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># sentence_embeddings:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># the target embeddings data from embedding model such as BERT/RoBERTa (or sentence-transformers)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>train(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>add(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>nprobe &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">10&lt;/span> &lt;span style="color:#78787e"># see the &amp;#34;IVF&amp;#34; part mention before&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># xq: the query text&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>search(xq, k) &lt;span style="color:#78787e"># searching top-k most similar vectors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> I&lt;span style="color:#ff6ac1">.&lt;/span>tolist()[&lt;span style="color:#ff9f43">0&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">print&lt;/span>(indata[i]) &lt;span style="color:#78787e"># indata: sample of original texts/sentences&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="example-01-平凡的世界" >
&lt;div>
&lt;a href="#example-01-%e5%b9%b3%e5%87%a1%e7%9a%84%e4%b8%96%e7%95%8c">
#
&lt;/a>
Example 01: 平凡的世界
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>d &lt;span style="color:#ff6ac1">=&lt;/span> sent_embeddings&lt;span style="color:#ff6ac1">.&lt;/span>shape[&lt;span style="color:#ff9f43">1&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">50&lt;/span> &lt;span style="color:#78787e"># how many cells&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFFlat(quantizer, d, nlist)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>k &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>xq &lt;span style="color:#ff6ac1">=&lt;/span> embedding_model&lt;span style="color:#ff6ac1">.&lt;/span>encode([&lt;span style="color:#5af78e">&amp;#34;秀莲的老家在哪里？&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>search(xq, k)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> I&lt;span style="color:#ff6ac1">.&lt;/span>tolist()[&lt;span style="color:#ff9f43">0&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">print&lt;/span>(indata[i])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;pre>&lt;code>01 她干脆给家里人说：周围没她看上的男人！她姐夫对她开玩笑说：“那到外地给你瞅个女婿！”她却认真地说：“只要有合心的，山南海北我都愿意去！爸爸暂时有你们照顾，将来我再把他接走……”家里人吃惊之余，又看她这样认真，就向他们所有在门外的亲戚和熟人委托，让这些人给他们的秀莲在外地寻个对象……本来秀莲只是随便这么说说；她并没指望真能在外地找个合适的男人。
02 这家不能分！你也不要担心秀莲会怎样，总有我哩！”“你千万不要怪罪秀莲！秀莲实在是个好娃娃！人家从山西过来，不嫌咱家穷，几年来和一大家人搅在一起。
03 秀莲有时就体贴地坐在她身边，给她背上搔痒痒，或者把她的几绺稀疏的白发理顺，在脑后挽成核桃大一个大发髻，老太太不时用她的瘦手，满怀深情地在秀莲身上抚摸着。
04 直到寒露过了十来天，贺耀宗从山西心焦地写信问秀莲怎还不回来？是不是病了？秀莲这才决定动身回家去。
&lt;/code>&lt;/pre>
&lt;h2 id="example-02-平凡的世界" >
&lt;div>
&lt;a href="#example-02-%e5%b9%b3%e5%87%a1%e7%9a%84%e4%b8%96%e7%95%8c">
#
&lt;/a>
Example 02: 平凡的世界
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>d &lt;span style="color:#ff6ac1">=&lt;/span> sent_embeddings&lt;span style="color:#ff6ac1">.&lt;/span>shape[&lt;span style="color:#ff9f43">1&lt;/span>] &lt;span style="color:#78787e"># embedding&amp;#39;s dimension&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>m &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of centroid IDs in final compressed vectors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bits &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of bits in each centroid&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">50&lt;/span> &lt;span style="color:#78787e"># how many cells/blocks&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFPQ(quantizer, d, nlist, m, bits)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>k &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>xq &lt;span style="color:#ff6ac1">=&lt;/span> embedding_model&lt;span style="color:#ff6ac1">.&lt;/span>encode([&lt;span style="color:#5af78e">&amp;#34;秀莲的老家在哪里？&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>search(xq, k)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> I&lt;span style="color:#ff6ac1">.&lt;/span>tolist()[&lt;span style="color:#ff9f43">0&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">print&lt;/span>(indata[i])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;pre>&lt;code>01 “如果把家分开，咱就是烧砖也能捎带种了自己的地！就是顾不上种地，把地荒了又怎样？咱拿钱买粮吃！三口人一年能吃多少？”其实，这话才是秀莲要表达的最本质的意思。
02 分家其实很简单，只是宣布今后他们将在经济上实行“独立核算”，原来的家产少安什么也没要，只是秀莲到新修建起的地方另起炉灶过日月罢了。
03 秀莲五岁上失去母亲以后，一直是她父亲把她和她姐秀英拉扯大的。
04 她干脆给家里人说：周围没她看上的男人！她姐夫对她开玩笑说：“那到外地给你瞅个女婿！”她却认真地说：“只要有合心的，山南海北我都愿意去！爸爸暂时有你们照顾，将来我再把他接走……”家里人吃惊之余，又看她这样认真，就向他们所有在门外的亲戚和熟人委托，让这些人给他们的秀莲在外地寻个对象……本来秀莲只是随便这么说说；她并没指望真能在外地找个合适的男人。
&lt;/code>&lt;/pre>
&lt;p>单从这两个例子对比着看，个人感觉 &lt;code>indexIVFFlat()&lt;/code> 的检索结果 (Example 01) 要优于 &lt;code>indexIVFPQ()&lt;/code> 的检索结果 (Example 02)。&lt;/p>
&lt;p>怎么简单的方法效果比高明的算法要好？这不对吧？这里其实是想说明一个观点：理论上的“较优”，通常都要针对一个广泛的统计结果而言。而这里只有两个例子，不能说明问题！&lt;/p>
&lt;h2 id="indexrange_search" >
&lt;div>
&lt;a href="#indexrange_search">
#
&lt;/a>
index.range_search()
&lt;/div>
&lt;/h2>
&lt;p>The method range_search returns &lt;strong>all vectors within a radius around the query point&lt;/strong> (as opposed to the k nearest ones). Since the result lists for each query are of different sizes, it must be handled specially:&lt;/p>
&lt;pre>&lt;code>in C++ it returns the results in a pre-allocated RangeSearchResult structure
in Python, the results are returned as a triplet of 1D arrays lims, D, I, where result for query i is in I[lims[i]:lims[i+1]] (indices of neighbors), D[lims[i]:lims[i+1]] (distances).
&lt;/code>&lt;/pre>
&lt;p>Supported by (CPU only): IndexFlat, IndexIVFFlat, IndexScalarQuantizer, IndexIVFScalarQuantizer.&lt;/p>
&lt;p>from &lt;a href="https://github.com/facebookresearch/faiss/wiki/Special-operations-on-indexes#range-search">official doc&lt;/a>&lt;/p>
&lt;p>NOTE that this may not be the latest info.&lt;/p>
&lt;p>Example code block:&lt;/p>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># read the text data, and get the embeddings:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#texts_data = pd.Series(...)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#sentence_embeddings = embedding_model.encode(texts_data.values)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># First, you need to use an index that supports Inner Product as metric, for example :&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>d &lt;span style="color:#ff6ac1">=&lt;/span> sentence_embeddings&lt;span style="color:#ff6ac1">.&lt;/span>shape[&lt;span style="color:#ff9f43">1&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">10&lt;/span> &lt;span style="color:#78787e"># how many voronoi cells&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFFlat(quantizer, d, nlist)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>train(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>add(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>query &lt;span style="color:#ff6ac1">=&lt;/span> [&lt;span style="color:#5af78e">&amp;#34;there and back again&amp;#34;&lt;/span>, &lt;span style="color:#5af78e">&amp;#34;a hobbit&amp;#39;s journey&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>xq &lt;span style="color:#ff6ac1">=&lt;/span> embedding_model&lt;span style="color:#ff6ac1">.&lt;/span>encode(query)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Then, you should probably normalize all embeddings first&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ( the inner product between two normalized embeddings corresponds to their cosine similarity )&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># https://github.com/facebookresearch/faiss/blob/master/python/faiss.py#L673&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>faiss&lt;span style="color:#ff6ac1">.&lt;/span>normalize_L2(x&lt;span style="color:#ff6ac1">=&lt;/span>sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>faiss&lt;span style="color:#ff6ac1">.&lt;/span>normalize_L2(x&lt;span style="color:#ff6ac1">=&lt;/span>xq)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>threshold &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">0.95&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lims, D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>range_search(x&lt;span style="color:#ff6ac1">=&lt;/span>xq, thresh&lt;span style="color:#ff6ac1">=&lt;/span>threshold)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># turn search results into dataframes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dfresults &lt;span style="color:#ff6ac1">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> &lt;span style="color:#ff5c57">range&lt;/span>(&lt;span style="color:#ff5c57">len&lt;/span>(xq)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Ii &lt;span style="color:#ff6ac1">=&lt;/span> I[lims[i]:lims[i&lt;span style="color:#ff6ac1">+&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Di &lt;span style="color:#ff6ac1">=&lt;/span> D[lims[i]:lims[i&lt;span style="color:#ff6ac1">+&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfout &lt;span style="color:#ff6ac1">=&lt;/span> pd&lt;span style="color:#ff6ac1">.&lt;/span>concat([texts_data[Ii], pd&lt;span style="color:#ff6ac1">.&lt;/span>Series(Di, index&lt;span style="color:#ff6ac1">=&lt;/span>Ii)], axis&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfout&lt;span style="color:#ff6ac1">.&lt;/span>columns &lt;span style="color:#ff6ac1">=&lt;/span> [&lt;span style="color:#5af78e">&amp;#34;texts&amp;#34;&lt;/span>, &lt;span style="color:#5af78e">&amp;#34;distances&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfresults&lt;span style="color:#ff6ac1">.&lt;/span>append(dfout)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Noise_in_DSP</title><link>/posts/dsp101/2024-05-10-noise_in_dsp/</link><pubDate>Fri, 10 May 2024 11:23:02 +0800</pubDate><guid>/posts/dsp101/2024-05-10-noise_in_dsp/</guid><description>&lt;h1 id="whats-in-a-noise" >
&lt;div>
&lt;a href="#whats-in-a-noise">
##
&lt;/a>
What&amp;rsquo;s in a &amp;ldquo;Noise&amp;rdquo;?
&lt;/div>
&lt;/h1>
&lt;ul>
&lt;li>As in English, it can mean an unwanted signal of any kind. If two signals interfere
with each other, each signal would consider the other to be noise.&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>&amp;ldquo;Noise&amp;rdquo; also refers to a signal that contains components at many frequecies, so it
lacks the harmonic structure of the periodic signals.&lt;/li>
&lt;/ul>
&lt;p>This post is about the second kind.&lt;/p>
&lt;h2 id="uncorrelated-noise" >
&lt;div>
&lt;a href="#uncorrelated-noise">
#
&lt;/a>
Uncorrelated noise
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Uncorrelated uniform noise (UU noise)
&amp;ldquo;uniform&amp;rdquo; means the signal contants random values from a uniform distribution,
&amp;ldquo;uncorrelative&amp;rdquo; means the values are independent (one value provides no information about the others)&lt;/p>
&lt;p>Relationship between power (square of amplitude) and frequency: In the spectrum of
UU noise, the power at all frequecies is drawn from the same distribution; that is,
the average power is the same for all the frequecies. (Better discribed by a
Integrated spectrum of UU noise which it&amp;rsquo;s x-axis is frequency (Hz) and y-axis is
cumulative fraction of total power.)&lt;/p>
&lt;p>And the &amp;ldquo;Integrated Spectrum&amp;rdquo; figure should show a straight line for UU noise, which
indicates that power at all frequecies is constant, on average. Noise with equal
power at all frequecies is called &lt;strong>white noise&lt;/strong> (by analogy with light, because an
equal mixture of light at all visible frequecies is white.)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="brownian-noise" >
&lt;div>
&lt;a href="#brownian-noise">
#
&lt;/a>
Brownian noise
&lt;/div>
&lt;/h2>
&lt;p>In a Brownian noise, each value is the sum of the previous value and a random &amp;ldquo;step&amp;rdquo;. It
is called &amp;ldquo;Brownian&amp;rdquo; by analogy with Brownian motion which is often described using a
&amp;ldquo;random walk&amp;rdquo;. A random walk is a mathematical model of a path where the distance
between steps is characterized by a random distribution.&lt;/p>
&lt;p>In a one-dimensional random walk of Brownian motion of particle, it moves up or down by
a random amount at each time step. The location of the particle at any point in time is
the sum of all previous steps. And that is how Brownian noise would be generated.&lt;/p>
&lt;p>For Brownian noise, the slope of the power spectrum is -2, so we can write this
relationship as:
$$
\log P = k - 2\log f
$$
where $P$ is power, $f$ is grequency, and $k$ is the intercept of the line.
Exponentiating both sides yields:
$$
P = K / f^2
$$
where $K$ is $e^k$, a scalar. And that power is proportional to $1/f^2$, which is
characteristic of Brownian noise.&lt;/p>
&lt;p>Brownian noise is also called &amp;ldquo;red noise&amp;rdquo;, for the same reason that white noise is
called &amp;ldquo;white&amp;rdquo; &amp;ndash; combining visible light with power proportional to $1/f^2$, most of
the power would be at the low-frequency end of the spectrum, which is red.&lt;/p>
&lt;h2 id="pink-noise" >
&lt;div>
&lt;a href="#pink-noise">
#
&lt;/a>
Pink noise
&lt;/div>
&lt;/h2>
&lt;p>More generally, we can synthesize noise with any exponent, $\beta$, in power-frequency
relationship:
$$
P = K / f^{\beta}
$$
when $\beta = 0$, power is constant at all frequencies, so the result is white noise.
when $\beta = 2$, the result is red noise.&lt;/p>
&lt;p>when $\beta$ is between 0 and 2, the result is between white and red noise, so it is
called &amp;ldquo;pink noise&amp;rdquo;.&lt;/p>
&lt;h2 id="gaussian-noise" >
&lt;div>
&lt;a href="#gaussian-noise">
#
&lt;/a>
Gaussian noise
&lt;/div>
&lt;/h2>
&lt;p>When people talk about &amp;ldquo;white noise&amp;rdquo;, they don&amp;rsquo;t always mean UU noise. In fact, more
often they mean uncorrelative Gaussian noise (UG noise).&lt;/p>
&lt;p>UG noise is similar in many ways to UU noise. The spectrum has equal power at all
frequecies, on average, so UG is also white. And it has one other interesting property:
the spectrum of UG noise is also UG noise. More precisely, the real and imaginary parts
of the spectrum are Uncorrelated Gaussian values. (Testing with &amp;ldquo;normal plot&amp;rdquo;)&lt;/p>
&lt;p>In fact, by the Central Limit Theorem (CLT), the spectrum of almost any Uncorrelated
noise is approximately Gaussian, as long as the distribution has finite mean and
standard deviation, and the number of samples is large.&lt;/p></description></item><item><title>About Me: 大道如青天，我独不得出</title><link>/about/</link><pubDate>Sat, 27 Apr 2024 19:58:25 +0800</pubDate><guid>/about/</guid><description>&lt;p>大道如青天，我独不得出。&lt;/p>
&lt;p>羞逐长安社中儿，赤鸡白雉赌梨栗。&lt;/p>
&lt;p>弹剑作歌奏苦声，曳裾王门不称情。&lt;/p>
&lt;p>淮阴市井笑韩信，汉朝公卿忌贾生。&lt;/p>
&lt;p>君不见昔时燕家重郭隗，拥篲折节无嫌猜。&lt;/p>
&lt;p>剧辛乐毅感恩分，输肝剖胆效英才。&lt;/p>
&lt;p>昭王白骨萦蔓草，谁人更扫黄金台？&lt;/p>
&lt;p>行路难，归去来！&lt;/p>
&lt;p>&lt;a href="https://so.gushiwen.cn/shiwenv_95834b2324cc.aspx">唐代 · 李白《行路难 · 其二》&lt;/a>&lt;/p></description></item><item><title>LLMs_interview_faq</title><link>/posts/llm_faqs/</link><pubDate>Fri, 26 Apr 2024 11:04:16 +0800</pubDate><guid>/posts/llm_faqs/</guid><description>&lt;h2 id="01简述gpt和bert的区别" >
&lt;div>
&lt;a href="#01%e7%ae%80%e8%bf%b0gpt%e5%92%8cbert%e7%9a%84%e5%8c%ba%e5%88%ab">
#
&lt;/a>
01:简述GPT和BERT的区别
&lt;/div>
&lt;/h2>
&lt;p>GPT (Decoder-only) 和 BERT (Encoder-only) 都是基于 Transformer 架构的自然语言处理模型，它们在设计上有一些显著区别：&lt;/p>
&lt;ul>
&lt;li>任务类型
&lt;ul>
&lt;li>GPT 以生成文本为主要任务，其目标是生成与输入文本连贯和相关的文本。因此，GPT 通
常用于生成文本 (如：摘要总结，文本补充和chatbot)。&lt;/li>
&lt;li>BERT 以理解文本为主要任务，其目标是从输入文本中提取语义信息。因此适用于各种文
本理解任务，如：情感分析、 文本分类、命名实体识别等下游任务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>预训练目标
&lt;ul>
&lt;li>GPT：单向语言建模。GPT通过自左向右的注意力机制来预测下一个单词，即根据上下文预
测下一个单词/词元是什么。&lt;/li>
&lt;li>BERT：双向语言建模。BERT使用掩码语言建模（MLM）和下一句预测（NSP）两个任务，前
者在MLM任务中随机遮掩输入中的一些词语，模型需要预测这些被掩盖的词语是什么；
NSP的任务是判断两个句子是否在原文中是前后连接的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>结构特点
&lt;ul>
&lt;li>GPT：Transformer-decoder的堆叠，仅使用自注意力机制&lt;/li>
&lt;li>BERT：Transformer-encoder的堆叠，包含多层双向Transformer-encoder。在预训练阶段，
BERT同时使用了自注意力机制和前馈神经网络。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>模型微调
&lt;ul>
&lt;li>GPT：由于其生成式的特点，GPT在微调时通常将整个模型作为单独的序列生成任务进行微
调。&lt;/li>
&lt;li>BERT：由于其双向表示的特点，BERT在微调时通常用于各种文本理解任务，微调时可以在
模型顶层添加适当的输出层来适应下游特定任务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="02llm中的因果语言建模与掩码语言建模有什么区别" >
&lt;div>
&lt;a href="#02llm%e4%b8%ad%e7%9a%84%e5%9b%a0%e6%9e%9c%e8%af%ad%e8%a8%80%e5%bb%ba%e6%a8%a1%e4%b8%8e%e6%8e%a9%e7%a0%81%e8%af%ad%e8%a8%80%e5%bb%ba%e6%a8%a1%e6%9c%89%e4%bb%80%e4%b9%88%e5%8c%ba%e5%88%ab">
#
&lt;/a>
02:LLM中的因果语言建模与掩码语言建模有什么区别？
&lt;/div>
&lt;/h2>
&lt;p>因果语言建模（Causal Language Modeling）&lt;/p>
&lt;pre>&lt;code>在因果语言建模中，模型被要求根据输入序列的左侧内容来预测右侧的下一个词或标记。也就是
说，模型只能看到输入序列中已经生成的部分，而不能看到后续的内容。这种训练方式有助于模
型学习生成连贯和合理的文本，因为模型需要在生成每个词语时考虑上下文的信息，同时不能依
赖于未来的信息。GPT（Generative Pre-trained Transformer）就是以因果语言建模为基础的
模型。
&lt;/code>&lt;/pre>
&lt;p>掩码语言建模（Masked Language Modeling）：&lt;/p>
&lt;pre>&lt;code>在掩码语言建模中，模型被要求预测输入序列中一些被随机掩盖或掩码的词语。模型需要基于上
下文来预测这些被掩盖的词语是什么。
这种训练方式通常用于双向的语言理解任务，因为模型需要考虑上下文中的所有信息来预测被掩盖的词语。
BERT（Bidirectional Encoder Representations from Transformers）就是以掩码语言建模为基础的模型。
&lt;/code>&lt;/pre>
&lt;h2 id="03请简述transformer基本原理" >
&lt;div>
&lt;a href="#03%e8%af%b7%e7%ae%80%e8%bf%b0transformer%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86">
#
&lt;/a>
03:请简述Transformer基本原理
&lt;/div>
&lt;/h2>
&lt;p>Transformer 是一种用于处理序列数据的深度学习模型，由谷歌团队于2017年提出，其主要原理包括
自注意力机制和位置编码。&lt;/p>
&lt;h3 id="自注意力机制" >
&lt;div>
&lt;a href="#%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6">
##
&lt;/a>
自注意力机制：
&lt;/div>
&lt;/h3>
&lt;pre>&lt;code>允许模型在序列的任意两个位置间直接建立依赖关系，而不考虑它们之间的距离。具体就是将词
元线性转换为三个向量Q,K,V，然后将Q和K用来计算内积(相似度分数)并进行注意力缩放（scaled
dot-product)，然后通过softmax归一化，得到每个词元相对于其他词元的注意力权重，然后用
注意力权重对向量V进行加权和计算得到“上下文向量”(context vector)，然后将上下文向量用
前馈网络（FFNN）进行变换，就得到编码器隐层输出。注意：自注意力机制中，每个输入词元的
context vector 以及后续的 hidden state，可以看成是相应的 Q 向量的函数，其他的如 K，V，
以及自注意力机制的参数对所有的 Q 都是恒定值。
+ 多头注意力：
在多头注意力中，注意力机制被复制多次，并且每个注意力头都学习到一组不同的Q,K,V的
表示，然后将它们的输出拼接起来，再通过FFNN进行维度对齐。
- 复制注意力机制：原始输入序列会被用来计算多个注意力头（例如8个或16个头）
- 独立学习：每个注意力头都会独立地学习一组Q，K，V的表示，也就是：每个注意力头都
有自己的权重矩阵，将输入序列转换为Q,K,V向量。
- 注意力计算：每个注意力头像单头注意力机制那样计算注意力分数和注意力权重。
- 拼接输出：将所有注意力头的输出拼接成一个向量，形成多头注意力的最终输出。这意味
着每个词元都会得到来自多个不同视角的表示，从而提高模型对输入序列的理解。
- 线性变换：拼接后的输出通过FFNN进行处理，维持输出维度以及融合不同注意力头的信息。
+ narrow attn：Each attention head will get a chunk of the transformed data points
(projections) to work with. This is a details of utmost importance: The
attention heads DO NOT use chunks of the original data points, but rather those
of their projections. It computes the projections first and then chunks them
later, so that each value in the projection is a linear combination of all
features in the data point.
&lt;/code>&lt;/pre>
&lt;h3 id="位置编码" >
&lt;div>
&lt;a href="#%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81">
##
&lt;/a>
位置编码：
&lt;/div>
&lt;/h3>
&lt;pre>&lt;code>位置编码通常是通过将一个与位置相关的向量添加到输入嵌入（input embeddings）
中来实现的。这个向量为序列中的每个位置提供了一个唯一的表示，从而使模型能够
区分不同的单词顺序。
特别是基于 transformer 架构的模型，由于自注意力机制无法捕捉词元顺序，因此必
须通过加入位置编码来获取输入序列中各个词元的位置信息。
尽管自注意力机制（Self-Attention Mechanism）确实可以捕捉序列中元素之间的关
系，但它主要依赖于元素之间的交互和权重计算，而不是它们的绝对位置信息。位置
编码的作用是补充自注意力机制，提供序列中元素顺序的额外信息，使得模型能够更
好地理解序列的结构。
+ 正弦/余弦函数组合编码 (偶数位用 sin(), 奇数位用 cos())
它们为序列中的每个位置提供了一个唯一的、与位置直接相关的编码。这种编码
方式能够明确地告诉模型每个单词在序列中的绝对位置。
绝对位置编码的一个潜在缺点是它们是静态的，不会随着模型训练的进行而改变。
这意味着它们可能不足以捕捉长序列中复杂的依赖关系，特别是在模型需要动态
地调整位置信息以适应输入序列的变化时。
信息的局限性：固定的位置编码仅提供了位置的绝对信息，而没有考虑序列中元
素之间的相对关系。在长序列中，元素之间的相对位置和距离可能更为重要。
+ 旋转位置编码：旋转位置编码的核心思想是将每个位置的编码表示为一个旋转矩阵，
该矩阵可以应用于输入嵌入。旋转矩阵是动态生成的，这意味着它们可以根据输入
序列的内容进行调整，从而更好地捕捉长距离依赖。
&lt;/code>&lt;/pre>
&lt;h3 id="残差连接与层归一化" >
&lt;div>
&lt;a href="#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e4%b8%8e%e5%b1%82%e5%bd%92%e4%b8%80%e5%8c%96">
##
&lt;/a>
残差连接与层归一化：
&lt;/div>
&lt;/h3>
&lt;pre>&lt;code>+ 残差连接：将每个子层的输入与其输出相加，然后传递给下一层。这使得模型在学
习过程中，能更容易地学习到残差（输入于输出之差），从而缓解梯度消失问题；
提高训练稳定性；允许更深的网络结构；以及提高模型性能。
+ 层归一化：在每个层的输入之后都应用归一化，即对每个特征维度进行归一化操作，
使得它们均值为0，标准差为1，有助于缓解梯度消失和梯度爆炸的问题，从而使
模型训练更加稳定，也提高其泛化能力。
- “批次归一化”（Batch Norm）：
The mean and variance statistics used for normalization are calculated
across all elements of all instances in a batch, for each feature
independently.
即：均值和方差是通过对一个批次里所有实例（序列）的所有元素（词元）的某
个特征进行统计的。
- “层归一化”（Layer Norm）：
For layernorm, the statistics are calculated across the feature
dimension, for each element and instance independently.
即：均值和方差是通过对某个实例（序列）中的某个元素（词元）的所有特征进
行统计的。
NOTE By &amp;quot;element&amp;quot; and &amp;quot;instance,&amp;quot; I mean &amp;quot;word&amp;quot; and &amp;quot;sentence&amp;quot;
respectively for an NLP task, and &amp;quot;pixel&amp;quot; and &amp;quot;image&amp;quot; for a CV task.
&lt;/code>&lt;/pre>
&lt;p>&lt;img alt="IMG: LayerNorm &amp;amp; BatchNorm" src="https://fgg100y.github.io/posts/llm_faqs/images/LLMs_layerNorm_batchNorm.png">&lt;/p>
&lt;h2 id="04-注意力机制的改良版本们" >
&lt;div>
&lt;a href="#04-%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6%e7%9a%84%e6%94%b9%e8%89%af%e7%89%88%e6%9c%ac%e4%bb%ac">
#
&lt;/a>
04: 注意力机制的改良版本们
&lt;/div>
&lt;/h2>
&lt;p>MHA，GQA，MQA三种注意力机制的区别是什么？&lt;/p>
&lt;p>注意力机制在自然语言处理和机器学习领域有多种不同的实现方式，其中常见的包括多头自注意力
（Multi-Head Self-Attention，MHA）、全局注意力（Global Attention，GQA）和多头查询注意力
（Multi-Query Attention，MQA）。这些不同的实现方式在机制和应用上有一些区别：&lt;/p>
&lt;pre>&lt;code>多头自注意力（MHA）：
机制：MHA将输入序列中的每个位置的表示都作为查询（Query）、键（Key）和值（Value），
通过计算查询与所有键的相似度，然后将相似度作为权重对值进行加权求和，从而获得每个
位置的注意力输出。
特点：MHA允许模型在不同的表示空间上进行多头并行计算，通过多头机制，可以学习到不同的关注点和表示。
应用：MHA常用于Transformer等模型中，用于捕捉输入序列中不同位置之间的依赖关系。
全局注意力（GQA）：
机制：GQA将所有的输入位置都作为查询，与所有的键计算相似度，然后将所有位置的值根
据相似度进行加权求和，得到一个全局的输出。
特点：GQA考虑了序列中所有位置的关系，但在处理长序列时可能会受到计算资源的限制，
因为需要计算所有位置之间的相似度。
应用：GQA常用于对整个输入序列进行全局的信息聚合，例如在图像分类任务中。
多头查询注意力（MQA）：
机制：MQA与MHA类似，但在每个头的注意力计算中，使用不同的查询向量，而不是所有头都共享相同的查询向量。
特点：MQA允许模型为每个头学习不同的查询模式，增强了模型的灵活性和表达能力。
应用：MQA常用于需要根据不同的查询来获取注意力信息的任务，如问答系统或需要针对不同问题进行推理的场景
&lt;/code>&lt;/pre>
&lt;h2 id="05-attention的改良版本们" >
&lt;div>
&lt;a href="#05-attention%e7%9a%84%e6%94%b9%e8%89%af%e7%89%88%e6%9c%ac%e4%bb%ac">
#
&lt;/a>
05: Attention的改良版本们
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>简述一下 FlashAttention 的原理&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>Flash Attention是一种新型的注意力算法，旨在解决传统Transformer模型中自注意力机制的计
算和内存效率问题。由于自注意力机制的时间和存储复杂度与序列长度成二次方关系，这使得处
理长序列数据时面临巨大挑战。Flash Attention通过精心设计，显著减少了对高带宽内存（HBM）
的读写次数，从而加快了运行速度并降低了内存占用。&lt;/p>
&lt;h3 id="flash-attention的核心原理和技术" >
&lt;div>
&lt;a href="#flash-attention%e7%9a%84%e6%a0%b8%e5%bf%83%e5%8e%9f%e7%90%86%e5%92%8c%e6%8a%80%e6%9c%af">
##
&lt;/a>
Flash Attention的核心原理和技术：
&lt;/div>
&lt;/h3>
&lt;pre>&lt;code>平铺（Tiling）：Flash Attention将输入分割成小块，并在每个块上执行注意力操作。这种方法减少了对高带宽内存的访问次数，因为不需要一次性将整个大矩阵加载到内存中。
重新计算（Recomputation）：在后向传播过程中，Flash Attention避免了存储大型中间矩阵（如S和P矩阵），而是利用前向传播中的统计量来快速重新计算这些矩阵，从而减少了内存消耗。
在线Softmax：为了处理Softmax操作，Flash Attention采用了在线Softmax技术，它允许分块计算softmax，并通过适当的归一化因子来确保最终结果的正确性。
内存层次结构意识（IO-Awareness）：Flash Attention考虑了GPU内存层次结构，优化了不同层级内存之间的数据访问，如在GPU的SRAM和HBM之间。
&lt;/code>&lt;/pre>
&lt;h3 id="flash-attention-2" >
&lt;div>
&lt;a href="#flash-attention-2">
##
&lt;/a>
Flash Attention-2：
&lt;/div>
&lt;/h3>
&lt;p>在Flash Attention的基础上，研究人员进一步提出了Flash Attention-2，它通过改进工作分配和并行化策略，进一步提高了计算速度。Flash Attention-2的优化包括：&lt;/p>
&lt;pre>&lt;code>减少非矩阵乘法（non-matmul）的浮点运算次数（FLOPs）。
通过在不同的线程块上并行化注意力计算，提高了GPU的占用率。
在每个线程块内，将工作分配给不同的warp，以减少通过共享内存的通信。
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;strong>PagedAttention的原理是什么，解决了LLM中的什么问题？&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>Paged Attention（PA）技术是一种用于优化大型语言模型（LLM）推理性能的方法，特别是在处理自
回归生成任务时对内存使用效率的显著提升。这项技术的核心思想是借鉴操作系统中虚拟内存和分页
的技术，将传统的注意力机制中的键值对（Key-Value pairs，简称K-V pairs）缓存以分页的形式存
储和管理。&lt;/p>
&lt;p>在自回归解码过程中，模型为每个输入令牌生成注意力键和值，这些键值对被存储在GPU的显存中以
预测下一个令牌。由于这些缓存的键值对大小是动态变化的，并且可能会占用大量的显存空间，因此
有效管理这些缓存成为一个挑战。传统的注意力算法在处理时会受限于显存的大小，这限制了模型的
批处理能力和整体的吞吐量。&lt;/p>
&lt;h2 id="06llm微调与量化" >
&lt;div>
&lt;a href="#06llm%e5%be%ae%e8%b0%83%e4%b8%8e%e9%87%8f%e5%8c%96">
#
&lt;/a>
06:LLM微调与量化
&lt;/div>
&lt;/h2>
&lt;p>30.参数高效的微调（PEFT）有哪些方法？
31.LORA微调相比于微调适配器或前缀微调有什么优势？
32.有了解过什么是稀疏微调吗？
33.训练后量化（PTQ）和量化感知训练（QAT）与什么区别？
34.LLMs中，量化权重和量化激活的区别是什么？
35.AWQ量化的步骤是什么？&lt;/p>
&lt;h2 id="07嵌入向量模型" >
&lt;div>
&lt;a href="#07%e5%b5%8c%e5%85%a5%e5%90%91%e9%87%8f%e6%a8%a1%e5%9e%8b">
#
&lt;/a>
07:嵌入向量模型
&lt;/div>
&lt;/h2>
&lt;p>40.自前主流的中文嵌入向量模型有哪些？&lt;/p>
&lt;h2 id="其他" >
&lt;div>
&lt;a href="#%e5%85%b6%e4%bb%96">
#
&lt;/a>
其他
&lt;/div>
&lt;/h2>
&lt;p>45.DeepSpeed推理对算子融合做了哪些优化？
48.请介绍一下微软的ZeRO优化器&lt;/p>
&lt;p>3.为什么现在的大模型大多是decoder-only的架构？
4.讲一下生成式语言模型的工作机理
5.哪些因素会导致LLM的偏见？
7.如何减轻LLM中的幻觉现象？
8.解释ChatGPT的零样本和少样本学习的概念
10.如何评估大语言模型（LLMs）的性能？
11.如何缓解LLMs重复读问题？
16.Wordpiece与BPE之间的区别是什么？
17.有哪些常见的优化LLMs输出的技术？
18.GPT-3拥有的1750亿参数，是怎么算出来的？
19.温度系数和top-p，top-k参数有什么区别？
21.介绍-下postlayernorm和prelayernorm的区别
22.什么是思维链（CoT）提示？
23.你觉得什么样的任务或领域适合用思维链提示？
24.你了解ReAct吗，它有什么优点？
25.解释一下langchainAgent的概念
26.langchain有哪些替代方案？
27.langchaintoken计数有什么问题？如何解决？
28.LLM预训练阶段有哪几个关键步骤？
29.RLHF模型为什么会表现比SFT更好？
36.介绍一下GPipe推理框架
37.矩阵乘法如何做张量并行？
38.请简述下PPO算法流程，它跟TRPO的区别是什么？
39.什么是检索增强生成（RAG）？
41.为什么LLM的知识更新很困难？
42.RAG和微调的区别是什么？
43.大模型一般评测方法及基准是什么？
50.什么是投机采样技术，请举例说明？&lt;/p></description></item><item><title>Tokenization: BPE, Unigram and more</title><link>/posts/llm_tokenization/</link><pubDate>Mon, 22 Apr 2024 15:41:56 +0800</pubDate><guid>/posts/llm_tokenization/</guid><description>&lt;h1 id="there-is-more-than-one-way-to-tokenize-a-sentence" >
&lt;div>
&lt;a href="#there-is-more-than-one-way-to-tokenize-a-sentence">
##
&lt;/a>
There is more than one way to tokenize a sentence
&lt;/div>
&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>word-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>A big vocabulary is needed&lt;/li>
&lt;li>We combine words: what exactly constitutes a word (&amp;ldquo;bachelor of science&amp;rdquo;, or
isolated words)&lt;/li>
&lt;li>Abbreviated words: &amp;ldquo;LOL&amp;rdquo;, &amp;ldquo;IMO&amp;rdquo;, are these collections of words or new words?&lt;/li>
&lt;li>Languages that don&amp;rsquo;t segment by spaces&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>character-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>Lack of meaning: Unlike words, characters don&amp;rsquo;t have any inherent meaning, model
may lose the semantic-specific feature of words.&lt;/li>
&lt;li>Increased input computation&lt;/li>
&lt;li>Limits netword+k choices: It&amp;rsquo;s difficult to use architectures which process input
sequentially since the input sequences will be much longer.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Subword-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>We want a tokenization scheme that deals with an infinite potential vocabulary via
a finite list of known words. Make up the word “unfortunately” via “un” + “for”+
“tun” + “ate” + “ly”.&lt;/li>
&lt;li>Subword tokenisation will break the text into chunks based on the word frequency.
In practice what happens is that common words will be tokenized generally as
whole words, e.g. “the”, “at”, “and”, etc., while rarer words will be broken
into smaller chunks and can be used to create the rest of the words in the
relevant dataset.&lt;/li>
&lt;li>BPE(Byte Pair Encoding): One popular algorithm for subword tokenisation which
follows the above approach is BPE. BPE was originally used to help compress data
by finding common byte pair combinations. It can also be applied to NLP to find
the most efficient way of representing text.
&lt;ul>
&lt;li>What is merging?
The main goal of the BPE subword algorithm is to find a way to represent
your entire text dataset with the least amount of tokens. Similar to a
compression algorithm, you want to find the best way to represent your image,
text or whatever you are encoding, which uses the least amount of data, or
in our case tokens. In the BPE algorithm merging is the way we try and
“compress” the text into subword units.&lt;/li>
&lt;li>There are a few steps to these merging actions:
&lt;ol>
&lt;li>Get the word &lt;strong>count&lt;/strong> frequency&lt;/li>
&lt;li>Get the &lt;strong>initial token count&lt;/strong> and frequency (i.e., how many times each
character occurs)&lt;/li>
&lt;li>Merge the &lt;strong>most common byte pairing&lt;/strong>&lt;/li>
&lt;li>Add this to the list of tokens and &lt;strong>recalculate the frequency count&lt;/strong>
for each token (this will change with each merging step)&lt;/li>
&lt;li>&lt;strong>Rinse and repeat&lt;/strong> until get reached pre-defined token limits (vocab
size) or a set of number of iterations&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Greedy algorithm: BPE ensures that the most common words will be represented in
the new vocabulary as a single token, while less common words will be broken
down into two or more subword tokens. To achieve this, BPE will go through every
potential option at each step and pick the tokens to merge based on the highest
frequency.One downside of BPE’s greedy approach is it can result in a potentially
ambiguous final token vocabulary.
For instance GPT has a vocabulary size of 40,478 since they have 478 base
characters and chose to stop training after 40,000 merges.&lt;/li>
&lt;li>BBPE(byte-level PBE): A base vocabulary that includes all possible base characters
can be quite large if e.g. all unicode characters are considered as base
characters. To have a better base vocabulary, GPT-2 uses bytes as the base
vocabulary, which is a clever trick to force the base vocabulary to be of size
256 while ensuring that every base character is included in the vocabulary. With
some additional rules to deal with punctuation, the GPT2’s tokenizer can
tokenize every text without the need for the &lt;unk> symbol. GPT-2 has a
vocabulary size of 50,257, which corresponds to the 256 bytes base tokens, a
special end-of-text token and the symbols learned with 50,000 merges.
&lt;a href="https://huggingface.co/docs/transformers/en/tokenizer_summary#byte-pair-encoding-bpe">from hf doc&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="probabilistic-subword-tokenization" >
&lt;div>
&lt;a href="#probabilistic-subword-tokenization">
##
&lt;/a>
Probabilistic Subword Tokenization
&lt;/div>
&lt;/h1>
&lt;p>Using the frequency of subword patterns for tokenization can result in ambiguous final
encodings. The problem is that we have no way to predict which particular token is more
likely to be the best one when encoding any new input text.
Luckily, needing to predict the most likely sequence of text is not a unique problem to
tokenization. We can leverage this knowledge to build a better tokenizer.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Unigram Subword Tokenization&lt;/p>
&lt;ul>
&lt;li>The goal for a subword model, however, is different from a LM that is trying to
predict a full sentence. We only want something that generates unambiguous
tokenization.&lt;/li>
&lt;li>The unigram approach differs from BPE in that it attempts to choose the most
likely option rather than the best option at each iteration. To generate a
unigram subword token set you need to first define the desired final size of
your token set and also a starting seed subword token set.&lt;/li>
&lt;li>You can choose the seed subword token set in a similar way to BPE and choose
the most frequently occurring substrings. Once you have this in place then
you need to:
&lt;ol>
&lt;li>Work out the probability for each subword token&lt;/li>
&lt;li>Work out a loss value which would result if each subwork token were to be
dropped. The loss is worked out via Expectation Maximization algorithm.&lt;/li>
&lt;li>Drop the tokens which have the largest loss value (e.g., the bottom 10%
or 20% of subword tokens based on their loss calculations).&lt;/li>
&lt;li>Repeat these steps until reach the desired final vocabulary size or there
is no change in token numbers after successive iterations.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>WordPiece (greedy approach tokenzier, BERT partner)
Think of WordPiece as an intermediary between the BPE approach and the unigram approach.&lt;/p>
&lt;ul>
&lt;li>BPE, if you remember, takes two tokens, looks at the frequency of each pair and then
merges the pairs that have the highest combined frequency count. It only considers
the most frequent pair combinations at each step, nothing else.&lt;/li>
&lt;li>An alternate approach is to check the potential impact of merging that particular
pair. You can do this using the probabilistic LM approach. At each iterative step,
choose the character pair which will result in the largest increase in likelihood
once merged. This is the difference between the probability of the new meged pair
occurring minus the probability of both individual tokens occurring individually.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>The main difference is that WordPiece is a greedy approach. It still tries to build a
tokenizer from the bottom up, picking the best pair at each iteration to merge.
WordPiece uses the likelihood rather than count frequency but otherwise it is a similar
approach. Unigram in contrast is a fully probabilistic approach which uses probability
to both choose the pairs to merge and whether to merge them or not. It also removes
tokens based on the fact that they add the least to the overall likelihood of the
unigram model.&lt;/p>
&lt;h1 id="briefly-summarize" >
&lt;div>
&lt;a href="#briefly-summarize">
##
&lt;/a>
briefly summarize:
&lt;/div>
&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>BPE: Just uses the frequency of occurrences to identify the best match at every
iteration until it reaches the predefined vocabulary size.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>WordPiece: Similar to BPE and uses frequency occurrences to identify potential
merges but makes the final decision based on the likelihood of the merged token&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Unigram: A fully probabilistic model which does not use frequency
occurrences. Instead, it trains a LM using a probabilistic model, removing
the token which improves the overall likelihood the least and then starting
over until it reaches the final token limit.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="sentencepiece" >
&lt;div>
&lt;a href="#sentencepiece">
##
&lt;/a>
SentencePiece
&lt;/div>
&lt;/h1>
&lt;p>SentencePiece basically tries to bring all the subword tokenization tools and techniques
under one banner. It’s kind of like the Swiss Army knife for subword tokenization. To be
a Swiss Army-like tool something has to be capable of solving multiple problems. So what
problems is SentencePiece addressing:&lt;/p>
&lt;ol>
&lt;li>All other models assume input is already tokenized: BPE and Unigram are great model
but they share one big disadvantage: they both need to have their input already
tokenized. SentencePiece deals with this by simply taking in an input in raw text and
then doing everything needed on that input to perform subword tokenization.&lt;/li>
&lt;li>Language agnostic: Since all other subword algorithms need to have their input
pre-tokenized, it limits their applicability to many languages.&lt;/li>
&lt;li>Decoding is difficult: Another problem which is caused by model like BPE and unigram
requiring already tokenized inputs is that you do not know what encoding rules were
used. For example, how were spaces encoded in the tokens? So you cannot decode the
input and return it to is original format.&lt;/li>
&lt;li>No end to end solution: You cannot just plug in a raw input to BPE (or Unigram) and
get an output.&lt;/li>
&lt;/ol>
&lt;p>Some of the techniques SentencePiece uses to address the above shortcomings:&lt;/p>
&lt;ol>
&lt;li>Encode everything as unicode: SentencePiece first converts all the input into unicode
characters. This makes it a language agnostic tool.&lt;/li>
&lt;li>&amp;ldquo;space&amp;rdquo; encoded as &amp;ldquo;_&amp;quot;(U+2581): To get around the word segmenting issues.&lt;/li>
&lt;li>And it&amp;rsquo;s faster: One of the issues preventing other subword algorithms from being used
to tokenize raw sentences as part of model training was that there lack of speed. If
you processed input in real time and performed your tokenization on the raw input it
would be too slow. SentencePiece addresses this by using a priority queue for the BPE
algorithm to speed it up so that you can use it as part of an end-to-end solution.&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>&lt;a href="https://www.openteams.com/tokenizers-how-machines-read/">https://www.openteams.com/tokenizers-how-machines-read/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>TODO: 补充中文&lt;/p></description></item><item><title>test rendering of equations of latex in Hugo</title><link>/posts/hugo101/test_math_equation_rendering/</link><pubDate>Fri, 25 Aug 2023 13:49:40 +0800</pubDate><guid>/posts/hugo101/test_math_equation_rendering/</guid><description>&lt;p>式子能正常渲染，但需要在两个地方的下标处添加额外转义字符 &lt;code>\&lt;/code>，
也就是：&lt;code>\mathbb{E}\_{xxx}&lt;/code>和&lt;code>p\_{model}&lt;/code>，其他地方却不需要 &lt;code>\hat{p}_{data}&lt;/code>&lt;/p>
&lt;p>$$
\mathbb{E}_{x \sim \hat{p}_{data}} {\text{log}\ p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>是因为 &lt;code>\mathbb{}&lt;/code> 导致的吗？看起来不是：
$$
E_{x \sim \hat{p}_{data}} {\text{log}\ p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>是因为 &lt;code>\text{}&lt;/code> 导致的吗？看起来不是 (&lt;code>\text{log}&lt;/code> -&amp;gt; &lt;code>\log&lt;/code>)：
$$
\mathbb{E}_{x \sim \hat{p}_{data}}{\log p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>如果 &lt;code>\mathbb{}_&lt;/code> 渲染不出来，那它渲染失败是怎么样的 (下式&lt;code>\mathbb{}_&lt;/code>中的&lt;code>_&lt;/code>不见了)：&lt;/p>
&lt;p>$$
\mathbb{E}&lt;em>{x \sim \hat{p}&lt;/em>{data}}{\text{log}\ p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>为什么 &lt;code>p_{model}&lt;/code> 也渲染不出来， 而非要添加转意字符 &lt;code>p\_{model}&lt;/code> 呢？&lt;/p>
&lt;p>$$
\mathbb{E}_{x \sim \hat{p}&lt;em>{data}}{\text{log}\ p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>$$
E_{x \sim \hat{p}&lt;em>{data}}{\text{log}\ p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>$$
\mathbb{E}&lt;em>{x \sim \hat{p}_{data}}{\text{log}\ p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>或许是嵌套下标这儿出的问题 (&lt;code>\hat{p}_{data}&lt;/code> -&amp;gt; &lt;code>\hat{p}\_{data}&lt;/code> )？:
$$
E_{x \sim \hat{p}_{data}}{\text{log}\ p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>Bingo?? No bingo:&lt;/p>
&lt;p>只在嵌套下标的地方添加转义字符：&lt;/p>
&lt;p>$$
\tag{5.59}
\theta_{ML} = \underset{\theta}{\operatorname{argmax}} \mathbb{E}&lt;em>{x \sim \hat{p}_{data}}{\log p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>只在&lt;code>p_{model}&lt;/code>下标的地方添加转义字符：&lt;/p>
&lt;p>$$
\tag{5.59}
\theta_{ML} = \underset{\theta}{\operatorname{argmax}} \mathbb{E}&lt;em>{x \sim \hat{p}&lt;/em>{data}}{\log p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>只在&lt;code>\mathbb{}&lt;/code>下标的地方添加转义字符：&lt;/p>
&lt;p>$$
\tag{5.59}
\theta_{ML} = \underset{\theta}{\operatorname{argmax}} \mathbb{E}_{x \sim \hat{p}&lt;em>{data}}{\log p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>简而言之，找不到明确的语法规则来解释这个问题。可能是hugo在使用mathjax解析时出了问题，也有可能是mathjax自己的问题。&lt;/p>
&lt;p style="text-align:center;color:blue;">
Hugo的markdown文档里的数学公式块，如果不确定，就在下标那里前置一个`\`。&lt;br>
同样的问题也出现在多行公式组里进行转行时，使用 `\\\\\`，而不是通常的 `\\\`
&lt;/p>
&lt;p>惹出这么许多不明所以的问题, 最初就是下面这个公式 (就是我所认知的、通常表达下标的普通方式，
讽刺的是：不把它们放在 &lt;code>$$&lt;/code> 数学公式块里，我还必须添加转义字符，否则渲染不出这个效果😂):&lt;/p>
&lt;p>\tag{5.59}
\theta_{ML} = \underset{\theta}{\operatorname{argmax}} \mathbb{E}_{x \sim \hat{p}_{data}}{\log p_{model} {(x^i; \theta})}&lt;/p>
&lt;p>数学公式块里表达下标的语法，无端端要添加一个前置转义字符，这就是我所没有料到的。想必应该是Hugo没有做好关于转义字符的上下文解析问题，且先将就着吧。&lt;/p></description></item><item><title>利器4: Vim 编辑器 -- 只因为在键盘之中，方向键太遥远</title><link>/posts/thecli/thevim/2022-08-13-vim8/</link><pubDate>Sat, 13 Aug 2022 21:37:59 +0800</pubDate><guid>/posts/thecli/thevim/2022-08-13-vim8/</guid><description>&lt;h2 id="vim-初体验" >
&lt;div>
&lt;a href="#vim-%e5%88%9d%e4%bd%93%e9%aa%8c">
#
&lt;/a>
Vim 初体验
&lt;/div>
&lt;/h2>
&lt;p>“多年以后，面对显示屏，&amp;ldquo;逃离了巨硬·仍旧愤怒·懵懂菜鸟&amp;quot;将会回想起初次尝试 Vim 编辑器
而被困在里面叫天不应叫地不灵的那个遥远的下午”。&lt;/p>
&lt;p>那时候的我（2017），是个二十多岁的青年，刚刚认识终端和 Linux 大概是怎么一回事，
感觉恰似上天给我关了那扇“窗”，自己推开了 Linux 世界的大门。
世界新生伊始，许多事物还不知其名何处，对许多“拿来主义”的命令仍旧半信半疑，
简直就是一场大冒险 (没有性命之攸的那种)。&lt;/p>
&lt;p>当我发现在文本编辑器里的光标可以用 h,j,k,l 来进行左下上右移动时，“不懂，但我大受震撼”。&lt;/p>
&lt;p>（其实就是见识少，不是所有键盘都有独立的方向键，更不是操作系统就只一个 windows
，不过我是二十好几的人了才知道这个事情，用于连的话讲就是：“啊，这是一场侮辱”。）&lt;/p>
&lt;p>虽然第一次尝试 Vim 就被抛弃到了荒岛，好在我对这样一个新奇的世界，早有心理准备。
事实证明，要适应新环境，最好的武器不过是“一点好奇心和多点耐心”。从那以后，
感觉就好像“居住在兔子皮毛深处的微生物”竭力向毛尖爬去，“以便将魔术师看个清楚”。&lt;/p>
&lt;p>终端里能用的优秀工具多得让我觉得简直“就像是在海边拣贝壳的孩子&amp;rdquo;，而 Vim 编辑器无疑是我最喜爱的那一枚。
而在海边放贝壳的无疑是那些乐于分享的同道中人，我相信真正的进步来自于分享。&lt;/p>
&lt;p>后来当我大概明白 vimrc 文件是怎么一回事之后，我第一件事就是给它加上了这一句:&lt;/p>
&lt;p>&lt;code>set mouse=&lt;/code>&lt;/p>
&lt;p>其实当时是怀着对旧日那种凡事必得“鼠标点击拖拽”宣战的忐忑心态。&lt;/p>
&lt;p>后来怎么样了？&lt;/p>
&lt;p>后来我发现，其实不怎么需要“专门腾出一只手用鼠标操控”。
如果是在终端干活，你乐意的话，那就是：根本不需要。
如果你极端点，在哪里都不需要鼠标。
除非是你另一只手在忙点别的什么，或者是老板要“麻烦”你给“赶紧”修改一篇work文档，客户在线等那种&amp;hellip;&lt;/p>
&lt;h2 id="vim-编辑器" >
&lt;div>
&lt;a href="#vim-%e7%bc%96%e8%be%91%e5%99%a8">
#
&lt;/a>
Vim 编辑器
&lt;/div>
&lt;/h2>
&lt;h3 id="vim-是干啥的" >
&lt;div>
&lt;a href="#vim-%e6%98%af%e5%b9%b2%e5%95%a5%e7%9a%84">
##
&lt;/a>
Vim 是干啥的
&lt;/div>
&lt;/h3>
&lt;p>首先应该了解： Vim 适用于什么场景？&lt;/p>
&lt;blockquote>
&lt;p>“Vim是从 vi 发展出来的一个文本编辑器。
其代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。
和Emacs并列成为类Unix系统用户最喜欢的编辑器。”&lt;/p>
&lt;/blockquote>
&lt;p>平时我在浏览中（尤其是寻找一些功能插件过程）也看到有人发博客说他/她是用 Vim 进
行“写作”的（主要是关于 $\LaTeX$, $\TeX$, markdown 的插件），但我想如果是用来进
行文学创作这一类的工作的话，重点可能不在于编辑器，很简单，还没有“电脑”的时代就
已经诞生了太多优秀作品。
（想象大佬曹雪芹面对电脑屏幕“十年删改”《红楼梦》总觉得有点荒诞，
但是就算是有电脑，这难点肯定不在于删改（编辑器无关紧要），而在于文学创造。
极有可能他根本买不起电脑。）&lt;/p>
&lt;p>反过来却不一样，至少我们这年代，没有听说哪个成功的软件产品，它的代码是用手写在草稿纸上 &amp;hellip;
怪诞的是，面试的时候倒是有不少这种要手写代码啊伪代码这种事情，我觉得这多多少少有点黑色幽默。&lt;/p>
&lt;p>简而言之，vim是个编辑器，很多人用它来写代码，也有人用它来干其他。&lt;/p>
&lt;p>随着了解深入，慢慢就会接触到诸如“编辑器之战”、“编程语言之争”这一类话题。&lt;/p>
&lt;h3 id="编辑器之战" >
&lt;div>
&lt;a href="#%e7%bc%96%e8%be%91%e5%99%a8%e4%b9%8b%e6%88%98">
##
&lt;/a>
编辑器之战
&lt;/div>
&lt;/h3>
&lt;blockquote>
&lt;p>“编辑器之战是指计算机编程领域内，
两类文本编辑器 vi（以及衍生版本）和 Emacs 用户之间的对抗冲突。
这已经成为黑客文化和自由软件社区文化的一部分。&lt;/p>
&lt;/blockquote>
&lt;p>一些 Emacs 用户说：&lt;/p>
&lt;blockquote>
&lt;p>Vi 有两个模式，“不停地哔哔叫”和“搞砸一切”。&lt;/p>
&lt;/blockquote>
&lt;p>而据 Vi 用户称：&lt;/p>
&lt;blockquote>
&lt;p>一些 Emacs 用户由于修改键过多而使用脚踏板。&lt;/p>
&lt;/blockquote>
&lt;p>一些博客博文、影视作品也都会出现这些内容场景，而且大都是轻松欢乐的场景。比如，
《硅谷》里理查德和他“简直就是踩了狗屎运”才勾搭上的漂亮女友就为了 Vim 和 Emacs
、使用 Tab 还是 Space 进行代码缩进以及缩进风格而吵了起来，继而直接闹掰，
最后以理查德秀逗了的在用身体力行进行“缩进演示”中滚下楼梯而告终。
&amp;hellip;&lt;/p>
&lt;blockquote>
&lt;p>战火在两群用户之间多次点燃，他们互相蔑视，坚信自己的选择才是最完美的。
相比其他的IT领域战争（浏览器大战、操作系统之争、编程语言之争、代码缩进风格之战
等等)，编辑器的选择其实通常只是个人问题。 ”&lt;/p>
&lt;/blockquote>
&lt;p>如果不小心也卷入了这些战争，请记住：编辑器的选择其实通常只是个人问题。&lt;/p>
&lt;p>当然，实在吵得不可开交的时候，别忘了搬出编程语言之争里那句一锤定音的话题终结语：
“PHP 才是真好的编程语言，不接受任何反驳。”&lt;/p>
&lt;p>如果想了解更多，可以去 &lt;a href="https://zh.m.wikipedia.org/zh-hans/Vim">Vim 维基词条&lt;/a>
了解更多精彩内容。如果你甚至无法访问维基百科，那不是你的错，不过你得想办法。&lt;/p>
&lt;h2 id="vim-及其配置" >
&lt;div>
&lt;a href="#vim-%e5%8f%8a%e5%85%b6%e9%85%8d%e7%bd%ae">
#
&lt;/a>
vim 及其配置
&lt;/div>
&lt;/h2>
&lt;p>如果你是想入门而还在门口徘徊的，可以先在终端 (Terminal) 里输入 &lt;code>vimtutor&lt;/code>，
然后看看你感觉如何。如果你认真追随，你会发现一切自有道理。貌似还挺好玩。
嗯，咦，怎么退出这编辑器呢？&lt;/p>
&lt;h3 id="现代码仔如何在终端界面退出vim编辑器" >
&lt;div>
&lt;a href="#%e7%8e%b0%e4%bb%a3%e7%a0%81%e4%bb%94%e5%a6%82%e4%bd%95%e5%9c%a8%e7%bb%88%e7%ab%af%e7%95%8c%e9%9d%a2%e9%80%80%e5%87%bavim%e7%bc%96%e8%be%91%e5%99%a8">
##
&lt;/a>
现代码仔如何在终端界面退出vim编辑器
&lt;/div>
&lt;/h3>
&lt;p>如果你和我当初一样一头雾水&amp;hellip; 淡定淡定，输入 &lt;code>:q&lt;/code> ，按下 &lt;code>Enter&lt;/code> 即可退出。&lt;/p>
&lt;p>嗯，如果你正在输入，需要先按下 &lt;code>Esc&lt;/code>，然后输入 &lt;code>:q&lt;/code> 来退出。&lt;/p>
&lt;p>这个操作也不好使？八成你是在别的模式里，比如 &lt;code>Ex mode&lt;/code>，
八成它也会提示你输入 &lt;code>visual&lt;/code> 来返回到 &lt;code>normal mode&lt;/code>。&lt;/p>
&lt;p>如果不是这种情况，极有可能是你不小心按了 &lt;code>q&lt;/code> 进入命令录制，
通常要是你多按几次 &lt;code>q&lt;/code> 来观察，会发现有 &lt;code>recording @&lt;/code> 的提示，
这就是多命令录制无疑，重复操作：输入 &lt;code>:q&lt;/code> ，按下 &lt;code>Enter&lt;/code> 即可退出。&lt;/p>
&lt;p>如果都不是，并且“他X的按什么也没用”，先检查一下你的机器是否还在正常工作，
是，则重复以下操作：输入 &lt;code>:q&lt;/code>，按下 &lt;code>Enter&lt;/code>。&lt;/p>
&lt;p>如果你所有好奇心还没有被消耗殆尽，我来告诉你一个好消息：
vim 共有 &lt;a href="https://en.wikipedia.org/wiki/Vim_(text_editor)">12种模式&lt;/a>。&lt;/p>
&lt;p>这确实是个新世界。&lt;/p>
&lt;h2 id="vimrc" >
&lt;div>
&lt;a href="#vimrc">
#
&lt;/a>
vimrc
&lt;/div>
&lt;/h2>
&lt;p>应当注意：从第一次在终端输入 &lt;code>vim&lt;/code> 到开始了解和使用自己配置的 &lt;code>.vimrc&lt;/code>，
从前者到后者，每个人所经历的时间不太一样，毕竟每个人的生活和目的千差万别。
（倒不是说，刚开始使用 vim 就不能直接上手个人配置，而是想说明，
“步子迈大了，容易扯着蛋”；一旦放弃了探索和思考，容易一碰挫折就十分沮丧。）
但在很多文章里，这两者之间多半就是一个空行的距离。
（因此我决定在这个空行之前添加一点说明，以下的内容新手初看时不太明白实属正常）&lt;/p>
&lt;p>Vim 如此受欢迎，它的丰富的插件生态应该是一个重要的原因。为什么有这么多插件呢？
因为有这么多的需求。因为有那么多的插件，所以有了要管理插件（更新、删除等）的
插件。使用比较广泛的有：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/junegunn/vim-plug">vim-plug&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/VundleVim/Vundle.vim">Vundle&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/tpope/vim-pathogen">Pathogen&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/k-takata/minpac">minpac&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>它们的安装和使用条件都在各自的主页有详细说明，这里不再搬运。那到底用哪个呢？
你在阅读他们的说明的时候自己就会有答案，如果还是难以决定，我的建议就是像八戒
所说的那样：“待俺老猪一家家吃将去！”。（我自己嘛，吃过了三家）&lt;/p>
&lt;p>从 vim8.0 开始，vim 自带插件管理的功能特性（实际上，前述的 &lt;code>minpac&lt;/code> 就利用了
这些特性），我仅在这个功能出来的时候尝过新（满足好奇心而已，浅尝辄止），
因为已经习惯了所用的管理插件的插件：）(更新：后来我改变了主意)&lt;/p>
&lt;p>如果说管理插件的插件可以由 vim 自带的功能所提供，那么，有多少插件是必须的呢？&lt;/p>
&lt;p>有人作了很好的总结：
&lt;a href="https://thoughtbot.com/blog/how-to-do-90-of-what-plugins-do-with-just-vim">How to Do 90% of What Plugins Do (With Just Vim)&lt;/a>&lt;/p>
&lt;p>如果你崇尚极简主义，值得一试。（不是说就一定要如此，而是知道有的选择）&lt;/p>
&lt;p>这里提到的应该都理解为是“别人的”个人配置，而所谓“个人配置”，基本意思就是：
走过路过，可以随便错过。
看到钟意的，拿走不谢。看到不爽的，请去Pull Request，切勿乱喷粪。&lt;/p>
&lt;p>大佬&lt;a href="https://en.wikipedia.org/wiki/Linus_Torvalds">林纳斯·托瓦兹&lt;/a>早就看透了那些到处乱喷的键盘侠，他的至理名言说明了一切：&lt;/p>
&lt;blockquote>
&lt;p>&amp;ldquo;On the Internet, talk is cheap, show me the code.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;h2 id="vimrc-vimrc" >
&lt;div>
&lt;a href="#vimrc-vimrc">
#
&lt;/a>
vimrc (~/.vimrc)
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-vim" data-lang="vim">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34; ================================Part-1: Plugins============&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>call plug#begin(&lt;span style="color:#5af78e">&amp;#39;~/.vim/bundle&amp;#39;&lt;/span>) &lt;span style="color:#78787e">&amp;#34; reuse the bundle dir&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== tmux ===-------------------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;christoomey/vim-tmux-navigator&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; vim &amp;lt;-&amp;gt; tmux, pane dance&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;edkolev/tmuxline.vim&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; status line&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Coding enhancement ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;airblade/vim-gitgutter&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; shows git diff sign and more&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;tpope/vim-fugitive&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; awsome git wrapper!&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;tpope/vim-repeat&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; enhance . repeat&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;dense-analysis/ale&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; linters config&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;mileszs/ack.vim&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; cherrypick your strings&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;junegunn/fzf&amp;#39;&lt;/span>, { &lt;span style="color:#5af78e">&amp;#39;do&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;./install --all&amp;#39;&lt;/span> } | Plug &lt;span style="color:#5af78e">&amp;#39;junegunn/fzf.vim&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Python enhancement ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; Plug &amp;#39;Valloric/YouCompleteMe&amp;#39; &amp;#34; for completion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;davidhalter/jedi-vim&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; python auto-completion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Wiki/markdown enhancement ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;vimwiki/vimwiki&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; for personal wiki&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;mzlogin/vim-markdown-toc&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; for table_of_content&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;plasticboy/vim-markdown&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; couple with vim-instant-markdown&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;instant-markdown/vim-instant-markdown&amp;#39;&lt;/span>, {&lt;span style="color:#5af78e">&amp;#39;for&amp;#39;&lt;/span>: [&lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;markdown.pandoc&amp;#39;&lt;/span>]}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Latex support ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;lervag/vimtex&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; for LaTeX files&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;xuhdev/vim-latex-live-preview&amp;#39;&lt;/span>, { &lt;span style="color:#5af78e">&amp;#39;for&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;tex&amp;#39;&lt;/span> } &lt;span style="color:#78787e">&amp;#34; Lively Previewing&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Julia lang ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;JuliaEditorSupport/julia-vim&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== for GnuPG ===-----------------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;jamessan/vim-gnupg&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; transparent editting .gpg files&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Code/Project navigation ===-------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;easymotion/vim-easymotion&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; quickly move&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;preservim/nerdtree&amp;#39;&lt;/span>, { &lt;span style="color:#5af78e">&amp;#39;on&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;NERDTreeToggle&amp;#39;&lt;/span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== local plugins (manually install and update) ===-----&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34; 中文跳转 (easymotion-like)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;~/.vim/bundle/vim-PinyinSearch&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>call plug#end() &lt;span style="color:#78787e">&amp;#34; required&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装和使用 vim-plug 的步骤：&lt;/p>
&lt;ol>
&lt;li>下载并保存到 &lt;code>~/.vim/autoload/&lt;/code> 目录下 （在终端操作）&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>curl -fLo ~/.vim/autoload/plug.vim --create-dirs &lt;span style="color:#5af78e">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">&lt;/span> https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>配置 &lt;code>~/.vimrc&lt;/code> 文件的相应内容（必须遵循的格式）：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>call plug#begin&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;~/.vim/bundle&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">)&lt;/span> &lt;span style="color:#5af78e">&amp;#34; reuse the bundle dir
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">Plug &amp;#39;tpope/vim-fugitive&amp;#39; &amp;#34;&lt;/span> awsome git wrapper!
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>call plug#end&lt;span style="color:#ff6ac1">()&lt;/span> &lt;span style="color:#5af78e">&amp;#34; required
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 &lt;code>plug#begin()&lt;/code> 和 &lt;code>plug#end()&lt;/code> 之间就是你想要安装和管理的插件的列表。
&lt;code>Plug 'tpope/vim-fugitive'&lt;/code> 就是指明想要安装并管理 vim-fugitive 这个插件。&lt;/p>
&lt;p>如果 &lt;code>plug#begin()&lt;/code> 括弧里为空，则默认是奖所有的插件安装到 &lt;code>.vim/plugged/&lt;/code>，
上文的我的配置中，我是指定了 &lt;code>.vim/bundle&lt;/code> 作为插件的目录
（因为我在使用 vim-plug 之前就已经在这个目录下存放了许多插件，简单复用而已）。&lt;/p>
&lt;p>vim-plug 会自动执行以下两个命令（许多插件需要这两个设定）：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>filetype indent on&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>syntax enable&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>如果你发现自己“完全”按照官方的指南进行安装，可是“插件死活不起作用”，极有可能是
因为你在某个地方设置了完全相反的设定（因为从别的地方 copy 一大段自己没有认真看
过的内容到自己的 .vimrc 文件里）。&lt;/p>
&lt;hr>
&lt;p>更详细的使用方法应该直接去 &lt;a href="https://github.com/junegunn/vim-plug">vim-plug&lt;/a>
的主页了解，那里不仅告诉大家应该怎么安装此插件，还给出各种情况的说明和例子。&lt;/p>
&lt;hr></description></item><item><title>利器1: Oh, My Tmux -- 键盘驱动(为主)的工作流</title><link>/posts/thecli/2022-08-07-tmux/</link><pubDate>Sun, 07 Aug 2022 21:17:59 +0800</pubDate><guid>/posts/thecli/2022-08-07-tmux/</guid><description>&lt;h2 id="tmuxhttpsgithubcomtmuxtmux" >
&lt;div>
&lt;a href="#tmuxhttpsgithubcomtmuxtmux">
#
&lt;/a>
&lt;a href="https://github.com/tmux/tmux">Tmux&lt;/a>
&lt;/div>
&lt;/h2>
&lt;p>&lt;a href="https://github.com/tmux/tmux">Tmux&lt;/a> 是一个终端多路复用器&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>：&amp;hellip;&lt;/p>
&lt;blockquote>
&lt;p>Tmux is a terminal multiplexer: it enables a number of terminals to be
created, accessed, and controlled from a single screen. tmux may be detached
from a screen and continue running in the background, then later reattached.&lt;/p>
&lt;/blockquote>
&lt;p>那到底什么是&lt;ruby>“终端”&lt;rt>terminal&lt;/rt>&lt;/ruby>？&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> 我回答不了这个问题，但我发现了一个很好的解释 &amp;ndash;
&lt;a href="https://unix.stackexchange.com/questions/4126/what-is-the-exact-difference-between-a-terminal-a-shell-a-tty-and-a-con">terminal&lt;/a>&lt;/p>
&lt;p>突然想起《统计学》关于“卡方检验”那一章的经典导语：&lt;/p>
&lt;blockquote>
&lt;p>不要问它的含义，宁可问如何使用它。&amp;ndash; 维特根斯坦&lt;/p>
&lt;/blockquote>
&lt;p>本着“拿来主义”精神，那就来粗略看看 Tmux 能如何使用吧：&lt;/p>
&lt;p>&lt;img alt="IMG_MyTmux &amp;ndash; (gif 失效)" src="https://fgg100y.github.io/img/posts/tmux/ssr_myTmuxDemo.gif">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>启动 Termainal (CTRL+Enter, 这是个人定义的快捷键)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>启动 Tmux 进入我的工作环境 (须知：我这里展示的不是初始化的 Tmux 启动)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>检查一下昨天写的博客写到哪里了 (貌似差不多了，写其他内容)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>切换到下一场“会话”(session) &amp;ndash; vimwiki (这里是我个人项目根目录)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>按进度今天应该介绍一下 Tmux 这个工具 (然后，就到这里了)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>现在阳光明媚（过一会儿就变毒辣），白天还是换到白色背景合适些&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;del>搬砖滴干活咯各位&lt;/del>&lt;br>
&lt;del>嗯，干活？更像是创作&lt;/del>&lt;br>
&lt;del>创作？这算哪门子的&amp;hellip;&lt;/del>&lt;br>
所以还是，干点活吧 ：）&lt;/p>
&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="tmux-的一些关键配置" >
&lt;div>
&lt;a href="#tmux-%e7%9a%84%e4%b8%80%e4%ba%9b%e5%85%b3%e9%94%ae%e9%85%8d%e7%bd%ae">
#
&lt;/a>
Tmux 的一些关键配置
&lt;/div>
&lt;/h2>
&lt;p>如果还没有安装 Tmux，命令行中安装起来也不费事 (Debian系列)：&lt;code>apt install tmux&lt;/code>&lt;/p>
&lt;p>以下的内容均围绕 &lt;code>~/.tmux.conf&lt;/code> 文件展开。如果没有就自己创建一个这文件。
默认这些代码框里的内容（等宽字体那些）是要添加到 &lt;code>~/.tmux.conf&lt;/code> 文件里。&lt;/p>
&lt;p>&amp;ldquo;#&amp;rdquo; 开头的语句是注释说明&lt;br>
&amp;ldquo;$&amp;rdquo; 开头的语句是要在命令行运行的命令&lt;br>
&amp;ldquo;:command&amp;rdquo; 以“冒号接命令名”开头的语句是要在vim命令模式运行的命令&lt;/p>
&lt;h2 id="默认快捷键修改-ctrl-b---ctrl-a" >
&lt;div>
&lt;a href="#%e9%bb%98%e8%ae%a4%e5%bf%ab%e6%8d%b7%e9%94%ae%e4%bf%ae%e6%94%b9-ctrl-b---ctrl-a">
#
&lt;/a>
默认快捷键修改: Ctrl-b -&amp;gt; Ctrl-a
&lt;/div>
&lt;/h2>
&lt;p>Tmux 的默认快捷键是 &lt;code>ctrl-b&lt;/code>，这在键盘上距离略微有点远 (对于我的短手指来说)，
因此我把它修改为 &lt;code>ctrl-a&lt;/code> 组合键。&lt;/p>
&lt;p>将下面语句加入 .tmux.conf 文件：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">set&lt;/span> -g prefix C-a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># # unbind the C-b&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>unbind C-b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># # ensure that we can send Ctrl-a to other apps (e.g., vim)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">bind&lt;/span> C-a send-prefix
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># # setting the delay between prefix and command&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">set&lt;/span> -s escape-time &lt;span style="color:#ff9f43">1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>既然是要用快捷键，那么重新加载 .tmux.conf 文件的自然也安排上：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># reload the .tmux.conf file with Prefix-r&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">bind&lt;/span> r source-file ~/.tmux.conf &lt;span style="color:#5af78e">\;&lt;/span> display &lt;span style="color:#5af78e">&amp;#34;tmuxconf reloaded!&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后，在命令行直接输入快捷组合键：&lt;code>Ctrl+a+r&lt;/code> 即可使配置生效 (&lt;code>+&lt;/code>号的意思是同时摁下)。&lt;/p>
&lt;h2 id="vimtmux-强强组合" >
&lt;div>
&lt;a href="#vimtmux-%e5%bc%ba%e5%bc%ba%e7%bb%84%e5%90%88">
#
&lt;/a>
vim/tmux 强强组合
&lt;/div>
&lt;/h2>
&lt;p>Tmux 支持多个终端窗格 (terminal panes)，每个窗格都是独立的终端，
因此，最明显的事情就是，你可以同时在一块屏幕上“监控”多个不同任务，意思是，
这些不同的任务在视觉上是“同时”呈现的（相对于重叠的 标签页(tab) 而言）。&lt;/p>
&lt;p>如果你恰好也喜欢用 vim 进行码字，也打开了 vim 编辑器 (vim 本身也有窗格功能)，
自然而然的，你肯定想以相同的快捷键来实现不同的 vim/tmux 窗格之间的切换。&lt;/p>
&lt;p>幸运的是，已经有人实现了这样的功能，并共享了，这就是
&lt;a href="https://github.com/christoomey/vim-tmux-navigator">vim-tmux-navigator&lt;/a>.&lt;/p>
&lt;p>vim 有丰富的插件生态，这是 vim 强大生命力的一个体现。
这么好的模式，自然值得借鉴。因此，tmux 也有一个用来管理插件的
&lt;a href="https://github.com/tmux-plugins/tpm">tpm&lt;/a>.&lt;/p>
&lt;p>需要在 vim 和 tmux 两个方面进行配置：&lt;/p>
&lt;ol>
&lt;li>在 vim 方面, 将以下语句加入 .vimrc 文件：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 如果你用的是 Vim-Plug 插件管理器的话&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;christoomey/vim-tmux-navigator&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后运行 &lt;code>:PlugInstall&lt;/code> 来安装这个插件。&lt;/p>
&lt;p>如果你是第一次配置 vim 插件，先去了解
&lt;a href="https://github.com/junegunn/vim-plug">Vim-Plug&lt;/a>.&lt;/p>
&lt;ol start="2">
&lt;li>在 tmux 方面，将下面语句加入 .tmux.conf 文件：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># tpm is a tmux-plugin manager. [details in its github repos]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">set&lt;/span> -g @plugin &lt;span style="color:#5af78e">&amp;#39;tmux-plugins/tpm&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># vim-tmux-navigator: Seamless navigation between tmux panes and vim splits&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">set&lt;/span> -g @plugin &lt;span style="color:#5af78e">&amp;#39;christoomey/vim-tmux-navigator&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># put this &amp;#39;run&amp;#39; command to the very end of .tmux.conf, says the tpm&amp;#39;s readme&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>run &lt;span style="color:#5af78e">&amp;#39;~/.tmux/plugins/tpm/tpm&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>加入这些内容之后，重新加载 tmux 环境, (在已经启动tmux的命令行运行以下命令)：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ tmux &lt;span style="color:#ff5c57">source&lt;/span> ~/.tmux.conf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="主题背景颜色切换" >
&lt;div>
&lt;a href="#%e4%b8%bb%e9%a2%98%e8%83%8c%e6%99%af%e9%a2%9c%e8%89%b2%e5%88%87%e6%8d%a2">
#
&lt;/a>
主题背景颜色切换
&lt;/div>
&lt;/h2>
&lt;p>在我的印象里，感觉黑色/暗色系一下子成了很多应用软件的默认背景色，
我在命令行过活很多年了，对此很是习惯，个人很少看到谁的Terminal是白色背景的。
主要应该是：1）配置了白天黑夜都友好的主题；2）不当回事儿。
但有时候，特别是光线充足的时候，我比较喜欢白色的背景。
所以，我需要能随心所欲切换背景色调。&lt;/p>
&lt;p>这个貌似没法不依赖于外部脚本来实现，至少我没有发现可行的办法。因此，你也需要
&lt;a href="https://www.seanh.cc/2021/01/02/change-between-light-and-dark-themes-in-tmux/">去下载这个脚本&lt;/a>&lt;/p>
&lt;p>Linux 环境氛围是这样的，不要盲目相信别人写的脚本，特别是那些你不认识的人。
相信开源和相信陌生人，毕竟不是同一件事。
意思就是，你在使用这些脚本之前好歹也要看看人家到底写了什么吧。
特别是这种都不超过一页内容的脚本。&lt;/p>
&lt;p>什么？你说你看不懂。事实是，没有人在一开始就什么都看得懂。比如说，
你看到脚本里有这么一句类似于windows上“清理垃圾”的命令： &lt;code>sudo rm -rf /*&lt;/code>，
那你就要保持警惕了。
据说，有些系统会阻止你这么干，但有些系统会“开心地”执行你的旨意；
反正我没试过，我也没有以任何方式暗示或鼓励你要这么清理系统垃圾。&lt;/p>
&lt;p>如果说你下载了那个脚本，放到你喜欢它待的位置，比如说， &lt;code>~/.tmux/bin/&lt;/code>，
然后将下面这条语句加入 &lt;code>~/.tmux.conf&lt;/code> 文件中。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">bind&lt;/span> T run-shell ~/.tmux/bin/toggle-theme
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="关于配置和插件以及管理插件的插件" >
&lt;div>
&lt;a href="#%e5%85%b3%e4%ba%8e%e9%85%8d%e7%bd%ae%e5%92%8c%e6%8f%92%e4%bb%b6%e4%bb%a5%e5%8f%8a%e7%ae%a1%e7%90%86%e6%8f%92%e4%bb%b6%e7%9a%84%e6%8f%92%e4%bb%b6">
#
&lt;/a>
关于配置和插件以及管理插件的插件
&lt;/div>
&lt;/h2>
&lt;p>以上内容分别对应着：&lt;/p>
&lt;p>1）直接对 tmux 进行基本配置；&lt;/p>
&lt;p>2）使用 tmux 插件管理器对 tmux 进行配置；&lt;/p>
&lt;p>3）借用 脚本程序 对 tmux 进行配置。&lt;/p>
&lt;p>毕竟，不是每个人都热衷于使用插件管理器，插件和主件之间的交互方式并不设限。你可以选择使用你觉得合适的方法来完成任务。
要是觉得现有的都不满意，无法满足你的特殊需求，手痒痒的，那就自己搞一个。
很多优秀的软件都是如此，它提供足够好的默认值，但也提供足够多的灵活性，让用户有的选。&lt;/p>
&lt;p>刘建明说“以前没的选，现在想选回做好人，给个机会”，陈永仁答“去同法官讲”。“有的选”这一点十分可贵。&lt;/p>
&lt;hr>
&lt;p>Last update: 2024-07-04&lt;/p>
&lt;blockquote>
&lt;p>USER: Tmux 是什么？
GPT4o: Tmux 是一个终端多路复用器 (terminal multiplexer)，允许用户在一个终端窗口内运行和管理多
个终端会话。它提供了一种方便的方法来分割一个物理终端窗口成多个虚拟终端，并在这些虚拟终端
之间自由切换。Tmux 的主要功能包括：&lt;/p>
&lt;ul>
&lt;li>会话管理：Tmux 可以创建、分离和重新附加会话，使用户可以在不同的终端会话之间快速切换。&lt;/li>
&lt;li>窗口分割：用户可以在一个Tmux会话中将窗口分割成多个窗格，每个窗格可以独立运行一个命令行程序。&lt;/li>
&lt;li>持久性：即使终端窗口关闭，Tmux 会话仍然会保持运行，这样用户可以稍后重新附加会话，继续工作。&lt;/li>
&lt;li>可定制性：Tmux 提供了丰富的配置选项和快捷键，用户可以根据自己的需求进行定制。&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>而如今，或许应该问问GPT4o&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>想知道怎么像这样标注名词吗？去看看&lt;a href="https://www.junyi.dev/posts/a-writing-trick/">这篇博文&lt;/a>&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>利器2: Vimwiki 之 安装和适配数据科学的一些配置</title><link>/posts/thecli/thevim/2022-07-15-vimwiki_part2/</link><pubDate>Sat, 06 Aug 2022 23:33:32 +0800</pubDate><guid>/posts/thecli/thevim/2022-07-15-vimwiki_part2/</guid><description>&lt;p>Last update: 2022-08-06 23:33:32&lt;/p>
&lt;h2 id="vimwiki-插件简介安装和一些设置" >
&lt;div>
&lt;a href="#vimwiki-%e6%8f%92%e4%bb%b6%e7%ae%80%e4%bb%8b%e5%ae%89%e8%a3%85%e5%92%8c%e4%b8%80%e4%ba%9b%e8%ae%be%e7%bd%ae">
#
&lt;/a>
vimwiki 插件简介、安装和一些设置
&lt;/div>
&lt;/h2>
&lt;p>在 vimwiki 里，所有的入口集中在指定的项目根目录下的 index.md 文档里。也就是要构
建的整个笔记系统（随便管它叫什么），index.md 可以成为它的整体框架以及各个主题的
索引。从这里可以去到各个主题，从各个主题的索引去到对应的内容，也可以从一个内容
去到另一个内容，内容可以是本地文档内/文档间，这完全取决于如何构建内容之间的连接。&lt;/p>
&lt;p>vimwiki 提供了必要的基础。但通常我们要写的文档并不是纯文本 (plain text) 而是带有
修饰语法的文本，比如 markdown, Tex/Latex 格式的文档。这两者的区别在于，前者是“
所见即所得”，意思就是你写出来的内容和最后呈现的内容一模一样；后者则更像是写代码，
最后呈现出来的和所写的内容一致（但大部分时候不会一模一样），有人称之为
“所想即所得”，听起来有点玄乎。直接用 plain text 格式不就完了，折腾这些干嘛？遗憾
的是，只要你想要写一些复杂一点的数学公式（求导的链式法则），那么，没有专门的编辑
器的话，最快能够得到规范的数学公式的方法就是 &amp;ndash; 手写。教科书内那些数学公式的呈现
效果基本都来自排版系统工具（Tex/Latex等）的支持。&lt;/p>
&lt;p>如果工作的内容涉及到较多的高等数学，并想自己编写的日志博客得到类似教科书式的数学
公式呈现，markdown 文档是相当友好的文本格式，而从 markdown 到最终效果的呈现之间，
需要我们作一些&lt;a href="https://fgg100y.github.io/posts/thecli/thevim/2022-07-15-vimwiki_part2/###数学公式的呈现">额外配置&lt;/a>。&lt;/p>
&lt;p>现在我只需要用 mardown 格式编写内容，在本地链接的文字上敲击回车键(命令模式下)，
就可以打开这个本地链接的内容文档，然后编辑内容或者发呆或者别的什么，敲击 Delete
键(命令模式下)回到之前跳转来的地方；当然也可以设置和使用其他组合键来去到其他地
方。在每个地方，都可以用浏览器展示当前文档的内容的最终呈现效果，比如使用默认的
&lt;code>&amp;lt;leader&amp;gt;+w+h+h&lt;/code> 快捷键就能在你的默认浏览器展示当前文档的内容，数学公式正是课本
上的那种它该有的样子，也可以像浏览百科网页时那样，自由跳转，来去自如。&lt;/p>
&lt;p>闲话少叙，直接上手。&lt;/p>
&lt;h3 id="安装-vimwiki-插件" >
&lt;div>
&lt;a href="#%e5%ae%89%e8%a3%85-vimwiki-%e6%8f%92%e4%bb%b6">
##
&lt;/a>
安装 vimwiki 插件
&lt;/div>
&lt;/h3>
&lt;p>(使用管理插件的 &lt;a href="https://github.com/junegunn/vim-plug">Vim-Plug&lt;/a> 插件来安装和管理)&lt;/p>
&lt;p>将下面的语句加入你自己的 vim 配置文件中，&lt;/p>
&lt;p>&lt;code>Plug 'vimwiki/vimwiki'&lt;/code>&lt;/p>
&lt;p>然后运行命令 &lt;code>:PlugInstall&lt;/code>&lt;/p>
&lt;p>如果你还不清楚这是什么意思，搜索: vimrc 或者 &lt;a href="https://vim.fandom.com/wiki/Open_vimrc_file">点击这里&lt;/a>&lt;/p>
&lt;h3 id="配置-vimwiki-插件" >
&lt;div>
&lt;a href="#%e9%85%8d%e7%bd%ae-vimwiki-%e6%8f%92%e4%bb%b6">
##
&lt;/a>
配置 vimwiki 插件
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>markdwon 格式&lt;/li>
&lt;/ul>
&lt;p>vimwiki 默认使用 .wiki 格式，但这个格式的语法没有 markdown 语法使用的广泛和普遍,
所以我个人是更倾向于使用 markdown 格式来编写文档。可以按照下面的做法进行相应配置：
将下面的语句加入 &lt;code>.vimrc&lt;/code>:&lt;/p>
&lt;p>&lt;code>let g:vimwiki_ext2syntax={'.md': 'markdown', '.markdown': 'markdown', '.mdown': 'markdown', '.rmd': 'markdown'}&lt;/code>&lt;/p>
&lt;p>这是几个较为常见的 markdown 文档的后缀，最后一种 &lt;code>rmd&lt;/code> 是 Rmardown 格式后缀。&lt;/p>
&lt;ul>
&lt;li>多个 index.md 文档&lt;/li>
&lt;/ul>
&lt;p>前面提到过，index.md 是 vimwiki 的默认入口，类似于一本书的主目录，或者电子菜单。
通常我们需要多个菜单，每个主题配一个菜单，从而使得内容更精简和自洽，而不是所有
的内容全都汇集并拥挤在同一个地方。在顶级菜单，只需要给出到各个主题的链接即可。
就像大饭店的电子菜单，客人对川菜感兴趣就点击“川菜”的目录即可，但没有必要将八大
菜系所有菜名全都拥挤到一个主菜单上。&lt;br>
同上，将下面的语句加入到 &lt;code>.vimrc&lt;/code> &lt;br>
(不要直接复制粘贴，然后指望它就马上见效 🙄 因为你的目录不会/也不需要和我的相同):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-vim" data-lang="vim">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">let&lt;/span> g:vimwiki_list = [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;index&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;index&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;path_html&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimwikiHtml&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;template_ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.html&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;template_default&amp;#39;&lt;/span>:&lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;template_path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/template/&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;custom_wiki2html&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/wiki2html.sh&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/LinuxTools&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/LinuxTools/vim8&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/LinuxTools/CLIs&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing/Julia&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing/Latex&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing/Python&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing/ShellScripts&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ ]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在上面这个例子中，每一个花括号的内容其实就是对应一个主题的菜单 (index.md)，根据
vimwiki 的默认快捷键, 比如， &lt;code>2&amp;lt;leader&amp;gt;ww&lt;/code> 就会直接打开 &lt;code>~/Vimwiki/LinuxTools/index.md&lt;/code> 这个文件。
那么，和以上的设置对应的目录结构是怎么样的呢？以下就是我个人 vimwiki 目录结构 (使用命令 &lt;code>tree -L 2&lt;/code>):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── index.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── LinuxTools
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── commonCommandLines.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── images
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── index.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── jupyterWithDSKernels.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── linux_oracle_client_sqlplus_install_and_connection_setup.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── linux_sqlserver_sqlcmd_install_and_connection_setup.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── newBashConfig.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── python_packages_management.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── tmux.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── vim8.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   └── vimwiki.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── mathjax
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── bower.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── composer.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── CONTRIBUTING.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── es5
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── LICENSE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── package.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   └── README.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── myvimwikidir.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── Programming
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── index.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── Julia
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── Latex
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── Python
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   └── ShellScripts
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── Session.vim
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── template
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── default.html
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   └── markdown.html
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>└── wiki2html.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如前所述，根目录的 &lt;code>index.md&lt;/code> 是顶级主菜单，从这个文件内跳转到各个子主题。比如，
我个人感兴趣的、一直在学习的3大主题分别是：机器学习（未列出），编程和Linux工具。
而在 Programming 这个目录下的 &lt;code>index.md&lt;/code> 就是这个主题的主菜单，显然，这个主题
下还有‘Julia’，‘Latex’，‘Python’，‘ShellScripts’等几个内容。不用说，还可以设计
更细分的内容。每个主题都足够我喝上几壶的了 🍻 。毕竟，谁又说了构建比较完整的
知识体系是一朝一夕能完成的呢？正所谓，志不强者智不达。&lt;/p>
&lt;p>而 mathjax 目录，正是想要展现数学公式效果所依赖的本地包，接下来就讲这个的配置。&lt;/p>
&lt;h3 id="数学公式的呈现" >
&lt;div>
&lt;a href="#%e6%95%b0%e5%ad%a6%e5%85%ac%e5%bc%8f%e7%9a%84%e5%91%88%e7%8e%b0">
##
&lt;/a>
数学公式的呈现
&lt;/div>
&lt;/h3>
&lt;p>&lt;code>vimwiki2html&lt;/code> 命令和 &amp;ldquo;mathjax&amp;rdquo; 目录&lt;/p>
&lt;p>vimwiki 自带了一个 &lt;code>vimwiki2html&lt;/code> 命令，顾名思义，就是把 mardown/wiki 格式的源
文档转换成 html 格式的文档。但这个命令并不支持数学公式的渲染，得改造。这正是
&lt;a href="https://www.mathjax.org/">mathjax&lt;/a> 闪亮登场的地方。已经有人把 &lt;code>vimwiki2html&lt;/code>
命令所依赖的脚本作了相应的&lt;a href="https://gist.github.com/enpassant/0496e3db19e32e110edca03647c36541">升级版&lt;/a>，
它能将 markdown 文件转换为 html 文件，并支持数学公式的渲染。有些人走的&lt;a href="https://gist.github.com/maikeldotuk/54a91c21ed9623705fdce7bab2989742">更远&lt;/a>
但他们均假设没有所谓的什么“外网”访问限制云云。所以，还需要一点折中操作，那就是
‘本地化’。先哲说‘山不过来，我走过去’。网络时代刚好相反，既然访问不到，那就把它
复制回来（基本前提是开源，嗯，伟大的开源）。&lt;/p>
&lt;p>所谓本地化，就是：1）把 mathjax 复制到本地；2）配置 vimwiki 的命令脚本找到它。
以下是具体操作：&lt;/p>
&lt;ol>
&lt;li>在 vimwiki 的根目录下，执行以下命令：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>git clone https://github.com/mathjax/MathJax.git mathjax&lt;span style="color:#5af78e">`&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>下载并更改 &lt;code>wiki2html.sh&lt;/code> 文件的以下内容
(# 号开头的语句是被注释掉的原文，以备参考):&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># HAS_MATH=$(grep -o &amp;#34;\$\$.\+\$\$&amp;#34; &amp;#34;$INPUT&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># if [ ! -z &amp;#34;$HAS_MATH&amp;#34; ]; then&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># MATH=&amp;#34;--mathjax=https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># else&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># MATH=&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># fi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">HAS_MATH&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">$(&lt;/span>grep -o &lt;span style="color:#5af78e">&amp;#34;\$\$*\+\$\$&amp;#34;&lt;/span> &lt;span style="color:#5af78e">&amp;#34;&lt;/span>&lt;span style="color:#ff5c57">$INPUT&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&lt;/span>&lt;span style="color:#ff6ac1">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># # load mathjax from local copy (in case the CDN not work)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> &lt;span style="color:#ff6ac1">[&lt;/span> -n &lt;span style="color:#5af78e">&amp;#34;&lt;/span>&lt;span style="color:#ff5c57">$HAS_MATH&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&lt;/span> &lt;span style="color:#ff6ac1">]&lt;/span>; &lt;span style="color:#ff6ac1">then&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">MATH&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;--mathjax=path2your-mathjax/es5/tex-chtml.js?config=TeX-AMS-MML_HTMLorMML&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">else&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">MATH&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">fi&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意：&amp;ldquo;path2your-mathjax&amp;rdquo; 应该修改成你自己的路径，
比如我的路径是这样的：&amp;rsquo;/home/myacct/VimWiki/mathjax/es5/'&lt;/p>
&lt;p>我不太懂 html，我在这里的诉求就是能让转换后的 html 文档正常显示数学公式。
但后来发现，要实现这个目标，其实不一定非得先转换成 html 文件。&lt;/p>
&lt;h2 id="markdown-文档的即时展示-vim-instant-markdown" >
&lt;div>
&lt;a href="#markdown-%e6%96%87%e6%a1%a3%e7%9a%84%e5%8d%b3%e6%97%b6%e5%b1%95%e7%a4%ba-vim-instant-markdown">
#
&lt;/a>
markdown 文档的即时展示: &lt;code>vim-instant-markdown&lt;/code>
&lt;/div>
&lt;/h2>
&lt;p>前面说过，大部分的 markdown 并非“所见即所得”，但如果一个人的欲望正常，通常都想
要看看正在写的内容到底是什么显示效果，毕竟，早发现早治疗嘛（一气呵成的爽文自然
是有，但我更相信优秀的作品通常是修改出来的）。当然，早就有人把这种正常不过的
需求实现并共享了，那就是： &lt;a href="https://github.com/instant-markdown/vim-instant-markdown">vim instant markdown&lt;/a>
这也是一个 Vim 的插件，具体的安装和配置也简便，直接根据其 readme 文件进行即可。&lt;/p>
&lt;p>但其实“每改一个字就刷新一次”和“写完了所有内容才看上一眼最终效果”一样不甚妥贴，
前者使人分心，后者使人担心。因此，当想要检查某个段落（尤其是包含许多数学公式
的段落）的呈现效果时，调用命令 &lt;code>InstantMarkdwonPreview&lt;/code> ，停用则 &lt;code>InstantMarkdwonStop&lt;/code>。
我很喜欢这种快速反应，有仇就报，当场就报；知错就改，善莫大焉。
但如果觉得白纸黑字的预览网页版面过于朴素不够滋味，那么，可能你需要的是一个能够自定义的网页。&lt;/p>
&lt;h2 id="markdown-文档的即时展示-jekyll-site" >
&lt;div>
&lt;a href="#markdown-%e6%96%87%e6%a1%a3%e7%9a%84%e5%8d%b3%e6%97%b6%e5%b1%95%e7%a4%ba-jekyll-site">
#
&lt;/a>
markdown 文档的即时展示: jekyll-site
&lt;/div>
&lt;/h2>
&lt;p>&lt;code>vim-instant-markdown&lt;/code> 展示的就是文档的呈现内容，也仅仅就是内容而已。如果想要
更多，那么，备选方案就是静态网站生成器（如&lt;a href="https://jekyllrb.com/">jekyll&lt;/a>)，
顾名思义，就是这玩意儿直接给你打包生成网站需要的一揽子部件。
（网站意味着高度定制的自由，是不是听着就觉得开心？如果你够耐心看到这里，我就
估摸着你也应该也是个爱折腾的人，爱在机器上捣鼓各种工具的人想必也知道，所谓的
“高度定制”的另一个说法大约是说：来呀，折腾呀，快活呀）。&lt;/p>
&lt;p>你知道吗？从 &lt;code>vimwiki&lt;/code> 的编辑系统到 jekyll 博客网页，只需要一个命令：&lt;code>:Postit&lt;/code>&lt;/p>
&lt;p>当然了，这明显属于广告用语，和‘一天学会python，七天掌握机器学习’之类差不多。&lt;/p>
&lt;p>俗语有云：“前端一分钟，后端十年功”。&lt;code>Postit&lt;/code> 命令需要一些基础来支撑：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-viml" data-lang="viml">&lt;span style="display:flex;">&lt;span>command Postit :&lt;span style="color:#ff6ac1">execute&lt;/span> &lt;span style="color:#5af78e">&amp;#34;w!&amp;#34;&lt;/span> . &lt;span style="color:#5af78e">&amp;#34;Path_to_jekyllsite_root/_posts/&amp;#34;&lt;/span> . strftime(&lt;span style="color:#5af78e">&amp;#34;%Y-%m-%d-&amp;#34;&lt;/span>) . expand(&lt;span style="color:#5af78e">&amp;#34;%:t&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这语句要写在 &lt;code>.vimrc&lt;/code> 文件里，这个实际上是设置 vim 命令。&lt;/p>
&lt;p>注: 这个命令的实际意思是：将当前编辑的文件以 jekyll 的 post 文件的所要求格式
进行命名，并保存到你的 jekyll 项目的 _post/ 目录下。&lt;/p>
&lt;p>因为 jekyll 的 post 全部要求以“年-月-日-”作为文件名前缀 (比如：
“2022-02-02-好多二.md”)。命令中的 “.” 是 viml 语法中 &amp;ldquo;concatenate&amp;rdquo; 的意思。&lt;/p>
&lt;p>虽然谈不上难以忍受，但我个人不是很理解这种硬编码，文件命名格式为何非如此不可？
是bug还是feature，那就见仁见智了。我听说还有一个静态网站生成器名叫
&lt;a href="https://gohugo.io/">Hugo&lt;/a> 的，不知其手艺如何 &amp;hellip;&lt;/p>
&lt;hr>
&lt;p>刚开始使用 vimwiki 时，也是不停的摸索，数学公式的显示一直是个头疼的问题，毕竟，
从“歪果仁”那里借鉴来的默认配置需要能访问外网，而这个想必不是我们能够默认得了的，
只能先忍着那些令人不快的如同乱码的 latex 语句挂在页面上，
（尤其是，当你明明知道这些公式本可以优雅的展示，却不能够时，不快就变成了愤怒）。&lt;/p>
&lt;p>没有像作为新手时在不同的 Linux 发行版跳来跳去那般，我知道 vimwiki 就是我的菜，
以前使用 vimwiki 过程碰上的各种“暂时”的没有解决的问题，开始变得令人不能忍受，
特别是平时浏览其他网页时每每看到人家的的数学公式又多又靓，那简直就是一场侮辱。
我走了这么远，就差那么最后一步，我心不甘。所以我就折腾，一天，两天，三天 &amp;hellip;
我是贪婪的人，无法放弃一步之遥的诱惑，幸运的是我还是折腾到了我想要的“更多”。&lt;/p>
&lt;p>是的，距离太远可能直接放弃，而一步之遥最是销魂 😂&lt;/p>
&lt;p>其实，该庆幸的是我碰上的问题早就有人先碰上也先解决了，我只是找到了这个方法，
应该说是‘搜索’到了这个方法，并作了必要的调整。‘闻道有先后’的基础就是分享，
对于这些解决了实际问题的人，很是感激他们的分享，没有分享，大家的日子不会好过。&lt;/p></description></item><item><title>利器3: Jupyterlab and its Kernels</title><link>/posts/thecli/2022-07-22-jupyterwithdskernels/</link><pubDate>Fri, 22 Jul 2022 22:01:51 +0800</pubDate><guid>/posts/thecli/2022-07-22-jupyterwithdskernels/</guid><description>&lt;p>&lt;img alt="IMG_jupyterlab" src="images/jupyter_kernels.png">&lt;/p>
&lt;p>New machine needs to be tailored for a better personal workflow. And this is
about how &lt;a href="https://jupyter.org/">jupyter&lt;/a> can be a multi-language support
co-work platform for regular DataScience works. Also note that Julia community
has &lt;a href="https://github.com/fonsp/Pluto.jl">pluto&lt;/a> notebook, and R has its
&lt;a href="https://www.rstudio.com/">RStudio&lt;/a>.&lt;/p>
&lt;h1 id="jupyter-julia--python--r-all-in-one" >
&lt;div>
&lt;a href="#jupyter-julia--python--r-all-in-one">
##
&lt;/a>
JuPyteR: Julia + Python + R all in one
&lt;/div>
&lt;/h1>
&lt;p>1 check the Python came with system&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ which python3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If there is no python3 yet, install one:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ sudo apt install python3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that this would install the latest version of Python.&lt;/p>
&lt;p>2 Poetry or Virtualenv (Poetry is way tooooo slow 2021-12)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># create virtual envs:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>python3 -m venv dsvenv
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># install jupyterlab:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./dsvenv/bin/python -m pip install jupyterlab
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that this may create a venv without &lt;code>activate&lt;/code> scripts.
If this is the case, check &lt;a href="https://stackoverflow.com/questions/26215790/venv-doesnt-create-activate-script-python3">more discussion
here&lt;/a>&lt;/p>
&lt;p>3 &lt;a href="https://mirrors.tuna.tsinghua.edu.cn/CRAN/">install R&lt;/a>, then&lt;/p>
&lt;p>4 &lt;a href="https://julialang.org/downloads/platform/#linux_and_freebsd">install Julia&lt;/a>&lt;/p>
&lt;p>5 activate python&amp;rsquo;s dsvenv (source ./dsvenv/bin/activate), then&lt;/p>
&lt;p>a. Enter interactive R (REPL environment)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-R" data-lang="R">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># install &amp;#39;IRkernel&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#57c7ff">install.packages&lt;/span>(&lt;span style="color:#5af78e">&amp;#39;IRkernel&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># register the kernel in the current R installation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>IRkernel&lt;span style="color:#ff6ac1">::&lt;/span>&lt;span style="color:#57c7ff">installspec&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># exit&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#57c7ff">q&lt;/span>()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>b. Enter interactive Julia (./path-to/julia.1.6.5/bin/julia)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-Julia" data-lang="Julia">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">using&lt;/span> Pkg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Pkg&lt;span style="color:#ff6ac1">.&lt;/span>add(&lt;span style="color:#5af78e">&amp;#34;IJulia&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Optional: build IJulia&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Pkg&lt;span style="color:#ff6ac1">.&lt;/span>build(&lt;span style="color:#5af78e">&amp;#34;IJulia&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that if the path of binary of Julia somehow changed (reinstall etc),
one need to perform extra command &lt;code>Pkg.build(&amp;quot;IJulia&amp;quot;)&lt;/code> which tells jupyter
where to find the binary of Julia.&lt;/p>
&lt;p>6 launch jupyterlab server, and that&amp;rsquo;s it!&lt;/p></description></item><item><title>利器2: Vimwiki 之 如何用 vimwiki 记笔记</title><link>/posts/thecli/thevim/2022-07-15-vimwiki/</link><pubDate>Thu, 21 Jul 2022 23:37:31 +0800</pubDate><guid>/posts/thecli/thevim/2022-07-15-vimwiki/</guid><description>&lt;h2 id="个人维基-personal-wiki" >
&lt;div>
&lt;a href="#%e4%b8%aa%e4%ba%ba%e7%bb%b4%e5%9f%ba-personal-wiki">
#
&lt;/a>
个人维基 (personal wiki)
&lt;/div>
&lt;/h2>
&lt;p>阅读过《爱丽丝漫游奇境》的小伙伴应该会觉得熟悉，维基就像那个“兔子洞”，
每个词条都可以是一个通往其他奇境的大门，但它只对有好奇心的人才打开。
（或者说有好奇心的人才会打开它，尼奥要是没有选择红色💊，故事恐怕就没趣得多）。
这是在维基上阅读时常有的感受。（其他网站很多时候则搞的更像是“盘丝洞”。）&lt;/p>
&lt;p>每个人都有创作的冲动。
然而事实可能更简单:平时读书学习工作时喜欢东写西划总会留下一些‘笔记’。
对别人来说就是些胡涂乱画，可自己总觉得“珍贵” &amp;ndash; “娘不嫌儿丑”说的大概就是这个。
慢慢地，积累的内容越来越多，涉及的范围越来越广，也就显得越来越零碎。
（嗯，为什么不在开始的时候就规划好呢？爸妈通常都是提这种好问题的高手)。
不过这在我看来更像一种“马后炮”式的责问，总有一丢丢“似是而非”的感觉。
学习的过程更像一种探索过程，对大部分人来说，事先恐怕都无法清晰地知道,
书山的路通向何处，学海的舟引你走向哪里。对于不能预先知道细节的内容，
通常会在开始的时候冠以“我的笔记”这么一个目录，然后下设一些粗略的学科名称目录，
直到不再满意这样的安排。毫无疑问，下一步就是要用一种合适的方式将它们组织起来。&lt;/p>
&lt;p>相对独立的主题自成体系，不同主题之间关联的内容可以连接起来，
不仅在阅读时可以享受这种便捷的自由跳转，最好在设计和编写时也能如此。
对我而言，答案就是 &lt;a href="https://github.com/vimwiki/vimwiki">vimwiki&lt;/a>.&lt;/p>
&lt;p>阅读的时候自由跳转，这个好理解，可编写内容不都一篇一篇的来吗？
编写的时候也“胡崩乱跳”的，听起来可不怎么美妙，怕不是有毛病？不，不要误会，
这其实是指：1）同时在多个窗格(Pane)打开多个文档；2）在窗格之间进行“闪转腾挪”。&lt;/p>
&lt;p>如果是编写过比较复杂的模块的小伙伴可能会更深有感触，
这种不同文档之间的“旋转跳跃我开天眼”的要求其实并不过分,
只恨自己的屏幕不够多不够大放不下那段段优雅的代码
（据可靠的谣言称，有些程序猿一天80%的时间是在欣赏自己写的代码中度过）。&lt;/p>
&lt;p>最典型的莫过于从函数调用的地方，跳转到在那遥远的地方的函数定义模块，
如果这两个地方的关系隔着三五个或者更多的模块的时候，(可能也是需要重构的信号)
那么，如果不能同时将这几个‘密接’文档铺在眼前，而是一个看完再看另一个，
朋友，我不知道你的情况如何，反正我是很容易迷失在这茂密的代码丛林里，晕头转向。&lt;/p>
&lt;p>总而言之，
核心的问题在于如何组织这些文档，使得自己在构建个人‘知识库’的过程更丝滑畅快。&lt;/p>
&lt;p>维基的特点就是“你中有我，我中有他”，比如说，
在组织和构建关于“线性回归”内容，我希望有一个“入口”文档，称之为主题目录，
这个文档只对要写的章节内容进行罗列和简介，更像一种“顶级菜单” (top level manu) ，
这个菜单包含些什么菜呢？简介大概是这样的：&lt;/p>
&lt;ol>
&lt;li>简单线性回归
&lt;ul>
&lt;li>斜率和截距&lt;/li>
&lt;li>最小二乘法&lt;/li>
&lt;li>参数评估有多准
&lt;ul>
&lt;li>置信度区间&lt;/li>
&lt;li>假设检验&lt;/li>
&lt;li>P值: 有多少爱可以重来&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>多元线性回归
&lt;ul>
&lt;li>自变量和因变量到底有没有关系&lt;/li>
&lt;li>因变量和哪些自变量有什么关系&lt;/li>
&lt;li>模型拟合
&lt;ul>
&lt;li>残差(RSE)&lt;/li>
&lt;li>$R^2$ 统计量&lt;/li>
&lt;li>Adjusted $R^2$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>贝叶斯线性回归
&lt;ul>
&lt;li>是先验还是偏见？
&lt;ul>
&lt;li>我认为 $\Theta$ 不只一个&lt;/li>
&lt;li>贝叶斯定律&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>后验概率估计
&lt;ul>
&lt;li>MCMC&lt;/li>
&lt;li>吉布斯采样&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>广义线性回归
&lt;ul>
&lt;li>指数族分布：不只有正态分布&lt;/li>
&lt;li>最大熵：我来教你挑选分布&lt;/li>
&lt;li>链接函数：线性空间到非线性空间的映射&lt;/li>
&lt;li>汉密尔顿蒙特卡洛&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>这就是关于“线性回归”内容的主题目录，
列出来的每个点都可以设置为链接点（但不是必须这么做），
从这个主题目录，可以去到任何的单个文档，在每个文档里，
都可以设置指向其他文档的链接，或者指向网络资源的链接（事事亲为并非必要）。&lt;/p>
&lt;p>多年以来我已经或多或少地做了一些章节内容的笔记，缺的正是这样的一个主题目录。&lt;/p>
&lt;p>至于编辑内容的时候要不要在一块屏幕上“同时”并列展开多个文档，并“跳来跳去”，
可以说这只是一些人的特殊癖好，并不是非如此不可。
比如，24寸屏幕上如果只打开一个文档，我觉得是对空间的极大浪费；
但要知道，如果在13寸的屏幕上，有时我也进入 &lt;a href="https://github.com/junegunn/goyo.vim">goyo
模式&lt;/a> 。&lt;/p>
&lt;p>如果你点开前文 vimwiki 的链接，那你应该知道它是 Vim 的一个插件。&lt;/p>
&lt;p>如果你尚不清楚 Vim 是干什么的，或者仅仅听说 Vim 的学习曲线是“出了名的吓人”，
这是不对的，至少你可以看到：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">&lt;img alt="learning_curves" src="https://fgg100y.github.io/img/posts/vimwiki_intro/editors_learning_curves.jpg">&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">&lt;em>some text editors&amp;rsquo; learning curve&lt;/em>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Emacs 才是无可争议的 NO.1 😂&lt;/p>
&lt;p>如果不幸的是至今您仍旧只在不幸的操作系统过活，👉 是的，我指的就是巨硬系统。
不妨去&lt;a href="https://www.vim.org/download.php">下载 Gvim&lt;/a>来尝试别样的编辑的滋味，&lt;/p>
&lt;p>或者您是刚刚开启 Linux 幸福之路的人，或者想试一试 Vim ，
很简单，直接上手类型的，在 Terminal 中输入 &lt;code>vimtutor&lt;/code>，退出输入 &lt;code>:q&lt;/code>&lt;/p>
&lt;p>最好的 vim 学习材料会在输入 &lt;code>:help&lt;/code> 之后出现（但不一定是最好的入门材料）。
或许你会想看看一些入门的材料，比如 &lt;a href="http://vimcasts.org/">vimcast&lt;/a> 视频，
比如，年代略微久远的 &lt;a href="https://vim.swaroopch.com/">A Byte of Vim&lt;/a>，
内容及其详尽的 &lt;a href="http://www.oualline.com/vim-book.html">Vim Tutorial and Reference&lt;/a>&lt;/p>
&lt;hr>
&lt;p>Last update: 2024-07-04 Thu&lt;/p></description></item><item><title>Linear Regression: frequentist and bayesian</title><link>/posts/regressionmodels/linear_regression/</link><pubDate>Wed, 25 Aug 2021 13:49:40 +0800</pubDate><guid>/posts/regressionmodels/linear_regression/</guid><description>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>**Important Note**:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Almost all the contents (text, images) are came from these great books and
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>online resources:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Statistics, by David Freeman, Robert Pisani, and Roger Perves
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* 统计学, David Freeman *et.al* 著，魏宗舒 等译，中国统计出版社
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* 机器学习, 周志华 著 (大名鼎鼎的‘西瓜书’)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* An Introduction to Statistical Learning, by Gareth James, Daniela Witten,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Trevor Hastie, and Robert Tibshirani
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Deep Learning, a.k.a, the flower book, by Ian Goodfellow, Yoshua Bengio, and
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Aaron Courville
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Introduction to Machine Learning, Barnabas Poczos, Aarti Singh, CMU-10701
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Bayesian Methods, Nicholas Ruozzi, UT-DALLAS
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 style="text-align: center;">Linear Regression&lt;/h1>
&lt;h2 id="part-0-regression-101" >
&lt;div>
&lt;a href="#part-0-regression-101">
#
&lt;/a>
Part-0: Regression 101
&lt;/div>
&lt;/h2>
&lt;blockquote>
&lt;p>$\text{You&amp;rsquo;ve got to draw the line somewhere.}$&lt;/p>
&lt;/blockquote>
&lt;h3 id="introduction" >
&lt;div>
&lt;a href="#introduction">
##
&lt;/a>
Introduction
&lt;/div>
&lt;/h3>
&lt;p>The regression method describes how one variable depends on another. For example, take height and weight. Naturally, the taller men weighed more. How much of an increase in weight is associated with a unit increase in height? To get started, look at the scatter diagram (figure 1 on below). Height is plotted on the horizontal axis, and weight on the vertical. The summary statistics are&lt;/p>
&lt;p>$\text{average height} \approx 70 \ inches,\qquad SD \approx 3 \ inches$&lt;/p>
&lt;p>$\text{average height} \approx 70 \ inches, \qquad SD \approx 45 \ pounds, \qquad r \approx 0.40$&lt;/p>
&lt;p>The scales on the vertical and horizontal axes have been chosen so that one SD of height and one SD of weight cover the same distance on the page. This makes the SD line (dashed) rise at 45 degreed across the page. There is a fair amount of scatter around the line: $r$ is only 0.40.&lt;/p>
&lt;p>&lt;img alt="IMG: regression_line" src="images/stats_weight_height.png">&lt;/p>
&lt;p>Figure 1. Scatter diagram. Each point shows the height and weight for one of 471 men age 18-24 in a dataset. The vertical strip represents men who are about one SD above average in height. Those who are also one SD above average in weight would be plotted along the dashed SD line. Most of the men in the strip are below the SD line: they are only part of an SD above average in weight. The &lt;strong>solid&lt;/strong> regression line estimates average weight at each height.&lt;/p>
&lt;p>The vertical strip in figure 1 shows the men who were one SD above average in height were quite a bit less than one SD above average in weight. This is where the correlation of 0.40 comes in. Associated with an increase of one SD in height there is an increase of &lt;strong>only 0.40&lt;/strong> SDs in weight, on the average.&lt;/p>
&lt;p>To be more specific, take the men who are one SD above average in height:
$$
\text{average height} + SD\ \text{of height} = 70 \ in + 3 \ in = 73 \ in
$$
Their average weight will be above the overall average by $0.40 \times 45 \ lb = 18 \ lb$.&lt;/p>
&lt;p>So, the average weight of these men is around
$$
\text{average weight} + 0.40 \times (SD\ \text{of weight}) = 180 \ lb + 18 \ lb = 198 \ lb
$$
The point (73 inches, 198 pounds) is marked by a cross in figure 1 ( and the points that are 2SD above (76 in, 216 lb) and below (64 in, 144 lb) the average of height as well). All the points (height, estimate for average weight) fall on the solid line shown in figure 1. This is the &lt;em>regression line&lt;/em>. The line goes through the point of averages: men of average height should also be of average weight.&lt;/p>
&lt;p style="text-align:center;color:blue;">
The regression line estimates the average value for y corresponding to each value of x.
&lt;/p>
&lt;p>Along the regression line, associated with each increase of one SD in height there is an increase of only 0.40 SDs in weight. Remember where the 0.40 comes from. It is the correlation between height and weight. NOTE that: Two different SDs are involved here: the SD of $x$, to gauge change in $x$; and the SD of $y$, to gauge changes in $y$.&lt;/p>
&lt;p>This way of using the correlation coefficient to estimate the average value of $y$ for each value of $x$ is called the &lt;strong>regression method&lt;/strong>. The method can be stated as follows.
$$
\fbox{Associated with each increase of one SD in x there is an increase of only r SDs in y, on the average.}
$$&lt;/p>
&lt;blockquote>
&lt;p>Correlation: Like father, like son.&lt;/p>
&lt;blockquote>
&lt;p>If there is a strong association between two variables, then knowing one helps a lot in predicting the other. But when there is a weak association, information about one variable does not help much in guessing the other.&lt;/p>
&lt;/blockquote>
&lt;p>The correlation coefficient is a measure of linear association, or clustering around a line. The relationship between two variables can be summarized by&lt;/p>
&lt;ul>
&lt;li>the average of the $x$-values, the SD of the $x$-values,&lt;/li>
&lt;li>the average of the $y$-values, the SD of the $y$-values,&lt;/li>
&lt;li>the correlation coefficient $r$.&lt;/li>
&lt;/ul>
&lt;p>Computing the correlation coefficient&lt;/p>
&lt;p>Here is the procedure for computing the correlation coefficient.
$$
\boxed{\text{Convert each variable to standard units.} \\
\text{The average of the products gives the correlation coefficient.}}
$$&lt;/p>
&lt;p>$$
\fbox{Convert each variable to standard units.
The average of the products gives the correlation coefficient.}
$$&lt;/p>
&lt;p>Recall that &amp;ldquo;Convert each variable to standard units&amp;rdquo; means &lt;strong>standardization&lt;/strong>. Let $x = {1, 3, 4, 5, 7 }, y = {5, 9, 7, 1, 13 } $ be vectors of variables, the mean is given by
$$
\mu = \frac{1}{|a|} \sum_i a_i
$$
And the SD is the &amp;ldquo;r.m.s size of the deviation from the average&amp;rdquo;, can be given by
$$
\sigma = \sqrt{\frac{1}{|a|} \sum_i (a_i - \mu)^2}
$$
where $|a|$ is the number of data points, $a_i$ is the $i$-th data point in the data set.&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>Table 1. Computing $r$.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">x&lt;/th>
&lt;th style="text-align:center">y&lt;/th>
&lt;th style="text-align:center">x in standard units&lt;/th>
&lt;th style="text-align:center">y in standard units&lt;/th>
&lt;th style="text-align:center">Product&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">-1.5&lt;/td>
&lt;td style="text-align:center">-0.5&lt;/td>
&lt;td style="text-align:center">0.75&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">9&lt;/td>
&lt;td style="text-align:center">-0.5&lt;/td>
&lt;td style="text-align:center">0.5&lt;/td>
&lt;td style="text-align:center">-0.25&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">4&lt;/td>
&lt;td style="text-align:center">7&lt;/td>
&lt;td style="text-align:center">0.0&lt;/td>
&lt;td style="text-align:center">0.0&lt;/td>
&lt;td style="text-align:center">0.00&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0.5&lt;/td>
&lt;td style="text-align:center">-1.5&lt;/td>
&lt;td style="text-align:center">-0.75&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">7&lt;/td>
&lt;td style="text-align:center">13&lt;/td>
&lt;td style="text-align:center">1.5&lt;/td>
&lt;td style="text-align:center">1.5&lt;/td>
&lt;td style="text-align:center">2.25&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>$$
\begin{eqnarray}
r
&amp;amp;=&amp;amp; \text{average of [(x in standard units) times (x in standard units)]} \\
\\
&amp;amp;=&amp;amp; \frac{0.75 - 0.25 + 0.00 -0.75 + 2.25}{5} = 0.40
\end{eqnarray}
$$&lt;/p>
&lt;p>This complete the solution.&lt;/p>
&lt;/blockquote>
&lt;h3 id="slope-and-intercept" >
&lt;div>
&lt;a href="#slope-and-intercept">
##
&lt;/a>
Slope and Intercept
&lt;/div>
&lt;/h3>
&lt;p>Does education pay? Figure 1 shows the relationship between income and education, for a sample of 562 men age 25-29 in 2005. The summary statistics are
$$
\begin{eqnarray}
\text{average education} &amp;amp;\approx&amp;amp; 12.5\ \text{years}, &amp;amp;\qquad&amp;amp; SD \approx 3\ \text{years} \\
\text{average income} &amp;amp;\approx&amp;amp; $30000,\ &amp;amp;\qquad&amp;amp; SD \approx $24000, \qquad r \approx 0.25
\end{eqnarray}
$$
The regression estimates for average income at each educational level fall along the regression line shown in the figure. The line slopes up, showing that on the average, income does go up with education.&lt;/p>
&lt;p>&lt;img alt="Do education pay" src="./images/stats_education_income.png">&lt;/p>
&lt;p>Any line can be described in terms of its slope and intercept. The y-intercept is the height of the line when $x$ is $0$. And the slope is the rate at which $y$ increases, per unit increase in $x$. Slope and intercept are illustrated in figure 2.&lt;/p>
&lt;p>&lt;img alt="IMG: slopeNintercept" src="images/stats_slope_intercept.png">&lt;/p>
&lt;p>&lt;strong>How do you get the slope of the regression line?&lt;/strong> Take the income-education example.
Associated with an increase of one SD in education, there is an increase of $r$ SDs in
income. On this basis, 3 extra years (one SD) of education are worth an extra
$r \times SD = 0.25 \times 24000 = 6000$ of income, on the average. So each extra year in
worth \$6000 / 3 = \$2000. The slope of the regression line is \$2000 per year.&lt;/p>
&lt;p>&lt;img alt="IMG: slopeNintercept2" src="images/stats_slope_intercept2.png">&lt;/p>
&lt;p>The intercept of the regression line is the height when $x = 0$, corresponding to men with $0$ years of education. There men are 12.5 years below average in education.
Each year costs \$2000 -- that is what the slope says. A man with no education should have an income which is below average by
$$
12.5\ \text{years} \times 2000\ \text{per year} = 25000.
$$
His income should be $\$30000 - \$25000 = \$5000$. That is the intercept (figure 3): the predicted value of $y$ when $x = 0$.&lt;/p>
&lt;hr>
&lt;p style="text-align:justify;color:blue;">
Associated with a unit increase in x there is some average change in y. The slope of the regression line estimates this change. The formula for the slope is
&lt;/p>
&lt;p>$$
{r \times SD\ \text{of y} \over SD\ \text{of x}}
$$&lt;/p>
&lt;p style="text-align:justify;color:blue;">
The intercept of the regression line is just the predicted value for y when x is 0.
&lt;/p>
&lt;hr>
&lt;p>The equation of a line can be written in terms of the slope and intercept:
$$
y = \text{slope} \times x + \text{intercept},
$$
which is called the &lt;em>regression equation&lt;/em>. There is nothing new here. The regression equation is just a way of predicting $y$ from $x$ by the regression method.&lt;/p>
&lt;p>The regression line becomes unreliable when you are far from the center of the data, so a &lt;em>negative&lt;/em> intercept is not too disturbing (when the calculation results in some negative value which may seen absurd).&lt;/p>
&lt;p style="text-align:justify;color:blue;">
If you run an observational study, the regression line only describes the data that you see. The line cannot be relied on for predicting the results of interventions.
&lt;/p>
&lt;h3 id="the-least-squares" >
&lt;div>
&lt;a href="#the-least-squares">
##
&lt;/a>
The Least Squares
&lt;/div>
&lt;/h3>
&lt;p>Sometimes the points on a scatter diagram seem to be following a line. The problem discussed in this section is &lt;strong>how to find the line which best fits the points&lt;/strong>. Usually, this involves a compromise: moving the line closer to some points will increase it distance from others. To resolve the conflict, two steps are necessary.&lt;/p>
&lt;ul>
&lt;li>First, define an average distance from the line to all the points.&lt;/li>
&lt;li>Second, move the line around until this average distance is as small as possible.&lt;/li>
&lt;/ul>
&lt;p>To be more specific, suppose the line will be used to predict $y$ from $x$. Then the error made at each point is the vertical distance from the point to the line (a.k.a, the &lt;strong>residual&lt;/strong>, means the difference between the $i$th observed and the $i$th response that is predicted by linear model). In statistics, the usual way to define the average distance is by taking the root-mean-square of the errors. This measure of average distance is called the &lt;em>r.m.s error of the line&lt;/em>. (It was first proposed by Gauss)&lt;/p>
&lt;p>The second problem, how to move the line around to minimize the r.m.s error, was also solved by Gauss:&lt;/p>
&lt;hr>
&lt;p style="text-align:center;color:blue;">
Among all lines, the one that makes the smallest r.m.s error in predicting y form x is the regression line.
&lt;/p>
&lt;hr>
&lt;blockquote>
&lt;p>Recall that:&lt;/p>
&lt;p>The r.m.s error for regression says how far typical points are above or below the regression line.
$$
r.m.s\ error = \sqrt{\frac{1}{n} \sum^n_i (y_i - \hat{y_i})^2}
$$
where $n$ is the number of data points, $y_i$ the $i$-th actual value, $\hat{y_i}$ the corresponding predicted value.&lt;/p>
&lt;p>And the r.m.s error for the regression line of $y$ on $x$ can also be figured as
$$
\sqrt{1 - r^2} \times SD_y
$$
where $r$ is the correlation coefficient&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> between $x$ and $y$.&lt;/p>
&lt;/blockquote>
&lt;p>For this reason, the regression line is often called &lt;em>least squares line&lt;/em>: the errors are squared to compute the r.m.s error, and the regression line makes the r.m.s error as small as possible.&lt;/p>
&lt;p>In other words, the least squares approaches choose $\beta_0$ (the intercept) and $\beta_1$ (the slope) to minimize the &lt;em>residual sum of squares&lt;/em> (RSS) which is defined as
$$
RSS = e_1^2 + e_2^2 + \cdots + e_n^2 = \sum^n_{i=1} (y_i - \hat{y_i})^2
$$
where $e = y_i - \hat{y_i}$ is called the &lt;strong>residual&lt;/strong>. Obviously, the r.m.s error is the root of the mean of RSS.&lt;/p>
&lt;p>Linear regression is a very simple approach for supervised learning. In particular, linear regression is a useful tool for predicting a quantitative response. Many fancy statistical learning approaches can be seen as generalizations or extensions of linear regression.&lt;/p>
&lt;p>$\color{Green}{\text{Example}}$&lt;/p>
&lt;p>According to Hooke&amp;rsquo;s law, the amount of stretch is proportional to the weight $x$. The new length of the spring is
$$
y = mx + b.
$$
In this equation, $m \in \mathbb{R}$ and $b \in \mathbb{R}$ are constants which depend on the spring. Their values are unknown, and have to be estimated using &lt;strong>experimental data&lt;/strong>.&lt;/p>
&lt;center>
Table 1. Data on Hooke's law.
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Weight (kg)&lt;/th>
&lt;th>Length (cm)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>0&lt;/td>
&lt;td>439.00&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>439.12&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4&lt;/td>
&lt;td>439.21&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>6&lt;/td>
&lt;td>439.31&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>439.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>10&lt;/td>
&lt;td>439.50&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/center>
The correlation coefficient[^1] for the data in table 1 is 0.999, very close to 1 indeed. So the points almost form a straight line (figure 5), just as Hooke's law predicts. The minor deviations from linearity are probably due to measurement error; neither the weights nor the length have been measured with perfect accuracy. (Nothing ever is. [When it comes to measurement])
&lt;p>&lt;img alt="Hooke&amp;rsquo;s law" src="images/stats_hookes_law.png">&lt;/p>
&lt;p>Our goal is to estimate $\hat{m}$ and $\hat{b}$ in the equation of Hooke&amp;rsquo;s law for this spring:
$$
y = \hat{m} x + \hat{b}
$$
The graph of this equation is a perfect straight line. If the points in figure 5 happened to fall exactly on some line, the slope&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> of that line would estimate $m$, and its intercept would estimate $b$. However, the points do not line up perfectly. Many different lines could be drawn across the scatter diagram, each having a slightly different slope and intercept.&lt;/p>
&lt;p>Which line should be used? Hooke&amp;rsquo;s equation predicts the length from weight. As discussed above, it is natural to choose $m$ and $b$ so as to minimize the r.m.s error, the line $y = \hat{m} x + \hat{b}$ which does the job is the &lt;strong>regression line&lt;/strong>. This is the &lt;em>method of least squares&lt;/em>. In other words, $m$ in Hooke&amp;rsquo;s law should be estimated as the slope of the regression line, and $b$ as its intercept. These are called &lt;em>least squares estimate&lt;/em>, because they minimize root-mean-square error.&lt;/p>
&lt;p>Let&amp;rsquo;s do the arithmetic (in python code):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> numpy &lt;span style="color:#ff6ac1">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># X the weight data; y the length data&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>X &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array([&lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">2&lt;/span>, &lt;span style="color:#ff9f43">4&lt;/span>, &lt;span style="color:#ff9f43">6&lt;/span>, &lt;span style="color:#ff9f43">8&lt;/span>, &lt;span style="color:#ff9f43">10&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array([&lt;span style="color:#ff9f43">439.00&lt;/span>, &lt;span style="color:#ff9f43">439.12&lt;/span>, &lt;span style="color:#ff9f43">439.21&lt;/span>, &lt;span style="color:#ff9f43">439.31&lt;/span>, &lt;span style="color:#ff9f43">439.40&lt;/span>, &lt;span style="color:#ff9f43">439.50&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># mean and Standard Deviation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ---------------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># avg = sum(X) / len(X)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mu_x &lt;span style="color:#ff6ac1">=&lt;/span> X&lt;span style="color:#ff6ac1">.&lt;/span>mean()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mu_y &lt;span style="color:#ff6ac1">=&lt;/span> y&lt;span style="color:#ff6ac1">.&lt;/span>mean()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(&lt;span style="color:#5af78e">f&lt;/span>&lt;span style="color:#5af78e">&amp;#34;The means of X and y: &lt;/span>&lt;span style="color:#5af78e">{&lt;/span>mu_x, mu_y&lt;span style="color:#5af78e">}&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># The means of X and y: (5.0, 439.25666666666666)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># std is the &amp;#34;r.m.s size of the deviation from the average&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>SD_x &lt;span style="color:#ff6ac1">=&lt;/span> X&lt;span style="color:#ff6ac1">.&lt;/span>std()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>SD_y &lt;span style="color:#ff6ac1">=&lt;/span> y&lt;span style="color:#ff6ac1">.&lt;/span>std()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(&lt;span style="color:#5af78e">f&lt;/span>&lt;span style="color:#5af78e">&amp;#34;The SDs of X and y: &lt;/span>&lt;span style="color:#5af78e">{&lt;/span>SD_x, SD_y&lt;span style="color:#5af78e">}&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># The SDs of X and y: (3.415650255319866, 0.16799470891138593)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># convert X into standard unit form&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>X_standard_unit &lt;span style="color:#ff6ac1">=&lt;/span> (X &lt;span style="color:#ff6ac1">-&lt;/span> mu_x) &lt;span style="color:#ff6ac1">/&lt;/span> SD_x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># convert y into standard unit form&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_standard_unit &lt;span style="color:#ff6ac1">=&lt;/span> (y &lt;span style="color:#ff6ac1">-&lt;/span> mu_y) &lt;span style="color:#ff6ac1">/&lt;/span> SD_y
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># correlation coefficient is the average of the products&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r &lt;span style="color:#ff6ac1">=&lt;/span> (X_standard_unit&lt;span style="color:#ff6ac1">.&lt;/span>dot(y_standard_unit)) &lt;span style="color:#ff6ac1">/&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(X_standard_unit)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># r = 0.999167257319307&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># the slope&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>m_hat &lt;span style="color:#ff6ac1">=&lt;/span> (r &lt;span style="color:#ff6ac1">*&lt;/span> SD_y) &lt;span style="color:#ff6ac1">/&lt;/span> SD_x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># m_hat = 0.0491428571428563&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># the intercept, this is the *predicted length* when weight is 0,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>b_hat &lt;span style="color:#ff6ac1">=&lt;/span> mu_y &lt;span style="color:#ff6ac1">-&lt;/span> (mu_x &lt;span style="color:#ff6ac1">*&lt;/span> m_hat)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># b_hat = 439.0109523809524&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>this gives us: $\hat{m} \approx 0.05$ per kg and $\hat{b} \approx 439.01$ cm.&lt;/p>
&lt;p>The length of the spring under no load is estimated as 439.01 cm. And each kilogram of load causes the spring to stretch by about 0.05 cm. Of course, even Hooke&amp;rsquo;s law has its limits: beyond some point, the spring will break. &lt;strong>Extrapolating beyond the data is risky&lt;/strong>.&lt;/p>
&lt;p>The method of least squares and the regression method involve the same mathematics; but the contexts may be different. In some fields, investigators talk about &amp;ldquo;least squares&amp;rdquo; when they are estimating parameters &amp;ndash; unknown constants of nature like $m$ and $b$ in Hooke&amp;rsquo;s law. In other fields, investigators talk about regression when they are studying the relationship between two variables, like income and education, using non-experimental data.&lt;/p>
&lt;p>&lt;strong>A technical point:&lt;/strong> The least squares estimate for the length of the spring under no load was 439.01 cm. This is a tiny bit longer than the measured length at no load (439.00 cm). A statistician might trust the least squares estimate over the measurement. Why? Because the least squares estimate takes advantage of all six measurements, not just once: some of the measurement error is likely to cancel out. Of course, the six measurements are tied together by a good theory &amp;ndash; Hooke’s law. Without the theory, the least squares estimate wouldn’t be worth much.&lt;/p>
&lt;h3 id="assessing-the-accuaracy-of-the-coefficient-estimates" >
&lt;div>
&lt;a href="#assessing-the-accuaracy-of-the-coefficient-estimates">
##
&lt;/a>
Assessing the Accuaracy of the Coefficient Estimates
&lt;/div>
&lt;/h3>
&lt;p>Assume that the &lt;em>true&lt;/em> relationship (e.g., the Hooke’s law) between $X$ and $Y$ takes the form $Y = f(X) + \epsilon$ for some unknown function $f$, where $\epsilon$ is a mean-zero random error term. If $f$ is to be approximated by a linear function, then we can write this relationship as
$$
Y = \beta_0 + \beta_1 X + \epsilon.
$$
This is the &lt;em>population regression line&lt;/em>. Here $\beta_0$ is the intercept (the expected value of $Y$ when $X$ = 0) and the $\beta_1$ the slop (the average increase in $Y$ associated with a one-unit increase in $X$). The $\epsilon$ (error term, typically assumed to be independent of $X$) is a catch-all for what we miss with this simple model: the true relationship is probably not linear, there may be other variables that cause variation in $Y$, and there may be measurement error.&lt;/p>
&lt;p>The model of &lt;em>population regression line&lt;/em> is the best linear approximation to the true relationship between $X$ and $Y$ (NOTE that the assumption of linearity is often a useful working model. However, it may be not true in reality). The true relationship is generally not known for real data, but the least squares line can always be computed using the cofficient estimation methods. A natural question is as follows: how accurate is the least square line as an estimate of the population regression line?&lt;/p>
&lt;p>The analogy between linear regression and estimation of the mean of a random variable is an apt one based on the concept of &lt;em>bias&lt;/em>. If we use the sample mean $\hat{\mu}$ to estimate $\mu$, this estimate is &lt;em>unbiased&lt;/em>, in the sense that on average, we expect $\hat{\mu}$ to equal $\mu$, if we could average a huge number of estimates of $\mu$ obtained from a huge number of sets of observations. Hence, an unbiased estimator does not &lt;em>systematically&lt;/em> over- or under-estimate the true parameter. The property of unbiasedness holds for the least squares coefficient estimates as well: if we estimate $\beta_0$ and $\beta_1$ on the basis of a particular data set, then our estimates won&amp;rsquo;t be exactly equal to $\beta_0$ and $\beta_1$. But if we could average the estimates obtained over a huge number of date sets, then the average would be spot on!&lt;/p>
&lt;p>So how far off will that single estimate of $\hat{\mu}$ be? In general, we answer this question by computing the &lt;em>standard error&lt;/em> of $\hat{\mu}$, written as $SE(\hat{\mu})$. We have the well-known formula
$$
Var(\hat{\mu}) = SE(\hat{\mu})^2 = {\sigma^2 \over n},
$$
where $\sigma$ is the standard deviation of each of the realizations $y_i$ of $Y$. NOTE that this formula holds iff the $n$ observations are uncorrelated. To compute the standard errors associated with $\hat{\beta_0}$ and $\hat{\beta_1}$, we use the following formulas:
$$
SE(\hat{\beta_0})^2 =
\sigma^2 [{1 \over n} + \frac{\bar{x}^2}{\sum^n_{i=1}(x_i - \bar{x})^2}],
&lt;br>
SE(\hat{\beta_1})^2 =\frac{\sigma^2}{\sum^n_{i=1}(x_i - \bar{x})^2}
$$
where $\sigma^2 = Var(\epsilon)$. In general, $\sigma^2$ is not known, but can be estimated from the data. This estimate of $\sigma$ is known as the &lt;em>residual standard error&lt;/em>, and is given by the formula
$$
\sigma = RSE = \sqrt{RSS / (n-2)}
$$&lt;/p>
&lt;h4 id="confidence-interval" >
&lt;div>
&lt;a href="#confidence-interval">
###
&lt;/a>
Confidence Interval
&lt;/div>
&lt;/h4>
&lt;p>Standard errors can be used to compute the &lt;em>confidence intervals&lt;/em>. A 95% confidence interval is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameters. The range is defined in terms of lower and upper limits computed from the sample of data.&lt;/p>
&lt;p>For linear regression, the 95% confidence interval for $\beta_1$ approximately takes the form
$$
\hat{\beta_1} \pm 2 \cdot SE(\hat{\beta_1}).
$$
That is, there is approximately a 95% chance the true value of $\beta_1$ would be in this range.&lt;/p>
&lt;p>Similarly, for $\beta_0$, its 95% confidence interval takes the form
$$
\hat{\beta_0} \pm 2 \cdot SE(\hat{\beta_0}).
$$
NOTE that here we make an assumption that the errors are Gaussian. And the factor of $2$ in the formula will vary slightly depending on the number of observations $n$ in the linear regression.&lt;/p>
&lt;h4 id="hypothesis-tests" >
&lt;div>
&lt;a href="#hypothesis-tests">
###
&lt;/a>
Hypothesis tests
&lt;/div>
&lt;/h4>
&lt;p>Standard errors can also be used to perform &lt;em>hypothesis tests&lt;/em> on the coefficients. The most common hypothesis test involves testing the &lt;em>null hypothesis&lt;/em> of
$$
H_0 : \text{There is no relationship between X and Y}
$$
versus the &lt;em>alternative hypothesis&lt;/em>
$$
H_a : \text{There is some relationship between X and Y}.
$$
Mathematically, this corresponds to testing
$$
H_0 : \beta_1 = 0
$$
versus
$$
H_a : \beta_1 \ne 0,
$$
since if $\beta_1 = 0$ then the linear regression model reduces to $Y = \beta_0 + \epsilon$, and $X$ is not associated with $Y$.&lt;/p>
&lt;p>To test the null hypothesis, we need to determine whether $\hat{\beta_1}$, our estimate for $\beta_1$, is sufficiently far from zero that we can be confident that $\beta_1$ is non-zero. How far is far enough? This is of course depends on the accuracy of $\hat{\beta_1}$ &amp;ndash; that is, it depends on $SE(\hat{\beta_1})$:&lt;/p>
&lt;ul>
&lt;li>If $SE(\hat{\beta_1})$ is small, then even relatively small values of $\hat{\beta_1}$ may provide strong evidence that $\beta_1 \ne 0$;&lt;/li>
&lt;li>if $SE(\hat{\beta_1})$ is large, then $\hat{\beta_1}$ must be large in absolute value in order for us to reject the null hypothesis.&lt;/li>
&lt;/ul>
&lt;p>In practice, we compute a &lt;em>t-statistic&lt;/em>, given by
$$
t = \frac{\hat{\beta_1} - 0}{SE(\hat{\beta_1})},
$$
which measures the number of standard deviations that $\hat{\beta_1}$ is away from $0$.&lt;/p>
&lt;p>If there really is no relationship between $X$ and $Y$, then we expect that &lt;em>t-statistic&lt;/em> will have a $t$-distribution with $n-2$ degrees of freedom. Consequently, it is a simple matter to compute the probability of observing any number equal to $|t|$ or larger in absolute value, assuming $\beta_1 = 0$. We call this probability the &lt;em>p-value&lt;/em>.&lt;/p>
&lt;p>&lt;strong>p-value interpretation&lt;/strong>&lt;/p>
&lt;p>Roughly speaking, we interpret the p-value as follows: a small p-value indicates that it is unlikely to observe such a substantial association between the predictor and the response due to chance, in the absence of any real relationship between $X$ and $Y$. Hence we &lt;em>reject the null hypothesis&lt;/em>, and declare a relationship to exist between $X$ and $Y$, if the p-value is small enough. Typical p-value cutoffs for rejecting the null hypothesis are 5% or 1%, when $n = 30$, these correspond to &lt;em>t-statistics&lt;/em> of around $2$, and $2.75$, respectively.&lt;/p>
&lt;blockquote>
&lt;p>A small p-value indicates that a particular sample is unlikely if the null hypothesis
is true. It is akin to a jury concluding that it was unlikely that it would have been
presented with this set of evidence if the defendant were innocent, and therefore
reaching a guilty verdict. Of course, that doesn&amp;rsquo;t mean that the defendant is actually
guilty. Perhaps the jury was presented with misleading evidence.
Analogously, a low p-value might be attributable to the null hypothesis actually being
false, or it could simply be that the sample is unrepresentative of the population from
which it is drawn, i.e., the evidence is misleading.&lt;/p>
&lt;/blockquote>
&lt;p>More info about p-value see &amp;ldquo;21.2 Beware of P-values&amp;rdquo; in the book of Prof. John Guttag &amp;lt;&amp;lt;Introduction to computation and programming using python&amp;gt;&amp;gt;.&lt;/p>
&lt;h3 id="assessing-the-accuracy-of-the-model" >
&lt;div>
&lt;a href="#assessing-the-accuracy-of-the-model">
##
&lt;/a>
Assessing the Accuracy of the Model
&lt;/div>
&lt;/h3>
&lt;p>Once we have rejected the null hypothesis in favor of the altervative hypothesis, it is natrual to want to quantify &lt;em>the extent to which the model fits the data&lt;/em>. The quality of a linear regression fit is typically assessed using two related quantities: the &lt;em>residual standard error&lt;/em> ($RSE$) and the $R^2$ statistic.&lt;/p>
&lt;h4 id="residual-standard-error" >
&lt;div>
&lt;a href="#residual-standard-error">
###
&lt;/a>
Residual Standard Error
&lt;/div>
&lt;/h4>
&lt;p>From the model $Y = \beta_0 + \beta_1 X + \epsilon$ that associated with each observation is an error term $\epsilon$. Due to the presence of these error terms, even if we knew the true regression line (i.e., $\beta$s were known), we would not be perfectly predict $Y$ from $X$. The $RSE$ is an estimate of the standard deviation of $\epsilon$. Roughly speaking, it is the average amount that the response will deviate from the true regression line. It is computed using the formula
$$
RSE
= \sqrt{{1 \over n-2} RSS}
= \sqrt{{1 \over n-2} \sum^n_{i=1}(y_i - \hat{y_i})^2}.
$$
NOTE that $RSE$ is slightly different from &lt;em>r.m.s error&lt;/em> which the latter using the number of all samples ($n$) as denominator while the former using $n-2$.&lt;/p>
&lt;p>The $RSE$ is considered a measure of the &lt;em>lack of fit&lt;/em> of the model to the data. The smaller $RSE$ the better the model fitted to the data.&lt;/p>
&lt;h4 id="r2-statistic" >
&lt;div>
&lt;a href="#r2-statistic">
###
&lt;/a>
$R^2$ Statistic
&lt;/div>
&lt;/h4>
&lt;p>The $RSE$ provides an absolute measure of lack of fit of the model to the data. But since it is measured in the units of $Y$, it is not always clear what consititues a good $RSE$. The $R^2$ statistic provides an alternative measure of fit. It takes the form of a &lt;em>proportion&lt;/em>, the proportion of variance explained, and so it always takes on a value between $0$ and $1$, and is independent of the scale of $Y$.&lt;/p>
&lt;p>To calculate $R^2$, we use the formula
$$
R^2 = \frac{TSS - RSS}{TSS} = 1 - \frac{RSS}{TSS}
$$
where $TSS = \sum(y_i - \bar{y})^2$ is the &lt;em>total sum of squares&lt;/em>. Hence $R^2$ measures the &lt;em>proportion of variability in $Y$ that can be explained using $X$&lt;/em>.&lt;/p>
&lt;h3 id="multiple-linear-regression" >
&lt;div>
&lt;a href="#multiple-linear-regression">
##
&lt;/a>
Multiple Linear Regression
&lt;/div>
&lt;/h3>
&lt;p>Simple linear regression[^3] is a useful approach for predicting a response on the basis of a single predictor variable. But in practice we often have more than one predictor. One option is to run multiple separate simple linear regression, each of which uses a different feature as a predictor. However, this approach is not entirely satisfactory[^4].&lt;/p>
&lt;p>Instead of fitting a separate simple linear regression model for each predictor, a better approach is to extend the simple linear regression model[^5] so that it can directly accommodate multiple predictors. We can do this by giving each predictor a separate slope coefficient in a single model. In general, suppose we have $p$ distinct predictors. Then the multiple linear regression model takes the form&lt;/p>
&lt;p>$$
\tag{3.19}
\label{mlr}
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + + \beta_p X_p + \epsilon
$$&lt;/p>
&lt;p>where $X_j$ represents the $j$-th predictor and $\beta_j$ quantifies the association
between that variable and the response. We interpret $\beta_j$ as the &lt;em>average&lt;/em> effect
on $Y$ of a unit increase in $X_j$, &lt;strong>holding all other predictors fixed&lt;/strong>[^6].&lt;/p>
&lt;p>As was the case in the simple linear regression setting, the regression coefficients
$\beta_0, \beta_1, \ldots, \beta_p$ in ($\ref{mlr}$) are unknown, and must be estimated.
Given estimates $\hat{\beta_0}, \hat{\beta_1}, \ldots, \hat{\beta_p}$, we can make
predictions using the formula&lt;/p>
&lt;p>$$
\tag{3.21}
\label{mlrpred}
\hat{y} = \hat{\beta_0} + \hat{\beta_1} x_1 + \hat{\beta_2} x_2 + \cdots + \hat{\beta_p} x_p.
$$&lt;/p>
&lt;p>Then parameters are estimated using the same &lt;strong>least squares&lt;/strong> approach that we saw in
the context of simple linear regression. We choose $\beta_0, \beta_1, \ldots, \beta_p$
to minimize the &lt;strong>sum of squared residuals&lt;/strong>&lt;/p>
&lt;p>$$
\begin{eqnarray}
RSS
&amp;amp;=&amp;amp; \sum^n_{i=1}(y_i - \hat{y}_i)^2 \\
\tag{3.22} \label{rss}
&amp;amp;=&amp;amp; \sum^n_{i=1} \big( y_i - (\hat{\beta_0} + \hat{\beta_1} x_1 + \hat{\beta_2} x_2 + \cdots + \hat{\beta_p} x_p) \big)^2
\end{eqnarray}
$$&lt;/p>
&lt;p>The values $\hat{\beta_0}, \hat{\beta_1}, \ldots, \hat{\beta_p}$ that minimize
($\ref{rss}$) are the multiple least squares regression coefficient estimates. Unlike
the simple linear regression coefficient estimation (the Python code block in previous
section), the multiple regression coefficient estimates have somewhat complicated forms
that are most easily represented using matrix algebra (see detail in section of Normal
equation).&lt;/p>
&lt;p>When we perform multiple linear regression, we usually are interested in answering a few important questions.&lt;/p>
&lt;hr>
&lt;ol>
&lt;li>Is at least one of the predictors $X_1, X_2, \ldots, X_p$ useful in predicting the response?&lt;/li>
&lt;li>Do all the predictors help to explain $Y$, or is only a subset of the predictors useful?&lt;/li>
&lt;li>How well does the model fit the data?&lt;/li>
&lt;li>Given a set of predictor values, what response value should we predict, and how accurate is our prediction?&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>We now address each of these questions in turn.&lt;/p>
&lt;h4 id="one-is-there-a-relationship-between-the-response-and-predictions" >
&lt;div>
&lt;a href="#one-is-there-a-relationship-between-the-response-and-predictions">
###
&lt;/a>
One: Is There a Relationship Between the Response and Predictions?
&lt;/div>
&lt;/h4>
&lt;p>Recall that in the simple linear regression setting, in order to determine whether there is a relationship between the response and the predictor we can simply check whether the slope equals $0$. In the multiple regression setting with $p$ predictors, we need to ask whether all of the regression coefficients are zero. We also use a &lt;strong>hypothesis test&lt;/strong> to answer this question. We test the &lt;strong>null hypothesis&lt;/strong>,
$$
H_0:\beta_0 = \beta_1 = \ldots = \beta_p = 0
$$
versus the alternative
$$
H_{\alpha}: \text{at least one } \beta_j \text{ is non-zero}
$$
This hypothesis test is performed by computing the &lt;strong>F-statistic&lt;/strong>,
$$
\tag{3.23}
F = \frac{(TSS - RSS) / p}{RSS / (n - p -1)}
$$
where, as with simple linear regression, $TSS = \sum(y_i - \bar{y})^2$ and $RSS = \sum(y_i - \hat{y})^2$ where $\bar{y} = {1 \over n} \sum^n_{i=1} y_i$ is the sample mean. If the linear model assumptions are correct, one can show that
$$
E {RSS / (n - p - 1) } = \sigma^2
$$
and that, provided $H_0$ is true,
$$
E {(TSS - RSS) / p } = \sigma^2
$$
Hence, when there is no relationship between the response and predictors, one would expect the F-statistic to take on a value close to $1$. On the other hand, if $H_{\alpha}$ is true, then $E {(TSS - RSS) / p } &amp;gt; \sigma^2$, so we expect the F-statistic to be greater than $1$.&lt;/p>
&lt;p>However, what if the F-statistic had been closer to $1$? How large does the F-statistic need to be before we can reject $H_0$ and conclude that there is a relationship? It turns out that the answer depends on the values of $n$ and $p$.&lt;/p>
&lt;ul>
&lt;li>When $n$ is large, an F-statistic that is just a little larger than 1 might still provide evidence against $H_0$.&lt;/li>
&lt;li>Inctrast, a larger F-statistic is needed to reject $H_0$ if $n$ is small.&lt;/li>
&lt;/ul>
&lt;p>When $H_0$ is true, and the errors $\epsilon_i$ have normal distribution, the F-statistic follows an F-distribution[^7]. For any given value of $n$ and $p$, any statistical software package can be used to compute the p-value[^8] associated with F-statistic using this distribution. Based on this p-value, we determine whether or not to reject $H_0$.&lt;/p>
&lt;p>Sometimes we want to test that a particular subset of $q$ of the coefficients are zero. This corresponds to a null hypothesis
$$
H_0 = \beta_{p-q+1} = \beta_{p-q+2} = \cdots = \beta_{p} = 0,
$$
where for convenience we have put the variables chosen for omission at the end of the list. In this case we fit a second model that uses all the variables except those last $q$. Suppose that the residual sum of squares for that model is $RSS_0$. Then the appropriate F-statistic is
$$
\tag{3.24} \label{ftest2}
F = \frac{(RSS_0 - RSS) / q}{RSS / (n - p -1)}.
$$
For each individual predictor a t-statistic and a p-value can be obtain, these statistics provide information about whether each individual predictor is related to the response, after adjusting for the other predictors. It turns out that each of these are exactly equivalent to the F-test that omits that single variable from the model, leaving all the others in (means $q=1$ in equation $\ref{ftest2}$). So it reports the &lt;em>partial effect&lt;/em> of adding that variable to the model.&lt;/p>
&lt;p>Given these individual p-values for each variable, why do we need to look at the over F-statistic? After all, it seems likely that if any one of the p-values for the individual variables is very small, then &lt;em>at least one of the predictors is related to the response&lt;/em>. However, this logic is flawed, especially when the number of predictors $p$ is large.&lt;/p>
&lt;p>For instance, consider an example in which $p = 100$ and $H_0:\beta_0 = \beta_1 = \ldots = \beta_p = 0$ is true, so no variable is truly associated with the response. In this situation, about &lt;strong>5%&lt;/strong> of the p-values associated with each variable will be below 0.05 by chance. &lt;strong>In other words, we expect to see approximately five small p-values even in the absence of any true association between the predictors and the response. In fact, we are almost guaranteed that we will observe at least one p-value below 0.05 by chance!&lt;/strong>&lt;/p>
&lt;p>Hence, if we use individual t-statistic and the associated p-value in order to confirm the association between any predictor and the response, there is a very high chance that we will incorrectly conclude that there is a relationship.&lt;/p>
&lt;p>However, the F-statistic does not suffer from this problem because it adjusts for the number of predictors. If $H_0$ is true, there is only a 5% chance that the F-statistic will result in a p-value below 0.05, regardless of the number of predictors or the number of observations.&lt;/p>
&lt;p>Note that when $p$ is larger than $n$, we cannot even fit the multiple linear regression model using least squares. Less flexible least squares models, such as forward stepwise selection, ridge regression, lasso regression and principal components regression, are particular useful for performing regression in the high-dimensional setting.&lt;/p>
&lt;h4 id="two-deciding-on-important-variable" >
&lt;div>
&lt;a href="#two-deciding-on-important-variable">
###
&lt;/a>
Two: Deciding on Important Variable
&lt;/div>
&lt;/h4>
&lt;p>If we conclude on the basis of the F-statistic and its associated p-value that at least one of the predictors is related to the response, then it is natural to wonder which are the guilty ones. The task of determining which predictors are associated with the response, in order to fit a single model involving only those predictors, is referred to as &lt;strong>variable selection&lt;/strong>.&lt;/p>
&lt;p>Ideally, we would like to preform variable selection by trying out a lot of different models, each containing a different subset of the predictors. Unfortunately, there are a total $2^p$ models that contain subsets of $p$ variables (Note that even with a moderate value of $p$, say, $p=30$, then $2^{30}=1,073,741,824$ models make this infeasible). We need an automated and efficient approach to choose a smaller set of models to consider. There are three classical approaches for this task:&lt;/p>
&lt;ul>
&lt;li>Forward selection. We begin with the &lt;strong>null model&lt;/strong> (which contains only the intercept). We then fit $p$ simple linear regressions and add to the null model the variable that results in the lowest $RSS$, and then add to that model the variable which results in the lowest $RSS$ for the new two-variable model. This approach is continued until some stopping rule is satisfied.&lt;/li>
&lt;li>Backward selection. We start with all variables in the model, and remove the variable with largest p-value. The new ($p - 1$)-variable model is fit, and the variable with the largest p-value is removed. This procedure continues until a stopping rule is reached (such as when all remaining variables have a p-value below some threshold).&lt;/li>
&lt;li>Mixed selection. We start with no variables in the model, and as with forward selection, we add the variable that provides the best fit. We continue to add variables one-by-one. If at any point the p-value for one of the variables in the model rises above a certain threshold, then we remove that variable from the model. We continue to perform forward and backward steps until all variable in the model have a low p-value, and all the variables outside the model have a large p-value if added to the model.&lt;/li>
&lt;/ul>
&lt;p>Backward selection cannot be used when $p &amp;gt; n$, forward selection is a greedy approach, and might include variable early that later become redundant. Mixed selection can remedy this.&lt;/p>
&lt;h4 id="three-model-fit" >
&lt;div>
&lt;a href="#three-model-fit">
###
&lt;/a>
Three: Model Fit
&lt;/div>
&lt;/h4>
&lt;p>Two of the most common numerical measures of model fit are the $RSE$ and the $R^2$. Recall that in simple regression, $R^2$ is the square of the correlation coefficient between predictor and the response. In multiple linear regression, it turns out that it equals the square of the correlation coefficient between the response and the fitted model (this implies that the fitted model maximizes this correlation among all possible linear model).&lt;/p>
&lt;p>To calculate $R^2$, we use the formula
$$
\begin{eqnarray}
R^2
&amp;amp;=&amp;amp; \frac{\sum(y_i - \bar{y})^2 - \sum(y_i - \hat{y})^2}{\sum(y_i - \bar{y})^2} \\
\\
&amp;amp;=&amp;amp; \frac{TSS - RSS}{TSS} \\
\\
\tag{3.17}
&amp;amp;=&amp;amp; 1 - {RSS \over TSS},
\end{eqnarray}
$$
where ($\bar{y} = {1 \over n} \sum^n_{i=1} y_i$) is the sample mean, $\hat{y}$ is defined in ($\ref{mlrpred}$).&lt;/p>
&lt;p>An $R^2$ value close to 1 indicates that the model explains a large portion of the variance in the response variable. It turns out that $R^2$ will always increase when more variables are added to the model, even they are only weakly associated with the response. This is due to the fact that with more variable to the least squares equations must allow us to fit the training data more accurately (though not necessarily the testing data, a.k.a., over fitting).&lt;/p>
&lt;p>In general, $RSE$ is defined as
$$
\tag{3.25}
RSE = \sqrt{{1 \over {n - p - 1}} RSS}
$$
Thus model with more variables can have higher $RSE$ if the decrease in $RSS$ is small relative to the increase in $p$.&lt;/p>
&lt;h5 id="adjusted-r2-from-wikihttpsenwikipediaorgwikicoefficient_of_determinationadjusted_r2" >
&lt;div>
&lt;a href="#adjusted-r2-from-wikihttpsenwikipediaorgwikicoefficient_of_determinationadjusted_r2">
####
&lt;/a>
Adjusted $R^2$ &lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2">(From wiki)&lt;/a>
&lt;/div>
&lt;/h5>
&lt;p>The use of an adjusted $R^2$ (one common notation is $\bar{R}^2$; another is $R_{adj}^2$)
is an attempt to account for the phenomenon of the $R^2$ automatically and spuriously
increasing when extra explanatory variables are added to the model. There are many
different ways of adjusting, by far the most used one, to the point that it is typically
just referred to as &lt;em>adjusted $R^2$&lt;/em>, is the correction prosposed by Mordecai Ezekiel,
and adjusted $R^2$ is defined as
$$
\bar{R}^2 = 1 - (1 - R^2){\frac{n-1}{n-p-1}}
$$
where $p$ is the total number of explantory variables in the model (not including the constant term), and $n$ is the sample size. It can also be written as
$$
\bar{R}^2 = 1 - \frac{RSS / df_e}{TSS / df_t}
$$
where $df_t$ is the &lt;em>degrees of freedom&lt;/em> $n-1$ of the estimate of the population variance of the dependent variable, and the $df_e$ is the degrees of freedom $n-p-1$ of the estimate of the underlying population error variance.&lt;/p>
&lt;p>The adjusted $R^2$ can be negative, and its value will always be less than or equal to that of $R^2$. Unlike $R^2$, the adjusted $R^2$ increases only when the increase in $R^2$ (due to the inclusion of a new variable) is more than one would expect to see by chance. If a set of explanatory variables with a predtermined hierarchy of importance are introduced into a regression one at a time, with the adjusted $R^2$ computed each time, the level at which adjusted $R^2$ reaches a maximum, and decreases afterward, would be the regression with ideal combination of having the best fit without excess/unnecessary terms.&lt;/p>
&lt;blockquote>
&lt;p>Degrees of Freedom &lt;a href="https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)">(From wiki)&lt;/a>:&lt;br>
The number of &lt;em>degrees of freedom&lt;/em> is the number of values in the final calculation of a statistic that are free to vary.
Estimates of statistical parameters can be based upon different amounts of information or data. The number of independent pieces of information that go into the estimate of a parameter are called the degrees of freedom.
Mathematically, degrees of freedom is the number of dimensions of the domain of a random vector, or essentially the number of &amp;ldquo;free&amp;rdquo; components (how many components need to be know before the vector is fully determined).
Suppose we have a sample of independent normally distributed observations, ${X_1, X_2, \ldots, X_n}$. This can be represented as an n-dimensional random vector:
$X^T$. Since this random vector can lie anywhere in n-dimensional space, it has $n$ degrees of freedom.
Now let $\bar{X}$ be the sample mean. The random vector can be decomposed as the sum of the sample mean plus a vector of residuals:&lt;/p>
&lt;/blockquote>
&lt;p>$$
\begin{pmatrix}
X_{1} \\
\vdots \\
X_{n} \\
\end{pmatrix}
= \bar{X} \cdot
\begin{pmatrix}
1 \\
\vdots \\
1 \\
\end{pmatrix}
+
\begin{pmatrix}
X_{1} - \bar{X} \\
\vdots \\
X_{n} - \bar{X} \\
\end{pmatrix}
$$&lt;/p>
&lt;p>The first vector on the right-hand side is constrained to be a multiple of the vector of $1$&amp;rsquo;s, and the only free quantity is $\bar{X}$. It therefore has only one degree of freedom.
The second vector is constrained by the relation $\sum(X_i - \bar{X}) = 0$. The first $n-1$ components of this vector can be anything. However, once you know the first $n-1$ components, the constraint tells you the value of the $n$th component. Therefore, this vector has $n-1$ degrees of freedom.&lt;/p>
&lt;h4 id="four-prediction" >
&lt;div>
&lt;a href="#four-prediction">
###
&lt;/a>
Four: Prediction
&lt;/div>
&lt;/h4>
&lt;p>Once we have fit the multiple regression model, it is straightforward to apply the fitted model $\hat{y} = \hat{f}(X) = \hat{\beta} X$ (a more verbose version see $\ref{mlrpred}$) in order to predict the response based on the values of the predictors. However, there are three sorts of uncertainty associated with this prediction.&lt;/p>
&lt;ol>
&lt;li>The coefficient estimate is the least squares estimation of the true coefficient which is unknown. The inaccuracy in the coefficient estimates is related to the &lt;em>reducible error&lt;/em>[^9]. We can compute a &lt;strong>confidence interval&lt;/strong> in order to determine how close $\hat{y}$ will be to $f(X)$.&lt;/li>
&lt;li>In practice assuming a linear model for $f(X)$ is almost always an approximation of reality, so if the true pattern is non-linear, there is an additional reducible error called &lt;em>model bias&lt;/em>.&lt;/li>
&lt;li>Even if we knew $f(X)$ &amp;ndash; that is, we knew the true value of $\beta$ &amp;ndash; the response value cannot be predicted perfectly, because of the random error $\epsilon$ in the model ($\ref{mlrpred}$), this is the &lt;em>irreducible error&lt;/em>.&lt;/li>
&lt;/ol>
&lt;h3 id="summary" >
&lt;div>
&lt;a href="#summary">
##
&lt;/a>
Summary
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>The regression line can be specified by two descriptive statistics: the &lt;em>slope&lt;/em> and the &lt;em>intercept&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Among all lines, the regression line for $y$ on $x$ makes the smallest r.m.s error in predicting $y$ from $x$. For that reason, the regression line is often called the &lt;em>least squares line&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With a controlled experiment, the slope can tell you the average change in $y$ that would be caused by a change in $x$. With an observational study, however, the slope cannot be relied on to predict the results of interventions. It takes a lot of hard work to draw causal inferences from observational data, with or without regression.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If the average of $y$ depends on $x$ in a non-linear way, the regression line can be quite misleading.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Multiple regression is a powerful technique, but it is not a substitute for understanding. (Such as the poor investigator would fit a multiple regression equation of the form $ predicted\ area = a + b \times perimeter + c \times diagonal$ to predict the area of a rectangle).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="part-i-how-to-learn" >
&lt;div>
&lt;a href="#part-i-how-to-learn">
#
&lt;/a>
Part-I: How to learn
&lt;/div>
&lt;/h2>
&lt;p>Linear regression is of course an extremely simple and limited learning algorithm, but it provides an example of how a learning algorithm can work.&lt;/p>
&lt;h3 id="normal-equation" >
&lt;div>
&lt;a href="#normal-equation">
##
&lt;/a>
Normal Equation
&lt;/div>
&lt;/h3>
&lt;p>The goal is to build a system that can take a vector $x \in \mathbb{R^n}$ as input and predict the value of a scalar $y \in \mathbb{R}$ as its output. The output of linear regression is a linear function of the input. Let $\hat{y}$ be the value that our model predicts $y$ should take on. We define the output to be
$$
\begin{equation}
\tag{5.3}
\hat{y} = w^{\mathsf{T}}x
\end{equation}
$$&lt;/p>
&lt;p>where $w \in \mathbb{R^n}$ is a vector of &lt;strong>parameters&lt;/strong>.&lt;/p>
&lt;p>We thus have a definition of our task &lt;em>T&lt;/em> : to predict $y$ from $x$ by outputting $\hat{y}=w^{\mathsf{T}}x$.&lt;/p>
&lt;p>Next we need a definition of our performance measure, &lt;em>P&lt;/em>. One way of measuring the performance of the model is to compute the &lt;strong>mean squared error (MSE)&lt;/strong> of the model on the test set. If $\hat{y}^{(test)}$ gives the predictions of the model on the test set, then the MSE is given by
$$
\tag{5.4}
MSE_{test} = \frac{1}{m} \sum_i{(\hat{y}^{(test)} - {y}^{(test)})^2_i}
$$
Intuitively, one can see that this error measure decreases to 0 when $\hat{y}^{(test)} = {y}^{(test)}$. We can also see that
$$
\tag{5.5}
MSE_{test} = \frac{1}{m} ||{\hat{y}^{(test)} - {y}^{(test)}}||^2_2
$$
so the error increases whenever the Euclidean distance between the predictions and the targets increases.&lt;/p>
&lt;blockquote>
&lt;p>In machine learning, we usually measure the size of vectors using a function called a &lt;strong>norm&lt;/strong>. Formally, the $L^p$ norm is given by
$$
||x||_p = \bigg(\sum_i |x_i|^p \bigg)^{\frac{1}{p}}
$$
for $p \in \mathbb{R}, p \geq 1$.&lt;/p>
&lt;p>The $L^2$ norm, with $p = 2$, is known as the &lt;strong>Euclidean norm&lt;/strong>, often denoted simply as $||x||$. It is also common to measure the size of a vector using the squared $L^2$ norm, which can be calculated simply as $x^{\mathsf{T}}x$.&lt;/p>
&lt;/blockquote>
&lt;p>To make a machine learning algorithm, we need to design an algorithm that will improve the weights $w$ in a way that reduces $MSE_{test}$ when the algorithm is allowed to gain experience by observing a training set ($X^{(train)}, y^{(train)}$).&lt;/p>
&lt;p>One intuitive way of doing this is (to minimize $MSE_{test}$) just to minimize the MSE on the training set, $MSE_{train}$ . (Does this make any sense? Keep on reading.)&lt;/p>
&lt;p>To minimize $MSE_{train}$ , we can simply solve for where its gradient is &lt;strong>0&lt;/strong>:
$$
\begin{eqnarray}
\tag{5.6}
\nabla_w MSE_{train} = 0 \\
&amp;amp; \Rightarrow &amp;amp; \frac{1}{m} \nabla_w ||{\hat{y}^{(test)} - {y}^{(test)}}||^2_2 = 0 \\
&amp;amp; \Rightarrow &amp;amp; \frac{1}{m} \nabla_w ||{\hat{y}^{(train)} - {y}^{(train)}}||^2_2 = 0 \\
&amp;amp; \Rightarrow &amp;amp; \frac{1}{m} \nabla_w ||{X^{(train)}w - y^{(train)}}||^2_2 = 0 \\
&amp;amp; \Rightarrow &amp;amp; \nabla_w \big({X^{(train)}w - y^{(train)}}\big)^{\mathsf{T}} \big({X^{(train)}w - y^{(train)}}\big) = 0
\end{eqnarray}
$$&lt;/p>
&lt;p>$$
\tag{5.10}
\Rightarrow \nabla_w \big( w^{\mathsf{T}} X^{(train)\mathsf{T}} X^{(train)}w - 2w^{\mathsf{T}} X^{(train)\mathsf{T}} y^{(train)} + y^{(train)\mathsf{T}} y^{(train)} \big) = 0 \
$$&lt;/p>
&lt;p>$$
\tag{5.11}
\Rightarrow 2X^{(train)\mathsf{T}} X^{(train)}w - 2X^{(train)\mathsf{T}} y^{(train)} = 0 \
$$&lt;/p>
&lt;p>$$
\tag{5.12}
\Rightarrow w = \big(X^{(train)\mathsf{T}} X^{(train)}\big)^{-1} X^{(train)\mathsf{T}} y^{(train)}
$$&lt;/p>
&lt;p>The system of equations whose solution is given by equation 5.12 is known as the &lt;strong>normal equation&lt;/strong>. Evaluating equation 5.12 constitutes a simple learning algorithm.&lt;/p>
&lt;blockquote>
&lt;p>链式法则(Chain Rule)是计算复杂导数时的重要工具。简单地说，若函数 $f(x) = g(h(x))$，则有
$$
\tag{A.31}
\frac{\partial{f(x)}}{\partial{x}} = \frac{\partial{g(h(x))}}{\partial{h(x)}} \cdot \frac{\partial{h(x)}}{\partial{x}}.
$$&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>例如在计算下式时，将$(Ax - b)$看作一个整体可简化计算：
$$
\begin{align*}
&amp;amp;\frac{\partial}{\partial{x}}(Ax - b)^{\mathsf{T}} W(Ax - b) \\
&amp;amp;= \frac{\partial{(Ax - b)}}{\partial{x}} \cdot 2W(Ax - b) \\
&amp;amp;= 2AW(Ax - b)
\end{align*}
$$&lt;/p>
&lt;/blockquote>
&lt;p>It is worth noting that the term &lt;strong>linear regression&lt;/strong> is often used to refer to a slightly more sophisticated model with one additional parameter &amp;ndash; an intercept term $b$. In this model&lt;/p>
&lt;p>$$
\tag{5.13}
\hat{y} = w^{\mathsf{T}}x + b
$$&lt;/p>
&lt;p>so the mapping from parameters to predictions is still a linear function but the mapping from features to predictions is now an &lt;strong>affine function&lt;/strong> (which is in the form of equation 5.13, it means that the plot of model&amp;rsquo;s predictions still looks like a line, but it need not pass though the origin). One can continue to use the model with only weights but augment $x$ with an extra entry that is always set to 1. Then the weight corresponding to the extra 1 entry plays the role of the bias parameter (i.e., the intercept term, $b$, a.k.a., the bias term).&lt;/p>
&lt;blockquote>
&lt;p>The intercept term $b$ is often called the &lt;strong>bias&lt;/strong> parameter of the affine transformation. This terminology derives from the point of view that the output of the transformation is biased toward being $b$ in the absence of any input.&lt;/p>
&lt;p>This term is different from the idea of a statistical bias, in which a statistical estimation algorithm&amp;rsquo;s expected estimate of a quantity is not equal to the true quantity.&lt;/p>
&lt;/blockquote>
&lt;h3 id="gradient-based-method" >
&lt;div>
&lt;a href="#gradient-based-method">
##
&lt;/a>
Gradient-based method
&lt;/div>
&lt;/h3>
&lt;p>Example: Linear Least Squares&lt;/p>
&lt;p>Suppose we want to find the value of $x$ that minimizes&lt;/p>
&lt;p>$$
\tag{4.21}
f(x) = \frac{1}{2}||Ax - b||^2_2
$$&lt;/p>
&lt;p>Specialized linear algebra algorithms can solve this problem efficiently; however, we can also explore how to solve it using gradient-based optimization as a simple example of how these techniques work.&lt;/p>
&lt;p>First, we need to obtain the gradient (Recall the Chain Rule):&lt;/p>
&lt;p>$$
\tag{4.42}
\nabla_x f(x) = A^{\mathsf{T}} (Ax - b) = A^{\mathsf{T}}Ax - A^{\mathsf{T}}b
$$&lt;/p>
&lt;p>We can then follow this gradient downhill, taking small steps.&lt;/p>
&lt;hr>
&lt;p>Algorithm 4.1 An algorithm to minimize $f(x) = \frac{1}{2}||Ax - b||^2_2$ with respect to $x$ using gradient descent, starting from an arbitrary value of $x$.&lt;/p>
&lt;hr>
&lt;p>Set the step size ($\epsilon$, a.k.a., learning rate) and tolerance ($\delta$) to small, positive numbers.&lt;/p>
&lt;p>&lt;strong>while&lt;/strong> $||A^{\mathsf{T}}Ax - A^{\mathsf{T}}b||_2 &amp;gt; \delta$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>$x \leftarrow x - \epsilon (A^{\mathsf{T}}Ax - A^{\mathsf{T}}b)$&lt;/p>
&lt;p>&lt;strong>end while&lt;/strong>&lt;/p>
&lt;hr>
&lt;blockquote>
&lt;p>关于梯度下降法(Gradient Descent)&lt;/p>
&lt;p>梯度下降法是一种常用的一阶(first-order)优化方法, 是求解无约束优化问题最简单,最经典的方法之一.&lt;/p>
&lt;p>考虑无约束优化问题$min_x f(x)$,其中$f(x)$为连续可微函数.若能构造一个序列$x^0, x^1, x^2, \ldots$ 满足
$$
\tag{B.15}
\label{eq_ngd}
f(x^{(t+1)}) &amp;lt; f(x^{(t)}), t = 0,1,2,\ldots
$$
则不断执行该过程即可收敛到局部极小点.欲满足式($\ref{eq_ngd}$),根据泰勒展式有
$$
\tag{B.16}
f(x + \Delta x) \simeq f(x) + \Delta x^{\mathsf{T}} \nabla f(x)
$$
于是,欲满足$f(x + \Delta x) &amp;lt; f(x)$,可选择
$$
\tag{B.17}
\Delta x = - \epsilon \nabla f(x)
$$
其中步长(step size)$\epsilon$是一个小常数.这就是梯度下降法.&lt;/p>
&lt;p>若目标函数$f(x)$满足一些条件,则通过选取合适的步长,就能确保通过梯度下降收敛到局部极小点.例如,若$f(x)$满足L-Lipschitz条件(亦即,对于任意$x$,存在常数$L$使得$||\nabla f(x)|| \leq L$成立),则将步长设置为$1/(2L)$即可确保收敛到局部极小点.当目标函数是凸函数时,局部极小点就是全局最小点,此时,梯度下降法可确保收敛到全局最优解.&lt;/p>
&lt;p>当目标函数$f(x)$二阶连续可微时,可将式($B.16$)替换成更为精确的二阶泰勒展式,这样就得到了牛顿法(Newton&amp;rsquo;s method).牛顿法是典型的二阶方法,其迭代轮数远小于梯度下降法.但牛顿法使用了二阶导数$\nabla^2 f(x)$ (second derivative),其每轮迭代中涉及到海森矩阵(Hessian matrix)的求逆,计算复杂度相当高,尤其在高维问题中几乎不可行.其次,牛顿法仅适用于附近点有局部极小点的情况(也就是,海森矩阵为正定矩阵,也就是海森矩阵所有的特征值都是正数),若附近点是鞍点(saddle point)则牛顿法失效.然而,梯度下降却不会被鞍点困住.若能以较低的计算代价寻找海森矩阵的近似逆矩阵,则可以显著降低计算开销,这就是拟牛顿法(quai-Newton method).&lt;/p>
&lt;/blockquote>
&lt;h3 id="newtons-method" >
&lt;div>
&lt;a href="#newtons-method">
##
&lt;/a>
Newton&amp;rsquo;s method
&lt;/div>
&lt;/h3>
&lt;p>Sometimes we need to find all the partial derivatives of a function whose input and output are both vectors. The matrix containing all such partial derivatives is known as a &lt;strong>Jacobian matrix&lt;/strong>. Specifically, if we have a function $f: \mathbb{R}^m \rightarrow \mathbb{R}^n$, then the Jacobian matrix $\mathbf{J} \in \mathbb{R}^{m \times n}$ of $f$ is defined such that $J_{i, j} = \frac{\partial}{\partial x_j}f(x)_i$.&lt;/p>
&lt;p>We are also sometimes interested in a derivative of a derivative. This is known as a &lt;strong>second derivative&lt;/strong>. For example, for a function $f : \mathbb{R}^n \rightarrow \mathbb{R}$, the derivative with respect to $x_i$ of the derivative of $f$ with respect to $x_j$ is denoted as $\frac{\partial^2}{\partial x_i \partial x_j}f$.&lt;/p>
&lt;p>In a single dimension, we can denote $\frac{d^2}{d x^2}$ by $f&amp;rsquo;&amp;rsquo;(x)$. The second derivative tells us how the first derivative will change when we vary the input. This is important because it tells us whether a gradient step will cause as much of an improvement as we would expect based on the gradient alone. We can think of the second derivative as measuring &lt;strong>curvature&lt;/strong>.&lt;/p>
&lt;p>Suppose we have a quadratic function (or in practice it can be approximated well as quadratic, at least locally). If such a function has:&lt;/p>
&lt;ul>
&lt;li>Second derivative of zero: there is no curvature, it is a flat line, its value can be predict using only the gradient. If the gradient is 1, set the step size of $\epsilon$ along the negative gradient, then the cost function will decrease by $\epsilon$.&lt;/li>
&lt;li>Second derivative is negative: the function curves downward, decrease by more than $\epsilon$.&lt;/li>
&lt;li>Second derivative is positive: the function curves upward, decrease by less than $\epsilon$.&lt;/li>
&lt;/ul>
&lt;p>When our function has multiple input dimensions, there are many second derivatives. These derivatives can be collected together into a matrix called the &lt;strong>Hessian matrix&lt;/strong>. The Hessian matrix $H(f)(x)$ is defined such that&lt;/p>
&lt;p>$$
\tag{4.6}
H(f)(x)_{i, j} = \frac{\partial^2}{\partial x_i \partial x_j}f(x).
$$&lt;/p>
&lt;p>Equivalently, the Hessian is the Jacobian of the gradient.&lt;/p>
&lt;p>The (directional) second derivative tells us how well we can expect a gradient descent step to perform. We can make a second-order Taylor series approximation to the function $f(x)$ around the current point $x^{(0)}$:&lt;/p>
&lt;p>$$
\tag{4.8}
f(x) \approx f(x^{(0)}) + (x - x^{(0)})^{\mathsf{T}}g + \frac{1}{2} (x - x^{(0)})^{\mathsf{T}}H(x - x^{(0)}),
$$&lt;/p>
&lt;p>where $g$ is the gradient and $H$ is the Hessian at $x^{(0)}$. If we use a learning rate of $\epsilon$, then the new point $x$ will be given by $x^{(0)} - \epsilon g$. Substituting this into our approximation, we obtain&lt;/p>
&lt;p>$$
\tag{4.9}
f(x^{(0)} - \epsilon g) \approx f(x^{(0)}) - \epsilon g^{\mathsf{T}}g + \frac{1}{2} \epsilon^2 g^{\mathsf{T}}Hg.
$$&lt;/p>
&lt;p>There are three terms here:&lt;/p>
&lt;ul>
&lt;li>the original value of the function&lt;/li>
&lt;li>the expected improvement due to the slope of the function&lt;/li>
&lt;li>and the correction we must apply to account for the curvature of the function&lt;/li>
&lt;/ul>
&lt;p>When this last term is too large, the gradient descent step can actually move uphill.&lt;/p>
&lt;p>When $g^{\mathsf{T}}Hg$ is zero or negative, the Taylor series approximation predicts that increase $\epsilon$ forever will decrease $f$ forever. In practice, the Taylor series is unlikely to remain accurate for large $\epsilon$, so one must resort to more heuristic choices of $\epsilon$ in this case.&lt;/p>
&lt;p>When $g^{\mathsf{T}}Hg$ is positive, solving for the optimal step size that decrease the Taylor series approximation of the function the most yields&lt;/p>
&lt;p>$$
\tag{4.10}
\epsilon^* = \frac{g^{\mathsf{T}}g}{g^{\mathsf{T}}Hg}.
$$&lt;/p>
&lt;p>In the worst case, when $g$ aligns with the eigenvector of $H$ corresponding to the maximal eigenvalue $\lambda_{max}$, then this optimal step size is given by $\frac{1}{\lambda_{max}}$. (The eigenvalues of the Hessian determine the scale of the learning rate, if the function we minimized can be approximated well by a quadratic function.)&lt;/p>
&lt;p>Using the eigendecomposition of the Hessian matrix, we can generalize the &lt;strong>second derivative test&lt;/strong> to multiple dimensions. At a critical point, where $\nabla_x f(x) = 0$, we can examine the eigenvalues of the Hessian to determine whether the critical point is a local maximum, local minimum, or saddle point.&lt;/p>
&lt;ul>
&lt;li>when the Hessian is positive definite (all its eigenvalues are positive): local minimum.&lt;/li>
&lt;li>when the Hessian is negative definite (all its eigenvalues are negative): local maximum.&lt;/li>
&lt;li>the test is inconclusive whenever all the nonzero eigenvalues have the same sign but at least one eigenvalue is zero.&lt;/li>
&lt;/ul>
&lt;p>In multiple dimensions, there is a different second derivative for each direction at a single point. The &lt;strong>condition number&lt;/strong> of the Hessian at this point measures how much the second derivative differ from each other. When the Hessian has a poor condition number, gradient descent performs poorly. This is because in one direction, the derivative increases rapidly, while in another direction, it increases slowly, Gradient descent is unaware of this change in the derivative, so it does not know that it needs to explore preferentially in the direction where the derivative remains negative for longer.&lt;/p>
&lt;p>Poor condition number also makes choosing a good step size difficult. The step size must be small enough to avoid overshooting the minimum and going uphill in directions with strong positive curvature. This usually means that the step size is too small to make significant progress in other directions with less curvature.&lt;/p>
&lt;p>This issue can be resolved by using information from the Hessian matrix to guide the search. The simplest method for doing so is known as &lt;strong>Newton&amp;rsquo;s method&lt;/strong>. Newton&amp;rsquo;s method is based on using a second-order Taylor series expansion to approximate $f(x)$ near some point $x^{(0)}$:&lt;/p>
&lt;p>$$
\tag{4.11}
f(x) \approx f(x^{(0)}) + (x - x^{(0)})^{\mathsf{T}} \nabla_x f(x^{(0)}) + \frac{1}{2}(x - x^{(0)})^{\mathsf{T}}H(f)(x^{(0)})(x - x^{(0)})
$$&lt;/p>
&lt;p>If we solve for the critical point of this function, we obtain&lt;/p>
&lt;p>$$
\tag{4.12}
x^* = x^{(0)} - H(f)(x^{(0)})^{-1} \nabla_x f(x^{(0)})
$$&lt;/p>
&lt;p>When $f$ is a positive definite quadratic function, Newton&amp;rsquo;s method consist of applying equation 4.12 once to jump to the minimum of the function directly. When $f$ is not truly quadratic but can be locally approximated as a positive definite quadratic, Newton&amp;rsquo;s method consists of applying equation 4.12 multiple times. NOTE that Newton&amp;rsquo;s method is only appropriate when the nearby critical point is a minimum (all the eigenvalues of the Hessian are positive), whereas gradient is not attracted to saddle points unless the gradient points toward them.&lt;/p>
&lt;h2 id="part_ii-why-that--work" >
&lt;div>
&lt;a href="#part_ii-why-that--work">
#
&lt;/a>
Part_II: Why that Work
&lt;/div>
&lt;/h2>
&lt;h3 id="linear-regression-as-maximum-likelihood" >
&lt;div>
&lt;a href="#linear-regression-as-maximum-likelihood">
##
&lt;/a>
Linear Regression as Maximum Likelihood
&lt;/div>
&lt;/h3>
&lt;p>Previously, we motivated linear regression as an algorithm that learns to take an input $x$ and produce an output value $\hat{y}$. The mapping from $x$ to $\hat{y}$ is chosen to minimize mean squared error, a criterion that we introduced more or less arbitrarily. We now revisit linear regression from the point of view of maximum likelihood estimation.&lt;/p>
&lt;p>Instead of producing a single prediction $\hat{y}$, we now think of the model as producing a conditional distribution $p(y | x)$. We can imagine that with an infinitely large training set, we might see several training examples with the same input value $x$ but different values of $y$. The goal of the learning algorithm is now to fit the distribution $p(y | x)$ to all those different $y$ values that are all compatible with $x$.&lt;/p>
&lt;p>To derive the same linear regression algorithm we obtained before, we &lt;strong>define&lt;/strong> $p(y | x) = \mathcal{N}(y; \hat{y}(x; w), \sigma^2)$. In this example, we assume that the variance is fixed to some constant $\sigma^2$ chosen by user.&lt;/p>
&lt;p>Since the examples are assumed to be i.i.d., the conditional log-likelihood is given by&lt;/p>
&lt;p>$$
\begin{split}
&amp;amp;\sum^m_{i=1} log \ p(y^{(i)}|x^{(i)}; \theta) \\
&amp;amp;= -m \ log \ \sigma - \frac{m}{2} log(2 \pi) - \sum^m_{i=1} \frac{||\hat{y}^{(i)} - {y}^{(i)}||^2}{2 \sigma^2},
\end{split}
$$&lt;/p>
&lt;p>where $\hat{y}^{(i)}$ is the output of the linear regression on the $i$-th input $x^{(i)}$ and m is the number of the training examples. Comparing the log-likelihood with the mean squared error,&lt;/p>
&lt;p>$$
MSE_{train} = \frac{1}{m} \sum^m_{i=1} ||\hat{y}^{(i)} - {y}^{(i)}||^2,
$$&lt;/p>
&lt;p>we immediately see that maximizing the log-likelihood with respect to $w$ yields the same estimate of the parameters $w$ as does minimizing the mean squared error. The two criteria have different values but the same location of the optimum.&lt;/p>
&lt;p>This justifies the use of MSE as a maximum likelihood estimation procedure.&lt;/p>
&lt;h4 id="maximum-likelihood-estimation" >
&lt;div>
&lt;a href="#maximum-likelihood-estimation">
###
&lt;/a>
Maximum Likelihood Estimation
&lt;/div>
&lt;/h4>
&lt;p>Rather than guessing that some function might make a good estimator and then analyzing its bias and variance, we would like to have some principle from which we can derive specific functions that are good estimators for different models.&lt;/p>
&lt;p>The most common such principle is the maximum likelihood principle.&lt;/p>
&lt;p>Consider a set of m examples $\mathbb{X} = {x^{(1)}, \cdots, x^{(m)}}$ are i.i.d from true but unknown data-generating distribution $p_{data}(\mathbf{x})$.&lt;/p>
&lt;p>Let $p_{model}(\mathbf{x}; \mathbf{\theta})$ be a parametric family of probability distribution over the same space indexed by $\mathbf{\theta}$. In other words, $p_{model}({x}; \mathbf{\theta})$ maps any configuration $x$ to a real number estimating the true probability $p_{data}({x})$.&lt;/p>
&lt;p>The maximum likelihood estimator for $\mathbf{\theta}$ is then defined as&lt;/p>
&lt;p>$$
\begin{eqnarray}
\mathbf{\theta_{ML}}
\tag{5.56}
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} {p_{model}(\mathbb{x}; \mathbf{\theta})} \\
\tag{5.57}
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} \prod^m_{i=1}{p_{model}(x^{(i)}; \mathbf{\theta})}
\end{eqnarray}
$$&lt;/p>
&lt;p>This product over many probabilities can be inconvenient for various reasons. Such as it&amp;rsquo;s prone to numerical underflow. We observe that taking the logarithm of the likelihood does not change its argmax but does conveniently transform a product into a sum:&lt;/p>
&lt;p>$$
\tag{5.58}
\mathbf{\theta_{ML}} = \underset{\mathbf{\theta}}{\operatorname{argmax}} \sum^m_{i=1}{\text{log} \ p_{model}(x^{(i)}; \mathbf{\theta})}
$$&lt;/p>
&lt;p>Because the argmax does not change when we rescale the cost function, we can divide by
$m$ to obtain a version of the criterion that is expressed as an expectation with
respect to the empirical distribution $\hat{p}_{data}$ defined by the training data:&lt;/p>
&lt;p>FIXME: \mathbb in equation(5.59, 5.60, 5.61) not work.&lt;/p>
&lt;p>$$
\tag{5.59}
\mathbf{\theta_{ML}} = {\underset{\mathbf{\theta}}{\operatorname{argmax}}}\
\mathbb{E}_{\mathbf{x} \sim \hat{p}_{data}} {\text{log} p_{model}(x^{(i)}; \mathbf{\theta})}
$$&lt;/p>
&lt;p>One way to interpret maximum likelihood estimation is to view it as minimizing the
dissimilarity between the empirical distribution $\hat{p}_{data}$, defined by the
training set and the model distribution, with the degree of dissimilarity between the
two measured by the KL divergence. The KL divergence is given by&lt;/p>
&lt;p>$$
\tag{5.60}
D_{KL}(\hat{p}_{data} || p_{model}) = \mathbb{E}_{\mathbf{x} \sim \hat{p}_{data}} {[\log \hat{p}_{data}(x) - \log {p}_{model}(x)]}.
$$&lt;/p>
&lt;p>The term on the left is a function only of the data-generating process, not the model.
This means when we train the model to minimize the KL divergence, we need only minimize&lt;/p>
&lt;p>$$
\tag{5.61}
-\mathbb{E}_{\mathbf{x} \sim \hat{p}_{data}} {[\text{log} \hat{p}_{data}(x)]},
$$&lt;/p>
&lt;p>which is of course the same as the maximization in equation 5.59.&lt;/p>
&lt;p>Minimizing this KL divergence corresponds exactly to minimizing the cross-entropy between the distributions. Any loss consisting of a negative log-likelihood is a cross-entropy between the empirical distribution and the model distribution. For example, MSE is the cross-entropy between the empirical distribution and a Gaussian model.&lt;/p>
&lt;p>We can thus see maximum likelihood as an attempt to make the model distribution match the empirical distribution $\hat{p}_{data}$. While the optimal $\mathbf{\theta}$ is the same regardless of whatever we are maximizing the likelihood or minimizing the KL divergence, the values of the objective functions are different.&lt;/p>
&lt;p>In software, we often phrase both as minimizing a cost function.&lt;/p>
&lt;p>Maximum likelihood thus becomes minimization of the negative log-likelihood (NLL), or equivalently, minimization of the cross-entropy.&lt;/p>
&lt;p>关于KL散度&lt;/p>
&lt;p>KL散度(Kullback-Leibler divergence), 亦称相对熵(relative entropy)或信息散度(information divergence), 可用于度量两个概率分布之间的差异. 给定两个连续型概率分布$P$和$Q$, 二者之间的KL散度定义为&lt;/p>
&lt;p>$$
\label{eq_kld} \tag{C.34}
KL(P||Q) = \int^{\infty}_{-\infty} p(x) \text{log}\frac{p(x)}{q(x)} dx,
$$&lt;/p>
&lt;p>其中,$p(x)$和$q(x)$分别是$P$和$Q$的概率密度函数.&lt;/p>
&lt;p>KL散度满足非负性, 即&lt;/p>
&lt;p>$$
\tag{C.35}
KL(P||Q) \geq 0,
$$&lt;/p>
&lt;p>当且仅当$P=Q$时$KL(P||Q)=0$. 但是, KL散度不满足对称性, 即&lt;/p>
&lt;p>$$
\tag{C.36}
KL(P||Q) \neq KL(Q||P),
$$&lt;/p>
&lt;p>因此, KL散度不是一个度量(metric).&lt;/p>
&lt;p>若将KL散度的定义($\ref{eq_kld}$)展开, 可得&lt;/p>
&lt;p>$$
\begin{eqnarray}
KL(P||Q)
&amp;amp;=&amp;amp; \int^{\infty}_{-\infty} p(x)\log p(x)dx - \int^{\infty}_{-\infty} p(x)\log q(x)dx \\
\tag{C.37}
&amp;amp;=&amp;amp; -H(P) + H(P, Q),
\end{eqnarray}
$$&lt;/p>
&lt;p>其中$H(P)$为熵(entropy), $H(P,Q)$为交叉熵(cross-entropy).&lt;/p>
&lt;h3 id="bayesian-linear-regression" >
&lt;div>
&lt;a href="#bayesian-linear-regression">
##
&lt;/a>
Bayesian Linear Regression
&lt;/div>
&lt;/h3>
&lt;p>So far we have discussed &lt;strong>frequentist statistics&lt;/strong> and approaches based on estimating a single value of $\theta$, then making all predictions thereafter based on that one estimate. An other approach is to consider all possible values of $\theta$ when making a prediction. The latter is the domain of &lt;strong>Bayesian statistics&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>Freqentist: the true parameter value $\theta$ is fixed but unknown, while the point estimate $\hat{\theta}$ is a random variable on account of it being a function of the dataset (which is seen as random).&lt;/li>
&lt;li>Bayesian: the Bayesian uses probability to reflect degrees of certainty in states of knowledge. The dataset is directly observed and so is not random. On the other hand, the true parameter $\theta$ is unknown or uncertain and thus is represented as random variable.&lt;/li>
&lt;/ul>
&lt;p>Before observing the data, we represent our knowledge of $\theta$ using the &lt;strong>prior probability distribution&lt;/strong>, $p(\theta)$ (a.k.a., &amp;ldquo;the prior&amp;rdquo;). Generally, the machine learning practitioner selects a prior distribution that quite broad (i.e., with high entropy, such as uniform distribution) to reflect a high degree of uncertainty in the value of $\theta$ before observing any data.&lt;/p>
&lt;p>Now consider that we have a set of data samples {$x^{(1)}, \ldots, x^{(m)}$}. We can recover the effect of data on our belief about $\theta$ by combining the data likelihood $p(x^{(1)}, \ldots, x^{(m)} | \theta)$ with the prior via Bayes&amp;rsquo; rule:
$$
\tag{5.67}
p(\theta | x^{(1)}, \ldots, x^{(m)}) = \frac{p(x^{(1)}, \ldots, x^{(m)} | \theta) p(\theta)}{p(x^{(1)}, \ldots, x^{(m)})}
$$&lt;/p>
&lt;p>In the scenarios where Bayesian estimation is typically used, the prior begins as a relatively uniform or Gaussian distribution with high entropy, and the observation of the data usually causes the posterior to lose entropy and concentrate around a few highly likely values of the parameters.&lt;/p>
&lt;p>Bayesian estimation offers two important differences from MLE:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Unlike the MLE approach that makes predictions using a point estimate of $\theta$, the Bayesian approach is to make predictions using a full distribution over $\theta$. For example, after observing $m$ examples, the predicted distribution over the next data sample, $x^{(m+1)}$, is given by
$$
\tag{5.68}
p(x^{(m+1)} | x^{(1)}, \ldots, x^{(m)}) = \int p(x^{(m+1)} | \theta) p(\theta | x^{(1)}, \ldots, x^{(m)}) d \theta
$$
Here each value of $\theta$ with positive probability density contributes to the prediction of the next example, with the contribution weighted by the posterior density itself.&lt;/p>
&lt;p>After having observed {$x^{(1)}, \ldots, x^{(m)}$}, if we are still uncertain about the value of $\theta$, then this uncertainty is incorporated into any predictions we might make.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The prior has an influence by shifting probability mass density towards regions of the parameter space that are preferred a priori. In practice, the prior often expresses a preference for models that are simpler or more smooth.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Critics of the Bayesian approach identify the prior as a source of subjective human judgment affecting the predictions.&lt;/p>
&lt;p>Bayesian methods typically generalize much better when limited training data is available but typically suffer from high computational cost when the number of training examples is large.&lt;/p>
&lt;p>&lt;strong>$\color{Green}{\mathbf{Example}}$&lt;/strong>&lt;/p>
&lt;p>Here we consider the Bayesian estimation approach to learning the linear regression parameters. In linear regression, we learn a linear mapping from an input vector $x \in \mathbb{R}^n$ to predict the value of a scalar $y \in \mathbb{R}$. The prediction is parameterized by the vector $w \in \mathbb{R}^n$:
$$
\tag{5.69}
\hat{y} = w^{\mathsf{T}}x.
$$
Given a set of $m$ training samples ($X^{(train)}, y^{(train)}$), we can express the prediction of $y$ over the entire training set as
$$
\tag{5.70}
\hat{y}^{(train)} = X^{(train)}w.
$$
Expressed as a Gaussian conditional distribution on $y^{(train)}$, we have
$$
\begin{eqnarray}
p(y^{(train)} | X^{(train)}, w)
\tag{5.71}
&amp;amp;=&amp;amp; \mathcal{N}(y^{(train)} ; X^{(train)}w, I) \\
\tag{5.72}
&amp;amp;\varpropto&amp;amp; \text{exp} \bigg(
- \frac{1}{2}(y^{(train)} - X^{(train)}w)^{\mathsf{T}} (y^{(train)} - X^{(train)}w)
\bigg),
\end{eqnarray}
$$
where we follow the standard MSE formulation in assuming that the Gaussian variance on $y$ is one.&lt;/p>
&lt;p>In what follows, to reduce the notational burden, we refer to ($X^{(train)}, y^{(train)}$) as simply ($X, y$).&lt;/p>
&lt;p>To determine the posterior distribution over the model parameter vector $w$, we first need to specify a prior distribution. For real-valued parameters it is common to use a Gaussian as a prior distribution,
$$
\tag{5.73}
p(w) = \mathcal{N}(w; \mu_0, \Lambda_0) \varpropto \text{exp} \bigg(
-\frac{1}{2}(w - \mu_0)^{\mathsf{T}} \Lambda^{-1} (w - \mu_0) \bigg),
$$
where $\mu_0$ and $\Lambda_0$ are the prior distribution mean vector and covariance matrix respectively. (We assume a diagonal covariance matrix $\Lambda_0 = diag(\lambda_0)$, unless there is a reason to use a particular covariance structure.)&lt;/p>
&lt;p>With the prior thus specified, we can now proceed in determining the &lt;strong>posterior&lt;/strong> distribution over the model parameters:
$$
\begin{eqnarray}
p(w | X, y)
\tag{5.74}
&amp;amp;\varpropto&amp;amp; p(y | X, w)p(w) \\
\tag{5.75}
&amp;amp;\varpropto&amp;amp;
\text{exp} \bigg(- \frac{1}{2}(y - Xw)^{\mathsf{T}} (y - Xw) \bigg) \text{exp} \bigg(-\frac{1}{2}(w - \mu_0)^{\mathsf{T}} \Lambda^{-1} (w - \mu_0) \bigg) \\
\tag{5.76}
&amp;amp;\varpropto&amp;amp; \text{exp} \bigg(-\frac{1}{2} \big( -2y^{\mathsf{T}}Xw + w^{\mathsf{T}}X^{\mathsf{T}}Xw + w^{\mathsf{T}} \Lambda_0^{-1}w - 2\mu_0^{\mathsf{T}}\Lambda_0^{-1}w \big) \bigg)
\end{eqnarray}
$$
We now define $\Lambda_m = (X^{\mathsf{T}}X + \Lambda_0^{-1})^{-1}$ and $\mu_m = \Lambda_m (X^{\mathsf{T}}y + \Lambda_0^{-1} \mu_0)$. Using these new variables, we find that the posterior may be rewritten as a Gaussian distribution:
$$
\begin{eqnarray}
p(w | X, y)
\tag{5.77}
&amp;amp;\varpropto&amp;amp;
\text{exp} \bigg(- \frac{1}{2}(w - \mu_m)^{\mathsf{T}} \Lambda_m^{-1}(w - \mu_m) + \frac{1}{2} \mu_m^{\mathsf{T}}\Lambda_m^{-1}\mu_m \bigg) \\
\tag{5.78}
&amp;amp;\varpropto&amp;amp; \text{exp} \bigg(-\frac{1}{2} (w - \mu_m)^{\mathsf{T}} \Lambda_m^{-1}(w - \mu_m) \bigg)
\end{eqnarray}
$$
All terms that do not include the parameter vector $w$ have been omitted; they are implied by the fact that the distribution must be normalized to integrate to 1.&lt;/p>
&lt;p>Equation 3.23 shows how to normalize a multivariate Gaussian distribution:
$$
\tag{3.23}
\mathcal{N}(x; \mu, \Sigma) = \sqrt{\frac{1}{(2\pi)^n \text{det}(\Sigma)}} \text{exp} \bigg(-\frac{1}{2} (x - \mu)^{\mathsf{T}} \Sigma^{-1}(x - \mu) \bigg).
$$
When we wish to evaluate the PDF several times for many different values of the parameters, the covariance is not a computationally efficient way to parametrize the distribution, since we need to invert $\Sigma$ to evaluate the PDF. We can instead use a &lt;strong>precision matrix $\beta$&lt;/strong>:
$$
\tag{3.24}
\mathcal{N}(x; \mu, \beta^{-1}) = \sqrt{\frac{\text{det}(\beta)}{(2\pi)^n}} \text{exp} \bigg(-\frac{1}{2} (x - \mu)^{\mathsf{T}} \beta (x - \mu) \bigg).
$$&lt;/p>
&lt;h4 id="maximum-a-posteriori-map-estimation" >
&lt;div>
&lt;a href="#maximum-a-posteriori-map-estimation">
###
&lt;/a>
Maximum A Posteriori (MAP) Estimation
&lt;/div>
&lt;/h4>
&lt;p>While the most principled approach is to make predictions using the full Bayesian posterior distribution over the parameter $\theta$, it is still often desirable to have a single point estimate. One common reason for desiring a point estimate is that most operations involving the Bayesian posterior for most interesting models are intractable, and a point estimate offers a tractable approximation.&lt;/p>
&lt;p>Rather than simply returning to the MLE, we can still gain some of the benefit of the Bayesian approach by allowing the prior to influence the choice of the point estimate. One rational way to do this id to choose the &lt;strong>maximum a posteriori&lt;/strong> (MAP) point estimate. The MAP estimate chooses the point of maximal posterior probability ( or maximal probability density in the more common case of continuous $\theta$):
$$
\tag{5.79}
\theta_{MAP}
= \underset{\mathbf{\theta}}{\operatorname{argmax}} {p(\mathbf{\theta} | x)}
= \underset{\mathbf{\theta}}{\operatorname{argmax}} {\text{log} \ p(x | \mathbf{\theta})} + \text{log} \ p(\mathbf{\theta})
$$
We recognize, on the righthand side, $\text{log} \ p(x | \mathbf{\theta})$, that is, the standard log-likelihood term, and $\text{log} \ p(\mathbf{\theta})$, corresponding to the prior distribution.&lt;/p>
&lt;p>As an example, consider a linear regression model with a Gaussian prior on the weights $w$. If this prior is given by $\mathcal{N}(w; 0, \frac{1}{\lambda}I^2)$, then the log-prior term in equation 5.79 is proportional to the familiar $\lambda w^{\mathsf{T}}w$ weight decay penalty, plus a term that does not depend on $w$ and does not affect the learning process. MAP Bayesian inference with a Gaussian prior on the weights thus corresponds to weight decay.&lt;/p>
&lt;h3 id="mle-and-map-殊途同归" >
&lt;div>
&lt;a href="#mle-and-map-%e6%ae%8a%e9%80%94%e5%90%8c%e5%bd%92">
##
&lt;/a>
MLE and MAP: 殊途同归
&lt;/div>
&lt;/h3>
&lt;h4 id="binary-variables" >
&lt;div>
&lt;a href="#binary-variables">
###
&lt;/a>
Binary Variables
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Coin flipping: heads = 1, tails = 0 with bias $\mu$
$$
p(X = 1 | \mu) = \mu
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bernoulli Distribution
$$
Bern(x | \mu) = \mu^x \cdot (1 - \mu)^{1 - x} \\
\mathbf{E}[X] = \mu \\
var(X) = \mu \cdot (1 - \mu)
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>N coin flips: $X_1, \ldots, X_N$
$$
p(\Sigma_i X_i = m | N, \mu) = {N \choose m} \mu^m (1 - \mu)^{N - m} \\
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Binomial Distribution
$$
p(m | N, \mu) = {N \choose m} \mu^m (1 - \mu)^{N - m} \\
\mathbf{E}[\Sigma_i X_i] = N \mu \\
var[\Sigma_i X_i] = N \mu (1 - \mu)
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="the-bias-of-a-coin" >
&lt;div>
&lt;a href="#the-bias-of-a-coin">
###
&lt;/a>
The Bias of a Coin
&lt;/div>
&lt;/h4>
&lt;p>Suppose that we have a coin, and we would like to figure out what the probability is that it will flip up heads.&lt;/p>
&lt;ul>
&lt;li>How should we estimate the bias?&lt;/li>
&lt;/ul>
&lt;p>With these coin flips result: &lt;strong>[tail, head, tail, head, head]&lt;/strong>, our estimate of the bias is: 3/5 (&amp;ldquo;the frequency of heads&amp;rdquo;).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>why is this a good estimate of the bias?&lt;/p>
&lt;p>- how good is this estimation?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$P(Heads) = \theta, \ P(Tails) = 1 - \theta$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Flips are i.i.d.&lt;/p>
&lt;ul>
&lt;li>Independent events&lt;/li>
&lt;li>Identically distributed according to Binomial distribution&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Our training data consists of $\alpha_H$ heads and $\alpha_T$ tails
$$
p(D | \theta) = \theta^{\alpha_H} \cdot (1 - \theta)^{\alpha_T}
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="mle" >
&lt;div>
&lt;a href="#mle">
###
&lt;/a>
MLE
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Data: Observed set of $\alpha_H$ heads and $\alpha_T$ tails&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Hypothesis: Coin flips follow a binomial distribution&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Learning: Find the &amp;ldquo;best&amp;rdquo; $\theta$&lt;/p>
&lt;p>Maximum Likelihood Estimation: Choose $\theta$ to maximize probability of $D$ given $\theta$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{eqnarray}
\hat{\theta}
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} \ P(D | \theta) \\
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} \ \text{ln} \ P(D | \theta) \\
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} \ \text{ln} \ \theta^{\alpha_H} \cdot (1 - \theta)^{\alpha_T}
\end{eqnarray}
$$&lt;/p>
&lt;ul>
&lt;li>Set derivative to zero, and solve!&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{eqnarray}
\frac{d}{d\theta} \text{ln} \ P(D | \theta)
&amp;amp;=&amp;amp; \frac{d}{d\theta} [\text{ln} \ \theta^{\alpha_H} \cdot (1 - \theta)^{\alpha_T}] \\
&amp;amp;=&amp;amp; \frac{d}{d\theta} [\alpha_H \text{ln} \ \theta + \alpha_T \text{ln} (1 - \theta)] \\
&amp;amp;=&amp;amp; \alpha_H \frac{d}{d\theta} \text{ln} \ \theta + \alpha_T \frac{d}{d\theta} \text{ln} \ (1 - \theta) \\
&amp;amp;=&amp;amp; \frac{\alpha_H}{\theta} - \frac{\alpha_T}{1 - \theta} = 0 \\
\\
\Rightarrow \hat{\theta}_{MLE} &amp;amp;=&amp;amp; \frac{\alpha_H}{\alpha_H + \alpha_T}
\end{eqnarray}
$$&lt;/p>
&lt;p>As we can see now, that&amp;rsquo;s exactly the &amp;ldquo;Frequency of the heads&amp;rdquo;! In other words, the frequency of heads is exactly the &lt;strong>maximum likelihood estimator&lt;/strong> for this problem.&lt;/p>
&lt;h4 id="map" >
&lt;div>
&lt;a href="#map">
###
&lt;/a>
MAP
&lt;/div>
&lt;/h4>
&lt;p>Suppose we have 5 coin flips all of which are heads, Our estimate of the bias is: ???&lt;/p>
&lt;ul>
&lt;li>MLE would give $\theta_{MLE} = 1$&lt;/li>
&lt;li>This event occurs with probability $1 / 2^5 = 1/32$ for a fair coin&lt;/li>
&lt;li>Are we willing to commit to such a strong conclusion with such little evidence?&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Priors&lt;/strong> are a Bayesian mechanism that allow us to take into account &amp;ldquo;prior&amp;rdquo; knowledge about our belief in the outcome. Rather than estimating a single $\theta$, consider a distribution over possible values of $\theta$ given the data:&lt;/p>
&lt;ul>
&lt;li>Without any data observed, our best guess of $\theta$ is obeyed a Beta(2, 2),&lt;/li>
&lt;li>After we see some data (such as observed flips:[tails, tails]), we update our prior to Beta(3, 2).&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Bayesian Learning&lt;/strong>
$$
\begin{eqnarray}
\tag{L1}
p(\theta | D) = \frac{p(D | \theta) \ p(\theta)}{p(D)} \\
\tag{L2} \label{eq_map}
\Rightarrow p(\theta | D) \varpropto p(D | \theta) \ p(\theta)
\end{eqnarray}
$$
where&lt;/p>
&lt;ul>
&lt;li>$p(\theta | D)$ is the posterior,&lt;/li>
&lt;li>$p(D | \theta)$ is the data likelihood,&lt;/li>
&lt;li>$p(\theta)$ is the prior,&lt;/li>
&lt;li>$p(D)$ is the normalization factor.&lt;/li>
&lt;/ul>
&lt;p>We update the prior according to the observed data to get the posterior by applying Bayes rule.&lt;/p>
&lt;p>&lt;strong>Picking Priors&lt;/strong>&lt;/p>
&lt;p>How do we pick a good prior distribution?&lt;/p>
&lt;ul>
&lt;li>Priors could represent expert domain knowledge&lt;/li>
&lt;li>Statisticians choose them to make the posterior distribution &amp;ldquo;nice&amp;rdquo; (conjugate priors, which makes the posterior the same form as the prior)&lt;/li>
&lt;/ul>
&lt;p>What is a good prior for the bias in the coin flipping problem?&lt;/p>
&lt;ul>
&lt;li>Truncated Gaussian (tough to work with)&lt;/li>
&lt;li>Beta distribution (works well for binary random variables)&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Coin Flips with Beta Distribution&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Likelihood function: $p(D | \theta) = \theta^{\alpha_H} (1 - \theta)^{\alpha_T}$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior: $p(\theta) = \frac{\theta^{\beta_H - 1} (1 - \theta)^{\beta_T - 1}}{B(\beta_H, \beta_T)} \sim Beta(\beta_H, \beta_T)$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Posterior:
$$
\begin{eqnarray}
p(\theta | D)
&amp;amp;\varpropto&amp;amp; \theta^{\alpha_H}(1 - \theta)^{\alpha_T} \theta^{\beta_H - 1}(1 - \theta)^{\beta_T - 1} \\
&amp;amp;=&amp;amp; \theta^{\alpha_H + \beta_H - 1}(1 - \theta)^{\alpha_T + \beta_T - 1} \\
&amp;amp;=&amp;amp; Beta(\alpha_H + \beta_H, \alpha_T + \beta_T)
\end{eqnarray}
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>MAP Estimation&lt;/strong>&lt;/p>
&lt;p>Choosing $\theta$ to maximize the posterior distribution is called &amp;ldquo;maximum a posteriori (MAP)&amp;rdquo; estimation
$$
\theta_{MAP} = \underset{\mathbf{\theta}}{\operatorname{argmax}} \ {p(\mathbf{\theta} | D)}
$$
The only difference between $\theta_{MLE}$ and $\theta_{MAP}$ is that one assumes a &lt;strong>uniform&lt;/strong> prior (MLE) and the other allows an arbitrary prior.&lt;/p>
&lt;blockquote>
&lt;p>Recall that:&lt;/p>
&lt;p>With uniform prior $p(\theta) \varpropto 1$, according to $\ref{eq_map}$, the posterior $p(\theta | D) \varpropto p(D | \theta)$.&lt;/p>
&lt;/blockquote>
&lt;p>Suppose we have 5 coin flips all of which are heads,&lt;/p>
&lt;ul>
&lt;li>
&lt;p>MLE would give $\theta_{MLE} = 1$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MLE with a Beta(2, 2) prior gives $\theta_{MAP} = \frac{5 + 2 - 1}{5+2+0+2 - 2} = \frac{6}{7} \approx .857$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>As we see more data, the effect of the prior diminishes
$$
\begin{eqnarray}
\theta_{MAP}
&amp;amp;=&amp;amp; \frac{\alpha_H + \beta_H - 1}{\alpha_H + \beta_H + \alpha_T + \beta_T - 2} \\
\\
&amp;amp;\approx&amp;amp; \frac{\alpha_H}{\alpha_H + \alpha_T} \ (\text{for large number of observations})
\end{eqnarray}
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="sample-complexity" >
&lt;div>
&lt;a href="#sample-complexity">
###
&lt;/a>
Sample Complexity
&lt;/div>
&lt;/h4>
&lt;p>How many coin flips do we need in order to guarantee that our learned parameter does not differ too much from the true parameter (with high probability)? Say, I want to know the coin parameter $\theta$, within $\epsilon = 0.1$ error with probability at least $1 - \delta = 0.95$.&lt;/p>
&lt;p>Using the Chernoff bound, we have
$$
p(|\theta_{true} - \theta_{MLE}| \geq \epsilon) \leq 2e^{-2N \epsilon^2} \\
\delta \geq 2e^{-2N \epsilon^2} \Rightarrow N \geq \frac{1}{2\epsilon^2} \text{ln} \frac{1}{\delta}
$$&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Convert each variable to standard units. The average of the products gives the correlation coefficient (may be more intuitively in the python code)&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Associated with a unit increase in $x$ there is some average change in $y$. The slope of the regression line estimates this change. The formula for the slope is $\frac{r \times SD_y}{SD_x}$. And the intercept of the regression line is just the predicted value for $y$ when $x$ is $0$.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item></channel></rss>