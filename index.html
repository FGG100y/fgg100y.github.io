<!doctype html><html lang=en data-theme><head><meta name=generator content="Hugo 0.128.1"><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><title>fgg blog</title>
<meta name=description content><link rel=alternate type=application/rss+xml href=https://fgg100y.github.io/index.xml title="fgg blog"><link rel=icon type=image/x-icon href=https://fgg100y.github.io/favicon.ico><link rel=apple-touch-icon-precomposed href=https://fgg100y.github.io/favicon.png><style>body{visibility:hidden;opacity:0}</style><noscript><style>body{visibility:visible;opacity:1}</style></noscript><link rel=stylesheet href=https://fgg100y.github.io/css/style.min.b4d24af3f8cf20d1698a5b809c35d6912485c2ea8bee514632a7b387676076bd.css integrity="sha256-tNJK8/jPINFpiluAnDXWkSSFwuqL7lFGMqezh2dgdr0="><link rel=stylesheet href=https://fgg100y.github.io/css/style.min.31d1662db6dd546a5622c56e7095ebbe00b4974b957a58b42c47937a98a3a611.css integrity="sha256-MdFmLbbdVGpWIsVucJXrvgC0l0uVeli0LEeTepijphE="><link rel=stylesheet href=https://fgg100y.github.io/css/style.min.159579eb91bf655c726d836d5df3d31b773597682769d2ccf74f0ce820296522.css integrity="sha256-FZV565G/ZVxybYNtXfPTG3c1l2gnadLM908M6CApZSI="><script src=https://fgg100y.github.io/js/script.min.74bf1a3fcf1af396efa4acf3e660e876b61a2153ab9cbe1893ac24ea6d4f94ee.js type=text/javascript integrity="sha256-dL8aP88a85bvpKzz5mDodrYaIVOrnL4Yk6wk6m1PlO4="></script></head><body><a class=skip-main href=#main>Skip to main content</a><div class=container><header class=common-header><div class=header-top><div class=header-top-left><h1 class="site-title noselect"><a href=/>fgg blog</a></h1><div class=theme-switcher><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-sun-high" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14.828 14.828A4 4 0 109.172 9.172a4 4 0 005.656 5.656z"/><path d="M6.343 17.657l-1.414 1.414"/><path d="M6.343 6.343 4.929 4.929"/><path d="M17.657 6.343l1.414-1.414"/><path d="M17.657 17.657l1.414 1.414"/><path d="M4 12H2"/><path d="M12 4V2"/><path d="M20 12h2"/><path d="M12 20v2"/></svg></span></div><script>const STORAGE_KEY="user-color-scheme",defaultTheme="auto";let currentTheme,switchButton,autoDefinedScheme=window.matchMedia("(prefers-color-scheme: dark)");const autoChangeScheme=e=>{currentTheme=e.matches?"dark":"light",document.documentElement.setAttribute("data-theme",currentTheme),changeGiscusTheme(currentTheme)};document.addEventListener("DOMContentLoaded",function(){switchButton=document.querySelector(".theme-switcher"),currentTheme=detectCurrentScheme(),currentTheme==="auto"?(autoChangeScheme(autoDefinedScheme),autoDefinedScheme.addListener(autoChangeScheme)):document.documentElement.setAttribute("data-theme",currentTheme),switchButton&&switchButton.addEventListener("click",switchTheme,!1),showContent()});function detectCurrentScheme(){return localStorage!==null&&localStorage.getItem(STORAGE_KEY)?localStorage.getItem(STORAGE_KEY):defaultTheme?defaultTheme:window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"}function switchTheme(){currentTheme=currentTheme==="dark"?"light":"dark",localStorage&&localStorage.setItem(STORAGE_KEY,currentTheme),document.documentElement.setAttribute("data-theme",currentTheme),changeGiscusTheme(currentTheme)}function showContent(){document.body.style.visibility="visible",document.body.style.opacity=1}function changeGiscusTheme(e){function t(e){const t=document.querySelector("iframe.giscus-frame");if(!t)return;t.contentWindow.postMessage({giscus:e},"https://giscus.app")}t({setConfig:{theme:e}})}</script><ul class=social-icons><li><a href=https://github.com/fgg100y title=Github rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></span></a></li><li><a href=https://fgg100y.github.io/index.xml title=RSS rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 19m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></span></a></li></ul></div><div class=header-top-right></div></div><nav class=noselect><a class=active href=https://fgg100y.github.io/ title>Home</a>
<a href=https://fgg100y.github.io/posts/ title>Posts</a>
<a href=https://fgg100y.github.io/tags/ title>Tags</a>
<a href=https://fgg100y.github.io/about/ title>About</a></nav><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></header><main id=main tabindex=-1><div class=homepage-content></div><div class="articles h-feed"><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/momentsoflife/so_long/>so_long_and_no_thanks</a></h1></header></div><div class="content post-summary p-summary">如果你看过《银河系漫游指南》，应该记得地球生物智慧排第一的是海豚（人类只排第三）😂
离别时本来应该是来一句：
“So long! And thanks for all the fish."
但实际情况却是：</div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-07-04>2024-07-04</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/momentsoflife/so_long/>https://fgg100y.github.io/posts/momentsoflife/so_long/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href>#生活点滴，职场梦醒</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/dsp101/2024-07-03-short_time_fourier_transform/>Short_time_Fourier_Transform</a></h1></header></div><div class="content post-summary p-summary"><p>Sine Wave Signal</p><p>An audio signal, y(t), composed of exactly one sine wave, can be completely described by
the parameters $t, A, f$ and $\phi$,
$$
y(t) = A \sin(2 \pi f t + \phi)
$$
where $t$ represents time in seconds, $A$ is the wave&rsquo;s amplitude (unit-less), $f$ is
its frequency in Hz, and $\phi$ is its phase offset in radians (i.e., where in the cycle
the wave is at $t=0$). If $t \ne 0$, then the sine wave appears shifted in time by
$\frac{\phi}{2 \pi f}$, where negative values mean &ldquo;delay&rdquo; and positive &ldquo;advance&rdquo; it.</p><p>Fourier Series</p><blockquote><p>Our old pal Fourier told us that any sound can be represented as an infinite summation
of sine waves each with their own amplitudes, frequencies, and phase offsets. This means
that any sound we hear can be represented as many, many tuples of $t, A, f, \phi$.</p></blockquote></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-07-03>2024-07-03</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/dsp101/2024-07-03-short_time_fourier_transform/>https://fgg100y.github.io/posts/dsp101/2024-07-03-short_time_fourier_transform/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/stft/>#STFT</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/dsp101/2024-07-03-discrete_fourier_transform/>Discrete_Fourier_Transform</a></h1></header></div><div class="content post-summary p-summary"><p>An analysis problem, which is equivalent to the <strong>DFT</strong>:</p><pre><code>Given a signal, how to find the amplitude and phase offset of its frequency
components?
</code></pre><p>A synthesis problem, which is equivalent to the <strong>inverse DFT</strong>:</p><pre><code>Given a set of frequency components and their amplitudes, how can we construct a
signal?
</code></pre></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-07-03>2024-07-03</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/dsp101/2024-07-03-discrete_fourier_transform/>https://fgg100y.github.io/posts/dsp101/2024-07-03-discrete_fourier_transform/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/dft/>#DFT</a></li><li><a href=https://fgg100y.github.io/tags/idft/>#IDFT</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/resnet/>ResNet</a></h1></header></div><div class="content post-summary p-summary">思维实验： 在浅层网络结构的基础上（比如20层），往后面直接添加更多的同映射隐层（identity layers）， 得到的深层网络（比如50层）理论上效果应该不会变差。但实验结果说明，它真会变差。意味着： SGD算法无法找到使得更深层网络性能不变差的参数。
残差网络架构可以解决这个问题。
# Why, What, and How Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions.
训练一个深度（足够深的）神经网络是一件很难的事情（2015年）。 使用“残差”神经网络架构可以更容易地训练足够深的神经网络。 “残差”架构就是把这些中间层作为一个学习输入与输出的残差的函数。
就是说：增加的隐层去学习 $h(x) - x$（残差）而不是 $h(x)$，而输出的是当前隐层的输出加上前 一层的输出 $x$ （同时也是当前层的输入）。</div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-29>2024-06-29</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/resnet/>https://fgg100y.github.io/posts/resnet/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/resnet/>#Resnet</a></li><li><a href=https://fgg100y.github.io/tags/bottlenet-block/>#Bottlenet-Block</a></li><li><a href=https://fgg100y.github.io/tags/residual/>#Residual</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-28-knowledge_distillation2/>knowledge_distillation2</a></h1></header></div><div class="content post-summary p-summary"><h2 id=generalized-knowledge-distillation-gkd><div><a href=#generalized-knowledge-distillation-gkd>#
</a>Generalized Knowledge Distillation (GKD)</div></h2><p>泛化知识蒸馏是一种改进的知识蒸馏技术，旨在解决传统知识蒸馏方法在自回归序列模型中遇到的分
布不匹配问题，特别是在训练和推理阶段之间。传统的知识蒸馏方法通常基于固定的输出序列集进行，
这些序列或者是教师模型生成的，或者是基于真实数据的标签。然而，这导致学生模型在推理时生成
的序列可能与训练时见到的序列分布不同，从而影响了学生模型的泛化能力。</p><p>GKD 不再局限于固定输出序列的训练，而是允许学生模型在其自我生成的序列上进行学习，同时利用
教师模型提供的反馈。</p></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-28>2024-06-28</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/2024-06-28-knowledge_distillation2/>https://fgg100y.github.io/posts/2024-06-28-knowledge_distillation2/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/generalized-kd/>#Generalized KD</a></li><li><a href=https://fgg100y.github.io/tags/auto-regression-llm/>#Auto-Regression LLM</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-27-knowledge_distillation/>knowledge_distillation</a></h1></header></div><div class="content post-summary p-summary"><p>知识蒸馏（Knowledge Distillation）是一种机器学习技术，它通过将大型、复杂的模型（称为教师
模型，Teacher Model）的知识“蒸馏”到小型、简洁的模型（称为学生模型，Student Model）中，从
而实现模型压缩和加速，同时尽可能保持原始模型的性能。这一技术使得模型可以在资源有限的设备
上高效运行，如手机或嵌入式设备。</p><blockquote><p>The method works by incorporating an additional loss into the traditional cross entropy
loss, which is based on the softmax output of the teacher network. The assumption is
that the output activations of a properly trained teacher network carry additional
information that can be leveraged by a student network during training.</p></blockquote></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-27>2024-06-27</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/2024-06-27-knowledge_distillation/>https://fgg100y.github.io/posts/2024-06-27-knowledge_distillation/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/distillation/>#Distillation</a></li><li><a href=https://fgg100y.github.io/tags/tearch/student-models/>#Tearch/Student Models</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-27-mixup_beyond_erm/>mixup_beyond_ERM</a></h1></header></div><div class="content post-summary p-summary"><h1 id=empirical-risk-minimazation-erm><div><a href=#empirical-risk-minimazation-erm>##
</a>Empirical Risk Minimazation (ERM)</div></h1><p>经验风险最小化, Empirical Risk Minimazation principle (Vapnik, 1998)</p><ol><li>基于ERM训练模型：亦即在训练数据集上学习以最小化其平均误差。</li><li>当前SOTA模型的参数量随着训练数据集规模增大而线性增加。</li></ol><p>而经典VC学习理论（learning theory, Vapnik & Chervonenkis, 1971）表明：只要学习器的参数量
不随着训练样本数量增加，则基于ERM学习一定会收敛(convergence, i.e., good generalization
to new data)。亦即：模型的复杂度（参数量规模）相对于训练数据规模应该是固定的或者变动不大。</p></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-27>2024-06-27</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/2024-06-27-mixup_beyond_erm/>https://fgg100y.github.io/posts/2024-06-27-mixup_beyond_erm/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/mixup/>#Mixup</a></li><li><a href=https://fgg100y.github.io/tags/erm/>#ERM</a></li><li><a href=https://fgg100y.github.io/tags/vrm/>#VRM</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-13-calculate_gpu_vram_for_llama3-70b/>calculate_gpu_vram_for_llama3-70B</a></h1></header></div><div class="content post-summary p-summary"><p>How many GPUs do I need to be able to serve Llama 70B? In order to answer that, you need
to know how much GPU memory will be required by the Large Language Model.</p><p>The formula is simple:</p><p>$$
M=\frac{(P * 4B)}{(32/Q)} * 1.2
$$</p></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-13>2024-06-13</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/2024-06-13-calculate_gpu_vram_for_llama3-70b/>https://fgg100y.github.io/posts/2024-06-13-calculate_gpu_vram_for_llama3-70b/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/vram/>#VRAM</a></li><li><a href=https://fgg100y.github.io/tags/llama3-70b/>#Llama3-70B</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/mlteam101/lean_principles/>lean_principles</a></h1></header></div><div class="content post-summary p-summary">精益之道</div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-03>2024-06-03</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/mlteam101/lean_principles/>https://fgg100y.github.io/posts/mlteam101/lean_principles/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/lean-principle/>#Lean Principle</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/mlteam101/feedback_loops_and_times_to_feedback/>EffectiveML 01: Delivering successful ML projects</a></h1></header></div><div class="content post-summary p-summary">ML project feedback mechanisms and disciplines</div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-03>2024-06-03</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/mlteam101/feedback_loops_and_times_to_feedback/>https://fgg100y.github.io/posts/mlteam101/feedback_loops_and_times_to_feedback/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/ml-teams/>#ML Teams</a></li><li><a href=https://fgg100y.github.io/tags/task-feedback/>#Task Feedback</a></li></ul></div></div></article><div class="pagination noselect"><div class="left pagination-item disabled"></div><div class="right pagination-item"><a href=/page/2/>to old posts</a></div></div></div></main><footer class="common-footer noselect"><div class=common-footer-bottom><div style=display:flex;align-items:center;gap:8px>© fmh, 2024</div><div>Powered by <a target=_blank rel="noopener noreferrer" href=https://gohugo.io/>Hugo</a>, theme <a target=_blank rel="noopener noreferrer" href=https://github.com/Junyi-99/hugo-theme-anubis2>Anubis2</a>.<br></div></div><p class="h-card vcard"><a href=https://fgg100y.github.io/ class="p-name u-url url fn" rel=me>fmh</a></p></footer></div></body></html>