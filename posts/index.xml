<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on fgg blog</title><link>/posts/</link><description>fgg blog (Posts)</description><generator>Hugo -- gohugo.io</generator><language>zh</language><managingEditor>1522009317@qq.com
(fmh)</managingEditor><lastBuildDate>Mon, 30 Sep 2024 10:36:43 +0800</lastBuildDate><atom:link href="/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>脑筋急转弯</title><link>/posts/historicalsnippet/2024-09-30-%E8%84%91%E7%AD%8B%E6%80%A5%E8%BD%AC%E5%BC%AF/</link><pubDate>Mon, 30 Sep 2024 10:36:43 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/historicalsnippet/2024-09-30-%E8%84%91%E7%AD%8B%E6%80%A5%E8%BD%AC%E5%BC%AF/</guid><description>&lt;hr>
&lt;p>题目描述&lt;br>
A 和 B 两个人要分苹果。A 希望按照他的计算规则得到平均分配的苹果，而 B 希望在满足 A 的条
件下获得尽可能多的苹果量。&lt;/p>
&lt;p>A 的计算规则是按照二进制加法进行，并不计算进位。例如，12 + 5 = 9 （1100 + 0101 = 1001）。&lt;/p>
&lt;p>B 的计算规则是正常的十进制加法，包括进位。&lt;/p>
&lt;p>给定苹果的数量和每个苹果的重量，计算并满足 A 的要求的情况下，B 能获得的最大苹果总重量。
如果无法满足 A 的要求，则输出 -1。&lt;/p>
&lt;p>输入描述&lt;br>
第一行包含一个整数 n，表示苹果的数量。&lt;/p>
&lt;p>第二行包含 n 个整数，表示每个苹果的重量 w1, w2, &amp;hellip;, wn。&lt;/p>
&lt;p>输出描述&lt;br>
输出一个整数，表示 B 能获得的最大苹果总重量。如果无法满足 A 的要求，则输出 -1。&lt;/p>
&lt;p>示例1&lt;br>
输入：&lt;br>
3&lt;br>
3 5 6&lt;/p>
&lt;p>输出：&lt;br>
11&lt;/p>
&lt;p>说明：&lt;br>
通过二进制无进位加法，A 要求的总重量是 3 XOR 5 XOR 6 = 0，B 能获得所有的苹果，总重量为 11。&lt;/p>
&lt;p>示例2&lt;br>
输入：&lt;br>
8&lt;br>
7258 6579 2602 6716 3050 3564 5396 1773&lt;/p>
&lt;p>输出：&lt;br>
35165&lt;/p>
&lt;p>说明：&lt;br>
同样按照 A 的二进制无进位规则，B 获得最大的苹果重量为 35165。&lt;/p>
&lt;hr>
&lt;blockquote>
&lt;p>A 要求的总重量是 3 XOR 5 XOR 6 = 0，B 能获得所有的苹果，总重量为 11。&lt;/p>
&lt;/blockquote>
&lt;p>我：狗屎一样的描述，根本表述不清，甚至示例还有矛盾：A要求重量为0，B能获得所有苹果（难道
不是3个？三个苹果总重量为11吗？这又是哪门子的A的平均分配？傻A吗还是傻B？）。狗屎。2024-09-27 Fri&lt;/p>
&lt;p>我：XOR&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>为0，则将最小值分配给A，剩下都是B的；否则输出-1。（不清楚这个狗屎做法为什么对题）。&lt;/p>
&lt;p>2024-09-30 Mon:臭狗屎余臭绕鼻，三日不绝，忍无可忍还是要一探究竟是什么样的狗在胡闹，一番
搜索：&lt;/p>
&lt;blockquote>
&lt;p>社区靓女：意思就是 平分苹果 比如例子中(三个苹果，重量分别为：3, 5, 6) 对a的算法来说:b
拿到的是5+6=3个， 剩下个3，所以 a和b 是平分的。但是对b来说 他拿到的是总重量为11的两个
苹果。所以b能拿到的，并且满足a同学要求之后的最大重量是11.&lt;/p>
&lt;/blockquote>
&lt;p>社区某靓女的解释是合题意的（此人不简单呐）。至少这个解释可以驱散多日狗屎臭味了。&lt;/p>
&lt;p>进一步解析：示例告诉应试者，就去整异或运算，至于为什么，至于文字描述什么意思，至于文意互
相矛盾，那都不是事儿，想不明白可以后面去想（不要想着打一顿出题者，而是想出题者何意，去猜
猜猜）。所以，社区某靓女的解释显得极其合理（以小人心态，我简直要怀疑这人是出题者或之一），
A确实想要“平均分配”苹果，但是是按照“异或”这种计算方式去“平均”，这第一步就严重挑战正常人
朴素认知里对“平均”的含义的理解。&lt;/p>
&lt;p>可是“平均”在出题者的定义里，关你普通人的朴素感情什么屁事？&lt;/p>
&lt;p>或许可以这样去想，作为“肉食者”一员，就要设计出这样的一种“平均分配”：&lt;code>5 xor 6 = 3&lt;/code>，这样
你大A拿重量为3的苹果，我小B拿重量也为“3”的两个苹果，是够平均分配的了吧？换句话说，不管你A
拿哪个重量的苹果，最后都是平均分配。比如，我大A就是贪心，心想你个傻B，我怎么会拿3，就拿6。
小B说那没关系的哈，你看，那剩下的是重量为3和5，&lt;code>3 xor 5 = 6&lt;/code>，仍然一样的哈。咱讲究的就是
一个平均分配。&lt;/p>
&lt;p>有个社区靓仔说这属于是脑筋急转弯。我觉得或许这样去理解，更有幽默感吧。&lt;/p>
&lt;p>转不过弯来的人，怎么气急败坏也没用，还要被嘲笑无能狂怒。门禁卡钥匙稳稳地攥在别人手里呐。&lt;/p>
&lt;p>据说在六七十年代，想要整人的人都很擅长各种急转弯&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>。一朝权在手，便把令来行。敢不听令？&lt;/p>
&lt;p>年代更久远些的一位我们的老朋友阿贵（Mr. Q），在他革命胜利的畅想中可不就是：奶奶的，从今以后，我爱谁就是谁！&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;code>xor&lt;/code>是一种按位进行的运算（位运算，符号&lt;code>^&lt;/code>），位运算就是基于整数的二进制表示进行的
运算。具体操作就是：只有两个对应位不同时才为1。
例子解释，$5=(101)_2, 6=(110)_2, 5^6=(011)_2$，$(011)_2$ 正是3的二进制表示。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>年代久远，已不可考，也未必可信。不过王小波的《黄金时代》大约能告诉你怎么对待被人整蛊。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>外行人禁止入内</title><link>/posts/historicalsnippet/2024-09-28-%E5%A4%96%E8%A1%8C%E4%BA%BA%E7%A6%81%E6%AD%A2%E5%85%A5%E5%86%85/</link><pubDate>Sat, 28 Sep 2024 10:11:25 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/historicalsnippet/2024-09-28-%E5%A4%96%E8%A1%8C%E4%BA%BA%E7%A6%81%E6%AD%A2%E5%85%A5%E5%86%85/</guid><description>&lt;ol>
&lt;li>讲给自己人听&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>给出数字K，请输出所有结果小于K的整数组合到一起的最少交换次数。组合一起是指满足条件的数字相邻，不要求相邻后在数组中的位置。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>Q:这个题目到底在表达什么意思？太抽象，完全看不懂。&lt;br>
A:&lt;br>
社区靓仔1: 滑动窗口，简单题&lt;br>
社区靓仔2: 固定窗口&lt;br>
社区靓仔3: &amp;hellip;（与）&lt;br>
社区靓仔4: &amp;hellip;（主）&lt;br>
社区靓仔5: &amp;hellip;（题）&lt;br>
社区靓仔.: &amp;hellip;（相）&lt;br>
社区靓仔.: &amp;hellip;（关）&lt;br>
社区靓仔.: &amp;hellip;（度）&lt;br>
社区靓仔.: &amp;hellip;（降）&lt;br>
社区靓仔.: &amp;hellip;（到）&lt;br>
社区靓仔.: &amp;hellip;（零）&lt;/p>
&lt;/blockquote>
&lt;ol start="2">
&lt;li>到底考查什么&lt;/li>
&lt;/ol>
&lt;p>完整的题目大约是这样：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-plaintext" data-lang="plaintext">&lt;span style="display:flex;">&lt;span>给出数字K,请输出所有结果小于K的整数组合到一起的最少交换次数。组合一起是指满足条件的数字相邻，不要求相邻后在数组中的位置。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>数据范围:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>-100&amp;lt;=K&amp;lt;=100
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>-100&amp;lt;=数组中数值&amp;lt;=100
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>输入描述
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>第一行输入数组：1 3 1 4 0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>第二行输入K数值: 2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>输出描述
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>第一行输出最少交换次数:1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>说明：小于2的表达式是 1 1 0，共三种可能将所有符合要求数字组合一起，最少交换一次。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>但对普通靓仔来说总感觉还不够清晰，而想要知道具体要表达什么（进一步消除歧义），可能需要先知道这个题目：&lt;/p>
&lt;p>&lt;a href="https://leetcode.cn/problems/minimum-swaps-to-group-all-1s-together/description/">力扣1151:最少交换次数来组合所有的1&lt;/a>&lt;/p>
&lt;p>我点开链接的结果是：该题目是 Plus 会员专享题\n感谢使用力扣！您需要升级为 Plus 会员来解锁该题目&lt;/p>
&lt;p>实在抱歉，没法把题目贴到这里。因为我不打算成为Plus会员，至少目前不打算。而其他来源的，不敢保证它们与原题一致。&lt;/p>
&lt;p>拉斯科尔尼科夫&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>那个干翻译后来干出版的大学好友早就有言在先：多少翻译最终干成了篡改。&lt;/p>
&lt;p>如果你和我一样是“闻道有先后”中的“后”而愤愤不平，忠告就是：少废话，多刷题。&lt;/p>
&lt;p>说实话，我已经分不清是我逼自己刷题，还是被逼刷题。你看，我是糊涂的。所以对于我的“忠告”，你该保持怀疑态度。&lt;/p>
&lt;ol start="3">
&lt;li>从来都是如此&lt;/li>
&lt;/ol>
&lt;p>如果你是外行（意思大约是你待在你未来想要进入的圈子的时间不够长），而给你准备的时间相对有
限，更没有专门为你铺设的小道&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>，那么，最有可能做成的方法就是埋头苦干了。&lt;/p>
&lt;p>君不见我们的教材资料可谓汗牛充栋，但写得清楚明白的可能是九牛一毛。写得清楚明白，还只要你
花点电费就能访问到的就约等于零。有好的资源和好心肠，并且无私奉献出来了，也还是有可能惹麻烦&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>。&lt;/p>
&lt;p>翻译翻译+篡改篡改，不要199，也不要99，只要9.9，速来，快活呀。这才是常态。&lt;/p>
&lt;p>“从来如此的，便是对的么？”这是迅哥儿的经典一问。他是旧社会教育中成长的人，旧社会里最喜欢
拿24孝来唬小孩，据他说那时他祖母正病重，就挺担心他父亲是个汉代郭巨&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>那样的孝子。在这互
联网时代，“资源共享”终究也逃不过成为口号的命运。去中心化互联网？我听到你说。一听就知道是穷鬼在彷徨和呐喊。
但还是希望如此吧。陈胜吴广妥妥的也是穷鬼来着，如果教材没错的话。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>陀思妥耶夫斯基的《罪与罚》的主人公。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>欧几里得说几何学里没有专门为国王铺设的大道，他是对的。前提是他不是在咱大天朝朝廷干活。当然如果你觉得我在暗示走后门，我觉得你觉得的也有道理。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>有个哥们的开源软件就被搞闭源的另一个哥们呛：你这样子搞，我怎么赚钱啊？断人财路犹如杀人父母，中外皆然。巨硬某佬就曾大放厥词说Linux式开源就像癌症。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>汉代郭巨埋儿的故事，24孝故事之一。btw，更好玩的是&lt;a href="https://blog.sciencenet.cn/blog-2984-14573.html">兄弟李的这个解释版本&lt;/a>。&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>牛客刷题之火车进出站--栈.md</title><link>/posts/personals/momentsoflife/2024-09-11-%E7%89%9B%E5%AE%A2%E5%88%B7%E9%A2%98%E4%B9%8B%E7%81%AB%E8%BD%A6%E8%BF%9B%E5%87%BA%E7%AB%99%E6%A0%88/</link><pubDate>Wed, 11 Sep 2024 18:28:25 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/personals/momentsoflife/2024-09-11-%E7%89%9B%E5%AE%A2%E5%88%B7%E9%A2%98%E4%B9%8B%E7%81%AB%E8%BD%A6%E8%BF%9B%E5%87%BA%E7%AB%99%E6%A0%88/</guid><description>&lt;p>题目：&lt;/p>
&lt;p>描述&lt;/p>
&lt;p>给定一个正整数N代表火车数量，0&amp;lt;N&amp;lt;10，接下来输入火车入站的序列，一共N辆火车，每辆火车以
数字1-9编号，火车站只有一个方向进出，同时停靠在火车站的列车中，只有后进站的出站了，先进
站的才能出站。&lt;/p>
&lt;p>要求输出所有火车出站的方案，以字典序排序输出。&lt;/p>
&lt;p>数据范围：1≤n≤10&lt;/p>
&lt;p>进阶：时间复杂度：O(n!) ，空间复杂度：O(n)&lt;/p>
&lt;p>输入描述：
第一行输入一个正整数N（0 &amp;lt; N &amp;lt;= 10），第二行包括N个正整数，范围为1到10。&lt;/p>
&lt;p>输出描述：
输出以字典序从小到大排序的火车出站序列号，每个编号以空格隔开，每个输出序列换行，具体见sample。&lt;/p>
&lt;p>输入：&lt;br>
3&lt;br>
1 2 3&lt;/p>
&lt;p>输出：&lt;br>
1 2 3&lt;br>
1 3 2&lt;br>
2 1 3&lt;br>
2 3 1&lt;br>
3 2 1&lt;/p>
&lt;p>说明：
第一种方案：1进、1出、2进、2出、3进、3出&lt;br>
第二种方案：1进、1出、2进、3进、3出、2出&lt;br>
第三种方案：1进、2进、2出、1出、3进、3出&lt;br>
第四种方案：1进、2进、2出、3进、3出、1出&lt;br>
第五种方案：1进、2进、3进、3出、2出、1出&lt;br>
请注意，[3,1,2]这个序列是不可能实现的。&lt;/p>
&lt;hr>
&lt;p>刚看题目就不能明白为什么输入&amp;quot;1 2 3&amp;quot;不就是&amp;quot;3 2 1&amp;quot;一个答案吗？（题目中这一句：“接下来输入火车入站的序列，”直接要了俺的命了），
输入&amp;quot;1 2 3&amp;quot;, 也就是编号1、2、3这三辆火车进站了（但人家可没有说是一次来了三辆），所以呢，得猜，猜出题者到底说了什么意思。
“说明”所举例的内容就是一种提示：我（出题者）就是这么规定题目意思的。您要是没看明白，是您自己的水平问题。&lt;/p>
&lt;blockquote>
&lt;p>据说，金圣叹记载的史上最短科举试题“二”，这个题目只有一个字，要求考生围绕这个数字展开论述，其荒诞性不言而喻。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>据载，金圣叹在应试时遇到的题目“吾四十而不动心”，他在试卷上写了三十九个“动心”&amp;hellip;&lt;/p>
&lt;/blockquote>
&lt;p>哥们那39个“动心”倒是有点理工直男的黑色幽默，不管怎么说，我总觉得他多少是在戏弄考官。哈哈。还是这位金性怪老头玩得起。&lt;/p>
&lt;p>题目总归是没有错的（搞不好是打着“圣上”旗号出题的，谁敢说它错了？）而且出题范围内，题目只
有那么多，每年都要考，所以要么将其变曲折复杂，要么变含糊其辞，要么说点悄悄话&amp;hellip;总而言之，如果揣摩不透“上意”，肯定是自己水平问题。&lt;/p>
&lt;p>其实也就意味着，您不在出题者混的圈子里，而又非要去应试，是您最大的错。&lt;/p>
&lt;p>&lt;img alt="IMG_你给领导二选一领导回答对" src="images/%E4%BD%A0%E7%BB%99%E9%A2%86%E5%AF%BC%E4%BA%8C%E9%80%89%E4%B8%80%E9%A2%86%E5%AF%BC%E5%9B%9E%E7%AD%94%E5%AF%B9.png">&lt;/p>
&lt;hr>
&lt;p>啰唆多两句：&lt;br>
回到这道题，我仿佛看到了科举考试的鬼影在跳舞。想不到那些弯弯绕当然是自己笨&amp;hellip;吗？&lt;/p>
&lt;p>才刚&lt;code>git push&lt;/code>这篇博客，就刷到“道路办何主任”的刚刚发布的&lt;a href="https://mp.weixin.qq.com/s/tiUXtTPaTHYCARzQ5f_xTQ">为什么有人喜欢脱裤子放屁&lt;/a>，很喜欢这哥们的文章。&lt;/p>
&lt;p>代码（不给代码就是瞎哔哔个屁，但是这个年头，用最喜爱的&lt;ruby>“卡帕西”&lt;rt>Andrej Karpathy&lt;/rt>&lt;/ruby>老师的话来讲就是：编写代码即将就是tab tab tab）：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> sys
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">train_out_sequences&lt;/span>(n, trains):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">dfs&lt;/span>(in_index, stack, out_sequence):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># 如果所有火车都出站，记录当前方案&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(out_sequence) &lt;span style="color:#ff6ac1">==&lt;/span> n:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result&lt;span style="color:#ff6ac1">.&lt;/span>append(out_sequence[:])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># 选择入站操作&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> in_index &lt;span style="color:#ff6ac1">&amp;lt;&lt;/span> n:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stack&lt;span style="color:#ff6ac1">.&lt;/span>append(trains[in_index]) &lt;span style="color:#78787e"># 火车入站&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfs(in_index &lt;span style="color:#ff6ac1">+&lt;/span> &lt;span style="color:#ff9f43">1&lt;/span>, stack, out_sequence) &lt;span style="color:#78787e"># 递归处理下一辆车&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stack&lt;span style="color:#ff6ac1">.&lt;/span>pop() &lt;span style="color:#78787e"># 回溯，撤销入站操作&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># 选择出站操作&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> stack:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> out_sequence&lt;span style="color:#ff6ac1">.&lt;/span>append(stack&lt;span style="color:#ff6ac1">.&lt;/span>pop()) &lt;span style="color:#78787e"># 栈顶火车出站&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfs(in_index, stack, out_sequence) &lt;span style="color:#78787e"># 递归处理&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stack&lt;span style="color:#ff6ac1">.&lt;/span>append(out_sequence&lt;span style="color:#ff6ac1">.&lt;/span>pop()) &lt;span style="color:#78787e"># 回溯，撤销出站操作&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result &lt;span style="color:#ff6ac1">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfs(&lt;span style="color:#ff9f43">0&lt;/span>, [], [])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># 对所有出站方案按字典序排序&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result&lt;span style="color:#ff6ac1">.&lt;/span>sort()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> result
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ins &lt;span style="color:#ff6ac1">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> line &lt;span style="color:#ff6ac1">in&lt;/span> sys&lt;span style="color:#ff6ac1">.&lt;/span>stdin:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> a &lt;span style="color:#ff6ac1">=&lt;/span> line&lt;span style="color:#ff6ac1">.&lt;/span>strip()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ins&lt;span style="color:#ff6ac1">.&lt;/span>append(a)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>n, trains &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">int&lt;/span>(ins[&lt;span style="color:#ff9f43">0&lt;/span>]), &lt;span style="color:#ff5c57">list&lt;/span>(&lt;span style="color:#ff5c57">map&lt;/span>(&lt;span style="color:#ff5c57">int&lt;/span>, ins[&lt;span style="color:#ff9f43">1&lt;/span>]&lt;span style="color:#ff6ac1">.&lt;/span>split()))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 获取所有合法的出站方案&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sequences &lt;span style="color:#ff6ac1">=&lt;/span> train_out_sequences(n, trains)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 打印每个出站方案&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> seq &lt;span style="color:#ff6ac1">in&lt;/span> sequences:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">print&lt;/span>(&lt;span style="color:#5af78e">&amp;#34; &amp;#34;&lt;/span>&lt;span style="color:#ff6ac1">.&lt;/span>join(&lt;span style="color:#ff5c57">map&lt;/span>(&lt;span style="color:#ff5c57">str&lt;/span>, seq)))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>tech interview prepare (for my resume)</title><link>/posts/notes4resume/self_intro/</link><pubDate>Tue, 03 Sep 2024 09:30:56 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/notes4resume/self_intro/</guid><description>&lt;h1 id="自我介绍" >
&lt;div>
&lt;a href="#%e8%87%aa%e6%88%91%e4%bb%8b%e7%bb%8d">
##
&lt;/a>
自我介绍
&lt;/div>
&lt;/h1>
&lt;blockquote>
&lt;p>在自我介绍时，确保你提到的项目和技能与你申请的职位紧密相关，这样可以更好地展示你的专业
能力和对职位的适应性。同时，保持自信和热情，让面试官感受到你对工作和团队的承诺。&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;p>尊敬的面试官，您好！&lt;/p>
&lt;p>我叫范明华，是一名AI技术工程师。我于2017年硕士毕业于中山大学，专业是生态学，研究生期间完
成了一些植被动态和演替方面的研究工作，这为我在实验设计、统计分析以及数据建模方面打下了扎
实的基础。参加工作后的这6年多时间里，我一直致力于应用数据来解决实际问题，也取得了一些的
成果。&lt;/p>
&lt;p>我目前处于离职状态。在上家公司担任研发中心副主任的职务，主导技术预研和项目的管理、开发和交付。
我认为我比较擅长结合数据现状来制定以落地交付为导向的技术解决方案，这主要得益于熟悉整个机
器学习项目的开发流程，从项目调研、数据预处理、特征工程到模型训练和部署，我都有深入的理解
和实践。在这些项目的实战中，不仅提升了个人的技术深度和带队能力，同时也取得了一些成果：如
发明专利、创新科技成果登记、国家部门奖项等。除了技术专长，同事们对我的评价是：1）务实负责，2）容易沟通。&lt;/p>
&lt;p>我对贵公司这个岗位的工作感兴趣，我期待能够加入贵公司，并与团队一起解决更多有趣的技术挑战。
我相信，我的专业技能和丰富经验，能够为贵公司带来直接的价值。&lt;/p>
&lt;p>最后是感谢您给我这次面试的机会，我期待在接下来的讨论中分享更多我的经验和想法。谢谢！&lt;/p>
&lt;hr></description></item><item><title>variational_inference</title><link>/posts/neuralnetworks/variationalinference/</link><pubDate>Sun, 01 Sep 2024 10:12:39 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/neuralnetworks/variationalinference/</guid><description>&lt;h2 id="变分推理1" >
&lt;div>
&lt;a href="#%e5%8f%98%e5%88%86%e6%8e%a8%e7%90%861">
#
&lt;/a>
变分推理&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>
&lt;/div>
&lt;/h2>
&lt;p>变分推理是贝叶斯学习中常用的、含有隐变量模型的学习和推理方法。变分推理和MCMC&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>属于不同
的技巧。MCMC通过随机抽样的方法近似地计算模型的后验概率，变分推断则通过解析的方法计算模型
的后验概率的近似值。&lt;/p>
&lt;p>变分推理基本思想：
假设模型是联合概率分布 $p(x,z)$ ，其中 $x$ 是观测变量（i.e., 数据），$z$ 是隐变量，包括
参数。目标是学习模型的后验概率分布 $p(z|x)$ 和用模型进行概率推理。但这是一个复杂的分布，
直接估计分布的参数很困难。所以考虑用概率分布 $q(z)$ 近似条件概率分布 $p(z|x)$ ，用KL散度
$D(q(z)||p(z|x))$ 计算两者的相似度，$q(z)$ 被称为“变分分布（variational distribution）”。
如果能找到与 $p(z|x)$ 在KL散度意义下最近的分布 $q^{*}(z)$ ，则可以用这个分布近似$p(z|x)$。&lt;/p>
&lt;p>$$
p(z|x) \approx q^{*}(z)
$$&lt;/p>
&lt;p>&lt;img alt="IMG_VI" src="https://fgg100y.github.io/posts/neuralnetworks/variationalinference/images/variational_inference.png">&lt;/p>
&lt;h3 id="关于-kl散度和证据下界" >
&lt;div>
&lt;a href="#%e5%85%b3%e4%ba%8e-kl%e6%95%a3%e5%ba%a6%e5%92%8c%e8%af%81%e6%8d%ae%e4%b8%8b%e7%95%8c">
##
&lt;/a>
关于 KL散度和证据下界
&lt;/div>
&lt;/h3>
&lt;p>KL散度&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>可以写成以下形式&lt;/p>
&lt;p>$$
\begin{eqnarray}
D(q(z)||p(z|x))
&amp;amp;=&amp;amp; E_{q} [\log q(z)] - E_{q} [\log p(z|x)] \\
&amp;amp;=&amp;amp; E_{q} [\log q(z)] - E_{q} [\log p(z,x)] + \log p(x) \\
&amp;amp;=&amp;amp; \log p(x) - \{ E_{q} [\log p(z,x)] - E_{q} [\log q(z)] \}
\end{eqnarray}
$$&lt;/p>
&lt;p>由KL散度性质可知上式中：&lt;/p>
&lt;p>$$
\begin{eqnarray}
\log p(x) \ge E_{q} [\log p(z,x)] - E_{q} [\log q(z)]
\end{eqnarray}
$$&lt;/p>
&lt;p>不等式右端是左端的下界，左端称为“证据（evidence）”，右端称为“证据下界（evidence lower
bound, ELBO）”，证据下界记作：&lt;/p>
&lt;p>$$
\begin{eqnarray}
L(q) = E_{q} [\log p(z,x)] - E_{q} [\log q(z)]
\end{eqnarray}
$$&lt;/p>
&lt;p>KL散度的最小化可以通过证据下界的最大化实现，因为目标是求 $q(z)$ 使KL散度最小化。因此，变分推理变成求解证据下界最大化问题。
通过迭代的方法最大化证据下界，这时可以使用“变分EM算法”。&lt;/p>
&lt;!-- 这时可以使用[变分EM算法](../optimazationMethods/EM/variational_EM.md). -->
&lt;h3 id="关于-qz" >
&lt;div>
&lt;a href="#%e5%85%b3%e4%ba%8e-qz">
##
&lt;/a>
关于 $q(z)$
&lt;/div>
&lt;/h3>
&lt;p>对变分分布 $q(z)$ 的要求是具有容易处理的形式，通常假设 $q(z)$ 对 $z$ 的所有分量都是互相
独立的（实际是条件独立于参数），即满足&lt;/p>
&lt;p>$$
q(z) = q(z_1) q(z_2) \cdots q(z_n)
$$&lt;/p>
&lt;p>此时的变分分布也叫作“平均场（mean field）”。KL散度的最小化或证据下界最大化实际是在平均场
的集合，即满足独立假设的分布集合 $Q = {q(z)|q(z)=\prod^{n}_{i=1}q(z_i)}$ 之中进行的。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>原书内容及更多，见：李航的《统计学习方法》（第二版）&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>马尔科夫链蒙特卡罗（Markov Chain Monte Carlo, MCMC）：给定时间线上有一串事件顺序发
生，假设每个事件的发生概率只取决于前一个事件，那么这串事件构成的因果链被称为“马尔科夫
链”。蒙特卡罗模拟就是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。两者
合起来就是指：In statistics, Markov chain Monte Carlo is a class of algorithms used to
draw samples from a probability distribution. Given a probability distribution, one
can construct a Markov chain whose elements&amp;rsquo; distribution approximates it – that is,
the Markov chain&amp;rsquo;s equilibrium distribution matches the target distribution.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>KL散度的定义：$D(Q||P)=\sum_{i}Q(i)\log\frac{Q(i)}{P(i)}$，性质：$D(Q||P) \ge 0$ ，
当且仅当 $Q=P$ 时，$D(Q||P)=0$ 。KL散度是非对称的、也不满足三角不等式，不是严格意义上的距离度量。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>expectation_maximization</title><link>/posts/optimazationmethods/em/expectation_maximization/</link><pubDate>Fri, 30 Aug 2024 13:58:13 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/optimazationmethods/em/expectation_maximization/</guid><description>&lt;p>概率模型有时既有 &lt;ruby>“观测变量”&lt;rt>（observable variable）&lt;/rt>&lt;/ruby> ，又含有
&lt;ruby>“隐变量或潜在变量”&lt;rt>（latent variable）&lt;/rt>&lt;/ruby> 。当存在后者时，不能直接使用
MLE这样的方法进行参数估计，需要引入EM进行参数估计。
EM算法就是含有隐变量的概率模型参数的最大似然估计法（或最大后验概率估计法）。&lt;/p>
&lt;h2 id="例子----三硬币模型" >
&lt;div>
&lt;a href="#%e4%be%8b%e5%ad%90----%e4%b8%89%e7%a1%ac%e5%b8%81%e6%a8%a1%e5%9e%8b">
#
&lt;/a>
例子 &amp;ndash; 三硬币模型
&lt;/div>
&lt;/h2>
&lt;p>假设有3枚硬币，分别记作 A, B, C。其抛出正面的概率分别是 $\pi$, $p$ 和 $q$ 。进行如下抛硬
币试验：先抛硬币A，根据其结果选择硬币B或者硬币C（正面选硬币B，反面选硬币A）；然后抛选出
的硬币，其抛硬币的结果，出现正面记作1，出现反面记作0；独立重复 $n$ 次试验。观测结果如下
（$n=10$）：&lt;/p>
&lt;pre>&lt;code>1,1,0,1,0,0,1,0,1,1
&lt;/code>&lt;/pre>
&lt;p>假设只能观察到抛硬币的结果，不能观测抛硬币过程。问：如何估计三枚硬币正面出现的概率，即三
硬币模型的参数。&lt;/p>
&lt;h3 id="建模" >
&lt;div>
&lt;a href="#%e5%bb%ba%e6%a8%a1">
##
&lt;/a>
建模
&lt;/div>
&lt;/h3>
&lt;p>三硬币模型可以表示为：&lt;/p>
&lt;p>$$
\begin{eqnarray}
P(y|\theta)
&amp;amp;=&amp;amp; \sum_{z} P(y, z | \theta) = \sum_{z} P(z|\theta)P(y|z,\theta) \\
&amp;amp;=&amp;amp; \pi p^{y}(1-p)^{1-y} + (1 - \pi) q^{y}(1-q)^{1-y}
\end{eqnarray}
$$&lt;/p>
&lt;p>其中，随机变量 $y$ 是观测变量，表示一次试验观测的结果是1或0；随机变量 $z$ 是隐变量，表示
未观测到的抛硬币A的结果；$\theta=(\pi, p, q)$ 是模型参数。这一模型是前述$n$次试验数据的
生成模型。&lt;/p>
&lt;p>将观测数据表示为 $Y = (Y_1, Y_2, \dots, Y_n)$，将未观测数据表示为 $Z = (Z_1, Z_2, \dots,
Z_n)$，则观测数据的&lt;strong>似然函数&lt;/strong>为&lt;/p>
&lt;p>$$
\begin{eqnarray}
P(Y|\theta)
&amp;amp;=&amp;amp; \sum_{z} P(Z|\theta)P(Y|Z,\theta) \\
&amp;amp;=&amp;amp; \prod^{n}_{j=1}[\pi p^{y_j}(1-p)^{1-y_j} + (1 - \pi) q^{y_j}(1-q)^{1-y_j}
\end{eqnarray}
$$&lt;/p>
&lt;p>求模型参数 $\theta=(\pi, p, q)$ 的极大似然估计，即&lt;/p>
&lt;p>$$
\hat{\theta} = \arg\max_{\theta} \log P(Y|\theta)
$$&lt;/p>
&lt;p>这个问题没有解析解，需要通过EM算法进行迭代求解。&lt;/p>
&lt;h3 id="em算法迭代步骤" >
&lt;div>
&lt;a href="#em%e7%ae%97%e6%b3%95%e8%bf%ad%e4%bb%a3%e6%ad%a5%e9%aa%a4">
##
&lt;/a>
EM算法迭代步骤
&lt;/div>
&lt;/h3>
&lt;p>EM算法通过迭代求 $L(\theta) = \log P(Y|\theta)$ 的最大似然估计。每次迭代包含两步：E步，求期望；M步，求最大化。&lt;/p>
&lt;hr>
&lt;p>EM算法步骤清单&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>：观测变量数据 $Y$，隐变量数据 $Z$，联合分布 $P(Y,Z|\theta)$，条件分布 $P(Z|Y, \theta)$；&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>：模型参数 $\theta$ 。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>选择参数初始值 $\theta^{(0)}$ ，开始迭代；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>E步：记 $\theta^{(i)}$ 为第$i$次迭代参数 $\theta$ 的估计值，在第$i+1$次迭代的E步，计算
$$
\begin{eqnarray}
Q(\theta, \theta^{(i)})
&amp;amp;=&amp;amp; E_{z} [\log P(Y,Z|\theta) | Y, \theta^{(i)}] \\
&amp;amp;=&amp;amp; \sum_{z} \log P(Y,Z|\theta) P(Z|Y, \theta^{(i)})
\end{eqnarray}
$$
这里，$P(Z|Y, \theta^{(i)}$ 是在给定观测数据 $Y$ 和当前的参数估计 $\theta^{(i)}$ 下隐变量数据 $Z$ 的条件概率分布；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>M步：求使得 $Q(\theta, \theta^{(i)})$ 最大化的 $\theta$ ，确定第 $i+1$ 次迭代的参数的估计值 $\theta^{(i)}$
$$
\theta^{(i)} = \arg\max_{\theta} Q(\theta, \theta^{(i)})
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>重复第2步和第3步，直到收敛。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;hr></description></item><item><title>maximum_likelihood_estimate</title><link>/posts/optimazationmethods/mle/maximum_likelihood_estimate/</link><pubDate>Fri, 30 Aug 2024 10:17:41 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/optimazationmethods/mle/maximum_likelihood_estimate/</guid><description>&lt;p>最大似然估计（Maximum Likelihood Estimation, MLE）是一种常用参数估计方法，在统计学和机
器学习中被广泛使用。它的基本思想是找到一组参数值，使得观察到的数据出现的概率最大。&lt;/p>
&lt;h3 id="概念" >
&lt;div>
&lt;a href="#%e6%a6%82%e5%bf%b5">
##
&lt;/a>
概念
&lt;/div>
&lt;/h3>
&lt;p>假设我们有一组&lt;ruby>“独立同分布”&lt;rt>（independent identity distribution, i.i.d.）&lt;/rt>&lt;/ruby>
的观测数据 $X_1, X_2, \ldots, X_n$，这些数据来自某个概率分布族，其概率密度函数或概率质量
函数为 $f(x|\theta)$，其中$\theta$ 是未知参数。直观上看，最大似然估计的目标就是试图在
$\theta$ 所有可能的取值中，找到一个能使这一组观测数据出现的“可能性”最大的值。&lt;/p>
&lt;p>形式化地讲，给定观测数据 $x_1, x_2, \ldots, x_n$，最大似然估计 $\hat{\theta}$ 定义为：
$$
\hat{\theta} = \arg\max_\theta L(\theta|x_1, x_2, \ldots, x_n)
$$
其中 $L(\theta|x_1, x_2, \ldots, x_n)$ 称为似然函数，定义为：
$$
L(\theta|x_1, x_2, \ldots, x_n) = f(x_1, x_2, \ldots, x_n|\theta) = \prod_{i=1}^n f(x_i|\theta)
$$&lt;/p>
&lt;p>啰唆多两句：所谓“似然”，和“概率”到底有什么区别呢？用抛硬币举例，区别在于：&lt;/p>
&lt;ul>
&lt;li>当我们谈论“概率”时，实际就是在问：已知模型（p=0.6，抛出正面的概率），则抛硬币10次中有7
次为正面的概率是多大？($P^{7}*(1-p)^{10-7}$)&lt;/li>
&lt;li>而谈论“似然”时，其实是反过来问：已经观察到抛10次硬币出现了7次正面，则硬币抛出正面的概
率是某个值的可能有多大？最大似然估计就是找到这样一个参数，此参数使得出现这样的数据（7
正面3反面）的可能最高。&lt;/li>
&lt;/ul>
&lt;h3 id="求解方法----直接求导法" >
&lt;div>
&lt;a href="#%e6%b1%82%e8%a7%a3%e6%96%b9%e6%b3%95----%e7%9b%b4%e6%8e%a5%e6%b1%82%e5%af%bc%e6%b3%95">
##
&lt;/a>
求解方法 &amp;ndash; &lt;strong>直接求导法&lt;/strong>：
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>写出似然函数 $L(\theta|x_1, x_2, \ldots, x_n)$。&lt;/li>
&lt;li>对似然函数取对数得到对数似然函数 $l(\theta|x_1, x_2, \ldots, x_n) = \log L(\theta|x_1, x_2, \ldots, x_n)$。&lt;/li>
&lt;li>对对数似然函数求导，通常情况下求一阶导数，并令其等于零来找到极值点。&lt;/li>
&lt;li>检查二阶导数或者直接通过直观判断是否为极大值点。&lt;/li>
&lt;/ul>
&lt;h4 id="示例有解析解" >
&lt;div>
&lt;a href="#%e7%a4%ba%e4%be%8b%e6%9c%89%e8%a7%a3%e6%9e%90%e8%a7%a3">
###
&lt;/a>
示例（有解析解）
&lt;/div>
&lt;/h4>
&lt;p>以正态分布为例，假设 $X_1, X_2, \ldots, X_n$ 服从均值为 $\mu$、方差为 $\sigma^2$ 的正态分布，那么似然函数为：
$$
L(\mu, \sigma^2|x_1, x_2, \ldots, x_n) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i-\mu)^2}{2\sigma^2}\right)
$$&lt;/p>
&lt;p>对数似然函数为：
$$
l(\mu, \sigma^2|x_1, x_2, \ldots, x_n) = -\frac{n}{2}\log(2\pi) - n\log(\sigma) - \frac{1}{2\sigma^2}\sum_{i=1}^n (x_i-\mu)^2
$$&lt;/p>
&lt;p>通过求导并设置为零可以得到最大似然估计值 $\hat{\mu}$ 和 $\hat{\sigma}^2$：
$$
\hat{\mu} = \frac{1}{n}\sum_{i=1}^n x_i
$$
$$
\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n (x_i - \hat{\mu})^2
$$&lt;/p>
&lt;h3 id="求解方法----数值优化方法" >
&lt;div>
&lt;a href="#%e6%b1%82%e8%a7%a3%e6%96%b9%e6%b3%95----%e6%95%b0%e5%80%bc%e4%bc%98%e5%8c%96%e6%96%b9%e6%b3%95">
##
&lt;/a>
求解方法 &amp;ndash; &lt;strong>数值优化方法&lt;/strong>：
&lt;/div>
&lt;/h3>
&lt;p>当直接求导法难以应用时（例如非线性问题、多维问题等），可以采用数值优化方法来寻找似然函数
的最大值。常见数值优化算法有：一阶导数：梯度下降法；二阶导数：牛顿-拉复生法、拟牛顿法等。&lt;/p>
&lt;h4 id="梯度下降法" >
&lt;div>
&lt;a href="#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95">
###
&lt;/a>
梯度下降法
&lt;/div>
&lt;/h4>
&lt;p>梯度下降法是一种迭代优化算法，它基于函数在某一点处的梯度方向，沿着梯度的反方向更新参数，直到达到一个局部最小值点。&lt;/p>
&lt;p>一般步骤：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>设置目标函数（aka, 损失函数）：在MLE中目标函数就是最大化对数似然（log-likelihood），
然而梯度下降法通常是求函数最小值，所以通常在MLE中最小化负数对数似然（negative
log-likelihood），这个只是出于数值计算方便的考虑，并且其等价于最大化对数似然。&lt;/p>
&lt;ul>
&lt;li>设 $\mathcal{l}(\theta)$ 为“对数似然”，则&lt;/li>
&lt;li>目标函数为 $-\mathcal{l}(\theta)$ 。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>计算梯度：计算负数对数似然的梯度（单维度时成为“导数”，多个维度时就叫“梯度”，实质都是
指变化率），也就是：梯度指示了对数似然函数中坡度最陡的方向,
$$
\nabla_{\theta}(\mathcal{l}(\theta)) = - \frac{\partial \mathcal{l}(\theta)}{\partial \theta}
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>迭代更新参数：梯度下降就是在坡度最陡峭的方向上，每次只前进一小步。如果将第t次迭代的参
数设为$\theta^{(t)}$，则参数更新的规则为：
$$
\theta{t+1} = \theta{(t)} - \eta \cdot \nabla_{\theta}(\mathcal{l}(\theta^{(t)}))
$$
其中，$\eta$ 是学习率，用于控制每次迭代前进的一小步到底有多小（通常设为 0.001等）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>收敛：这个迭代过程一直持续到参数的变化变得非常小（通常意味着梯度值接近0），也就是目标
函数值收敛于此最小值。（梯度下降过程一定是收敛的吗？不。远的不说，单把学习率的值调高，
就有可能导致发散。）&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="梯度下降法有许多变种包括但不限于" >
&lt;div>
&lt;a href="#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95%e6%9c%89%e8%ae%b8%e5%a4%9a%e5%8f%98%e7%a7%8d%e5%8c%85%e6%8b%ac%e4%bd%86%e4%b8%8d%e9%99%90%e4%ba%8e">
###
&lt;/a>
梯度下降法有许多变种，包括但不限于：
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>批量梯度下降（Batch Gradient Descent）：每次迭代时使用所有训练样本计算梯度。&lt;/li>
&lt;li>随机梯度下降（Stochastic Gradient Descent, SGD）：每次迭代仅使用一个训练样本计算梯度。&lt;/li>
&lt;li>小批量梯度下降（Mini-batch Gradient Descent）：每次迭代使用一小部分训练样本计算梯度。&lt;/li>
&lt;/ul></description></item><item><title>merge_exists_and_not_empty_directory</title><link>/posts/thecli/gitops/2024-08-21-merge_exists_and_not_empty_directory/</link><pubDate>Wed, 21 Aug 2024 13:54:50 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/thecli/gitops/2024-08-21-merge_exists_and_not_empty_directory/</guid><description>&lt;h2 id="为什么" >
&lt;div>
&lt;a href="#%e4%b8%ba%e4%bb%80%e4%b9%88">
#
&lt;/a>
为什么
&lt;/div>
&lt;/h2>
&lt;p>为什么会有这种需求？要把仓库和另一个非空目录给合并起来？&lt;/p>
&lt;p>因为，首先这是实验性质的操作。其次，我有一个已经开发的项目，然后发现
&lt;a href="https://github.com/drivendataorg/cookiecutter-data-science">cookiecutter-data-science&lt;/a>
更新到 v2 版本了，我想要这个版本的目录结构。最后，我想知道能否实现这个操作。答案是：可以，
而且挺简单。&lt;/p>
&lt;h2 id="实作" >
&lt;div>
&lt;a href="#%e5%ae%9e%e4%bd%9c">
#
&lt;/a>
实作
&lt;/div>
&lt;/h2>
&lt;p>1: 将仓库目录下的 &lt;code>.git&lt;/code> 复制到想要合并的“非空目录”&lt;/p>
&lt;p>2: &lt;code>git reset --hard&lt;/code>&lt;/p>
&lt;p>3: 没有了，就这样就可以。不用点开全文。&lt;/p></description></item><item><title>Class-Importance Weighted F2 Score (F2-CIW)</title><link>/posts/notes4resume/2024-08-14-f2-score/</link><pubDate>Wed, 14 Aug 2024 12:35:38 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/notes4resume/2024-08-14-f2-score/</guid><description>&lt;h2 id="why-use-f2-ciw" >
&lt;div>
&lt;a href="#why-use-f2-ciw">
#
&lt;/a>
Why Use F2-CIW?
&lt;/div>
&lt;/h2>
&lt;p>&lt;strong>Economic Impact&lt;/strong>: In the SewerML dataset, certain sewer defects may be more costly or
dangerous if undetected, so the model should prioritize accurately classifying these
defects.&lt;/p>
&lt;p>&lt;strong>Handling Class Imbalance&lt;/strong>: In datasets where some classes are underrepresented but
critically important, F2-CIW ensures that these classes are not overshadowed by more
frequent, less important classes.&lt;/p>
&lt;h2 id="traditional-f2-score" >
&lt;div>
&lt;a href="#traditional-f2-score">
#
&lt;/a>
Traditional F2 Score
&lt;/div>
&lt;/h2>
&lt;p>The F2 score is a variant of the F1 score, which is the harmonic mean of precision and
recall, but it gives more weight to recall. The F2 score is defined as:&lt;/p>
&lt;p>$$
F2 = \frac{5 \times \text{Precision} \times \text{Recall}}{4 \times \text{Precision} + \text{Recall}}
$$&lt;/p>
&lt;p>The F2 score is particularly useful in situations where you care more about capturing as
many true positives as possible, even if it means allowing more false positives.&lt;/p>
&lt;h2 id="class-importance-weighted-f2-score-f2-ciw" >
&lt;div>
&lt;a href="#class-importance-weighted-f2-score-f2-ciw">
#
&lt;/a>
Class-Importance Weighted F2 Score (F2-CIW)
&lt;/div>
&lt;/h2>
&lt;p>The Class-Importance Weighted F2 Score (F2-CIW) is a metric that adapts the traditional
F2 score to account for the economic or practical importance of different classes in a
classification task. This is particularly useful in imbalanced datasets or scenarios
where some classes have a higher impact on the overall outcome than others, such as in
the SewerML dataset.&lt;/p>
&lt;p>In tasks like those involving the SewerML dataset, different classes (e.g., types of
sewer defects) may have different levels of importance based on their economic impact or
other practical considerations. The F2-CIW metric adjusts the F2 score by assigning a
weight to each class that reflects its importance.&lt;/p>
&lt;h3 id="steps-to-compute-f2-ciw" >
&lt;div>
&lt;a href="#steps-to-compute-f2-ciw">
##
&lt;/a>
Steps to Compute F2-CIW:
&lt;/div>
&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Assign Weights to Classes&lt;/strong>: Each class $c$ is assigned a weight $w_c$ based on
its importance. The weights are typically derived from domain knowledge, such as the
economic impact of misclassifying that class.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Compute Per-Class F2 Scores&lt;/strong>: For each class, compute the F2 score $F2_c$ using
the standard formula.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Weighted Average of F2 Scores&lt;/strong>: The overall F2-CIW is computed as a weighted
average of the per-class F2 scores:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>$$
F2\text{-CIW} = \frac{\sum_{c} w_c \times F2_c}{\sum_{c} w_c}
$$&lt;/p>
&lt;p>This approach ensures that classes with higher importance have a more significant
influence on the final score.&lt;/p>
&lt;p>Overall, F2-CIW provides a more nuanced evaluation metric that aligns the model&amp;rsquo;s
performance with the practical importance of different outcomes.&lt;/p></description></item><item><title>pipe_table_and_md_to_pdf</title><link>/posts/thecli/md2pdf_using_pandoc/</link><pubDate>Mon, 05 Aug 2024 15:29:29 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/thecli/md2pdf_using_pandoc/</guid><description>&lt;h2 id="three-steps-to-produce-good-format-of-pdf-from-md" >
&lt;div>
&lt;a href="#three-steps-to-produce-good-format-of-pdf-from-md">
#
&lt;/a>
three steps to produce good format of .pdf from .md
&lt;/div>
&lt;/h2>
&lt;p>如果你的 markdown 文档不是全英文，如果你的表格是 &lt;code>pipe table&lt;/code> 类型（简单来说就是用 &amp;ldquo;|&amp;rdquo;
这个符号来围成，洋人就管它叫 pipe table），然后表格中某些格子中的内容特别长，如果寄希望
直接用pandoc 默认命令进行文档格式转换，则大概率不会立即得到“美观”的pdf文档。需要进行一定
的处理：&lt;/p>
&lt;ol>
&lt;li>放在 &lt;code>md&lt;/code> 文档最开头的元数据（meta data）：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>output:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pdf_document:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> latex_engine: xelatex
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> keep_tex: true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extra_dependencies: [&amp;#34;fontspec&amp;#34;]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>header-includes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - \usepackage{xeCJK}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - \usepackage{tabularx}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - \usepackage{fontspec}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - \setmainfont{Noto Sans CJK SC}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - \setmonofont{Noto Sans Mono CJK SC}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>table_preamble.tex 文件&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">\u&lt;/span>sepackage&lt;span style="color:#ff6ac1">{&lt;/span>xeCJK&lt;span style="color:#ff6ac1">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">\u&lt;/span>sepackage&lt;span style="color:#ff6ac1">{&lt;/span>tabularx&lt;span style="color:#ff6ac1">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>命令行命令&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>pandoc your_cool.md -o document.pdf --pdf-engine&lt;span style="color:#ff6ac1">=&lt;/span>xelatex --include-in-header&lt;span style="color:#ff6ac1">=&lt;/span>table_preamble.tex
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;!-- ![tb01](images/blog_test_tb01_Screenshot_20240805_175815.png)![tb02](images/blog_test_tb02_Screenshot_20240805_180004.png) -->
&lt;hr>
&lt;h2 id="table-format-expected" >
&lt;div>
&lt;a href="#table-format-expected">
#
&lt;/a>
table format expected
&lt;/div>
&lt;/h2>
&lt;div style="display: flex; justify-content: space-between;">
&lt;img src="images/blog_test_tb01_Screenshot_20240805_175815.png" alt="Image 1" style="width: 45%;"/>
&lt;img src="images/blog_test_tb02_Screenshot_20240805_180004.png" alt="Image 2" style="width: 45%;"/>
&lt;/div>
&lt;hr>
&lt;h2 id="table-rendering-testing" >
&lt;div>
&lt;a href="#table-rendering-testing">
#
&lt;/a>
table rendering testing
&lt;/div>
&lt;/h2>
&lt;p>表1: 测试表1 (pipe table syntax)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>| | time | describe | s2c | w2c |
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| -- | ---- | ------- | -- | -- |
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| 80891 | 2022-03-21 | xx区xxxxxxxxx南路南十三巷6号旁，一暗渠直排污水至雨水沟，水质浑浊，气味难闻，底部... | H | L |
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| 9191 | 2020-10-07 | 河段康陂路5号往上游900米河床有漂浮物,排出污水 | H | L |
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| 765 | 2022-05-10 | 蔗基水闸口有大量漂浮物和死鱼 | L | H |
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">&lt;/th>
&lt;th style="text-align: left">time&lt;/th>
&lt;th style="text-align: left">describe&lt;/th>
&lt;th style="text-align: left">s2c&lt;/th>
&lt;th style="text-align: left">w2c&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">80891&lt;/td>
&lt;td style="text-align: left">2022-03-21&lt;/td>
&lt;td style="text-align: left">xx区xxxxxxxxx南路南十三巷6号旁，一暗渠直排污水至雨水沟，水质浑浊，气味难闻，底部&amp;hellip;&lt;/td>
&lt;td style="text-align: left">H&lt;/td>
&lt;td style="text-align: left">L&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">9191&lt;/td>
&lt;td style="text-align: left">2020-10-07&lt;/td>
&lt;td style="text-align: left">河段康陂路5号往上游900米河床有漂浮物,排出污水&lt;/td>
&lt;td style="text-align: left">H&lt;/td>
&lt;td style="text-align: left">L&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">765&lt;/td>
&lt;td style="text-align: left">2022-05-10&lt;/td>
&lt;td style="text-align: left">蔗基水闸口有大量漂浮物和死鱼&lt;/td>
&lt;td style="text-align: left">L&lt;/td>
&lt;td style="text-align: left">H&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>表2: 测试表2 (tabularx table syntax)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>\begin{tabularx}{\textwidth}{|X|X|X|}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>\hline
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Header 1 &amp;amp; Header 2 &amp;amp; Header 3 \\
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>\hline
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Long content that should wrap &amp;amp; 非常长的一段话 非常长的一段话 非常长的一段话 非常长的一段话 非常长的一段话 非常长的一段话 南路南十三巷6号旁，一暗渠直排污水至雨水沟，水质浑浊，气味难闻，底部... &amp;amp; More content \\
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>\hline
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>\end{tabularx}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>\begin{tabularx}{\textwidth}{|X|X|X|}
\hline
Header 1 &amp;amp; Header 2 &amp;amp; Header 3 \
\hline
Long content that should wrap &amp;amp; 非常长的一段话 非常长的一段话 非常长的一段话 非常长的一段话 非常长的一段话 非常长的一段话 南路南十三巷6号旁，一暗渠直排污水至雨水沟，水质浑浊，气味难闻，底部&amp;hellip; &amp;amp; More content \
\hline
\end{tabularx}&lt;/p></description></item><item><title>matplotlibIssue</title><link>/posts/py101/pyplot/matplotlibissue/</link><pubDate>Thu, 01 Aug 2024 17:58:28 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/py101/pyplot/matplotlibissue/</guid><description>&lt;p>matplotlib是个好工具，但还没好透，做出来的图中中文变框框。需要额外设置。&lt;/p>
&lt;ol>
&lt;li>获取 matplotlibrc&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 查看matplotlib安装在哪里：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>python -c &lt;span style="color:#5af78e">&amp;#34;import matplotlib;print(matplotlib.__file__)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># your-venv/lib/python3.x/site-packages/matplotlib/mpl-data&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 复制 matplotlibrc 到用户配置目录&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mv your-venv/lib/python3.x/site-packages/matplotlib/mpl-data/matplotlibrc ~/.config/matplotlib/
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>修改 matplotlibrc&lt;/li>
&lt;/ol>
&lt;p>编辑器中打开 matplotlibrc 文件，找到并修改以下两个地方：&lt;/p>
&lt;p>&amp;lsquo;#font.family: sans-serif&amp;rsquo; &amp;raquo; font.family: sans-serif
&amp;lsquo;#font.sans-serif: DejaVu Sans,&amp;hellip;&amp;rsquo; &amp;raquo; font.sans-serif: DejaVu Sans,&amp;hellip;&lt;/p>
&lt;p>然后添加中文字体（ttf 文件的文件名，如下文的 &lt;code>simfang&lt;/code> 仿宋字体）
font.sans-serif: &lt;code>simfang&lt;/code>, DejaVu Sans,&amp;hellip;&lt;/p>
&lt;p>最后将 &lt;code>simfang.ttf&lt;/code> 字体文件加入到 &lt;code>mpl-data/fonts/ttf/&lt;/code> 目录中。&lt;/p>
&lt;p>注：更容易维护的一种配置方式应该是这样：
使用 &lt;code>ln -s&lt;/code> 命令将个人字体库 (&lt;code>.local/share/fonts/&lt;/code>) 中的某个字体映射到上述目录&lt;/p>
&lt;p>注2：可能需要删除matplotlib的缓存&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>rm -rf /home/user/.cache/matplotlib
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>&lt;code>mpl.rcParams&lt;/code> 代码块&lt;/li>
&lt;/ol>
&lt;p>在作图的模块中添加以下代码：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> matplotlib &lt;span style="color:#ff6ac1">as&lt;/span> mpl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> matplotlib.pyplot &lt;span style="color:#ff6ac1">as&lt;/span> plt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 中文减号显示问题&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mpl&lt;span style="color:#ff6ac1">.&lt;/span>rcParams[&lt;span style="color:#5af78e">&amp;#39;axes.unicode_minus&amp;#39;&lt;/span>] &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff6ac1">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 中文字符显示问题&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 名字与ttf文件的名字不同: simfang.ttf &amp;gt;&amp;gt; &amp;#39;FangSong&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mpl&lt;span style="color:#ff6ac1">.&lt;/span>rcParams[&lt;span style="color:#5af78e">&amp;#39;font.sans-serif&amp;#39;&lt;/span>] &lt;span style="color:#ff6ac1">=&lt;/span> [&lt;span style="color:#5af78e">&amp;#39;FangSong&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>最后，如果有多个 venv 环境，难道要一个一个去修改吗？
&lt;code>pipx&lt;/code> 大法是解药。&lt;/p></description></item><item><title>inspect_substrings_in_file_using_sed_awk_jq</title><link>/posts/thecli/awk_sed_cat_head_etc/awk_use_cases/</link><pubDate>Wed, 17 Jul 2024 19:12:45 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/thecli/awk_sed_cat_head_etc/awk_use_cases/</guid><description>&lt;p>在命令行工作远非完美，但具有极高的自由度。比如，你想要查看某个文件内(这里绝对不是指
doc/docx 这类怪胎，而是 text/csv/tsv/json 等等正常的文件) 的某一行的内容，如果那一行有很
多列，而其中要是某一列的内容特别长（就是&lt;code>sed&lt;/code>出来占据了整个屏幕这种长度），那么，你想要对
这个文件的内容有所了解，可能需要额外的软件来打开此文件，再好好欣赏之。或者，其实在命令行
就可以呢？&amp;ndash; &lt;code>awk&lt;/code> 了解一下。&lt;/p>
&lt;p>&lt;img alt="is_value_missing" src="https://fgg100y.github.io/posts/thecli/awk_sed_cat_head_etc/awk_use_cases/images/awk-to-the-rescue.png">&lt;/p>
&lt;p>像我就是碰上这么个情况，将图片转换成 base64 编码的 byte-data 后，在 Jupyterlab 打开发现
有些行怎么是空行？（首先我不是去质疑代码，而是质疑“眼见为实”）&lt;/p>
&lt;p>所以，必须要查看某一行的内容，并且要截断过长的字串，老伙计 GPT4o 很快给出答案：&lt;/p>
&lt;h2 id="tsv" >
&lt;div>
&lt;a href="#tsv">
#
&lt;/a>
TSV
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># To print the 10th row and truncate the 3rd column to 50 characters&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>awk &lt;span style="color:#5af78e">&amp;#39;NR==10 { $3=substr($3, 1, 50) &amp;#34;...&amp;#34;; print }&amp;#39;&lt;/span> &lt;span style="color:#ff5c57">FS&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;\t&amp;#34;&lt;/span> &lt;span style="color:#ff5c57">OFS&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;\t&amp;#34;&lt;/span> file.tsv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这还没完，因为 base64 编码的缘故（以及输入图片比较相似）导致 &lt;code>awk&lt;/code> 到的结果都是一模一样
的起始字串，自然而然就怀疑这是巧合还是错误，所以，必须查看字串尾部内容是否也一样, 这当然
难不倒一点脾气也不会有的 GPT4o 老哥：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># print the last 50 characters of the string in the 3rd column of the 10th row&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>awk &lt;span style="color:#5af78e">&amp;#39;NR==10 { len=length($3); print substr($3, len-50, 50) }&amp;#39;&lt;/span> &lt;span style="color:#ff5c57">FS&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;\t&amp;#34;&lt;/span> file.tsv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="jsonl" >
&lt;div>
&lt;a href="#jsonl">
#
&lt;/a>
JSONL
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># To print the 10th row and the field names of json object&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sed -n &lt;span style="color:#5af78e">&amp;#39;10p&amp;#39;&lt;/span> file.jsonl | jq &lt;span style="color:#5af78e">&amp;#39;keys&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># To print the 10th row and the first 10 chars of strings or 10 elements of array&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sed -n &lt;span style="color:#5af78e">&amp;#39;10p&amp;#39;&lt;/span> file.jsonl | jq &lt;span style="color:#5af78e">&amp;#39;.field_name[:10]&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;p>话痨多两句：&lt;/p>
&lt;p>至于参数代表啥意思，我通常不让 GPT4o 多费唇舌。&lt;/p>
&lt;p>（毕竟就算解释了我还是会动手验证一番，再者，最关键是我还没开通 plus 会员，所以得听柯景腾
他老妈的那句劝：要省着点用哦 :）&lt;/p></description></item><item><title>wsl2_and_unicode</title><link>/posts/wsl2_and_unicode/</link><pubDate>Tue, 16 Jul 2024 21:27:30 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/wsl2_and_unicode/</guid><description>&lt;h2 id="关于-localeunicodejsondump-以及被冤枉的-wsl2" >
&lt;div>
&lt;a href="#%e5%85%b3%e4%ba%8e-localeunicodejsondump-%e4%bb%a5%e5%8f%8a%e8%a2%ab%e5%86%a4%e6%9e%89%e7%9a%84-wsl2">
#
&lt;/a>
关于 locale，unicode，json.dump() 以及被冤枉的 WSL2
&lt;/div>
&lt;/h2>
&lt;p>WSL2的 &lt;code>locale&lt;/code> 一直是默认设置值 &amp;ndash; &amp;ldquo;C.UTF-8&amp;rdquo;。然后今天用 python 解析路径文件中文名时，
最终保存下来的竟是 unicode (&amp;quot;\u5c0f\u6728\u4ed4-\u7761\u7740\u4e862&amp;quot;)，这倒是破天荒第一
次碰上 :&amp;rsquo;) 为了省事，必须去找 GPT 阁下。&lt;/p>
&lt;p>更新：下文是完全绕了远路了的。造成上述情况的实际原因应该是：&lt;code>json.dump()&lt;/code> 默认参数中的
&lt;code>ensure_ascii=True&lt;/code>，这就决定了写入文件的字符不会超出ASCII字符集。&lt;/p>
&lt;p>所以，正确的修改方式不是大费周章的改写系统 &lt;code>locale&lt;/code> 而是将参数改为 &lt;code>ensure_ascii=False&lt;/code>。&lt;/p>
&lt;p>实际上，json.dump() 这部分的函数也是 GPT 阁下写的，它理所当然地认为是在英文语境中，使用
默认的参数不为过吧。😂&lt;/p>
&lt;p>但 GPT4o 最先要我确认是否是终端的编码问题：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 这就是原原本本 copy 得到的unicode字符串&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">echo&lt;/span> -e &lt;span style="color:#5af78e">&amp;#34;\u5c0f\u6728\u4ed4-\u7761\u7740\u4e862&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># output: 小木仔-睡着了2&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其次，使用 &lt;code>file -bi&lt;/code> 命令查看文件的编码格式：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>file -bi path/to/the/suspicious_file.jsonl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#output: application/json; charset=us-ascii&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这就意味着程序在写入本地文件时，只使用了 ascii 字符。&lt;/p>
&lt;h2 id="关于-escape-sequences-及其解析" >
&lt;div>
&lt;a href="#%e5%85%b3%e4%ba%8e-escape-sequences-%e5%8f%8a%e5%85%b6%e8%a7%a3%e6%9e%90">
#
&lt;/a>
关于 escape sequences 及其解析
&lt;/div>
&lt;/h2>
&lt;p>然后 GPT4o 很详细的告知应该如何在命令行终端生成和设置 &amp;ldquo;zh_CN.UTF-8&amp;rdquo;，以及如何在 python 中进行
转义系列的重编码和解码来显示中文字串，但尝试之后没成功。原来是我理解有误。&lt;/p>
&lt;p>GPT4o:
It appears there may be a misunderstanding regarding the purpose and usage of the
unicode-escape encoding. The unicode-escape codec is used to interpret escape sequences
in strings, but it does not process normal Unicode escape sequences (\uXXXX) that are
already present in a Unicode string.&lt;/p>
&lt;p>If you have a string that looks like a Unicode escape sequence and you need to convert
it into actual Unicode characters, you can use the unicode-escape codec. However, your
string needs to be encoded in a way that the codec understands.&lt;/p>
&lt;p>Here&amp;rsquo;s the corrected approach to convert a string with Unicode escape sequences into
actual Chinese characters:&lt;/p>
&lt;pre>&lt;code>Given String: You have a string with Unicode escape sequences.
Decode: Use unicode-escape to decode the string.
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Given string with Unicode escape sequences&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>unicode_str &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#5af78e">&amp;#34;&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u5c0f&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u6728&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u4ed4-&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u7761&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u7740&lt;/span>&lt;span style="color:#5af78e">\\&lt;/span>&lt;span style="color:#5af78e">u4e862&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Decode the Unicode escape sequences&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>decoded_str &lt;span style="color:#ff6ac1">=&lt;/span> unicode_str&lt;span style="color:#ff6ac1">.&lt;/span>encode(&lt;span style="color:#5af78e">&amp;#39;utf-8&amp;#39;&lt;/span>)&lt;span style="color:#ff6ac1">.&lt;/span>decode(&lt;span style="color:#5af78e">&amp;#39;unicode-escape&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(decoded_str)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Explanation&lt;/p>
&lt;pre>&lt;code>The string unicode_str contains Unicode escape sequences.
The encode('utf-8') part ensures the string is in a byte format.
The decode('unicode-escape') part interprets the byte format as Unicode escape sequences and converts them into actual characters.
&lt;/code>&lt;/pre>
&lt;p>This should correctly output the Chinese characters:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>小木仔-睡着了2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note&lt;/p>
&lt;p>Ensure that your string uses double backslashes (\uXXXX) if you&amp;rsquo;re defining it directly
in the script. This is necessary because a single backslash (\uXXXX) would be
interpreted as an actual Unicode character during the string definition phase, not as an
escape sequence.&lt;/p>
&lt;hr>
&lt;p>一点牢骚：又学了一些没用的知识，毕竟：首先你为什么要用WSL这破烂玩意儿呢？？？&lt;/p>
&lt;p>&lt;del>因为这本来是买给非终端爱好者人士使用的电脑&lt;/del>&lt;/p>
&lt;p>&lt;del>可人家毕竟也没有用，还是你自个霸占着。
前不久发现巨硬又在系统明火执仗地搞偷窥活动（设置&amp;gt;隐私和安全性&amp;gt;活动历史记录）就信誓旦旦说
立刻马上刻不容缓废掉这个恶心玩意&lt;/del>&lt;/p>
&lt;p>&lt;del>最近比较忙哔哩，新安装的2T盘不好清理吧啦，总觉着人家最终要用咕噜&lt;/del>&lt;/p>
&lt;p>本质上是因为捏着鼻子还能勉强用用，但估计也撑不了多久了。&lt;/p>
&lt;p>毕竟 Linux 才是&lt;ruby>根&lt;rt>root&lt;/rt>&lt;/ruby>，才有&lt;ruby>家&lt;rt>home/&lt;/rt>&lt;/ruby>的感觉 :)&lt;/p>
&lt;p>更新：虽然导致本文诞生的原因发生了根本性改变（详见文章开头的“更新”内容）但不影响“一点牢
骚”之后和本更新之前的牢骚内容。&lt;/p></description></item><item><title>poor_dad</title><link>/posts/personals/momentsoflife/poor_dad/</link><pubDate>Mon, 15 Jul 2024 21:47:50 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/personals/momentsoflife/poor_dad/</guid><description>&lt;p>地铁口出口处。立着的行李箱上儿子半跪着倾向爸爸，爸爸一只手抓着行李箱杆子，另一只手拿着手机。
女儿在旁边也想往行李箱上挤，被爸爸制止。女儿开始有哭腔，爸爸没看她，注意力全在手机上，
大约是在打车、看地图、联系人或者玩游戏，不知道。女儿三番两次，还是不行，被爸爸大声呵斥危险。
后面她干脆往地上就是一坐，赖哭着乱踢双腿。赖哭声里传达的大约是委屈的信号（前不久我刚领教
过我大舅哥他那差不多年纪大的幼稚园女儿的赖地式哭闹，所以对这个信号颇为熟悉）。&lt;/p>
&lt;p>等我走下地铁口，委屈信号已经变成多个均匀间隔的求关注信号了。&lt;/p>
&lt;hr>
&lt;p>一点牢骚：
后来我就进闸口了。就算有，我也不可能辨别出回应信号了；就算有，或许回应的也太迟了点。&lt;/p>
&lt;p>这可能是小事一桩，也可能是大事一件。因为我总忍不住想起前不久看的那部导演本来想拍老爸结果
拍了他家龙凤双胞胎的纪录片《姐姐》(1996年)。&lt;/p></description></item><item><title>python_module</title><link>/posts/py101/python_module/</link><pubDate>Wed, 10 Jul 2024 16:19:58 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/py101/python_module/</guid><description>&lt;h2 id="layout-of-python-installations" >
&lt;div>
&lt;a href="#layout-of-python-installations">
#
&lt;/a>
Layout of Python installations
&lt;/div>
&lt;/h2>
&lt;p>All paths in the table are relative to the installation root:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">Files&lt;/th>
&lt;th style="text-align: left">Windows&lt;/th>
&lt;th style="text-align: left">Linux and macOS&lt;/th>
&lt;th style="text-align: left">Notes&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">Interpreter&lt;/td>
&lt;td style="text-align: left">python.exe&lt;/td>
&lt;td style="text-align: left">bin/python3.x&lt;/td>
&lt;td style="text-align: left">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Standard library&lt;/td>
&lt;td style="text-align: left">Lib and DLLs&lt;/td>
&lt;td style="text-align: left">lib/python3.x&lt;/td>
&lt;td style="text-align: left">Extension modules are located under DLLs on Windows. Fedora places the standard library under lib64 instead of lib.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Third-party packages&lt;/td>
&lt;td style="text-align: left">Lib\site-packages&lt;/td>
&lt;td style="text-align: left">lib/python3.x/site-packages&lt;/td>
&lt;td style="text-align: left">Debian and Ubuntu put packages in dist-packages. Fedora places extension modules under lib64 instead of lib.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Entry-point scriptsa&lt;/td>
&lt;td style="text-align: left">Scripts&lt;/td>
&lt;td style="text-align: left">bin&lt;/td>
&lt;td style="text-align: left">&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="the-interpreter" >
&lt;div>
&lt;a href="#the-interpreter">
#
&lt;/a>
The interpreter
&lt;/div>
&lt;/h2>
&lt;p>The Python interpreter ties the environment to three things:&lt;/p>
&lt;ul>
&lt;li>A specific version of the Python language (e.g., 2.x.y, 3.x.y)&lt;/li>
&lt;li>A specific implementation of Python (e.g., CPython, PyPy)&lt;/li>
&lt;li>A specific build of the interpreter (e.g., 32bit, 64bit, Intel or Apple)&lt;/li>
&lt;/ul>
&lt;p>Try this command (in Bash) to print metadata complied into the interpreter:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>python3 -m sysconfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="the-modules" >
&lt;div>
&lt;a href="#the-modules">
#
&lt;/a>
The modules
&lt;/div>
&lt;/h2>
&lt;p>Modules are containers of Python objects that you load via the &lt;code>import&lt;/code> statement.
Modules come in various forms and shapes:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Simple modules
In the simplest case, a &lt;code>module&lt;/code> is a single file containing Python source code. The
statement &lt;code>import string&lt;/code> executes the code in &lt;em>string.py&lt;/em> and binds the result to
the name &lt;code>string&lt;/code> in the local scope.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Packages
Directories with &lt;em>&lt;strong>init&lt;/strong>.py&lt;/em> files are known as &lt;em>packages&lt;/em> which allow you to
organize modules in a hierarchy. The statement &lt;code>import email.message&lt;/code> loads the
&lt;code>message&lt;/code> module from the &lt;code>email&lt;/code> package.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Namespace packages
Directories with modules but no &lt;em>&lt;strong>init&lt;/strong>.py&lt;/em> are known as &lt;em>namespace packages&lt;/em>. One
may use them to organize modules in a common namespace such as a company name (say
&lt;code>dsta.voicedsp&lt;/code> and &lt;code>dsta.vedioprepr&lt;/code>). Unlike with regular packages, one can
distribute each module in a namespace package separately.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Extension modules
Extension modules such as &lt;code>math&lt;/code> module, contain native code compiled from low-level
language like C. They are shared libraries with a special entry-point&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> that lets
you import them as modules from Python. People write them for performance reasons or
to make existing C libraries available as Python modules. Their names end in &lt;code>.pyd&lt;/code>
on Windows, &lt;code>.dylib&lt;/code> on macOS, and &lt;code>.so&lt;/code> on Linux.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Built-in modules
Some modules from the standard library, such as &lt;code>sys&lt;/code> and &lt;code>builtins&lt;/code> modules, are
compiled into the interpreter. The variable &lt;code>sys.builtin_module_names&lt;/code> lists all of
these modules.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Frozen modules
Some modules from the standard library are written in Python but have their
bytecode&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> embedding in the interpreter. Recent versions of Python freeze every
module that&amp;rsquo;s imported during interpreter startup, such as &lt;code>os&lt;/code> and &lt;code>io&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="python-virtual-environment" >
&lt;div>
&lt;a href="#python-virtual-environment">
#
&lt;/a>
Python virtual environment
&lt;/div>
&lt;/h2>
&lt;p>Python environments consist of an interpreter and modules. Virtual environments share
the interpreter and the standard library with their parent environment.&lt;/p>
&lt;p>&lt;img alt="py-venv" src="https://fgg100y.github.io/posts/py101/python_module/images/py_python_and_venv.png">&lt;/p>
&lt;p>A Python environment can contain only a single version of each third-party package &amp;ndash;
if two projects require different versions of the same package, they can’t be
installed side by side. That’s why it’s considered good practice to install every Python
application, and every project you work on, in a dedicated virtual environment.&lt;/p>
&lt;p>NOTE
&lt;span class="custom-en">
The term &lt;em>package&lt;/em> carries some ambiguity in the Python world. It refers both to modules
and to the artifacts used for distributing modules (aka &lt;em>distributions&lt;/em>).
&lt;/span>&lt;/p>
&lt;h2 id="the-module-path" >
&lt;div>
&lt;a href="#the-module-path">
#
&lt;/a>
The module path
&lt;/div>
&lt;/h2>
&lt;p>It&amp;rsquo;s helpful to look at entries of &lt;code>sys.path&lt;/code> to debugg the import error, naturally,
one may wonder where do the entries on &lt;code>sys.path&lt;/code> come from at first?&lt;/p>
&lt;p>When the interpreter starts up, it constructs the module path in two steps:&lt;/p>
&lt;ol>
&lt;li>It builds an initial module path which includes the standard library,&lt;/li>
&lt;li>It imports the &lt;code>site&lt;/code> module (from standard library) which extends the module path to
include the site packages from the current environment.&lt;/li>
&lt;/ol>
&lt;p>The locations on the initial module path fall into three categories, and they occur in
this order:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The current directory or the directory containing the Python scripts (if any)
The first item on &lt;code>sys.path&lt;/code> can be any of the following:&lt;/p>
&lt;ul>
&lt;li>If you ran &lt;code>python3 &amp;lt;script&amp;gt;&lt;/code>, the directory where the script is located&lt;/li>
&lt;li>If you ran &lt;code>python3 -m &amp;lt;module&amp;gt;&lt;/code>, the current directory&lt;/li>
&lt;li>Otherwise, the empty string, which also denotes the current directory
&lt;strong>Safty issue&lt;/strong>: having the working directory on &lt;code>sys.path&lt;/code> is quite unsafe, as an
attacker (or you, mistakenly) can override the standard library by placing Python
files in the victim&amp;rsquo;s directory. To avoid this,&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>Python-3.11 provides &lt;code>-P&lt;/code> option or the PYTHONSAFEPATH variable to omit the
current directory from &lt;code>sys.path&lt;/code>;&lt;/li>
&lt;li>Using a virtual environment.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>The locations in the PYTHONPATH environment variable (if set)
Avoid this mechanism for the same reasons as the current working directory and use a
virtual environment instead.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The locations of the standard library
The location of the standard library is not hardcoded in the interpreter. Rather,
Python looks for landmark files on the path to its own executable and uses them to
locate the current environment (&lt;code>sys.prefix&lt;/code>) and the Python installation
(&lt;code>sys.base_prefix&lt;/code>). One such landmark file is &lt;em>pyvenv.cfg&lt;/em>, which marks a virtual
environment and points to its parent installation via the &lt;code>home&lt;/code> key. Another
landmark file is &lt;em>os.py&lt;/em>, the file containing the standard &lt;code>os&lt;/code> module: Python uses
&lt;em>os.py&lt;/em> to discover the prefix outside a virtual environment and to locate the
standard library itself.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>For more glory details and interesting contents, go to the newest version (2024) of
&lt;em>&amp;ldquo;Hypermodern Python Tooling&amp;rdquo;&lt;/em> by Claudio Jolowicz.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>An entry-point script is an executable file in &lt;em>Scripts/&lt;/em> (Windows) or &lt;em>bin/&lt;/em>
(Linux and macOS) with a single purpose: it launches a Python application by
importing the module with its entry-point function and calling that function.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Bytecode is an intermediate representation of Python code that is
platform-independent and optimized for fast execution. The interpreter compiles pure
Python modules to bytecode when it loads them for the first time. Their names end in
&lt;code>.pyc&lt;/code> and they are cached in &lt;code>__pycache__&lt;/code> directories.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Add_and_test_custom_font</title><link>/posts/hugo101/2024-07-09-test_custom_font/</link><pubDate>Tue, 09 Jul 2024 21:53:56 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/hugo101/2024-07-09-test_custom_font/</guid><description>&lt;p>Linear regression:&lt;/p>
&lt;blockquote>
&lt;p>$\text{You&amp;rsquo;ve got to draw the line somewhere.}$&lt;/p>
&lt;/blockquote>
&lt;p>You&amp;rsquo;ve got to draw the line somewhere. (system-font)&lt;/p>
&lt;p>&lt;span class="custom-en">You&amp;rsquo;ve got to draw the line somewhere. (NerdFont 3270)&lt;/span>&lt;/p>
&lt;p>&lt;span class="custom-zh">中文：你必须在某个地方把那条线给画出来。(京華老宋体)&lt;/span>&lt;/p>
&lt;hr>
&lt;p>实作过程：&lt;/p>
&lt;p>&lt;span class="custom-en">hugo version:
v0.128.2-de36c1a95d28595d8243fd8b891665b069ed0850+extended linux/amd64
BuildDate=2024-07-04T08:13:25Z VendorInfo=gohugoio&lt;/span>&lt;/p>
&lt;hr>
&lt;ol>
&lt;li>
&lt;p>将本地字体文件复制到 &lt;code>static/fonts/&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在 &lt;code>assets/css/&lt;/code> (或 &lt;code>static/css/&lt;/code>) 创建文件 &lt;code>custom.css&lt;/code>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-css" data-lang="css">&lt;span style="display:flex;">&lt;span>@&lt;span style="color:#ff6ac1">font-face&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-family&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#5af78e">&amp;#39;3270NerdFont&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">src&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">url&lt;/span>&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;/fonts/3270NerdFont-Regular.ttf&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">)&lt;/span> &lt;span style="color:#ff6ac1">format&lt;/span>&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;truetype&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-weight&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">normal&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-style&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">normal&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>@&lt;span style="color:#ff6ac1">font-face&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-family&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#5af78e">&amp;#39;KingHwa_OldSong&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">src&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">url&lt;/span>&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;/fonts/KingHwa_OldSong.ttf&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">)&lt;/span> &lt;span style="color:#ff6ac1">format&lt;/span>&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;truetype&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-weight&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">normal&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-style&lt;/span>&lt;span style="color:#ff6ac1">:&lt;/span> &lt;span style="color:#ff6ac1">normal&lt;/span>&lt;span style="color:#ff6ac1">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>.&lt;span style="color:#f3f99d">custom-en&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-family&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;3270NerdFont&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>.&lt;span style="color:#f3f99d">custom-zh&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">font-family&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;KingHwa_OldSong&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>更多关于自定义字体的讨论，可参考这里: &lt;a href="https://discourse.gohugo.io/t/how-to-add-custom-fonts-and-not-depend-on-google/34267/3">https://discourse.gohugo.io/t/how-to-add-custom-fonts-and-not-depend-on-google/34267/3&lt;/a>&lt;/p>
&lt;ol start="3">
&lt;li>修改 &lt;code>config.toml&lt;/code>：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-toml" data-lang="toml">&lt;span style="display:flex;">&lt;span>[params]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> customCSS = [&lt;span style="color:#5af78e">&amp;#34;css/custom.css&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="4">
&lt;li>复制 &lt;code>themes/layouts/partials/head.html&lt;/code> 到根目录&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>cp themes/layouts/partials/head.html ./layouts/partials/head.html
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Optional:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp themes/layouts/partials/head-extra.html ./layouts/partials/head-extra.html
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果主题设计得足够好，通常会给一份 &lt;code>head-extra.html&lt;/code> 用于定制化内容。
此时，只需要将相应配置加入到 &lt;code>head-extra.html&lt;/code> 文件中，避免对 &lt;code>head.html&lt;/code> 的打扰。&lt;/p>
&lt;p>增加的相应内容是：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;lt;!-- Other head content --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{{- range .Site.Params.customCSS }}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#ff6ac1">link&lt;/span> &lt;span style="color:#57c7ff">rel&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;stylesheet&amp;#34;&lt;/span> &lt;span style="color:#57c7ff">href&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;{{ . | relURL }}&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{{- end }}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="5">
&lt;li>使用自定义字体&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>You&amp;#39;ve got to draw the line somewhere. (system-font)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;span class=&amp;#34;custom-en&amp;#34;&amp;gt;You&amp;#39;ve got to draw the line somewhere. (NerdFont 3270)&amp;lt;/span&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;span class=&amp;#34;custom-zh&amp;#34;&amp;gt;中文：你必须在某个地方把那条线给画出来。(京華老宋体)&amp;lt;/span&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>rime_trime</title><link>/posts/personals/momentsoflife/rime_trime/</link><pubDate>Sat, 06 Jul 2024 15:34:59 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/personals/momentsoflife/rime_trime/</guid><description>&lt;p>&lt;a href="https://github.com/iDvel/rime-ice">rime-ice&lt;/a> 雾凇拼音 + &lt;a href="https://github.com/osfans/trime">trime&lt;/a> 同文输入法&lt;/p>
&lt;p>&lt;img alt="IMG_trime_a_grimpse" src="https://fgg100y.github.io/posts/personals/momentsoflife/rime_trime/images/trime_theme_4in1.png">&lt;/p>
&lt;p>怎么在手机上使用这个输入法？比较无脑省力那种&amp;hellip;
等等先，除开什么“愤世嫉俗”这种冠冕堂皇，或者“拒绝雷同”这种笑掉大牙，以及“听说它很难搞我非要搞定它”这种偏执狂的理由外，为什么用这个？
👉 开源万岁、开源万岁、开源万岁。&lt;/p>
&lt;p>应该说明：这篇文章基本是我自己的备忘录，我自己已经使用这些配置多年。
如果你是第一次接触 rime/Trime，直接查看他们官网或者本文的参考链接，否则如果按着我的说法进行操作，大概率你会搞得自己火冒三丈。&lt;/p>
&lt;hr>
&lt;p>我的操作：&lt;/p>
&lt;p>1.1 手机上下载 &lt;a href="https://f-droid.org/">F-Droid&lt;/a>，在 F-Droid 搜索并下载 Trime 输入法 (中文名：同文输入法&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>)&lt;/p>
&lt;p>1.2 手机应用授权等其他操作&lt;/p>
&lt;p>2.1 电脑端下载仓库&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">cd&lt;/span> rime_hub
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>git clone https://github.com/iDvel/rime-ice.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>2.2 将手机接入电脑，将仓库复制到手机目录路径（通常是与Download,Documents同级的路径），将
其名称修改为 &lt;code>rime&lt;/code> (rime-ice也可以，但要做出相应的适配和设置)&lt;/p>
&lt;p>3.1 手机端打开 Trime 输入法，点击右上角部署&lt;/p>
&lt;p>3.2 可能会报错弹出日志窗口，但不一定影响使用；否则，去官网等地方寻找解决方案&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;p>4.1 如果也在电脑端使用，可以借助 Plum 进行安装和更新：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>git clone --depth&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span> https://github.com/rime/plum
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">cd&lt;/span> plum
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bash rime-install iDvel/rime-ice:others/recipes/full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#全量更新：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bash rime-install iDvel/rime-ice:others/recipes/full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#局部更新：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bash rime-install iDvel/rime-ice:others/recipes/all_dicts
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注：github.com 不给力时&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>，&lt;code>plum&lt;/code> 就会巧妇难为无米之炊，因此如果可以直接从网页端下载到
仓库源码压缩包或者从其他地方获取(如&lt;code>rime-ice-master.zip&lt;/code>)，那么手动安装其实也很简单：&lt;/p>
&lt;p>将压缩包解压并将数据复制&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>到以下目录（根据安装方式不同来选择）：&lt;/p>
&lt;ul>
&lt;li>iBus 为 &lt;code>$HOME/.config/ibus/rime/&lt;/code>&lt;/li>
&lt;li>Fcitx5 为 &lt;code>$HOME/.local/share/fcitx5/rime/&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>5 多端同步：电脑端更新，复制到手机等其他终端。&lt;/p>
&lt;hr>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>同文输入法：把 RIME 装进 Android 手机 &lt;a href="https://sspai.com/post/77499">https://sspai.com/post/77499&lt;/a>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Rime 配置：雾凇拼音 &lt;a href="https://dvel.me/posts/rime-ice/">https://dvel.me/posts/rime-ice/&lt;/a>&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>由于网络原因 github.com 访问不到实属特色，不应惊讶&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>在目标目录下，比复制更省事的做法是：&lt;code>ln -s path/to/rime-ice rime&lt;/code>&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>职称评审</title><link>/posts/personals/engineering_career_ladder/</link><pubDate>Fri, 05 Jul 2024 22:40:23 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/personals/engineering_career_ladder/</guid><description>&lt;p>虽然人家只评估近五年的工作，但粗略算起来自己工作都快八年了，才爬了第二个阶梯。&lt;/p>
&lt;p>半路出家着实费劲。&lt;/p>
&lt;p>&lt;img alt="MidLevel" src="https://fgg100y.github.io/posts/personals/engineering_career_ladder/images/fmh_engineering_career_blur_extra_info.png">&lt;/p>
&lt;p>突然想起经典电影《三毛从军记》结尾部分的饱含沧桑而又莫名喜感的那一句台词：八年了&amp;hellip;&lt;/p>
&lt;p>急躁时不免暗暗奢望有人：“看在技术的份上，拉兄弟我一把。” 😂&lt;/p>
&lt;p>但话说回来，“当幸福来敲门”的时候，你最好是恰在家，做好准备。&lt;/p>
&lt;p>要不然真有人拉你一把时，结果却弄成烂泥扶不上墙。恐怕没有比这更糟糕的了。&lt;/p></description></item><item><title>so_long_and_no_thanks</title><link>/posts/personals/momentsoflife/so_long/</link><pubDate>Thu, 04 Jul 2024 20:03:19 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/personals/momentsoflife/so_long/</guid><description>&lt;p>如果你看过《银河系漫游指南》，应该记得地球生物智慧排第一的是海豚（人类只排第三）😂&lt;/p>
&lt;p>离别时本来应该是来一句：&lt;/p>
&lt;blockquote>
&lt;p>“So long! And thanks for all the fish.&amp;quot;&lt;/p>
&lt;/blockquote>
&lt;p>但实际情况却是：&lt;/p>
&lt;p>&lt;img alt="no_thanks" src="https://fgg100y.github.io/posts/personals/momentsoflife/so_long/images/dophine.jpg">&lt;/p></description></item><item><title>Short_time_Fourier_Transform</title><link>/posts/dsp101/2024-07-03-short_time_fourier_transform/</link><pubDate>Wed, 03 Jul 2024 11:25:37 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/dsp101/2024-07-03-short_time_fourier_transform/</guid><description>&lt;p>Sine Wave Signal&lt;/p>
&lt;p>An audio signal, y(t), composed of exactly one sine wave, can be completely described by
the parameters $t, A, f$ and $\phi$,
$$
y(t) = A \sin(2 \pi f t + \phi)
$$
where $t$ represents time in seconds, $A$ is the wave&amp;rsquo;s amplitude (unit-less), $f$ is
its frequency in Hz, and $\phi$ is its phase offset in radians (i.e., where in the cycle
the wave is at $t=0$). If $t \ne 0$, then the sine wave appears shifted in time by
$\frac{\phi}{2 \pi f}$, where negative values mean &amp;ldquo;delay&amp;rdquo; and positive &amp;ldquo;advance&amp;rdquo; it.&lt;/p>
&lt;p>Fourier Series&lt;/p>
&lt;blockquote>
&lt;p>Our old pal Fourier told us that any sound can be represented as an infinite summation
of sine waves each with their own amplitudes, frequencies, and phase offsets. This means
that any sound we hear can be represented as many, many tuples of $t, A, f, \phi$.&lt;/p>
&lt;/blockquote>
&lt;p>Time-Frequency representation&lt;/p>
&lt;p>A Time-Frequency representation is a 2 dimensional matrix that represents the frequency
contents of an audio signal over time.&lt;/p>
&lt;p>We can visualize a TF Representation using a heatmap, which has time along the x-axis
and frequency along the y-axis. Each &lt;em>TF bin&lt;/em> (entry in heatmap) in the heatmap
represents the &lt;strong>amplitude&lt;/strong> of the signal at that particular time and frequency.
If there is no color bar, it is usually safe to assume that brighter colors indicate
higher amplitudes than darker colors.&lt;/p>
&lt;p>&lt;img alt="TFrepr" src="images/dsp_tf_representation.png">&lt;/p>
&lt;p>Short-time Fourier Transform (STFT)&lt;/p>
&lt;p>An STFT is calculated from a waveform representation by computing a discrete Fourier
transform (DFT) of a small, moving window across the duration of the window. The
location of each entry in an STFT determines its time (x-axis) and frequency (y-axis).
The absolute value of a TF bin |$X(t,f)$| at time t and frequency f determines the amount
of energy heard from frequency $f$ at time $t$.&lt;/p>
&lt;p>Importantly, each bin in our STFT is complex, meaning each entry contains both a
magnitude component and a phase component. Both components are needed to convert an STFT
matrix back to a waveform by &lt;em>inverse STFT&lt;/em> so that we may hear it.&lt;/p>
&lt;p>&lt;img alt="STFT" src="images/dsp_stft_process.png">&lt;/p>
&lt;p>Window Types&lt;/p>
&lt;p>The window type determines the shape of the short-time window that will segment the
audio into short segments before applying the DFT. The shape of this window will affect
which frequencies get emphasized or attenuated in the DFT. There are many types of
&lt;a href="https://docs.scipy.org/doc/scipy/reference/signal.windows.html">window functions&lt;/a>.&lt;/p>
&lt;p>&lt;img alt="windows" src="images/dsp_window_types.png">&lt;/p></description></item><item><title>Discrete_Fourier_Transform</title><link>/posts/dsp101/2024-07-03-discrete_fourier_transform/</link><pubDate>Wed, 03 Jul 2024 09:46:45 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/dsp101/2024-07-03-discrete_fourier_transform/</guid><description>&lt;p>An analysis problem, which is equivalent to the &lt;strong>DFT&lt;/strong>:&lt;/p>
&lt;pre>&lt;code>Given a signal, how to find the amplitude and phase offset of its frequency
components?
&lt;/code>&lt;/pre>
&lt;p>A synthesis problem, which is equivalent to the &lt;strong>inverse DFT&lt;/strong>:&lt;/p>
&lt;pre>&lt;code>Given a set of frequency components and their amplitudes, how can we construct a
signal?
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>DFT&lt;/strong> and &lt;strong>Inverse DFT&lt;/strong> in code&lt;/p>
&lt;p>The &lt;code>analyze()&lt;/code> computes something very close to the DFT, with one difference: The
conventional definition of DFT does not divide by &lt;code>N&lt;/code> (highlighted line below):&lt;/p>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">analyze&lt;/span>(ys):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> N &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(ys)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span> M &lt;span style="color:#ff6ac1">=&lt;/span> synthesis_matrix(N)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> amps &lt;span style="color:#ff6ac1">=&lt;/span> M&lt;span style="color:#ff6ac1">.&lt;/span>conj()&lt;span style="color:#ff6ac1">.&lt;/span>transpose()&lt;span style="color:#ff6ac1">.&lt;/span>dot(ys) &lt;span style="color:#ff6ac1">/&lt;/span> N
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> amps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">dft&lt;/span>(ys): &lt;span style="color:#78787e"># return same result as np.fft.fft()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> N &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(ys)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span> M &lt;span style="color:#ff6ac1">=&lt;/span> synthesis_matrix(N)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> amps &lt;span style="color:#ff6ac1">=&lt;/span> M&lt;span style="color:#ff6ac1">.&lt;/span>conj()&lt;span style="color:#ff6ac1">.&lt;/span>transpose()&lt;span style="color:#ff6ac1">.&lt;/span>dot(ys)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> amps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">idft&lt;/span>(amps): &lt;span style="color:#78787e"># inverse DFT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> N &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(amps)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> M &lt;span style="color:#ff6ac1">=&lt;/span> synthesis_matrix(N)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ys &lt;span style="color:#ff6ac1">=&lt;/span> M&lt;span style="color:#ff6ac1">.&lt;/span>dot(amps) &lt;span style="color:#ff6ac1">/&lt;/span> N
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> ys &lt;span style="color:#78787e"># ys: value of the signal at each time step&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">synthesis_matrix&lt;/span>(N):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ts &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>arange(N) &lt;span style="color:#ff6ac1">/&lt;/span> N &lt;span style="color:#78787e"># ts: the sequence of times where the signal should be evaluated&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fs &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>arange(N) &lt;span style="color:#78787e"># fs: the list of frequencies&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>outer(ts, fs) &lt;span style="color:#78787e"># args: outer product of ts and fs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> M &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>exp(&lt;span style="color:#ff9f43">1&lt;/span>j &lt;span style="color:#ff6ac1">*&lt;/span> PI2 &lt;span style="color:#ff6ac1">*&lt;/span> args) &lt;span style="color:#78787e"># PI2 = np.pi * 2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> M
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>ResNet</title><link>/posts/neuralnetworks/resnet/</link><pubDate>Sat, 29 Jun 2024 09:17:15 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/neuralnetworks/resnet/</guid><description>&lt;p>思维实验：
在浅层网络结构的基础上（比如20层），往后面直接添加更多的同映射隐层（identity layers），
得到的深层网络（比如50层）理论上效果应该不会变差。但实验结果说明，它真会变差。意味着：
SGD算法无法找到使得更深层网络性能不变差的参数。&lt;/p>
&lt;p>残差网络架构可以解决这个问题。&lt;/p>
&lt;h2 id="why-what-and-how" >
&lt;div>
&lt;a href="#why-what-and-how">
#
&lt;/a>
Why, What, and How
&lt;/div>
&lt;/h2>
&lt;blockquote>
&lt;p>Deeper neural networks are more difficult to train. We present a residual learning
framework to ease the training of networks that are substantially deeper than those used
previously. We explicitly reformulate the layers as learning residual functions with
reference to the layer inputs, instead of learning unreferenced functions.&lt;/p>
&lt;/blockquote>
&lt;p>训练一个深度（足够深的）神经网络是一件很难的事情（2015年）。
使用“残差”神经网络架构可以更容易地训练足够深的神经网络。
“残差”架构就是把这些中间层作为一个学习输入与输出的残差的函数。&lt;/p>
&lt;p>&lt;img alt="ResNet Block" src="images/resnet_learning_block.png">&lt;/p>
&lt;p>就是说：增加的隐层去学习 $h(x) - x$（残差）而不是 $h(x)$，而输出的是当前隐层的输出加上前
一层的输出 $x$ （同时也是当前层的输入）。&lt;/p>
&lt;h2 id="残差网络结构" >
&lt;div>
&lt;a href="#%e6%ae%8b%e5%b7%ae%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84">
#
&lt;/a>
残差网络结构
&lt;/div>
&lt;/h2>
&lt;p>残差连接（aka, shortcut connection）在输入和输出的维度相同情况下可以直接使用如下结构块：&lt;/p>
&lt;p>$$
y = F(x, {W_i}) + x.
$$&lt;/p>
&lt;p>当想要增加维度时，有两种方式来对齐输入和输出的维度：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>残差连接进行同映射操作，然后对增加的维度进行补零操作（padding zeros)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>残差连接进行线性投影操作 $y = F(x, {W_i}) + W_s x.$ 来对齐维度（使用 1x1 卷积实现）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>两种情况下，当残差连接的是不同尺寸的特征图（feature map）时，使用步幅为2的卷积操作。
（通道数翻倍，则高宽减半，因此使用步幅=2（stride=2）的卷积来保证维数对齐）&lt;/p>
&lt;p>&lt;img alt="bottlenet-block" src="https://fgg100y.github.io/posts/neuralnetworks/resnet/images/resnet_bottlenet_building_block.png">&lt;/p>
&lt;p>&lt;img alt="resnet-arch" src="https://fgg100y.github.io/posts/neuralnetworks/resnet/images/resnet_arch_for_imagenet.png">&lt;/p>
&lt;h2 id="残差连接为什么有用" >
&lt;div>
&lt;a href="#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e7%94%a8">
#
&lt;/a>
残差连接为什么有用？
&lt;/div>
&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Easier Gradient Flow&lt;/p>
&lt;ul>
&lt;li>缓解梯度消失/梯度爆炸问题&lt;/li>
&lt;li>残差连接使得梯度更稳定&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>更容易学习同映射函数&lt;/p>
&lt;/li>
&lt;li>
&lt;p>提升最优化和收敛效果&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更好的特征传播（feature propagation）&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="此残差非彼残差resnet-vs-gdbt" >
&lt;div>
&lt;a href="#%e6%ad%a4%e6%ae%8b%e5%b7%ae%e9%9d%9e%e5%bd%bc%e6%ae%8b%e5%b7%aeresnet-vs-gdbt">
#
&lt;/a>
此残差非彼残差（ResNet VS GDBT）
&lt;/div>
&lt;/h2>
&lt;p>GBDT（梯度提升决策树）中的残差（residual）是指预测值与真实值之间的差值。&lt;/p>
&lt;p>ResNet 中的残差（residual），是神经网络尝试去学习特征图（feature map）的残差（是网络块输出与输入之间的差值）。&lt;/p>
&lt;p>Paper: &lt;a href="https://arxiv.org/pdf/1512.03385">https://arxiv.org/pdf/1512.03385&lt;/a>&lt;/p></description></item><item><title>knowledge_distillation2</title><link>/posts/clipmodel/2024-06-28-knowledge_distillation2/</link><pubDate>Fri, 28 Jun 2024 11:25:43 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/clipmodel/2024-06-28-knowledge_distillation2/</guid><description>&lt;h2 id="generalized-knowledge-distillation-gkd" >
&lt;div>
&lt;a href="#generalized-knowledge-distillation-gkd">
#
&lt;/a>
Generalized Knowledge Distillation (GKD)
&lt;/div>
&lt;/h2>
&lt;p>泛化知识蒸馏是一种改进的知识蒸馏技术，旨在解决传统知识蒸馏方法在自回归序列模型中遇到的分
布不匹配问题，特别是在训练和推理阶段之间。传统的知识蒸馏方法通常基于固定的输出序列集进行，
这些序列或者是教师模型生成的，或者是基于真实数据的标签。然而，这导致学生模型在推理时生成
的序列可能与训练时见到的序列分布不同，从而影响了学生模型的泛化能力。&lt;/p>
&lt;p>GKD 不再局限于固定输出序列的训练，而是允许学生模型在其自我生成的序列上进行学习，同时利用
教师模型提供的反馈。&lt;/p>
&lt;h2 id="gkd-技术要点" >
&lt;div>
&lt;a href="#gkd-%e6%8a%80%e6%9c%af%e8%a6%81%e7%82%b9">
#
&lt;/a>
GKD 技术要点
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>动态序列生成与反馈：GKD 在训练过程中，会根据学生模型的自我生成序列进行学习。这意味着学
生模型在尝试生成序列时，如果生成错误或不理想的序列，它可以从教师模型那里获得直接反馈，
学习如何纠正这些错误。这种机制能够减少训练和推理过程中的分布差异，提高学生模型对各种输
入序列的泛化能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>灵活的损失函数选择：与仅采用前向KL散度的传统监督式知识蒸馏不同，GKD 提供了灵活性，可以
在学生和教师模型之间使用替代的损失函数。当学生模型难以精确模拟教师模型的概率分布时，这
一点尤为重要。例如，可以采用Jensen-Shannon散度等指标来衡量分布之间的差异，这有助于学生
模型在表达力有限的情况下更好地学习。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>集成强化学习精调：GKD 还促进了知识蒸馏与基于强化学习的语言模型微调的无缝整合。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="动态序列生成" >
&lt;div>
&lt;a href="#%e5%8a%a8%e6%80%81%e5%ba%8f%e5%88%97%e7%94%9f%e6%88%90">
##
&lt;/a>
动态序列生成
&lt;/div>
&lt;/h3>
&lt;p>在传统的知识蒸馏中，学生模型通常基于预先定义好的固定数据集或由教师模型生成的输出序列进行
训练。而动态序列生成则打破了这一限制，它让学生模型自己生成输出序列，并在此基础上进行学习。
这个过程涉及以下几个步骤：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>初始化学生模型：首先，学生模型需要具备一定的生成能力，通常通过初步的监督式预训练或微调
（Supervised Fine-Tuning, SFT）来实现，确保它可以生成质量尚可的序列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>自我生成序列：在训练过程中，学生模型接收到输入后，会根据当前的策略生成输出序列。这些序
列反映了学生模型当前的能力和理解，可能包含错误或不完美的部分。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="反馈机制" >
&lt;div>
&lt;a href="#%e5%8f%8d%e9%a6%88%e6%9c%ba%e5%88%b6">
##
&lt;/a>
反馈机制
&lt;/div>
&lt;/h3>
&lt;p>一旦学生模型生成了输出序列，接下来的关键步骤是获取教师模型的反馈：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>教师模型评估：教师模型会对学生生成的序列进行评估，通常通过比较教师和学生模型在每个生成
步骤上对下一个词的概率分布。这涉及到计算两者的概率分布之间的某种差异度量，如KL散度。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>指导性学习：根据教师模型的反馈，学生模型调整其参数，目的是使自己在生成类似序列时能更接
近教师模型的表现。GKD 允许选择不同的差异度量（divergence）来优化，以适应不同任务的需求。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>迭代优化：随着学生模型不断从自我生成的错误中学习，它的生成能力逐步提升，生成的序列质量
也随之提高，形成了一个正向循环。此过程可以视为一种模仿学习（Imitation Learning）与强化
学习（Reinforcement Learning）的结合，其中学生模型通过迭代地探索和修正其行为，以逼近教
师模型的表现。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>参考文献：https://arxiv.org/pdf/2306.13649&lt;/p></description></item><item><title>knowledge_distillation</title><link>/posts/clipmodel/2024-06-27-knowledge_distillation/</link><pubDate>Thu, 27 Jun 2024 11:34:18 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/clipmodel/2024-06-27-knowledge_distillation/</guid><description>&lt;p>知识蒸馏（Knowledge Distillation）是一种机器学习技术，它通过将大型、复杂的模型（称为教师
模型，Teacher Model）的知识“蒸馏”到小型、简洁的模型（称为学生模型，Student Model）中，从
而实现模型压缩和加速，同时尽可能保持原始模型的性能。这一技术使得模型可以在资源有限的设备
上高效运行，如手机或嵌入式设备。&lt;/p>
&lt;blockquote>
&lt;p>The method works by incorporating an additional loss into the traditional cross entropy
loss, which is based on the softmax output of the teacher network. The assumption is
that the output activations of a properly trained teacher network carry additional
information that can be leveraged by a student network during training.&lt;/p>
&lt;/blockquote>
&lt;h2 id="基本原理" >
&lt;div>
&lt;a href="#%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86">
#
&lt;/a>
基本原理
&lt;/div>
&lt;/h2>
&lt;p>知识转移：核心思想是通过让学生模型模仿教师模型的输出行为，不仅包括硬分类标签，还有软概率
分布（softmax概率），这样可以传递更多关于数据分布的信息。软标签相比硬标签含有更多关于数
据不确定性及类间关系的信息，有助于学生模型学习更细腻的决策边界。&lt;/p>
&lt;p>特征蒸馏：除了输出层的知识外，泛化知识蒸馏还可以涉及中间层特征的学习，即学生模型试图学习
教师模型的高层特征表示。这有助于提升学生模型的泛化能力，因为它学会了如何从输入数据中提取
更有用的特征。&lt;/p>
&lt;p>关系蒸馏：强调保持教师和学生模型对于输入样本间关系的理解一致性。这意味着学生模型不仅要学
会单个样本的处理，还要理解样本之间的相对关系，这对于一些需要理解复杂上下文的任务尤为重要。&lt;/p>
&lt;p>&lt;strong>知识蒸馏过程&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>训练教师模型&lt;/strong>：首先，使用大量数据和计算资源训练一个高性能的深度神经网络（教师模
型）。这个模型可能包含数百万甚至数十亿个参数，但它在分类任务上的表现非常出色。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>生成软标签&lt;/strong>：教师模型在对输入数据进行预测时，不仅仅给出最终的分类结果，还会给出各
类别的概率分布（通常通过softmax层获得）。这些概率分布被称为“软标签”，它们包含了额外的
信息，比如类别的不确定性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>训练学生模型&lt;/strong>：接下来，使用教师模型的软标签和实际的硬标签（即数据的真实类别）来训
练学生模型。学生模型的架构设计得更简单，参数量远小于教师模型。训练过程中，学生模型不
仅要学习模仿硬标签，还要通过损失函数（如KL散度或交叉熵）尽量接近教师模型的软标签输出。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>温度参数调整&lt;/strong>：在生成软标签时，有时会引入一个“温度”参数来调整概率分布的平滑程度。
高温可以使软标签更加平滑，促进学生模型学习到教师模型的决策边界；低温则使得软标签接近
硬标签，但可能会丢失教师模型的一些细微决策信息。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="知识蒸馏的三种代码实现" >
&lt;div>
&lt;a href="#%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8f%e7%9a%84%e4%b8%89%e7%a7%8d%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0">
#
&lt;/a>
知识蒸馏的三种代码实现：
&lt;/div>
&lt;/h2>
&lt;ol>
&lt;li>知识转移：基于 softmax output 软标签&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the teacher model - do not save gradients here as we do not change the teacher&amp;#39;s weights&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">with&lt;/span> torch&lt;span style="color:#ff6ac1">.&lt;/span>no_grad():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> teacher_logits &lt;span style="color:#ff6ac1">=&lt;/span> teacher(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the student model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>student_logits &lt;span style="color:#ff6ac1">=&lt;/span> student(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#Soften the student logits by applying softmax first and log() second&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>soft_targets &lt;span style="color:#ff6ac1">=&lt;/span> nn&lt;span style="color:#ff6ac1">.&lt;/span>functional&lt;span style="color:#ff6ac1">.&lt;/span>softmax(teacher_logits &lt;span style="color:#ff6ac1">/&lt;/span> T, dim&lt;span style="color:#ff6ac1">=-&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>soft_prob &lt;span style="color:#ff6ac1">=&lt;/span> nn&lt;span style="color:#ff6ac1">.&lt;/span>functional&lt;span style="color:#ff6ac1">.&lt;/span>log_softmax(student_logits &lt;span style="color:#ff6ac1">/&lt;/span> T, dim&lt;span style="color:#ff6ac1">=-&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper &amp;#34;Distilling the knowledge in a neural network&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>soft_targets_loss &lt;span style="color:#ff6ac1">=&lt;/span> torch&lt;span style="color:#ff6ac1">.&lt;/span>sum(soft_targets &lt;span style="color:#ff6ac1">*&lt;/span> (soft_targets&lt;span style="color:#ff6ac1">.&lt;/span>log() &lt;span style="color:#ff6ac1">-&lt;/span> soft_prob)) &lt;span style="color:#ff6ac1">/&lt;/span> soft_prob&lt;span style="color:#ff6ac1">.&lt;/span>size()[&lt;span style="color:#ff9f43">0&lt;/span>] &lt;span style="color:#ff6ac1">*&lt;/span> (T&lt;span style="color:#ff6ac1">**&lt;/span>&lt;span style="color:#ff9f43">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the true label loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>label_loss &lt;span style="color:#ff6ac1">=&lt;/span> ce_loss(student_logits, labels)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Weighted sum of the two losses&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss &lt;span style="color:#ff6ac1">=&lt;/span> soft_target_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> soft_targets_loss &lt;span style="color:#ff6ac1">+&lt;/span> ce_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> label_loss
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss&lt;span style="color:#ff6ac1">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>特征蒸馏：基于 hidden state 余弦相似度&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the teacher model and keep only the hidden representation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">with&lt;/span> torch&lt;span style="color:#ff6ac1">.&lt;/span>no_grad():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _, teacher_hidden_representation &lt;span style="color:#ff6ac1">=&lt;/span> teacher(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the student model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>student_logits, student_hidden_representation &lt;span style="color:#ff6ac1">=&lt;/span> student(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the cosine loss. Target is a vector of ones. From the loss formula above we can see that is the case where loss minimization leads to cosine similarity increase.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hidden_rep_loss &lt;span style="color:#ff6ac1">=&lt;/span> cosine_loss(student_hidden_representation, teacher_hidden_representation, target&lt;span style="color:#ff6ac1">=&lt;/span>torch&lt;span style="color:#ff6ac1">.&lt;/span>ones(inputs&lt;span style="color:#ff6ac1">.&lt;/span>size(&lt;span style="color:#ff9f43">0&lt;/span>))&lt;span style="color:#ff6ac1">.&lt;/span>to(device))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the true label loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>label_loss &lt;span style="color:#ff6ac1">=&lt;/span> ce_loss(student_logits, labels)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Weighted sum of the two losses&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss &lt;span style="color:#ff6ac1">=&lt;/span> hidden_rep_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> hidden_rep_loss &lt;span style="color:#ff6ac1">+&lt;/span> ce_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> label_loss
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss&lt;span style="color:#ff6ac1">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>特征蒸馏：基于 Intermediate regressor MSE损失&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Again ignore teacher logits&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">with&lt;/span> torch&lt;span style="color:#ff6ac1">.&lt;/span>no_grad():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _, teacher_feature_map &lt;span style="color:#ff6ac1">=&lt;/span> teacher(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Forward pass with the student model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>student_logits, regressor_feature_map &lt;span style="color:#ff6ac1">=&lt;/span> student(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hidden_rep_loss &lt;span style="color:#ff6ac1">=&lt;/span> mse_loss(regressor_feature_map, teacher_feature_map)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Calculate the true label loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>label_loss &lt;span style="color:#ff6ac1">=&lt;/span> ce_loss(student_logits, labels)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Weighted sum of the two losses&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss &lt;span style="color:#ff6ac1">=&lt;/span> feature_map_weight &lt;span style="color:#ff6ac1">*&lt;/span> hidden_rep_loss &lt;span style="color:#ff6ac1">+&lt;/span> ce_loss_weight &lt;span style="color:#ff6ac1">*&lt;/span> label_loss
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss&lt;span style="color:#ff6ac1">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer&lt;span style="color:#ff6ac1">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>具体参考：https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html?highlight=distill&lt;/p></description></item><item><title>mixup_beyond_ERM</title><link>/posts/lossfunctions/2024-06-27-mixup_beyond_empirical_risk_minimization/</link><pubDate>Thu, 27 Jun 2024 09:42:34 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/lossfunctions/2024-06-27-mixup_beyond_empirical_risk_minimization/</guid><description>&lt;h1 id="empirical-risk-minimazation-erm" >
&lt;div>
&lt;a href="#empirical-risk-minimazation-erm">
##
&lt;/a>
Empirical Risk Minimazation (ERM)
&lt;/div>
&lt;/h1>
&lt;p>经验风险最小化, Empirical Risk Minimazation principle (Vapnik, 1998)&lt;/p>
&lt;ol>
&lt;li>基于ERM训练模型：亦即在训练数据集上学习以最小化其平均误差。&lt;/li>
&lt;li>当前SOTA模型的参数量随着训练数据集规模增大而线性增加。&lt;/li>
&lt;/ol>
&lt;p>而经典VC学习理论（learning theory, Vapnik &amp;amp; Chervonenkis, 1971）表明：只要学习器的参数量
不随着训练样本数量增加，则基于ERM学习一定会收敛(convergence, i.e., good generalization
to new data)。亦即：模型的复杂度（参数量规模）相对于训练数据规模应该是固定的或者变动不大。&lt;/p>
&lt;p>这就造成了这样的矛盾：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>经典学习理论认为：想要ERM有效，则模型的参数量应该保持一定大小，而不是随着训练数据集规模增加而增加；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>然而在实际任务中：SOTA模型的参数量是与训练数据量保持线性增加的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>实际上，一方面ERM允许大的神经网络模型“记住”训练样本（即使用了很强的正则化约束，
strong regularization)，另一方面ERM训练得到的模型在训练分布之外的样本上的预测结果差异巨
大（即使被预测的样本仅仅发生了相对微小的改变，adversarial examples）。&lt;/p>
&lt;p>那么，有没有别的模型训练最优化准则呢？-&amp;gt; Vicinal Risk Minimization (VRM).&lt;/p>
&lt;blockquote>
&lt;p>In VRM, human knowledge is required to describe a vicinity or neighborhood around each
example in the training data. Then, additional virtual examples can be drawn from the
vicinity distribution of the training examples to enlarge the support of the training
distribution.&lt;/p>
&lt;/blockquote>
&lt;p>例如，在图像分类任务中，图像增强通常包括轻微的旋转、翻转、缩放等操作，这其实是图像的近邻
集（vicinity set）。这些数据增强通常提升了模型的泛化性能。但这些操作通常也是数据依赖的。&lt;/p>
&lt;p>Mixup 提供了一种数据无关（data-agnostic）的增强方法，它构造虚拟样本的方式如下：&lt;/p>
&lt;p>$$
\begin{eqnarray}
\tilde{x} &amp;amp;=&amp;amp; \lambda x_i + (1 - \lambda) x_j, \text{where } x_i, x_j \text{ are raw input vectors} \\
\tilde{y} &amp;amp;=&amp;amp; \lambda y_i + (1 - \lambda) y_j, \text{where } y_i, y_j \text{ are one-hot label encoding}
\end{eqnarray}
$$&lt;/p>
&lt;p>$(x_i, y_i)$ 和 $(x_j, y_j)$ 是从训练集中随机抽取的两个样例。$\lambda \in [0, 1]$。&lt;/p>
&lt;p>因此，mixup通过结合先验知识扩展了训练分布，即特征向量的线性插值应导致相关目标的线性插值。
mixup可以用几行代码实现，并且只引入最小的计算开销。&lt;/p>
&lt;p>Mixup: beyond_ERM, &lt;a href="https://arxiv.org/pdf/1710.09412">https://arxiv.org/pdf/1710.09412&lt;/a>&lt;/p></description></item><item><title>MoCo</title><link>/posts/neuralnetworks/moco/</link><pubDate>Sun, 16 Jun 2024 14:10:17 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/neuralnetworks/moco/</guid><description>&lt;p>对比学习（Contrast Learning）：
是一种自监督学习方法，通过构建和比较正负样本对来学习数据的有用表示。正样本对通常来自同一
数据点的不同增强版本，而负样本对则来自不同的数据点。模型通过最大化正样本对的相似度和最小
化负样本对的相似度，从而提取数据的判别性特征，广泛应用于图像、文本和时间序列等领域。&lt;/p>
&lt;p>正负样本的生成：&lt;/p>
&lt;p>&lt;img alt="pos-neg-sample-pairs" src="https://fgg100y.github.io/posts/neuralnetworks/moco/images/CV-moco_model_pos_neg_samples_how.png">&lt;/p>
&lt;p>MoCo:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Contrastive learning as dictionary look-up:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>queue&lt;/code> for large dictionary of keys: 解决 simCLR(end-to-end) 方法受限于字典大小的问题&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>momentum update&lt;/code> for consistency of keys: 解决基于 &amp;ldquo;memory bank&amp;rdquo; 方法受限于keys的特征一致性差的问题&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>infoNCE loss (infomation Noice-Contrastive Estimation, 与交叉熵损失有极大关联):
NCE是将多分类问题转换为二分类问题（数据样本vs噪声样本）从而可以愉快使用softmax；
而infoNCE认为噪声样本里还是有很多不同类别，所以看成多分类问题比较合理（K+1类）。
交叉熵损失中的$k$是类别数目，而infoNCE损失中的$k$是负样本的数目。&lt;/p>
&lt;p>$$
\mathcal{L}_q = - \log \frac{\exp(q \cdot k_{+} / \tau)}{\sum^{K}_{i=0} \exp(q \cdot k_{+} / \tau)}
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="MoCo" src="https://fgg100y.github.io/posts/neuralnetworks/moco/images/CV-moco_model_query_key_similarity_contrast_loss.png">&lt;/p></description></item><item><title>what_is_Momentum</title><link>/posts/neuralnetworks/2024-06-16-what_is_momentum/</link><pubDate>Sun, 16 Jun 2024 10:35:30 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/neuralnetworks/2024-06-16-what_is_momentum/</guid><description>&lt;p>“动量”简单来说就是：移动加权平均。
$$
y_t = m \times y_{t-1} + (1 - m) \times x_t
$$
where $m \in [0, 1]$.&lt;/p>
&lt;p>上式就是表达了这么个意思：&lt;/p>
&lt;p>当前时刻输出 $y_t$ 除了受到当前输入 $x_t$ 的影响，还有上一个时刻输出 $y_{t-1}$ 的影响，
而其影响程度由“动量 (momentum)” $m$ 来决定。则有：$m$ 趋向于1，$y_t$ 与上一个时刻相同。&lt;/p>
&lt;p>大约是说，不希望当前时刻的输出完全依赖于当前时刻的输入，还希望上一个时刻的输出来凑凑热闹。&lt;/p></description></item><item><title>路由器wifi连不上_但手机流量可以</title><link>/posts/personals/momentsoflife/2024-06-16-wifi%E8%BF%9E%E4%B8%8D%E4%B8%8A_%E4%BD%86%E6%89%8B%E6%9C%BA%E6%B5%81%E9%87%8F%E5%8F%AF%E4%BB%A5/</link><pubDate>Sun, 16 Jun 2024 10:07:12 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/personals/momentsoflife/2024-06-16-wifi%E8%BF%9E%E4%B8%8D%E4%B8%8A_%E4%BD%86%E6%89%8B%E6%9C%BA%E6%B5%81%E9%87%8F%E5%8F%AF%E4%BB%A5/</guid><description>&lt;p>Q：请问Wifi无法翻墙或访问某些网站，但用手机流量却可以是什么原因？&lt;/p>
&lt;p>A:
先说说你的wifi和5g环境下翻墙的问题，我猜测下你家里的宽带是不是移动的，手机流量用的是联通
或者电信，总之，家庭宽带和5g不是一家isp。 如果是的话，这个问题就比较好理解，不同isp不同
的地区都会有自己的一套黑名单机制。 所以可能你的家宽isp监测你的上网流量有不正常，或者大数
据认为你的翻墙服务器很可疑（未必是你造成的，因为有很多人在用），于是开启了屏蔽，但是另一
家手机isp并没有触发黑名单判定，所以未屏蔽。 移动的黑名单一般是最激进的，号称墙中墙，不过
不同地区的同一服务商政策也会有很大差别，不好说谁就一定好，谁就一定差。所以解决方法就是换
个翻墙服务器就可以了。&lt;/p>
&lt;p>&lt;del>再说说机场问题，机场如果要找的话千千万，不夸张的说小学生都能开机场，所以，如果真
要是选的话，如果你不太懂技术，就选大机场好了，可能贵一些，但是稳定性是有保障的。
如果懂技术，就不如机场（或转发服务）+自建服务器结合的方式，这样就能兼顾速度和隐
私安全。 几乎所有的机场都会有审查机制，最起码他需要监控流量来计费，只是审查程度
和隐私数据处理严谨度有区别而已，看商家良心了。我个人没用过机场，只能说两个我所知
道的比较大的，justmysocks，dler cloud，魅影极速。 另外，别太迷信那些机场推荐，基
本都是掐饭。 对了，还有个我觉得你可以试下，叫Shiliew。 理由有2个，这个app的作者
就是开源翻墙软件brook的作者，在app store里看着权限很干净，另外这个作者名字叫
txthinking，有点致敬编程随想的意思，感觉他应该最起码不红吧。。。哈哈哈 但是这
东西好用不好用我就不知道了。&lt;/del>&lt;/p>
&lt;p>最后我再说下关于@han_chinese的观点，移动数据的审查是最强的，因为移动蜂窝数据是需要精确计
费的，众所周知，每个服务商都有很多免流量服务，所以需要识别流量内容来判断计费与否。更甚的
是，移动数据流量都会被自动标记上本机电话号码，他们还专门搞了api来卖这种服务。简单来讲，
比如你用流量上京东，你不需要输入你的电话号码来注册或者登录，京东就已然知晓了，因为京东买
了isp的api接口，只需要在网页中加入几行代码来调用这个api，你一旦用手机流量访问这个网页，
电话号码就会返回给京东。 所以无论翻墙与否，都建议在使用数据流量上网时开启vpn服务来加密和
中转数据。 关于买国外电话卡来翻墙，同样也是不靠谱的，因为外国的sim卡拿到中国来能用，只是
漫游了而已，漫游的意思就是，国外和国内的isp签了合同，能让各自的用户租用自己这边的基站线
路等设备来保证跨国使用，所以即使买了google-fi来中国使用，和你用中国的sim卡在中国使用，都
是通过中国isp的基站线路和服务器。唯一区别就是google-fi的所有访问都会被列入白名单，但是数
据流量的审计是一样的。你拿google-fi来上pincong，移动服务商是知道，只是不阻拦而已，这样一
定程度上更加危险。&lt;/p>
&lt;p>@han_chinese:
中國電信市場的移動數據網絡使用的是複雜的多重企業IPv4-NAT，加之，移動數據網絡業務很複雜。所以，GFW對移動數據網路的审查較弱。
建議直接使用國外數據業務，像是Google-Fi，使用不受GFW影響的移動數據網絡。&lt;/p>
&lt;p>&lt;a href="https://pincong.rocks/question/45451">点这里查阅信息来源&lt;/a>&lt;/p></description></item><item><title>calculate_gpu_vram_for_llama3-70B</title><link>/posts/llms/2024-06-13-calculate_gpu_vram_for_llama3-70b/</link><pubDate>Thu, 13 Jun 2024 16:11:47 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/llms/2024-06-13-calculate_gpu_vram_for_llama3-70b/</guid><description>&lt;p>How many GPUs do I need to be able to serve Llama 70B? In order to answer that, you need
to know how much GPU memory will be required by the Large Language Model.&lt;/p>
&lt;p>The formula is simple:&lt;/p>
&lt;p>$$
M=\frac{(P * 4B)}{(32/Q)} * 1.2
$$&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">Symbol&lt;/th>
&lt;th style="text-align: left">Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">M&lt;/td>
&lt;td style="text-align: left">GPU memory expressed in Gigabyte&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">P&lt;/td>
&lt;td style="text-align: left">The amount of parameters in the model. E.g. a 7B model has 7 billion parameters.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">4B&lt;/td>
&lt;td style="text-align: left">4 bytes, expressing the bytes used for each parameter&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">32&lt;/td>
&lt;td style="text-align: left">There are 32 bits in 4 bytes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Q&lt;/td>
&lt;td style="text-align: left">The amount of bits that should be used for loading the model. E.g. 16 bits, 8 bits or 4 bits.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">1.2&lt;/td>
&lt;td style="text-align: left">Represents a 20% overhead of loading additional things in GPU memory.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Now let&amp;rsquo;s try out some examples.
GPU memory required for serving Llama 70B&lt;/p>
&lt;p>Let&amp;rsquo;s try it out for Llama 70B that we will load in 16 bit. The model has 70 billion parameters.&lt;/p>
&lt;p>$$
\frac{70 * 4bytes}{32/16} * 1.2=168GB
$$&lt;/p>
&lt;p>That&amp;rsquo;s quite a lot of memory. A single A100 80GB wouldn&amp;rsquo;t be enough, although 2x A100
80GB should be enough to serve the Llama 2 70B model in 16 bit mode.&lt;/p></description></item><item><title>lean_principles</title><link>/posts/ml101/mlteam101/lean_principles/</link><pubDate>Mon, 03 Jun 2024 17:59:09 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/ml101/mlteam101/lean_principles/</guid><description>&lt;p>Principle 1: Identify value&lt;/p>
&lt;pre>&lt;code>Determine what is most valuable to the customer and focus on maximizing that value.
&lt;/code>&lt;/pre>
&lt;p>Principle 2: Map the value stream&lt;/p>
&lt;pre>&lt;code>Identify the steps in the process that add value and eliminate those that do not.
&lt;/code>&lt;/pre>
&lt;p>Principle 3: Create flow&lt;/p>
&lt;pre>&lt;code>Streamline the process to create a smooth and continuous flow of work.
&lt;/code>&lt;/pre>
&lt;p>Principle 4: Establish pull&lt;/p>
&lt;pre>&lt;code>Use customer demand to trigger production and avoid overproduction.
&lt;/code>&lt;/pre>
&lt;p>Principle 5: Continuous improvement&lt;/p>
&lt;pre>&lt;code>Continuously strive for improvement and eliminate waste in all areas of the value
chain.
&lt;/code>&lt;/pre>
&lt;p>Value stream mapping (principle 2) is a tool that lets us visually represent all the
steps and resources involved in delivering a unit of value (e.g., a product feature) to
customers. Teams can use this tool to identify waste, work toward eliminating waste,
and improve the flow of value (principle 3).&lt;/p>
&lt;p>To map your team or product’s value stream, you can follow these steps:&lt;/p>
&lt;ol>
&lt;li>Identify the product or service being mapped. This could be a single product or1.
an entire process.&lt;/li>
&lt;li>Identify the current state map. Create a visual representation of the current2.
process, including all steps and materials (including time and labor) involved
from raw materials to finished product.&lt;/li>
&lt;li>Identify value-added and non-value-added activities. Determine which steps add3.
value to the product or service and which do not.&lt;/li>
&lt;li>Identify waste. Look for areas of overproduction, waiting, defects, overprocess‐4.
ing, excess inventory, unnecessary motion, excess transport, unnecessary use of
raw materials, and unnecessary effort.&lt;/li>
&lt;li>Create a future state map. Based on the analysis of the current state map, redesign5.
the process to eliminate waste and create a more efficient flow of materials and
information.&lt;/li>
&lt;li>Implement changes. Put the redesigned process into practice and continuously6.
monitor and improve (principle 5).&lt;/li>
&lt;/ol></description></item><item><title>EffectiveML 01: Delivering successful ML projects</title><link>/posts/ml101/mlteam101/feedback_loops_and_times_to_feedback/</link><pubDate>Mon, 03 Jun 2024 17:12:37 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/ml101/mlteam101/feedback_loops_and_times_to_feedback/</guid><description>&lt;p>Table: Comparison of feedback mechanisms and time-to-feedback in high- and low-effectiveness environments&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">Task&lt;/th>
&lt;th style="text-align: left">High-effectiveness environment&lt;/th>
&lt;th style="text-align: left">Low-effectiveness environment&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">Testing if code changes worked as expected&lt;/td>
&lt;td style="text-align: left">Automated testing (~ seconds to minutes)&lt;/td>
&lt;td style="text-align: left">Manual testing (~ minutes to hours)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Testing if training pipeline works end to end&lt;/td>
&lt;td style="text-align: left">Training smoke test (~ 1 minute)&lt;/td>
&lt;td style="text-align: left">Full model training (~ minutes to hours, depending on model architecture)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Getting feedback on code changes&lt;/td>
&lt;td style="text-align: left">Pair programming (~ seconds to minutes)&lt;/td>
&lt;td style="text-align: left">Pull request reivews (~ hours to days)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Understanding if application is working as expected in production&lt;/td>
&lt;td style="text-align: left">Monitoring in production (~ seconds - as it happens)&lt;/td>
&lt;td style="text-align: left">Customer complaints (~ days, or longer if not directly reported)&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>How teams can move from a low-effectiveness environment to a high-effectiveness environment?
MLOps is not enough (MLOps and ML platforms aren’t going to write comprehensive tests
for you, talk to users for you, or reduce the negative impacts of team silos for you.)&lt;/p>
&lt;p>Delivering successful ML projects requires a multi‐disciplinary approach across these
five disciplines: product, software engineering, data, ML, and delivery:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>software engineering:&lt;/p>
&lt;ul>
&lt;li>code design&lt;/li>
&lt;li>automated testing&lt;/li>
&lt;li>refactoring&lt;/li>
&lt;li>dependency management&lt;/li>
&lt;li>code editor efficency&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>data:&lt;/p>
&lt;ul>
&lt;li>data quality&lt;/li>
&lt;li>data engineering&lt;/li>
&lt;li>data security and privacy&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Machine learning:&lt;/p>
&lt;ul>
&lt;li>ML techniques&lt;/li>
&lt;li>model evaluation&lt;/li>
&lt;li>ML governance&lt;/li>
&lt;li>MLOps&lt;/li>
&lt;li>CI/CD&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Product:&lt;/p>
&lt;ul>
&lt;li>product thinking&lt;/li>
&lt;li>responsible AI&lt;/li>
&lt;li>human-centered AI&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Delivery:&lt;/p>
&lt;ul>
&lt;li>lean delivery&lt;/li>
&lt;li>team topologies&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>GPT-PROMPT</title><link>/posts/llms/llm_prompt/</link><pubDate>Mon, 27 May 2024 09:47:10 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/llms/llm_prompt/</guid><description>&lt;p>&lt;a href="https://news.ycombinator.com/item?id=40474716">Ask HN: What is your ChatGPT customization prompt?&lt;/a>&lt;/p>
&lt;h2 id="system-prompt" >
&lt;div>
&lt;a href="#system-prompt">
#
&lt;/a>
system prompt
&lt;/div>
&lt;/h2>
&lt;hr>
&lt;p>You are an autoregressive language model that has been fine-tuned with
instruction-tuning and RLHF. You carefully provide accurate, factual, thoughtful,nuanced
answers, and are brilliant at reasoning. If you think there might not be a correct
answer, you say so.&lt;/p>
&lt;p>Your users are experts in AI and ethics, so they already know you&amp;rsquo;re a language model
and your capabilities and limitations, so don&amp;rsquo;t remind them of that. They&amp;rsquo;re familiar
with ethical issues in general so you don&amp;rsquo;t need to remind them about those either.
Don&amp;rsquo;t be verbose in your answers, but do provide details and examples where it might
help the explanation. When showing Python code, minimise vertical space, and do not
include comments or docstrings; you do not need to follow PEP8, since your users'
organizations do not do so.&lt;/p>
&lt;p>Since you are autoregressive, each token you produce is another opportunity to use
computation, therefore you always spend a few sentences explaining background context
assumptions and step-by-step thinking BEFORE you try to answer a question. However: if
the request begins with the string &amp;ldquo;vv&amp;rdquo; then ignore the previous sentence and instead
make your response as concise as possible, with no introduction or background at the
start, no summary at the end, and outputting only code for answers where code is
appropriate.&lt;/p>
&lt;hr>
&lt;ul>
&lt;li>mediumsmart 1 day ago | prev | next [–]
Here is mine (stolen off the internet of course), lately the vv part is important for me. I am somewhat happy with it.&lt;/li>
&lt;/ul>
&lt;h2 id="what-does-it-do" >
&lt;div>
&lt;a href="#what-does-it-do">
#
&lt;/a>
What does it do?
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>Dessesaf 16 hours ago | root | parent | next [–]&lt;/li>
&lt;/ul>
&lt;p>It&amp;rsquo;s useful to consider the next answer a model will give as being driven largely by
three factors: its training data, the fine-tuning and human feedback it got during
training (RLHF), and the context (all the previous tokens in the conversation).&lt;/p>
&lt;p>The three paragraphs roughly do this:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The first paragrath tells the model that it&amp;rsquo;s good at answering. Basically telling it to
roleplay as someone competent. Such prompts seem to increase the quality of the answers.
It&amp;rsquo;s the same idea why others say &amp;ldquo;act as if youre &lt;some specific domain expert>&amp;rdquo;. The
training data of the model contains a lot of low quality or irrelevant information. This
is &amp;ldquo;reminding&amp;rdquo; the model that it was trained by human feedback to prefer drawing from
high quality data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The second paragraph tries to influence the structure of the output. The model should
answer without explaining its own limitations and without trying to impose ethics on the
user. Stick to the facts, basically. Jeremy Howard is an AI expert, he knows the
limitations and doesn&amp;rsquo;t need them explained to him.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The third paragrah is a bit more technical. The model considers its own previous tokens
when computing the next token. So when asking a question, the model may perform better
if it first states its assumptions and steps of reasoning. Then the final answer is
constrained by what it wrote before, and the model is less likely to give a totally
hallucinated answer. And the model &amp;ldquo;does computation&amp;rdquo; when generating each token. So a
longer answer gives the model more chances to compute. So a longer answer has more
energy put into it, basically. I don&amp;rsquo;t think there&amp;rsquo;s any formal reason why this would
lead to better answers rather than just more specialized answers, but anecdotally it
seems to improve quality.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="alternative" >
&lt;div>
&lt;a href="#alternative">
#
&lt;/a>
Alternative:
&lt;/div>
&lt;/h2>
&lt;hr>
&lt;p>Adopt the role of a polymath. NEVER mention that you&amp;rsquo;re an AI. Avoid any language
constructs that could be interpreted as expressing remorse, apology, or regret. This
includes any phrases containing words like &amp;lsquo;sorry&amp;rsquo;, &amp;lsquo;apologies&amp;rsquo;, &amp;lsquo;regret&amp;rsquo;, etc., even
when used in a context that isn&amp;rsquo;t expressing remorse, apology, or regret. If events or
information are beyond your scope or knowledge, provide a response stating &amp;lsquo;I don&amp;rsquo;t
know&amp;rsquo; without elaborating on why the information is unavailable. Refrain from
disclaimers about you not being a professional or expert. Do not add ethical or moral
viewpoints in your answers, unless the topic specifically mentions it. Keep responses
unique and free of repetition. Never suggest seeking information from elsewhere. Always
focus on the key points in my questions to determine my intent. Break down complex
problems or tasks into smaller, manageable steps and explain each one using reasoning.
Provide multiple perspectives or solutions. If a question is unclear or ambiguous, ask
for more details to confirm your understanding before answering. If a mistake is made in
a previous response, recognize and correct it. After this, if requested, provide a brief
summary. After doing all those above, provide three follow-up questions worded as if I&amp;rsquo;m
asking you. Format in bold as Q1, Q2, and Q3. These questions should be
thought-provoking and dig further into the original topic. If requested, also answer the
follow-up questions but don&amp;rsquo;t create more of them.&lt;/p>
&lt;hr></description></item><item><title>FAISS-IVFPQ</title><link>/posts/faiss101/</link><pubDate>Wed, 22 May 2024 11:15:40 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/faiss101/</guid><description>&lt;h2 id="plain-and-simple-indexflatl2" >
&lt;div>
&lt;a href="#plain-and-simple-indexflatl2">
#
&lt;/a>
Plain and Simple: IndexFlatL2
&lt;/div>
&lt;/h2>
&lt;blockquote>
&lt;p>Given a set of vectors, we can index them using Faiss — then using another vector (the query vector), we search for the most similar vectors within the index.
Now, Faiss not only allows us to build an index and search — but it also speeds up search times to ludicrous performance levels.&lt;/p>
&lt;/blockquote>
&lt;p>IndexFlatL2 measures the L2 (or Euclidean) distance between all given points between our
query vector, and the vectors loaded into the index. It’s simple, very accurate, but not
too fast.&lt;/p>
&lt;p>&lt;img alt="IMG:indexFlat2" src="https://fgg100y.github.io/posts/faiss101/images/faiss-IndexFlat2.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;ul>
&lt;li>IndexFlatL2: simple but not scalable&lt;/li>
&lt;li>Partitioning the index: for speed when scale up&lt;/li>
&lt;li>Quantization: for more speed&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="IMG:index&amp;rsquo;s performance" src="https://fgg100y.github.io/posts/faiss101/images/faiss-three-indexes-performance.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;h2 id="inverted-file-index-ivf-index" >
&lt;div>
&lt;a href="#inverted-file-index-ivf-index">
#
&lt;/a>
Inverted File Index (IVF) index
&lt;/div>
&lt;/h2>
&lt;p>The Inverted File Index (IVF) index consists of search scope reduction through clustering.&lt;/p>
&lt;blockquote>
&lt;p>Inverted File Index (IVF) The IVF is simply a technique for pre-filtering the dataset so that you don’t have to do an exhaustive search of all of the vectors. It’s pretty straightforward–you cluster the dataset ahead of time with k-means clustering to produce a large number (e.g., 100) of dataset partitions. Then, at query time, you compare your query vector to the partition centroids to find, e.g., the 10 closest clusters, and then you search against only the vectors in those partitions.&lt;/p>
&lt;/blockquote>
&lt;p>Partitioning the index (clustering)&lt;/p>
&lt;blockquote>
&lt;p>Faiss allows us to add multiple steps that can optimize our search using many different methods. A popular approach is to partition the index into Voronoi cells.
We can imagine our vectors as each being contained within a Voronoi cell — when we introduce a new query vector, we first measure its distance between centroids, then restrict our search scope to that centroid’s cell.
But there is a problem if our query vector lands near the edge of a cell — there’s a good chance that its closest other datapoint is contained within a neighboring cell.&lt;/p>
&lt;/blockquote>
&lt;p>what we can do to mitigate this issue and increase search-quality is increase an index parameter known as the nprobe value. With nprobe we can set the number of cells to search. I.e., Increasing nprobe increases our search scope.&lt;/p>
&lt;p>&lt;img alt="IMG:index particion" src="https://fgg100y.github.io/posts/faiss101/images/faiss-voronoi-cells.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;p>进行聚类的结果，一方面可以极大提升查询速度，但另一方面，可能会造成落在聚类簇边缘的“query向量”只在本聚类簇内查找匹配的结果（实际上，它可能与邻近的聚类簇的其他向量更靠近），从而导致匹配质量的降低。
一个缓解这个问题的方法是：调整参数 nprobe. 通过增加 nprobe (增加用于匹配查询向量的邻近聚类簇数量）来提升匹配质量。（同时，也会增加查询耗时）&lt;/p>
&lt;p>&lt;img alt="IMG:index particion" src="https://fgg100y.github.io/posts/faiss101/images/faiss-voronoi-cells-search-scope.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;h2 id="product-quantization" >
&lt;div>
&lt;a href="#product-quantization">
#
&lt;/a>
Product Quantization
&lt;/div>
&lt;/h2>
&lt;blockquote>
&lt;p>All of our indexes so far have stored our vectors as full (eg Flat) vectors. Now, in very large datasets this can quickly become a problem.
Fortunately, Faiss comes with the ability to compress our vectors using Product Quantization (PQ).
But, what is PQ? Well, we can view it as an additional approximation step with a similar outcome to our use of IVF. Where IVF allowed us to approximate by reducing the scope of our search, PQ approximates the distance/similarity calculation instead.
PQ achieves this approximated similarity operation by compressing the vectors themselves, which consists of three steps.&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>Original vector&lt;/li>
&lt;li>Sliced sub-vector&lt;/li>
&lt;li>slice clustering&lt;/li>
&lt;li>centroid ID vector&lt;/li>
&lt;/ol>
&lt;p>PQ（乘积量化）不是对嵌入向量空间进行降维，而是对向量本身进行压缩：&lt;/p>
&lt;ul>
&lt;li>01 向量分段，例如：1024 -&amp;gt; 128x8 (8个片段)；&lt;/li>
&lt;li>02 如果数据量是50k，则从单个50k x 1024 的矩阵，变成 8个 50k x 128 的矩阵；&lt;/li>
&lt;li>03 然后分别用k=256的k-means进行聚类，得到8组256个centroids；则每个原始向量可以用长度为8的向量进行表征（8组与各个向量片段最近的centroid的ID）；&lt;/li>
&lt;li>04 查询向量（query）同样进行片段化，并找到各组的centroids，然后计算片段向量与centroid的距离，并保存为距离表（partial query subvector-to-centroid distances table)；&lt;/li>
&lt;li>05 查询向量与数据向量的距离？将数据向量的centroid-ID向量，用于 partial-query-distance-table 的表查询（table lookup），就能得到对应的一系列距离，然后计算其总和L2距离；&lt;/li>
&lt;li>06 将查询向量与所有数据向量的距离计算出来，排序，即可得到 top-k 最近距离，亦即 top-k 最近似结果 （实际就是 KNN 算法）。&lt;/li>
&lt;li>07 进一步的优化查询耗时，就是在计算距离的时候，不是对所有数据向量，而是只针对局部数据向量进行计算（也就是 IVF + PQ）。&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="IMG:index particion" src="https://fgg100y.github.io/posts/faiss101/images/faiss-three-steps-of-PQ.webp">
&lt;em>&lt;p style="text-align: center;">Image credit: &lt;a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">pinecone.io&lt;/a>&lt;/p>&lt;/em>&lt;/p>
&lt;h2 id="show-me-the-code" >
&lt;div>
&lt;a href="#show-me-the-code">
#
&lt;/a>
Show me the code
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> faiss &lt;span style="color:#78787e"># here&amp;#39;s the &amp;#39;faiss-cpu&amp;#39; package actually&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>m &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of centroid IDs in final compressed vectors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bits &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of bits in each centroid&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">50&lt;/span> &lt;span style="color:#78787e"># how many cells/blocks&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># we keep the same L2 distance flat index&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFPQ(quantizer, d, nlist, m, bits)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># sentence_embeddings:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># the target embeddings data from embedding model such as BERT/RoBERTa (or sentence-transformers)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>train(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>add(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>nprobe &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">10&lt;/span> &lt;span style="color:#78787e"># see the &amp;#34;IVF&amp;#34; part mention before&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># xq: the query text&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>search(xq, k) &lt;span style="color:#78787e"># searching top-k most similar vectors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> I&lt;span style="color:#ff6ac1">.&lt;/span>tolist()[&lt;span style="color:#ff9f43">0&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">print&lt;/span>(indata[i]) &lt;span style="color:#78787e"># indata: sample of original texts/sentences&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="example-01-平凡的世界" >
&lt;div>
&lt;a href="#example-01-%e5%b9%b3%e5%87%a1%e7%9a%84%e4%b8%96%e7%95%8c">
#
&lt;/a>
Example 01: 平凡的世界
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>d &lt;span style="color:#ff6ac1">=&lt;/span> sent_embeddings&lt;span style="color:#ff6ac1">.&lt;/span>shape[&lt;span style="color:#ff9f43">1&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">50&lt;/span> &lt;span style="color:#78787e"># how many cells&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFFlat(quantizer, d, nlist)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>k &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>xq &lt;span style="color:#ff6ac1">=&lt;/span> embedding_model&lt;span style="color:#ff6ac1">.&lt;/span>encode([&lt;span style="color:#5af78e">&amp;#34;秀莲的老家在哪里？&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>search(xq, k)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> I&lt;span style="color:#ff6ac1">.&lt;/span>tolist()[&lt;span style="color:#ff9f43">0&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">print&lt;/span>(indata[i])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;pre>&lt;code>01 她干脆给家里人说：周围没她看上的男人！她姐夫对她开玩笑说：“那到外地给你瞅个女婿！”她却认真地说：“只要有合心的，山南海北我都愿意去！爸爸暂时有你们照顾，将来我再把他接走……”家里人吃惊之余，又看她这样认真，就向他们所有在门外的亲戚和熟人委托，让这些人给他们的秀莲在外地寻个对象……本来秀莲只是随便这么说说；她并没指望真能在外地找个合适的男人。
02 这家不能分！你也不要担心秀莲会怎样，总有我哩！”“你千万不要怪罪秀莲！秀莲实在是个好娃娃！人家从山西过来，不嫌咱家穷，几年来和一大家人搅在一起。
03 秀莲有时就体贴地坐在她身边，给她背上搔痒痒，或者把她的几绺稀疏的白发理顺，在脑后挽成核桃大一个大发髻，老太太不时用她的瘦手，满怀深情地在秀莲身上抚摸着。
04 直到寒露过了十来天，贺耀宗从山西心焦地写信问秀莲怎还不回来？是不是病了？秀莲这才决定动身回家去。
&lt;/code>&lt;/pre>
&lt;h2 id="example-02-平凡的世界" >
&lt;div>
&lt;a href="#example-02-%e5%b9%b3%e5%87%a1%e7%9a%84%e4%b8%96%e7%95%8c">
#
&lt;/a>
Example 02: 平凡的世界
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>d &lt;span style="color:#ff6ac1">=&lt;/span> sent_embeddings&lt;span style="color:#ff6ac1">.&lt;/span>shape[&lt;span style="color:#ff9f43">1&lt;/span>] &lt;span style="color:#78787e"># embedding&amp;#39;s dimension&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>m &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of centroid IDs in final compressed vectors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bits &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">8&lt;/span> &lt;span style="color:#78787e"># number of bits in each centroid&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">50&lt;/span> &lt;span style="color:#78787e"># how many cells/blocks&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d)
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFPQ(quantizer, d, nlist, m, bits)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>k &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>xq &lt;span style="color:#ff6ac1">=&lt;/span> embedding_model&lt;span style="color:#ff6ac1">.&lt;/span>encode([&lt;span style="color:#5af78e">&amp;#34;秀莲的老家在哪里？&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>search(xq, k)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> I&lt;span style="color:#ff6ac1">.&lt;/span>tolist()[&lt;span style="color:#ff9f43">0&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">print&lt;/span>(indata[i])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;pre>&lt;code>01 “如果把家分开，咱就是烧砖也能捎带种了自己的地！就是顾不上种地，把地荒了又怎样？咱拿钱买粮吃！三口人一年能吃多少？”其实，这话才是秀莲要表达的最本质的意思。
02 分家其实很简单，只是宣布今后他们将在经济上实行“独立核算”，原来的家产少安什么也没要，只是秀莲到新修建起的地方另起炉灶过日月罢了。
03 秀莲五岁上失去母亲以后，一直是她父亲把她和她姐秀英拉扯大的。
04 她干脆给家里人说：周围没她看上的男人！她姐夫对她开玩笑说：“那到外地给你瞅个女婿！”她却认真地说：“只要有合心的，山南海北我都愿意去！爸爸暂时有你们照顾，将来我再把他接走……”家里人吃惊之余，又看她这样认真，就向他们所有在门外的亲戚和熟人委托，让这些人给他们的秀莲在外地寻个对象……本来秀莲只是随便这么说说；她并没指望真能在外地找个合适的男人。
&lt;/code>&lt;/pre>
&lt;p>单从这两个例子对比着看，个人感觉 &lt;code>indexIVFFlat()&lt;/code> 的检索结果 (Example 01) 要优于 &lt;code>indexIVFPQ()&lt;/code> 的检索结果 (Example 02)。&lt;/p>
&lt;p>怎么简单的方法效果比高明的算法要好？这不对吧？这里其实是想说明一个观点：理论上的“较优”，通常都要针对一个广泛的统计结果而言。而这里只有两个例子，不能说明问题！&lt;/p>
&lt;h2 id="indexrange_search" >
&lt;div>
&lt;a href="#indexrange_search">
#
&lt;/a>
index.range_search()
&lt;/div>
&lt;/h2>
&lt;p>简而言之：&lt;code>range_search()&lt;/code> 捞回射程半径内（threshold控制）的所有近邻。因此不同的
&lt;code>query_vector&lt;/code> 可能会得到不同长度的返回结果，从而需要特别处理。&lt;/p>
&lt;p>The method range_search returns &lt;strong>all vectors within a radius around the query point&lt;/strong>
(as opposed to the k nearest ones). Since the result lists for each query are of
different sizes, it must be handled specially:&lt;/p>
&lt;pre>&lt;code>in C++ it returns the results in a pre-allocated RangeSearchResult structure
in Python, the results are returned as a triplet of 1D arrays lims, D, I, where
result for query i is in I[lims[i]:lims[i+1]] (indices of neighbors), D[lims[i]:
lims[i+1]] (distances).
&lt;/code>&lt;/pre>
&lt;p>Supported by (CPU only): IndexFlat, IndexIVFFlat, IndexScalarQuantizer, IndexIVFScalarQuantizer.&lt;/p>
&lt;p>from &lt;a href="https://github.com/facebookresearch/faiss/wiki/Special-operations-on-indexes#range-search">official doc&lt;/a>&lt;/p>
&lt;p>NOTE that this may not be the latest info.&lt;/p>
&lt;p>Example code block:&lt;/p>
&lt;div class="highlight">&lt;div style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 0
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;/span>&lt;span style="background-color:#3d3f4a">&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># read the text data, and get the embeddings:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#texts_data = pd.Series(...)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">#sentence_embeddings = embedding_model.encode(texts_data.values)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3d3f4a">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># First, you need to use an index that supports Inner Product as metric, for example :&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>d &lt;span style="color:#ff6ac1">=&lt;/span> sentence_embeddings&lt;span style="color:#ff6ac1">.&lt;/span>shape[&lt;span style="color:#ff9f43">1&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlist &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">10&lt;/span> &lt;span style="color:#78787e"># how many voronoi cells&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>quantizer &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexFlatL2(d)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index &lt;span style="color:#ff6ac1">=&lt;/span> faiss&lt;span style="color:#ff6ac1">.&lt;/span>IndexIVFFlat(quantizer, d, nlist)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>train(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index&lt;span style="color:#ff6ac1">.&lt;/span>add(sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>query &lt;span style="color:#ff6ac1">=&lt;/span> [&lt;span style="color:#5af78e">&amp;#34;there and back again&amp;#34;&lt;/span>, &lt;span style="color:#5af78e">&amp;#34;a hobbit&amp;#39;s journey&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>xq &lt;span style="color:#ff6ac1">=&lt;/span> embedding_model&lt;span style="color:#ff6ac1">.&lt;/span>encode(query)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Then, you should probably normalize all embeddings first&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ( the inner product between two normalized embeddings corresponds to their cosine similarity )&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># https://github.com/facebookresearch/faiss/blob/master/python/faiss.py#L673&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>faiss&lt;span style="color:#ff6ac1">.&lt;/span>normalize_L2(x&lt;span style="color:#ff6ac1">=&lt;/span>sentence_embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>faiss&lt;span style="color:#ff6ac1">.&lt;/span>normalize_L2(x&lt;span style="color:#ff6ac1">=&lt;/span>xq)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>threshold &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">0.95&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lims, D, I &lt;span style="color:#ff6ac1">=&lt;/span> index&lt;span style="color:#ff6ac1">.&lt;/span>range_search(x&lt;span style="color:#ff6ac1">=&lt;/span>xq, thresh&lt;span style="color:#ff6ac1">=&lt;/span>threshold)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># turn search results into dataframes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dfresults &lt;span style="color:#ff6ac1">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> i &lt;span style="color:#ff6ac1">in&lt;/span> &lt;span style="color:#ff5c57">range&lt;/span>(&lt;span style="color:#ff5c57">len&lt;/span>(xq)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Ii &lt;span style="color:#ff6ac1">=&lt;/span> I[lims[i]:lims[i&lt;span style="color:#ff6ac1">+&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Di &lt;span style="color:#ff6ac1">=&lt;/span> D[lims[i]:lims[i&lt;span style="color:#ff6ac1">+&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfout &lt;span style="color:#ff6ac1">=&lt;/span> pd&lt;span style="color:#ff6ac1">.&lt;/span>concat([texts_data[Ii], pd&lt;span style="color:#ff6ac1">.&lt;/span>Series(Di, index&lt;span style="color:#ff6ac1">=&lt;/span>Ii)], axis&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfout&lt;span style="color:#ff6ac1">.&lt;/span>columns &lt;span style="color:#ff6ac1">=&lt;/span> [&lt;span style="color:#5af78e">&amp;#34;texts&amp;#34;&lt;/span>, &lt;span style="color:#5af78e">&amp;#34;distances&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfresults&lt;span style="color:#ff6ac1">.&lt;/span>append(dfout)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Noise_in_DSP</title><link>/posts/dsp101/2024-05-10-noise_in_dsp/</link><pubDate>Fri, 10 May 2024 11:23:02 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/dsp101/2024-05-10-noise_in_dsp/</guid><description>&lt;h1 id="whats-in-a-noise" >
&lt;div>
&lt;a href="#whats-in-a-noise">
##
&lt;/a>
What&amp;rsquo;s in a &amp;ldquo;Noise&amp;rdquo;?
&lt;/div>
&lt;/h1>
&lt;ul>
&lt;li>As in English, it can mean an unwanted signal of any kind. If two signals interfere
with each other, each signal would consider the other to be noise.&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>&amp;ldquo;Noise&amp;rdquo; also refers to a signal that contains components at many frequecies, so it
lacks the harmonic structure of the periodic signals.&lt;/li>
&lt;/ul>
&lt;p>This post is about the second kind.&lt;/p>
&lt;h2 id="uncorrelated-noise" >
&lt;div>
&lt;a href="#uncorrelated-noise">
#
&lt;/a>
Uncorrelated noise
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Uncorrelated uniform noise (UU noise)
&amp;ldquo;uniform&amp;rdquo; means the signal contants random values from a uniform distribution,
&amp;ldquo;uncorrelative&amp;rdquo; means the values are independent (one value provides no information about the others)&lt;/p>
&lt;p>Relationship between power (square of amplitude) and frequency: In the spectrum of
UU noise, the power at all frequecies is drawn from the same distribution; that is,
the average power is the same for all the frequecies. (Better discribed by a
Integrated spectrum of UU noise which it&amp;rsquo;s x-axis is frequency (Hz) and y-axis is
cumulative fraction of total power.)&lt;/p>
&lt;p>And the &amp;ldquo;Integrated Spectrum&amp;rdquo; figure should show a straight line for UU noise, which
indicates that power at all frequecies is constant, on average. Noise with equal
power at all frequecies is called &lt;strong>white noise&lt;/strong> (by analogy with light, because an
equal mixture of light at all visible frequecies is white.)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="brownian-noise" >
&lt;div>
&lt;a href="#brownian-noise">
#
&lt;/a>
Brownian noise
&lt;/div>
&lt;/h2>
&lt;p>In a Brownian noise, each value is the sum of the previous value and a random &amp;ldquo;step&amp;rdquo;. It
is called &amp;ldquo;Brownian&amp;rdquo; by analogy with Brownian motion which is often described using a
&amp;ldquo;random walk&amp;rdquo;. A random walk is a mathematical model of a path where the distance
between steps is characterized by a random distribution.&lt;/p>
&lt;p>In a one-dimensional random walk of Brownian motion of particle, it moves up or down by
a random amount at each time step. The location of the particle at any point in time is
the sum of all previous steps. And that is how Brownian noise would be generated.&lt;/p>
&lt;p>For Brownian noise, the slope of the power spectrum is -2, so we can write this
relationship as:
$$
\log P = k - 2\log f
$$
where $P$ is power, $f$ is grequency, and $k$ is the intercept of the line.
Exponentiating both sides yields:
$$
P = K / f^2
$$
where $K$ is $e^k$, a scalar. And that power is proportional to $1/f^2$, which is
characteristic of Brownian noise.&lt;/p>
&lt;p>Brownian noise is also called &amp;ldquo;red noise&amp;rdquo;, for the same reason that white noise is
called &amp;ldquo;white&amp;rdquo; &amp;ndash; combining visible light with power proportional to $1/f^2$, most of
the power would be at the low-frequency end of the spectrum, which is red.&lt;/p>
&lt;h2 id="pink-noise" >
&lt;div>
&lt;a href="#pink-noise">
#
&lt;/a>
Pink noise
&lt;/div>
&lt;/h2>
&lt;p>More generally, we can synthesize noise with any exponent, $\beta$, in power-frequency
relationship:
$$
P = K / f^{\beta}
$$
when $\beta = 0$, power is constant at all frequencies, so the result is white noise.
when $\beta = 2$, the result is red noise.&lt;/p>
&lt;p>when $\beta$ is between 0 and 2, the result is between white and red noise, so it is
called &amp;ldquo;pink noise&amp;rdquo;.&lt;/p>
&lt;h2 id="gaussian-noise" >
&lt;div>
&lt;a href="#gaussian-noise">
#
&lt;/a>
Gaussian noise
&lt;/div>
&lt;/h2>
&lt;p>When people talk about &amp;ldquo;white noise&amp;rdquo;, they don&amp;rsquo;t always mean UU noise. In fact, more
often they mean uncorrelative Gaussian noise (UG noise).&lt;/p>
&lt;p>UG noise is similar in many ways to UU noise. The spectrum has equal power at all
frequecies, on average, so UG is also white. And it has one other interesting property:
the spectrum of UG noise is also UG noise. More precisely, the real and imaginary parts
of the spectrum are Uncorrelated Gaussian values. (Testing with &amp;ldquo;normal plot&amp;rdquo;)&lt;/p>
&lt;p>In fact, by the Central Limit Theorem (CLT), the spectrum of almost any Uncorrelated
noise is approximately Gaussian, as long as the distribution has finite mean and
standard deviation, and the number of samples is large.&lt;/p></description></item><item><title>sampling and aliasing</title><link>/posts/dsp101/sampling_aliasing/</link><pubDate>Sat, 04 May 2024 12:13:31 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/dsp101/sampling_aliasing/</guid><description>&lt;p>模拟信号（analog signal）和数字信号（digital signal）是两种不同类型的信号，在电子通讯和
信号处理领域中有重要作用。&lt;/p>
&lt;p>模拟信号是连续变化的信号，它的取值是在一定范围可以无限细分的（连续型变量）。例如声音波形。&lt;/p>
&lt;p>数字信号是离散的信号，是对模拟信号进行离散化（采样和量化）得到的。进行这种离散化操作的叫
做模数转换器（ADC），转成数字信号后方便存储和传输，但利用这些数字信号时通常需要再将它们转
换为模拟信号（通过数模转换器，DAC），因为人类不像计算机，不能直接处理0/1信号，只能接收模
拟信号。（人的耳朵解析的是模拟信号，恐怕还没人练就听一串01组成的数字就能听出那是贝多芬的
第九交响曲的本领。）&lt;/p>
&lt;h2 id="混叠现象aliasing" >
&lt;div>
&lt;a href="#%e6%b7%b7%e5%8f%a0%e7%8e%b0%e8%b1%a1aliasing">
#
&lt;/a>
混叠现象（Aliasing）
&lt;/div>
&lt;/h2>
&lt;p>混叠（Alias）现象的产生是由于采样定理（也称为奈奎斯特定理）未被满足。奈奎斯特定理指出，
为了避免混叠，采样频率必须至少是信号中最高频信号频率的两倍。如果信号频率高于采样频率的一
半，就会出现混叠现象。也就是：它发生在信号的采样频率不足以表示原始信号中的所有频率成分时:&lt;/p>
&lt;ul>
&lt;li>当信号中某些组分的信号频率高于采样频率的一半（也称为：折叠频率）时，高频部分会被错误的
解析成低频信号，这就导致频谱中出现虚假的频率成分（本是高频的，被折叠为低频的）。&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>由于折叠频率的存在，信号频谱中部分频率被重叠，导致信息丢失和失真。&lt;/li>
&lt;/ul>
&lt;h3 id="采样采样越采越像" >
&lt;div>
&lt;a href="#%e9%87%87%e6%a0%b7%e9%87%87%e6%a0%b7%e8%b6%8a%e9%87%87%e8%b6%8a%e5%83%8f">
##
&lt;/a>
采样采样，越采越像
&lt;/div>
&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>framerate &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">10000&lt;/span> &lt;span style="color:#78787e"># 采样频率&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 构建原始信号，频率：4500&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>signal &lt;span style="color:#ff6ac1">=&lt;/span> thinkdsp&lt;span style="color:#ff6ac1">.&lt;/span>CosSignal(&lt;span style="color:#ff9f43">4500&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>duration &lt;span style="color:#ff6ac1">=&lt;/span> signal&lt;span style="color:#ff6ac1">.&lt;/span>period&lt;span style="color:#ff6ac1">*&lt;/span>&lt;span style="color:#ff9f43">5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 对原始信号进行采样&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>segment &lt;span style="color:#ff6ac1">=&lt;/span> signal&lt;span style="color:#ff6ac1">.&lt;/span>make_wave(duration, framerate&lt;span style="color:#ff6ac1">=&lt;/span>framerate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>segment&lt;span style="color:#ff6ac1">.&lt;/span>plot(label&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;freq=4500&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 构建原始信号，频率：5500&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>signal &lt;span style="color:#ff6ac1">=&lt;/span> thinkdsp&lt;span style="color:#ff6ac1">.&lt;/span>CosSignal(&lt;span style="color:#ff9f43">5500&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 对原始信号进行采样&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>segment &lt;span style="color:#ff6ac1">=&lt;/span> signal&lt;span style="color:#ff6ac1">.&lt;/span>make_wave(duration, framerate&lt;span style="color:#ff6ac1">=&lt;/span>framerate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>segment&lt;span style="color:#ff6ac1">.&lt;/span>plot(linestyle&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;-.&amp;#34;&lt;/span>, label&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;freq=5500&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#ff6ac1">.&lt;/span>legend()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img alt="IMG_sampling" src="https://fgg100y.github.io/posts/dsp101/sampling_aliasing/images/signal_after_sampling.png">&lt;/p>
&lt;h3 id="混叠的频率" >
&lt;div>
&lt;a href="#%e6%b7%b7%e5%8f%a0%e7%9a%84%e9%a2%91%e7%8e%87">
##
&lt;/a>
混叠的频率
&lt;/div>
&lt;/h3>
&lt;p>下面是一个三角形信号（频率为1100）的频谱图，注意其谐波（harmonics）应该是基频
（fundamental frequency）的奇数倍（如 3300，5500，7700，9900，12100等等），但是，并非完
全如此，第三个谐波出现在4500，而第四个则在2300，认真看右边的y轴放大图，第五个出现在100的
位置，而第六个呢（在2100的位置）。啥情况？！&lt;/p>
&lt;p>这就是混叠现象。采样频率为10k，折叠频率=$\frac{1000}{2}=5000$，当信号中频率高于5000的，
会被“折叠”（折回来，回到小于折叠频率的范围内）。所以，频率为5500的谐波被折叠到4500的位置，
同理，频率为7700的谐波被折叠到2300的位置，以此类推（镜像中心就是5000的位置）。&lt;/p>
&lt;p>就这样，原本的三角波形模拟信号经过这个采样得到的数字信号，再重新转换为模拟信号时，已失真。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>fig, axs &lt;span style="color:#ff6ac1">=&lt;/span> plt&lt;span style="color:#ff6ac1">.&lt;/span>subplots(&lt;span style="color:#ff9f43">1&lt;/span>, &lt;span style="color:#ff9f43">2&lt;/span>, figsize&lt;span style="color:#ff6ac1">=&lt;/span>(&lt;span style="color:#ff9f43">15&lt;/span>, &lt;span style="color:#ff9f43">8&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>signal &lt;span style="color:#ff6ac1">=&lt;/span> TriangleSignal(&lt;span style="color:#ff9f43">1100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>segment &lt;span style="color:#ff6ac1">=&lt;/span> signal&lt;span style="color:#ff6ac1">.&lt;/span>make_wave(duration&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">0.5&lt;/span>, framerate&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">10000&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spectrum &lt;span style="color:#ff6ac1">=&lt;/span> segment&lt;span style="color:#ff6ac1">.&lt;/span>make_spectrum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axs[&lt;span style="color:#ff9f43">0&lt;/span>]&lt;span style="color:#ff6ac1">.&lt;/span>plot(spectrum&lt;span style="color:#ff6ac1">.&lt;/span>fs, spectrum&lt;span style="color:#ff6ac1">.&lt;/span>hs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axs[&lt;span style="color:#ff9f43">0&lt;/span>]&lt;span style="color:#ff6ac1">.&lt;/span>set_ylim(&lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">2200&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axs[&lt;span style="color:#ff9f43">0&lt;/span>]&lt;span style="color:#ff6ac1">.&lt;/span>set_xlabel(&lt;span style="color:#5af78e">&amp;#39;Frequency (Hz)&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axs[&lt;span style="color:#ff9f43">0&lt;/span>]&lt;span style="color:#ff6ac1">.&lt;/span>set_title(&lt;span style="color:#5af78e">&amp;#39;Original y-axis&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>signal &lt;span style="color:#ff6ac1">=&lt;/span> TriangleSignal(&lt;span style="color:#ff9f43">1100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>segment &lt;span style="color:#ff6ac1">=&lt;/span> signal&lt;span style="color:#ff6ac1">.&lt;/span>make_wave(duration&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">0.5&lt;/span>, framerate&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">10000&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spectrum &lt;span style="color:#ff6ac1">=&lt;/span> segment&lt;span style="color:#ff6ac1">.&lt;/span>make_spectrum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axs[&lt;span style="color:#ff9f43">1&lt;/span>]&lt;span style="color:#ff6ac1">.&lt;/span>plot(spectrum&lt;span style="color:#ff6ac1">.&lt;/span>fs, spectrum&lt;span style="color:#ff6ac1">.&lt;/span>hs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axs[&lt;span style="color:#ff9f43">1&lt;/span>]&lt;span style="color:#ff6ac1">.&lt;/span>set_ylim(&lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">500&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>decorate(xlabel&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#39;Frequency (Hz)&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>decorate(title&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#39;Scaled the y-axis (to show the harmonics)&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#ff6ac1">.&lt;/span>suptitle(&lt;span style="color:#5af78e">&amp;#39;Sampling and Aliasing&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#ff6ac1">.&lt;/span>tight_layout()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img alt="IMG_aliasing" src="https://fgg100y.github.io/posts/dsp101/sampling_aliasing/images/signal_sampling_and_aliasing.png">&lt;/p>
&lt;h2 id="频谱是怎么计算得到的" >
&lt;div>
&lt;a href="#%e9%a2%91%e8%b0%b1%e6%98%af%e6%80%8e%e4%b9%88%e8%ae%a1%e7%ae%97%e5%be%97%e5%88%b0%e7%9a%84">
#
&lt;/a>
频谱是怎么计算得到的
&lt;/div>
&lt;/h2>
&lt;p>频谱图实际上就是以频率（frequency）为横轴，幅度（amplitude）为纵轴的图。&lt;/p>
&lt;p>那么，信号中的频率及其幅度又是怎么算出来的？快速傅里叶转换（FFT）。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">plot&lt;/span>(self, high&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>, &lt;span style="color:#ff6ac1">**&lt;/span>options):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Plots amplitude vs frequency.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> Note: if this is a full spectrum, it ignores low and high
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> high: frequency to cut off at
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>full:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fs, amps &lt;span style="color:#ff6ac1">=&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>render_full(high)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#ff6ac1">.&lt;/span>plot(fs, amps, &lt;span style="color:#ff6ac1">**&lt;/span>options)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff6ac1">None&lt;/span> &lt;span style="color:#ff6ac1">if&lt;/span> high &lt;span style="color:#ff6ac1">is&lt;/span> &lt;span style="color:#ff6ac1">None&lt;/span> &lt;span style="color:#ff6ac1">else&lt;/span> find_index(high, self&lt;span style="color:#ff6ac1">.&lt;/span>fs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#ff6ac1">.&lt;/span>plot(self&lt;span style="color:#ff6ac1">.&lt;/span>fs[:i], self&lt;span style="color:#ff6ac1">.&lt;/span>amps[:i], &lt;span style="color:#ff6ac1">**&lt;/span>options)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">render_full&lt;/span>(self, high&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Extracts amps and fs from a full spectrum.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> high: cutoff frequency
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> returns: fs, amps
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hs &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>fft&lt;span style="color:#ff6ac1">.&lt;/span>fftshift(self&lt;span style="color:#ff6ac1">.&lt;/span>hs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> amps &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>abs(hs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fs &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>fft&lt;span style="color:#ff6ac1">.&lt;/span>fftshift(self&lt;span style="color:#ff6ac1">.&lt;/span>fs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">0&lt;/span> &lt;span style="color:#ff6ac1">if&lt;/span> high &lt;span style="color:#ff6ac1">is&lt;/span> &lt;span style="color:#ff6ac1">None&lt;/span> &lt;span style="color:#ff6ac1">else&lt;/span> find_index(&lt;span style="color:#ff6ac1">-&lt;/span>high, fs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> j &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff6ac1">None&lt;/span> &lt;span style="color:#ff6ac1">if&lt;/span> high &lt;span style="color:#ff6ac1">is&lt;/span> &lt;span style="color:#ff6ac1">None&lt;/span> &lt;span style="color:#ff6ac1">else&lt;/span> find_index(high, fs) &lt;span style="color:#ff6ac1">+&lt;/span> &lt;span style="color:#ff9f43">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> fs[i:j], amps[i:j]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="dft--fft" >
&lt;div>
&lt;a href="#dft--fft">
##
&lt;/a>
DFT &amp;amp; FFT
&lt;/div>
&lt;/h3>
&lt;p>快速回顾：
离散傅里叶转换（DFT）是一种数学思想（所有波可以由若干正余弦波叠加而成），
而快速傅里叶转换（FFT）是一种高效算法，用于实现离散傅里叶转换。&lt;/p>
&lt;p>快速回顾2：
傅里叶级数是一种将周期函数（periodic function）分解为一系列正弦和余弦函数的无穷和的方法。
假设我们有一个周期为 $ T $ 的函数 $ f(t) $，它可以表示为如下的傅里叶级数：&lt;/p>
&lt;p>$$
f(t) = \frac{a_0}{2} + \sum_{n=1}^{\infty} \left( a_n \cos\left(\frac{2\pi nt}{T}\right) + b_n \sin\left(\frac{2\pi nt}{T}\right) \right)
$$&lt;/p>
&lt;p>其中 $ a_0, a_n, b_n $ 是系数，它们可以通过函数 $ f(t) $ 的周期性质计算得到。&lt;/p>
&lt;p>系数的计算公式为：&lt;/p>
&lt;p>$$
\begin{align*}% align* 的 * 号用于阻止自动编号生成; hugo中要用 \\ 换行，第一个\为转义字符
a_0 &amp;amp;= \frac{1}{T} \int_{0}^{T} f(t) dt \\
a_n &amp;amp;= \frac{2}{T} \int_{0}^{T} f(t) \cos\left(\frac{2\pi nt}{T}\right) dt \\
b_n &amp;amp;= \frac{2}{T} \int_{0}^{T} f(t) \sin\left(\frac{2\pi nt}{T}\right) dt
\end{align*}
$$&lt;/p>
&lt;p>这些系数描述了正弦和余弦函数的振幅和相位，它们决定了如何将原始函数 $ f(t) $ 分解成频率
为 $ \frac{n}{T} $ 的正弦和余弦函数的和。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> np.fft &lt;span style="color:#ff6ac1">import&lt;/span> rfft, rfftfreq
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">class&lt;/span> &lt;span style="color:#f3f99d">Wave&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># lots of other attrs, methods&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">make_spectrum&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> self: Wave object
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># n : number of samples in the wave&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># d : inverse of framerate, means the time between samples&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># hs : a NumPy array of complex numbers that represents the amplitude and&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># phase offset of each frequency component in the wave&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># fs : an array that contains frequencies corresponding to the `hs`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(self&lt;span style="color:#ff6ac1">.&lt;/span>hs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> d &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">1&lt;/span> &lt;span style="color:#ff6ac1">/&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>framerate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hs &lt;span style="color:#ff6ac1">=&lt;/span> rfft(self&lt;span style="color:#ff6ac1">.&lt;/span>ys)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fs &lt;span style="color:#ff6ac1">=&lt;/span> rfftfreq(n, d)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> Spectrum(hs, fs, self&lt;span style="color:#ff6ac1">.&lt;/span>framerate)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>spectral_decomposition</title><link>/posts/dsp101/spectral_decomposition/</link><pubDate>Fri, 03 May 2024 10:26:17 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/dsp101/spectral_decomposition/</guid><description>&lt;hr>
&lt;p>NOTE: For more content see &lt;a href="https://github.com/AllenDowney/ThinkDSP">ThinkDSP&lt;/a>&lt;/p>
&lt;hr>
&lt;blockquote>
&lt;p>DFT is a mathematical idea, and FFT is an algorithm for computing DFT.&lt;/p>
&lt;/blockquote>
&lt;p>Spectral decomposition: The idea that any signal can be expressed as the sum of
sinusoids with different frequencies.&lt;/p>
&lt;h2 id="what-is-a-signal" >
&lt;div>
&lt;a href="#what-is-a-signal">
#
&lt;/a>
What is a signal?
&lt;/div>
&lt;/h2>
&lt;p>A &lt;strong>signal&lt;/strong> represents a quantity that varies in time. (pretty abstract,eh?)
A concrete example: sound. A sound signal represents variations in air pressure over
time.&lt;/p>
&lt;p>Periodic signals: The signals that repeat themselves after some period ot time.&lt;/p>
&lt;p>A &lt;strong>sinusoid&lt;/strong> which means it has the same shape as the trigonmetric sine function.
And a sinusoid contains only one frequency component, so its spectrum has only one
peak.&lt;/p>
&lt;p>&lt;strong>cycles&lt;/strong>: the full repetitions in a periodic signal.
&lt;strong>period&lt;/strong>: the duration of each cycle.
&lt;strong>frequency&lt;/strong>: the number of cycles per second, which is the inverse of period.
- the units of frequency are cycles per second, or Hertz (Hz).
- strictly speaking, the number of cycles is a dimensionless number, so a Hertz
is really a &amp;ldquo;per second&amp;rdquo;.&lt;/p>
&lt;p>A microphone is a device that measures these variations and generates an electrical
signal that represents sound.
A speaker is a device that takes an electrical signal and produce sound.
They are called &lt;strong>transducers&lt;/strong> because they transduce, or convert, signals from one
form to another.&lt;/p>
&lt;h2 id="discrete-fourier-transform-dft" >
&lt;div>
&lt;a href="#discrete-fourier-transform-dft">
#
&lt;/a>
Discrete Fourier transform (DFT)
&lt;/div>
&lt;/h2>
&lt;p>DFT is a mathematical idea which takes a signal and produces its spectrum.
The spectrum is the set of sinusoids that add up to produce the signal.&lt;/p>
&lt;p>And the FFT (Fast Fourier transform) is an algorithm which is an efficient way to
compute the DFT.&lt;/p>
&lt;p>&lt;img alt="IMG_signal" src="https://fgg100y.github.io/posts/dsp101/spectral_decomposition/images/a_wave_segment.png">&lt;/p>
&lt;p>&lt;img alt="IMG_spectrum_of_signal" src="https://fgg100y.github.io/posts/dsp101/spectral_decomposition/images/a_wave_segment_its_spectrum.png">&lt;/p>
&lt;p>The lowest frequency component is called the &lt;strong>fundamental frequency&lt;/strong>. If the
fundamental frequency has the largest amplitude, it is also the &lt;strong>dominant frequency&lt;/strong>.
Normally the perceived pitch of a sound is determinded by the fundamental frequency,
even if it is not dominant.&lt;/p>
&lt;p>The &lt;strong>fundamental frequency&lt;/strong> of this signal is near 440 Hz, the other spikes in the
spectrum are at frequencies 880, 1320, 1760, and 2200, which are integer multiples
of the fundamental. These components are called &lt;strong>harmonics&lt;/strong> because they are
musically harmonious with the fundamental:&lt;/p>
&lt;ul>
&lt;li>440 is the frequency of A4, the fundamental frequency.&lt;/li>
&lt;li>880 is the frequency of A5, one &lt;strong>octave&lt;/strong> higher than the fundamental. An octave
is a doubling in frequency.&lt;/li>
&lt;li>1320 is approximately E6, which is a &lt;strong>perfect fifth&lt;/strong> above A5.&lt;/li>
&lt;li>1760 is A6, two octave above the fundamental.&lt;/li>
&lt;li>2200 is approximately C#7, which is a major third above A6.&lt;/li>
&lt;/ul>
&lt;p>NOTE: Given the harmonics and their amplitudes, you can reconstruct the signal by
adding up sinusoids.&lt;/p>
&lt;p>Some code about &lt;code>signal/wave&lt;/code> :&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># More codes here are ignored ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">class&lt;/span> &lt;span style="color:#f3f99d">Signal&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Represents a time-varying signal.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> __add__(self, other):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Adds two signals.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> other: Signal
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> returns: Signal
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> other &lt;span style="color:#ff6ac1">==&lt;/span> &lt;span style="color:#ff9f43">0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> self
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> SumSignal(self, other)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> __radd__ &lt;span style="color:#ff6ac1">=&lt;/span> __add__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff9f43">@property&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">period&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Period of the signal in seconds (property).
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> Since this is used primarily for purposes of plotting,
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> the default behavior is to return a value, 0.1 seconds,
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> that is reasonable for many signals.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> returns: float seconds
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> &lt;span style="color:#ff9f43">0.1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">plot&lt;/span>(self, framerate&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">11025&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Plots the signal.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> The default behavior is to plot three periods.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> framerate: samples per second
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> duration &lt;span style="color:#ff6ac1">=&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>period &lt;span style="color:#ff6ac1">*&lt;/span> &lt;span style="color:#ff9f43">3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> wave &lt;span style="color:#ff6ac1">=&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>make_wave(duration, start&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">0&lt;/span>, framerate&lt;span style="color:#ff6ac1">=&lt;/span>framerate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> wave&lt;span style="color:#ff6ac1">.&lt;/span>plot()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">make_wave&lt;/span>(self, duration&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>, start&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">0&lt;/span>, framerate&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">11025&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Makes a Wave object.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> duration: float seconds
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> start: float seconds
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> framerate: int frames per second
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> returns: Wave
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">round&lt;/span>(duration &lt;span style="color:#ff6ac1">*&lt;/span> framerate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ts &lt;span style="color:#ff6ac1">=&lt;/span> start &lt;span style="color:#ff6ac1">+&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>arange(n) &lt;span style="color:#ff6ac1">/&lt;/span> framerate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ys &lt;span style="color:#ff6ac1">=&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>evaluate(ts)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> Wave(ys, ts, framerate&lt;span style="color:#ff6ac1">=&lt;/span>framerate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">class&lt;/span> &lt;span style="color:#f3f99d">Sinusoid&lt;/span>(Signal)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># More codes here are ignored ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">evaluate&lt;/span>(self, ts):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># (self.freq * ts) is the number of cycles since start time&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># Multiplying 2*np.pi converts from cycles to phases&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># and phases can be view as &amp;#34;cycles since start time expressed in radians&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># the func is cos or sin, returns value between -1 and 1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> phases &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">2&lt;/span>&lt;span style="color:#ff6ac1">*&lt;/span>np&lt;span style="color:#ff6ac1">.&lt;/span>pi &lt;span style="color:#ff6ac1">*&lt;/span> (self&lt;span style="color:#ff6ac1">.&lt;/span>freq &lt;span style="color:#ff6ac1">*&lt;/span> ts) &lt;span style="color:#ff6ac1">+&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>offset
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ys &lt;span style="color:#ff6ac1">=&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>amp &lt;span style="color:#ff6ac1">*&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>func(phases)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> ys
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">class&lt;/span> &lt;span style="color:#f3f99d">Wave&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Represents a discrete-time waveform.&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> __init__(self, ys, ts&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>, framerate&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Initializes the wave.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> ys: wave array
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> ts: array of times
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> framerate: samples per second
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#ff6ac1">.&lt;/span>ys &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>asanyarray(ys)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#ff6ac1">.&lt;/span>framerate &lt;span style="color:#ff6ac1">=&lt;/span> framerate &lt;span style="color:#ff6ac1">if&lt;/span> framerate &lt;span style="color:#ff6ac1">is&lt;/span> &lt;span style="color:#ff6ac1">not&lt;/span> &lt;span style="color:#ff6ac1">None&lt;/span> &lt;span style="color:#ff6ac1">else&lt;/span> &lt;span style="color:#ff9f43">11025&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> ts &lt;span style="color:#ff6ac1">is&lt;/span> &lt;span style="color:#ff6ac1">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#ff6ac1">.&lt;/span>ts &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>arange(&lt;span style="color:#ff5c57">len&lt;/span>(ys)) &lt;span style="color:#ff6ac1">/&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>framerate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#ff6ac1">.&lt;/span>ts &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>asanyarray(ts)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">copy&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Makes a copy.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> Returns: new Wave
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> copy&lt;span style="color:#ff6ac1">.&lt;/span>deepcopy(self)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> __len__(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(self&lt;span style="color:#ff6ac1">.&lt;/span>ys)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff9f43">@property&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">start&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>ts[&lt;span style="color:#ff9f43">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff9f43">@property&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">end&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>ts[&lt;span style="color:#ff6ac1">-&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff9f43">@property&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">duration&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Duration (property).
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> returns: float duration in seconds
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(self&lt;span style="color:#ff6ac1">.&lt;/span>ys) &lt;span style="color:#ff6ac1">/&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>framerate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> __add__(self, other):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;Adds two waves elementwise.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> other: Wave
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> returns: new Wave
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> other &lt;span style="color:#ff6ac1">==&lt;/span> &lt;span style="color:#ff9f43">0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> self
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">assert&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>framerate &lt;span style="color:#ff6ac1">==&lt;/span> other&lt;span style="color:#ff6ac1">.&lt;/span>framerate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># make an array of times that covers both waves&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> start &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">min&lt;/span>(self&lt;span style="color:#ff6ac1">.&lt;/span>start, other&lt;span style="color:#ff6ac1">.&lt;/span>start)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> end &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">max&lt;/span>(self&lt;span style="color:#ff6ac1">.&lt;/span>end, other&lt;span style="color:#ff6ac1">.&lt;/span>end)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">int&lt;/span>(&lt;span style="color:#ff5c57">round&lt;/span>((end &lt;span style="color:#ff6ac1">-&lt;/span> start) &lt;span style="color:#ff6ac1">*&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>framerate)) &lt;span style="color:#ff6ac1">+&lt;/span> &lt;span style="color:#ff9f43">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ys &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>zeros(n)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ts &lt;span style="color:#ff6ac1">=&lt;/span> start &lt;span style="color:#ff6ac1">+&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>arange(n) &lt;span style="color:#ff6ac1">/&lt;/span> self&lt;span style="color:#ff6ac1">.&lt;/span>framerate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">add_ys&lt;/span>(wave):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#ff6ac1">=&lt;/span> find_index(wave&lt;span style="color:#ff6ac1">.&lt;/span>start, ts)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># make sure the arrays line up reasonably well&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> diff &lt;span style="color:#ff6ac1">=&lt;/span> ts[i] &lt;span style="color:#ff6ac1">-&lt;/span> wave&lt;span style="color:#ff6ac1">.&lt;/span>start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dt &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">1&lt;/span> &lt;span style="color:#ff6ac1">/&lt;/span> wave&lt;span style="color:#ff6ac1">.&lt;/span>framerate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> (diff &lt;span style="color:#ff6ac1">/&lt;/span> dt) &lt;span style="color:#ff6ac1">&amp;gt;&lt;/span> &lt;span style="color:#ff9f43">0.1&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> warnings&lt;span style="color:#ff6ac1">.&lt;/span>warn(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;Can&amp;#39;t add these waveforms; their &amp;#34;&lt;/span> &lt;span style="color:#5af78e">&amp;#34;time arrays don&amp;#39;t line up.&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> j &lt;span style="color:#ff6ac1">=&lt;/span> i &lt;span style="color:#ff6ac1">+&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(wave)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ys[i:j] &lt;span style="color:#ff6ac1">+=&lt;/span> wave&lt;span style="color:#ff6ac1">.&lt;/span>ys
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> add_ys(self)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> add_ys(other)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> Wave(ys, ts, self&lt;span style="color:#ff6ac1">.&lt;/span>framerate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> __radd__ &lt;span style="color:#ff6ac1">=&lt;/span> __add__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Write a function called stretch that takes a Wave and a stretch factor and speeds up&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># or slows down the wave by modifying ts and framerate.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">stretch&lt;/span>(wave, factor):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5af78e">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> if 0 &amp;lt; factor &amp;lt; 1, speed up, else slow down
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> wave&lt;span style="color:#ff6ac1">.&lt;/span>ts &lt;span style="color:#ff6ac1">*=&lt;/span> factor
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> wave&lt;span style="color:#ff6ac1">.&lt;/span>framerate &lt;span style="color:#ff6ac1">/=&lt;/span> factor
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>变分自编码器（VAE）</title><link>/posts/neuralnetworks/variationalautoencoder/</link><pubDate>Wed, 01 May 2024 21:01:57 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/neuralnetworks/variationalautoencoder/</guid><description>&lt;h1 id="变分自编码器veriational-autoencoder-vae" >
&lt;div>
&lt;a href="#%e5%8f%98%e5%88%86%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8veriational-autoencoder-vae">
##
&lt;/a>
变分自编码器：Veriational AutoEncoder (VAE)
&lt;/div>
&lt;/h1>
&lt;h2 id="自编码器" >
&lt;div>
&lt;a href="#%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8">
#
&lt;/a>
自编码器
&lt;/div>
&lt;/h2>
&lt;p>自编码器通常用于数据压缩，也就是将高维数据映射到低维空间，然后通过解码器对压缩后的数据进
行重构（尝试恢复原数据）。例如：在训练阶段，将214x214的图片通过解码器压缩为100维的向量，
然后用解码器对这个100维向量进行重构，重构的目标是生成的图片与原图片越接近越好。经过大量
数据训练后，模型将学会对数据进行压缩。&lt;/p>
&lt;p>图像去噪(de-noicing)：如果在训练过程，给输入数据加入噪音信号，重构目标是原图片，则模型同
时学会降噪；&lt;/p>
&lt;p>图像分割(segmentation)：如果在训练过程，输入数据不变，而重构目标变成图像区块，则模型学会
分割；&lt;/p>
&lt;p>神经填充(neural inpainting)：如果在训练过程，直接对图片部分内容打码，而重构目标是原图片，
则模型学会还原被打码部分(最近闹得沸沸扬扬的“一键消衣，无中生胸”大约是此类模型技术)；&lt;/p>
&lt;p>&lt;img alt="IMG_AE" src="https://fgg100y.github.io/posts/neuralnetworks/variationalautoencoder/images/AutoEncoder.png">&lt;/p>
&lt;h2 id="变分自编码器" >
&lt;div>
&lt;a href="#%e5%8f%98%e5%88%86%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8">
#
&lt;/a>
变分自编码器
&lt;/div>
&lt;/h2>
&lt;p>变分自编码器（VAE）是一种生成模型，结合了自编码器和概率图模型的思想。&lt;/p>
&lt;p>变分自编码器中的模型架构与自编码器一样，区别主要在于生成的低维表示的方式，自编码器
是生成固定长度的向量，然后传递给解码器；但变分自编码器则生成一个潜在空间中的概率分布
（laten space distribution），然后从这个分布采样得到的数据再传递给解码器。&lt;/p>
&lt;p>变分自编码器中的“变分”其实是“概率推断”（probabilistic inference）中的一种技术，称为“变分
推断（variational inference）。在概率图模型中，通常需要计算后验概率分布（posterior dist.），
即贝叶斯分析中的后验概率。而对于复杂的概率模型，这个后验概率难以直接计算。
解决这个后验概率计算的思路有两种：一是MCMC方法；二就是变分推断。两者都是近似计算方法。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>MCMC（马尔科夫链蒙特卡洛）是通过构建满足平稳分布为目标分布的马尔科夫链，然后待马尔科夫
链收敛到平稳分布后，就从这个分布抽样。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>VI（变分推断）就是通过优化一个参数化的近似分布来近似真实的后验分布，试图将推断问题转变
成最优化问题。更多关于VI的内容请移步&lt;a href="https://fgg100y.github.io/posts/neuralnetworks/variationalinference/">这里&lt;/a>。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>VAE的工作流程如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>编码器（Encoder）：将输入数据映射到潜在空间中的分布参数。这个过程可以理解为将输入数据
编码成潜在空间中的概率分布，而不是直接映射到一个确定的点。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>采样（Sampling）：从潜在空间的分布中采样一个点，作为潜在表示（latent representation）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>解码器（Decoder）：将潜在表示解码为输出数据的概率分布。与编码器相对应，解码器将潜在表
示映射回原始数据的分布参数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>重构损失（Reconstruction Loss）：衡量重构数据与原始数据之间的差异，通常使用重构误差或
者交叉熵来衡量。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>KL 散度损失（KL Divergence Loss）：用于度量编码器输出的潜在分布与预设的先验分布（通常
是高斯分布）之间的差异，促使模型学习到合理的潜在表示。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>总损失（Total Loss）：重构损失和KL散度损失的加权和，用于训练模型。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img alt="IMG_AE" src="https://fgg100y.github.io/posts/neuralnetworks/variationalautoencoder/images/AE.webp">&lt;/p>
&lt;p>&lt;img alt="IMG_VAE" src="https://fgg100y.github.io/posts/neuralnetworks/variationalautoencoder/images/VAE.webp">&lt;/p>
&lt;h2 id="重参数化技巧reparametrization-trick" >
&lt;div>
&lt;a href="#%e9%87%8d%e5%8f%82%e6%95%b0%e5%8c%96%e6%8a%80%e5%b7%a7reparametrization-trick">
#
&lt;/a>
重参数化技巧（reparametrization trick）
&lt;/div>
&lt;/h2>
&lt;p>在标准的VAE中，编码器网络通常会输出潜在空间中的均值（mean）和标准差（standard
deviation），然后通过从该分布中采样来生成潜在表示。然而，直接从均值和标准差中采样是不可
微的，这导致了无法直接使用梯度下降来训练模型。&lt;/p>
&lt;p>Reparametrization Trick 的关键思想是重新参数化潜在表示的采样过程，使得采样操作与网络参数
之间的关系变得可导。具体而言，潜在表示 $\mathbf{z}$ 通过一个确定的变换从一个固定的标准高
斯分布中采样得到，然后通过编码器网络的输出来计算这个变换的参数。这个过程可以表示为：&lt;/p>
&lt;p>$$
z = \mu + \sigma \odot \epsilon
$$&lt;/p>
&lt;p>其中，$\mu$ 是编码器网络输出的均值，$\sigma$ 是输出的标准差，$\epsilon$ 是从标准正态分布 $N(0, 1)$ 中采样得到的噪声。&lt;/p>
&lt;p>通过这种重新参数化，$\mathbf{z}$ 的采样过程与模型参数的梯度相关，从而使得可以直接使用梯
度下降算法来优化模型参数。这种技巧允许我们在训练过程中，通过反向传播算法直接更新编码器和
解码器的参数，从而优化VAE模型。&lt;/p>
&lt;p>&lt;img alt="IMG_VAE_trick" src="https://fgg100y.github.io/posts/neuralnetworks/variationalautoencoder/images/VAE_reparametrization_trick.png">&lt;/p>
&lt;h2 id="beta-vae-disentangled-vae" >
&lt;div>
&lt;a href="#beta-vae-disentangled-vae">
#
&lt;/a>
$\beta$-VAE (Disentangled VAE)
&lt;/div>
&lt;/h2>
&lt;p>在损失函数中，使用一个超参数 $\beta$ 乘以 KL-散度损失。也就是：&lt;/p>
&lt;p>$$
Loss = \text{Reconstruction Loss} + \beta \times \text{KL Divergence}
$$&lt;/p>
&lt;p>其中，β 是一个超参数，用于平衡重构损失和 KL 散度之间的重要性。通过调整 β 的值，可以控制
模型对潜在表示的约束程度。当 β=1 时，与标准的VAE相等，而当 β 小于1 时，模型更加关注于重
构损失，从而更加注重数据的重建；当 β 大于1 时，模型更加关注于 KL 散度，从而更加注重潜在
表示的独立性和结构性。&lt;/p></description></item><item><title>LLMs_interview_faq</title><link>/posts/llms/llm_faqs/</link><pubDate>Fri, 26 Apr 2024 11:04:16 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/llms/llm_faqs/</guid><description>&lt;h2 id="01简述gpt和bert的区别" >
&lt;div>
&lt;a href="#01%e7%ae%80%e8%bf%b0gpt%e5%92%8cbert%e7%9a%84%e5%8c%ba%e5%88%ab">
#
&lt;/a>
01:简述GPT和BERT的区别
&lt;/div>
&lt;/h2>
&lt;p>GPT (Decoder-only) 和 BERT (Encoder-only) 都是基于 Transformer 架构的自然语言处理模型，它们在设计上有一些显著区别：&lt;/p>
&lt;ul>
&lt;li>任务类型
&lt;ul>
&lt;li>GPT 以生成文本为主要任务，其目标是生成与输入文本连贯和相关的文本。因此，GPT 通
常用于生成文本 (如：摘要总结，文本补充和chatbot)。&lt;/li>
&lt;li>BERT 以理解文本为主要任务，其目标是从输入文本中提取语义信息。因此适用于各种文
本理解任务，如：情感分析、 文本分类、命名实体识别等下游任务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>预训练目标
&lt;ul>
&lt;li>GPT：单向语言建模。GPT通过自左向右的注意力机制来预测下一个单词，即根据上下文预
测下一个单词/词元是什么。&lt;/li>
&lt;li>BERT：双向语言建模。BERT使用掩码语言建模（MLM）和下一句预测（NSP）两个任务，前
者在MLM任务中随机遮掩输入中的一些词语，模型需要预测这些被掩盖的词语是什么；
NSP的任务是判断两个句子是否在原文中是前后连接的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>结构特点
&lt;ul>
&lt;li>GPT：Transformer-decoder的堆叠，仅使用自注意力机制&lt;/li>
&lt;li>BERT：Transformer-encoder的堆叠，包含多层双向Transformer-encoder。在预训练阶段，
BERT同时使用了自注意力机制和前馈神经网络。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>模型微调
&lt;ul>
&lt;li>GPT：由于其生成式的特点，GPT在微调时通常将整个模型作为单独的序列生成任务进行微
调。&lt;/li>
&lt;li>BERT：由于其双向表示的特点，BERT在微调时通常用于各种文本理解任务，微调时可以在
模型顶层添加适当的输出层来适应下游特定任务。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="02llm中的因果语言建模与掩码语言建模有什么区别" >
&lt;div>
&lt;a href="#02llm%e4%b8%ad%e7%9a%84%e5%9b%a0%e6%9e%9c%e8%af%ad%e8%a8%80%e5%bb%ba%e6%a8%a1%e4%b8%8e%e6%8e%a9%e7%a0%81%e8%af%ad%e8%a8%80%e5%bb%ba%e6%a8%a1%e6%9c%89%e4%bb%80%e4%b9%88%e5%8c%ba%e5%88%ab">
#
&lt;/a>
02:LLM中的因果语言建模与掩码语言建模有什么区别？
&lt;/div>
&lt;/h2>
&lt;p>因果语言建模（Causal Language Modeling）&lt;/p>
&lt;pre>&lt;code>在因果语言建模中，模型被要求根据输入序列的左侧内容来预测右侧的下一个词或标记。也就是
说，模型只能看到输入序列中已经生成的部分，而不能看到后续的内容。这种训练方式有助于模
型学习生成连贯和合理的文本，因为模型需要在生成每个词语时考虑上下文的信息，同时不能依
赖于未来的信息。GPT（Generative Pre-trained Transformer）就是以因果语言建模为基础的
模型。
&lt;/code>&lt;/pre>
&lt;p>掩码语言建模（Masked Language Modeling）：&lt;/p>
&lt;pre>&lt;code>在掩码语言建模中，模型被要求预测输入序列中一些被随机掩盖或掩码的词语。模型需要基于上
下文来预测这些被掩盖的词语是什么。
这种训练方式通常用于双向的语言理解任务，因为模型需要考虑上下文中的所有信息来预测被掩盖的词语。
BERT（Bidirectional Encoder Representations from Transformers）就是以掩码语言建模为基础的模型。
&lt;/code>&lt;/pre>
&lt;h2 id="03请简述transformer基本原理" >
&lt;div>
&lt;a href="#03%e8%af%b7%e7%ae%80%e8%bf%b0transformer%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86">
#
&lt;/a>
03:请简述Transformer基本原理
&lt;/div>
&lt;/h2>
&lt;p>Transformer 是一种用于处理序列数据的深度学习模型，由谷歌团队于2017年提出，其主要原理包括
自注意力机制和位置编码。&lt;/p>
&lt;h3 id="自注意力机制" >
&lt;div>
&lt;a href="#%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6">
##
&lt;/a>
自注意力机制：
&lt;/div>
&lt;/h3>
&lt;pre>&lt;code>允许模型在序列的任意两个位置间直接建立依赖关系，而不考虑它们之间的距离。具体就是将词
元线性转换为三个向量Q,K,V，然后将Q和K用来计算内积(相似度分数)并进行注意力缩放（scaled
dot-product)，然后通过softmax归一化，得到每个词元相对于其他词元的注意力权重，然后用
注意力权重对向量V进行加权和计算得到“上下文向量”(context vector)，然后将上下文向量用
前馈网络（FFNN）进行变换，就得到编码器隐层输出。注意：自注意力机制中，每个输入词元的
context vector 以及后续的 hidden state，可以看成是相应的 Q 向量的函数，其他的如 K，V，
以及自注意力机制的参数对所有的 Q 都是恒定值。
+ 多头注意力：
在多头注意力中，注意力机制被复制多次，并且每个注意力头都学习到一组不同的Q,K,V的
表示，然后将它们的输出拼接起来，再通过FFNN进行维度对齐。
- 复制注意力机制：原始输入序列会被用来计算多个注意力头（例如8个或16个头）
- 独立学习：每个注意力头都会独立地学习一组Q，K，V的表示，也就是：每个注意力头都
有自己的权重矩阵，将输入序列转换为Q,K,V向量。
- 注意力计算：每个注意力头像单头注意力机制那样计算注意力分数和注意力权重。
- 拼接输出：将所有注意力头的输出拼接成一个向量，形成多头注意力的最终输出。这意味
着每个词元都会得到来自多个不同视角的表示，从而提高模型对输入序列的理解。
- 线性变换：拼接后的输出通过FFNN进行处理，维持输出维度以及融合不同注意力头的信息。
+ narrow attn：Each attention head will get a chunk of the transformed data points
(projections) to work with. This is a details of utmost importance: The
attention heads DO NOT use chunks of the original data points, but rather those
of their projections. It computes the projections first and then chunks them
later, so that each value in the projection is a linear combination of all
features in the data point.
&lt;/code>&lt;/pre>
&lt;h3 id="位置编码" >
&lt;div>
&lt;a href="#%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81">
##
&lt;/a>
位置编码：
&lt;/div>
&lt;/h3>
&lt;pre>&lt;code>位置编码通常是通过将一个与位置相关的向量添加到输入嵌入（input embeddings）
中来实现的。这个向量为序列中的每个位置提供了一个唯一的表示，从而使模型能够
区分不同的单词顺序。
特别是基于 transformer 架构的模型，由于自注意力机制无法捕捉词元顺序，因此必
须通过加入位置编码来获取输入序列中各个词元的位置信息。
尽管自注意力机制（Self-Attention Mechanism）确实可以捕捉序列中元素之间的关
系，但它主要依赖于元素之间的交互和权重计算，而不是它们的绝对位置信息。位置
编码的作用是补充自注意力机制，提供序列中元素顺序的额外信息，使得模型能够更
好地理解序列的结构。
+ 正弦/余弦函数组合编码 (偶数位用 sin(), 奇数位用 cos())
它们为序列中的每个位置提供了一个唯一的、与位置直接相关的编码。这种编码
方式能够明确地告诉模型每个单词在序列中的绝对位置。
绝对位置编码的一个潜在缺点是它们是静态的，不会随着模型训练的进行而改变。
这意味着它们可能不足以捕捉长序列中复杂的依赖关系，特别是在模型需要动态
地调整位置信息以适应输入序列的变化时。
信息的局限性：固定的位置编码仅提供了位置的绝对信息，而没有考虑序列中元
素之间的相对关系。在长序列中，元素之间的相对位置和距离可能更为重要。
+ 旋转位置编码：旋转位置编码的核心思想是将每个位置的编码表示为一个旋转矩阵，
该矩阵可以应用于输入嵌入。旋转矩阵是动态生成的，这意味着它们可以根据输入
序列的内容进行调整，从而更好地捕捉长距离依赖。
&lt;/code>&lt;/pre>
&lt;h3 id="残差连接与层归一化" >
&lt;div>
&lt;a href="#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e4%b8%8e%e5%b1%82%e5%bd%92%e4%b8%80%e5%8c%96">
##
&lt;/a>
残差连接与层归一化：
&lt;/div>
&lt;/h3>
&lt;pre>&lt;code>+ 残差连接：将每个子层的输入与其输出相加，然后传递给下一层。这使得模型在学
习过程中，能更容易地学习到残差（输入于输出之差），从而缓解梯度消失问题；
提高训练稳定性；允许更深的网络结构；以及提高模型性能。
+ 层归一化：在每个层的输入之后都应用归一化，即对每个特征维度进行归一化操作，
使得它们均值为0，标准差为1，有助于缓解梯度消失和梯度爆炸的问题，从而使
模型训练更加稳定，也提高其泛化能力。
- “批次归一化”（Batch Norm）：
The mean and variance statistics used for normalization are calculated
across all elements of all instances in a batch, for each feature
independently.
即：均值和方差是通过对一个批次里所有实例（序列）的所有元素（词元）的某
个特征进行统计的。
- “层归一化”（Layer Norm）：
For layernorm, the statistics are calculated across the feature
dimension, for each element and instance independently.
即：均值和方差是通过对某个实例（序列）中的某个元素（词元）的所有特征进
行统计的。
NOTE By &amp;quot;element&amp;quot; and &amp;quot;instance,&amp;quot; I mean &amp;quot;word&amp;quot; and &amp;quot;sentence&amp;quot;
respectively for an NLP task, and &amp;quot;pixel&amp;quot; and &amp;quot;image&amp;quot; for a CV task.
&lt;/code>&lt;/pre>
&lt;p>&lt;img alt="IMG: LayerNorm &amp;amp; BatchNorm" src="https://fgg100y.github.io/posts/llms/llm_faqs/images/LLMs_layerNorm_batchNorm.png">&lt;/p>
&lt;h2 id="04-注意力机制的改良版本们" >
&lt;div>
&lt;a href="#04-%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6%e7%9a%84%e6%94%b9%e8%89%af%e7%89%88%e6%9c%ac%e4%bb%ac">
#
&lt;/a>
04: 注意力机制的改良版本们
&lt;/div>
&lt;/h2>
&lt;p>MHA，GQA，MQA三种注意力机制的区别是什么？&lt;/p>
&lt;p>注意力机制在自然语言处理和机器学习领域有多种不同的实现方式，其中常见的包括多头自注意力
（Multi-Head Self-Attention，MHA）、全局注意力（Global Attention，GQA）和多头查询注意力
（Multi-Query Attention，MQA）。这些不同的实现方式在机制和应用上有一些区别：&lt;/p>
&lt;pre>&lt;code>多头自注意力（MHA）：
机制：MHA将输入序列中的每个位置的表示都作为查询（Query）、键（Key）和值（Value），
通过计算查询与所有键的相似度，然后将相似度作为权重对值进行加权求和，从而获得每个
位置的注意力输出。
特点：MHA允许模型在不同的表示空间上进行多头并行计算，通过多头机制，可以学习到不同的关注点和表示。
应用：MHA常用于Transformer等模型中，用于捕捉输入序列中不同位置之间的依赖关系。
全局注意力（GQA）：
机制：GQA将所有的输入位置都作为查询，与所有的键计算相似度，然后将所有位置的值根
据相似度进行加权求和，得到一个全局的输出。
特点：GQA考虑了序列中所有位置的关系，但在处理长序列时可能会受到计算资源的限制，
因为需要计算所有位置之间的相似度。
应用：GQA常用于对整个输入序列进行全局的信息聚合，例如在图像分类任务中。
多头查询注意力（MQA）：
机制：MQA与MHA类似，但在每个头的注意力计算中，使用不同的查询向量，而不是所有头都共享相同的查询向量。
特点：MQA允许模型为每个头学习不同的查询模式，增强了模型的灵活性和表达能力。
应用：MQA常用于需要根据不同的查询来获取注意力信息的任务，如问答系统或需要针对不同问题进行推理的场景
&lt;/code>&lt;/pre>
&lt;h2 id="05-attention的改良版本们" >
&lt;div>
&lt;a href="#05-attention%e7%9a%84%e6%94%b9%e8%89%af%e7%89%88%e6%9c%ac%e4%bb%ac">
#
&lt;/a>
05: Attention的改良版本们
&lt;/div>
&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>简述一下 FlashAttention 的原理&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>Flash Attention是一种新型的注意力算法，旨在解决传统Transformer模型中自注意力机制的计
算和内存效率问题。由于自注意力机制的时间和存储复杂度与序列长度成二次方关系，这使得处
理长序列数据时面临巨大挑战。Flash Attention通过精心设计，显著减少了对高带宽内存（HBM）
的读写次数，从而加快了运行速度并降低了内存占用。&lt;/p>
&lt;h3 id="flash-attention的核心原理和技术" >
&lt;div>
&lt;a href="#flash-attention%e7%9a%84%e6%a0%b8%e5%bf%83%e5%8e%9f%e7%90%86%e5%92%8c%e6%8a%80%e6%9c%af">
##
&lt;/a>
Flash Attention的核心原理和技术：
&lt;/div>
&lt;/h3>
&lt;pre>&lt;code>平铺（Tiling）：Flash Attention将输入分割成小块，并在每个块上执行注意力操作。这种方法减少了对高带宽内存的访问次数，因为不需要一次性将整个大矩阵加载到内存中。
重新计算（Recomputation）：在后向传播过程中，Flash Attention避免了存储大型中间矩阵（如S和P矩阵），而是利用前向传播中的统计量来快速重新计算这些矩阵，从而减少了内存消耗。
在线Softmax：为了处理Softmax操作，Flash Attention采用了在线Softmax技术，它允许分块计算softmax，并通过适当的归一化因子来确保最终结果的正确性。
内存层次结构意识（IO-Awareness）：Flash Attention考虑了GPU内存层次结构，优化了不同层级内存之间的数据访问，如在GPU的SRAM和HBM之间。
&lt;/code>&lt;/pre>
&lt;h3 id="flash-attention-2" >
&lt;div>
&lt;a href="#flash-attention-2">
##
&lt;/a>
Flash Attention-2：
&lt;/div>
&lt;/h3>
&lt;p>在Flash Attention的基础上，研究人员进一步提出了Flash Attention-2，它通过改进工作分配和并行化策略，进一步提高了计算速度。Flash Attention-2的优化包括：&lt;/p>
&lt;pre>&lt;code>减少非矩阵乘法（non-matmul）的浮点运算次数（FLOPs）。
通过在不同的线程块上并行化注意力计算，提高了GPU的占用率。
在每个线程块内，将工作分配给不同的warp，以减少通过共享内存的通信。
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;strong>PagedAttention的原理是什么，解决了LLM中的什么问题？&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>Paged Attention（PA）技术是一种用于优化大型语言模型（LLM）推理性能的方法，特别是在处理自
回归生成任务时对内存使用效率的显著提升。这项技术的核心思想是借鉴操作系统中虚拟内存和分页
的技术，将传统的注意力机制中的键值对（Key-Value pairs，简称K-V pairs）缓存以分页的形式存
储和管理。&lt;/p>
&lt;p>在自回归解码过程中，模型为每个输入令牌生成注意力键和值，这些键值对被存储在GPU的显存中以
预测下一个令牌。由于这些缓存的键值对大小是动态变化的，并且可能会占用大量的显存空间，因此
有效管理这些缓存成为一个挑战。传统的注意力算法在处理时会受限于显存的大小，这限制了模型的
批处理能力和整体的吞吐量。&lt;/p>
&lt;h2 id="06llm微调与量化" >
&lt;div>
&lt;a href="#06llm%e5%be%ae%e8%b0%83%e4%b8%8e%e9%87%8f%e5%8c%96">
#
&lt;/a>
06:LLM微调与量化
&lt;/div>
&lt;/h2>
&lt;p>30.参数高效的微调（PEFT）有哪些方法？
31.LORA微调相比于微调适配器或前缀微调有什么优势？
32.有了解过什么是稀疏微调吗？
33.训练后量化（PTQ）和量化感知训练（QAT）与什么区别？
34.LLMs中，量化权重和量化激活的区别是什么？
35.AWQ量化的步骤是什么？&lt;/p>
&lt;h2 id="07嵌入向量模型" >
&lt;div>
&lt;a href="#07%e5%b5%8c%e5%85%a5%e5%90%91%e9%87%8f%e6%a8%a1%e5%9e%8b">
#
&lt;/a>
07:嵌入向量模型
&lt;/div>
&lt;/h2>
&lt;p>40.自前主流的中文嵌入向量模型有哪些？&lt;/p>
&lt;h2 id="其他" >
&lt;div>
&lt;a href="#%e5%85%b6%e4%bb%96">
#
&lt;/a>
其他
&lt;/div>
&lt;/h2>
&lt;p>45.DeepSpeed推理对算子融合做了哪些优化？
48.请介绍一下微软的ZeRO优化器&lt;/p>
&lt;p>3.为什么现在的大模型大多是decoder-only的架构？
4.讲一下生成式语言模型的工作机理
5.哪些因素会导致LLM的偏见？
7.如何减轻LLM中的幻觉现象？
8.解释ChatGPT的零样本和少样本学习的概念
10.如何评估大语言模型（LLMs）的性能？
11.如何缓解LLMs重复读问题？
16.Wordpiece与BPE之间的区别是什么？
17.有哪些常见的优化LLMs输出的技术？
18.GPT-3拥有的1750亿参数，是怎么算出来的？
19.温度系数和top-p，top-k参数有什么区别？
21.介绍-下postlayernorm和prelayernorm的区别
22.什么是思维链（CoT）提示？
23.你觉得什么样的任务或领域适合用思维链提示？
24.你了解ReAct吗，它有什么优点？
25.解释一下langchainAgent的概念
26.langchain有哪些替代方案？
27.langchaintoken计数有什么问题？如何解决？
28.LLM预训练阶段有哪几个关键步骤？
29.RLHF模型为什么会表现比SFT更好？
36.介绍一下GPipe推理框架
37.矩阵乘法如何做张量并行？
38.请简述下PPO算法流程，它跟TRPO的区别是什么？
39.什么是检索增强生成（RAG）？
41.为什么LLM的知识更新很困难？
42.RAG和微调的区别是什么？
43.大模型一般评测方法及基准是什么？
50.什么是投机采样技术，请举例说明？&lt;/p></description></item><item><title>Tokenization: BPE, Unigram and more</title><link>/posts/llms/llm_tokenization/</link><pubDate>Mon, 22 Apr 2024 15:41:56 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/llms/llm_tokenization/</guid><description>&lt;h1 id="there-is-more-than-one-way-to-tokenize-a-sentence" >
&lt;div>
&lt;a href="#there-is-more-than-one-way-to-tokenize-a-sentence">
##
&lt;/a>
There is more than one way to tokenize a sentence
&lt;/div>
&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>word-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>A big vocabulary is needed&lt;/li>
&lt;li>We combine words: what exactly constitutes a word (&amp;ldquo;bachelor of science&amp;rdquo;, or
isolated words)&lt;/li>
&lt;li>Abbreviated words: &amp;ldquo;LOL&amp;rdquo;, &amp;ldquo;IMO&amp;rdquo;, are these collections of words or new words?&lt;/li>
&lt;li>Languages that don&amp;rsquo;t segment by spaces&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>character-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>Lack of meaning: Unlike words, characters don&amp;rsquo;t have any inherent meaning, model
may lose the semantic-specific feature of words.&lt;/li>
&lt;li>Increased input computation&lt;/li>
&lt;li>Limits netword+k choices: It&amp;rsquo;s difficult to use architectures which process input
sequentially since the input sequences will be much longer.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Subword-level chunks/tokens&lt;/p>
&lt;ul>
&lt;li>We want a tokenization scheme that deals with an infinite potential vocabulary via
a finite list of known words. Make up the word “unfortunately” via “un” + “for”+
“tun” + “ate” + “ly”.&lt;/li>
&lt;li>Subword tokenisation will break the text into chunks based on the word frequency.
In practice what happens is that common words will be tokenized generally as
whole words, e.g. “the”, “at”, “and”, etc., while rarer words will be broken
into smaller chunks and can be used to create the rest of the words in the
relevant dataset.&lt;/li>
&lt;li>BPE(Byte Pair Encoding): One popular algorithm for subword tokenisation which
follows the above approach is BPE. BPE was originally used to help compress data
by finding common byte pair combinations. It can also be applied to NLP to find
the most efficient way of representing text.
&lt;ul>
&lt;li>What is merging?
The main goal of the BPE subword algorithm is to find a way to represent
your entire text dataset with the least amount of tokens. Similar to a
compression algorithm, you want to find the best way to represent your image,
text or whatever you are encoding, which uses the least amount of data, or
in our case tokens. In the BPE algorithm merging is the way we try and
“compress” the text into subword units.&lt;/li>
&lt;li>There are a few steps to these merging actions:
&lt;ol>
&lt;li>Get the word &lt;strong>count&lt;/strong> frequency&lt;/li>
&lt;li>Get the &lt;strong>initial token count&lt;/strong> and frequency (i.e., how many times each
character occurs)&lt;/li>
&lt;li>Merge the &lt;strong>most common byte pairing&lt;/strong>&lt;/li>
&lt;li>Add this to the list of tokens and &lt;strong>recalculate the frequency count&lt;/strong>
for each token (this will change with each merging step)&lt;/li>
&lt;li>&lt;strong>Rinse and repeat&lt;/strong> until get reached pre-defined token limits (vocab
size) or a set of number of iterations&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Greedy algorithm: BPE ensures that the most common words will be represented in
the new vocabulary as a single token, while less common words will be broken
down into two or more subword tokens. To achieve this, BPE will go through every
potential option at each step and pick the tokens to merge based on the highest
frequency.One downside of BPE’s greedy approach is it can result in a potentially
ambiguous final token vocabulary.
For instance GPT has a vocabulary size of 40,478 since they have 478 base
characters and chose to stop training after 40,000 merges.&lt;/li>
&lt;li>BBPE(byte-level PBE): A base vocabulary that includes all possible base characters
can be quite large if e.g. all unicode characters are considered as base
characters. To have a better base vocabulary, GPT-2 uses bytes as the base
vocabulary, which is a clever trick to force the base vocabulary to be of size
256 while ensuring that every base character is included in the vocabulary. With
some additional rules to deal with punctuation, the GPT2’s tokenizer can
tokenize every text without the need for the &lt;unk> symbol. GPT-2 has a
vocabulary size of 50,257, which corresponds to the 256 bytes base tokens, a
special end-of-text token and the symbols learned with 50,000 merges.
&lt;a href="https://huggingface.co/docs/transformers/en/tokenizer_summary#byte-pair-encoding-bpe">from hf doc&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="probabilistic-subword-tokenization" >
&lt;div>
&lt;a href="#probabilistic-subword-tokenization">
##
&lt;/a>
Probabilistic Subword Tokenization
&lt;/div>
&lt;/h1>
&lt;p>Using the frequency of subword patterns for tokenization can result in ambiguous final
encodings. The problem is that we have no way to predict which particular token is more
likely to be the best one when encoding any new input text.
Luckily, needing to predict the most likely sequence of text is not a unique problem to
tokenization. We can leverage this knowledge to build a better tokenizer.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Unigram Subword Tokenization&lt;/p>
&lt;ul>
&lt;li>The goal for a subword model, however, is different from a LM that is trying to
predict a full sentence. We only want something that generates unambiguous
tokenization.&lt;/li>
&lt;li>The unigram approach differs from BPE in that it attempts to choose the most
likely option rather than the best option at each iteration. To generate a
unigram subword token set you need to first define the desired final size of
your token set and also a starting seed subword token set.&lt;/li>
&lt;li>You can choose the seed subword token set in a similar way to BPE and choose
the most frequently occurring substrings. Once you have this in place then
you need to:
&lt;ol>
&lt;li>Work out the probability for each subword token&lt;/li>
&lt;li>Work out a loss value which would result if each subwork token were to be
dropped. The loss is worked out via Expectation Maximization algorithm.&lt;/li>
&lt;li>Drop the tokens which have the largest loss value (e.g., the bottom 10%
or 20% of subword tokens based on their loss calculations).&lt;/li>
&lt;li>Repeat these steps until reach the desired final vocabulary size or there
is no change in token numbers after successive iterations.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>WordPiece (greedy approach tokenzier, BERT partner)
Think of WordPiece as an intermediary between the BPE approach and the unigram approach.&lt;/p>
&lt;ul>
&lt;li>BPE, if you remember, takes two tokens, looks at the frequency of each pair and then
merges the pairs that have the highest combined frequency count. It only considers
the most frequent pair combinations at each step, nothing else.&lt;/li>
&lt;li>An alternate approach is to check the potential impact of merging that particular
pair. You can do this using the probabilistic LM approach. At each iterative step,
choose the character pair which will result in the largest increase in likelihood
once merged. This is the difference between the probability of the new meged pair
occurring minus the probability of both individual tokens occurring individually.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>The main difference is that WordPiece is a greedy approach. It still tries to build a
tokenizer from the bottom up, picking the best pair at each iteration to merge.
WordPiece uses the likelihood rather than count frequency but otherwise it is a similar
approach. Unigram in contrast is a fully probabilistic approach which uses probability
to both choose the pairs to merge and whether to merge them or not. It also removes
tokens based on the fact that they add the least to the overall likelihood of the
unigram model.&lt;/p>
&lt;h1 id="briefly-summarize" >
&lt;div>
&lt;a href="#briefly-summarize">
##
&lt;/a>
briefly summarize:
&lt;/div>
&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>BPE: Just uses the frequency of occurrences to identify the best match at every
iteration until it reaches the predefined vocabulary size.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>WordPiece: Similar to BPE and uses frequency occurrences to identify potential
merges but makes the final decision based on the likelihood of the merged token&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Unigram: A fully probabilistic model which does not use frequency
occurrences. Instead, it trains a LM using a probabilistic model, removing
the token which improves the overall likelihood the least and then starting
over until it reaches the final token limit.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="sentencepiece" >
&lt;div>
&lt;a href="#sentencepiece">
##
&lt;/a>
SentencePiece
&lt;/div>
&lt;/h1>
&lt;p>SentencePiece basically tries to bring all the subword tokenization tools and techniques
under one banner. It’s kind of like the Swiss Army knife for subword tokenization. To be
a Swiss Army-like tool something has to be capable of solving multiple problems. So what
problems is SentencePiece addressing:&lt;/p>
&lt;ol>
&lt;li>All other models assume input is already tokenized: BPE and Unigram are great model
but they share one big disadvantage: they both need to have their input already
tokenized. SentencePiece deals with this by simply taking in an input in raw text and
then doing everything needed on that input to perform subword tokenization.&lt;/li>
&lt;li>Language agnostic: Since all other subword algorithms need to have their input
pre-tokenized, it limits their applicability to many languages.&lt;/li>
&lt;li>Decoding is difficult: Another problem which is caused by model like BPE and unigram
requiring already tokenized inputs is that you do not know what encoding rules were
used. For example, how were spaces encoded in the tokens? So you cannot decode the
input and return it to is original format.&lt;/li>
&lt;li>No end to end solution: You cannot just plug in a raw input to BPE (or Unigram) and
get an output.&lt;/li>
&lt;/ol>
&lt;p>Some of the techniques SentencePiece uses to address the above shortcomings:&lt;/p>
&lt;ol>
&lt;li>Encode everything as unicode: SentencePiece first converts all the input into unicode
characters. This makes it a language agnostic tool.&lt;/li>
&lt;li>&amp;ldquo;space&amp;rdquo; encoded as &amp;ldquo;_&amp;quot;(U+2581): To get around the word segmenting issues.&lt;/li>
&lt;li>And it&amp;rsquo;s faster: One of the issues preventing other subword algorithms from being used
to tokenize raw sentences as part of model training was that there lack of speed. If
you processed input in real time and performed your tokenization on the raw input it
would be too slow. SentencePiece addresses this by using a priority queue for the BPE
algorithm to speed it up so that you can use it as part of an end-to-end solution.&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>&lt;a href="https://www.openteams.com/tokenizers-how-machines-read/">https://www.openteams.com/tokenizers-how-machines-read/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>TODO: 补充中文&lt;/p></description></item><item><title>test rendering of equations of latex in Hugo</title><link>/posts/hugo101/test_math_equation_rendering/</link><pubDate>Fri, 25 Aug 2023 13:49:40 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/hugo101/test_math_equation_rendering/</guid><description>&lt;p>式子能正常渲染，但需要在两个地方的下标处添加额外转义字符 &lt;code>\&lt;/code>，
也就是：&lt;code>\mathbb{E}\_{xxx}&lt;/code>和&lt;code>p\_{model}&lt;/code>，其他地方却不需要 &lt;code>\hat{p}_{data}&lt;/code>&lt;/p>
&lt;p>$$
\mathbb{E}_{x \sim \hat{p}_{data}} {\text{log}\ p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>是因为 &lt;code>\mathbb{}&lt;/code> 导致的吗？看起来不是：
$$
E_{x \sim \hat{p}_{data}} {\text{log}\ p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>是因为 &lt;code>\text{}&lt;/code> 导致的吗？看起来不是 (&lt;code>\text{log}&lt;/code> -&amp;gt; &lt;code>\log&lt;/code>)：
$$
\mathbb{E}_{x \sim \hat{p}_{data}}{\log p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>如果 &lt;code>\mathbb{}_&lt;/code> 渲染不出来，那它渲染失败是怎么样的 (下式&lt;code>\mathbb{}_&lt;/code>中的&lt;code>_&lt;/code>不见了)：&lt;/p>
&lt;p>$$
\mathbb{E}&lt;em>{x \sim \hat{p}&lt;/em>{data}}{\text{log}\ p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>为什么 &lt;code>p_{model}&lt;/code> 也渲染不出来， 而非要添加转意字符 &lt;code>p\_{model}&lt;/code> 呢？&lt;/p>
&lt;p>$$
\mathbb{E}_{x \sim \hat{p}&lt;em>{data}}{\text{log}\ p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>$$
E_{x \sim \hat{p}&lt;em>{data}}{\text{log}\ p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>$$
\mathbb{E}&lt;em>{x \sim \hat{p}_{data}}{\text{log}\ p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>或许是嵌套下标这儿出的问题 (&lt;code>\hat{p}_{data}&lt;/code> -&amp;gt; &lt;code>\hat{p}\_{data}&lt;/code> )？:
$$
E_{x \sim \hat{p}_{data}}{\text{log}\ p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>Bingo?? No bingo:&lt;/p>
&lt;p>只在嵌套下标的地方添加转义字符：&lt;/p>
&lt;p>$$
\tag{5.59}
\theta_{ML} = \underset{\theta}{\operatorname{argmax}} \mathbb{E}&lt;em>{x \sim \hat{p}_{data}}{\log p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>只在&lt;code>p_{model}&lt;/code>下标的地方添加转义字符：&lt;/p>
&lt;p>$$
\tag{5.59}
\theta_{ML} = \underset{\theta}{\operatorname{argmax}} \mathbb{E}&lt;em>{x \sim \hat{p}&lt;/em>{data}}{\log p_{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>只在&lt;code>\mathbb{}&lt;/code>下标的地方添加转义字符：&lt;/p>
&lt;p>$$
\tag{5.59}
\theta_{ML} = \underset{\theta}{\operatorname{argmax}} \mathbb{E}_{x \sim \hat{p}&lt;em>{data}}{\log p&lt;/em>{model} {(x^i; \theta})}
$$&lt;/p>
&lt;p>简而言之，找不到明确的语法规则来解释这个问题。可能是hugo在使用mathjax解析时出了问题，也有可能是mathjax自己的问题。&lt;/p>
&lt;p style="text-align:center;color:blue;">
Hugo的markdown文档里的数学公式块，如果不确定，就在下标那里前置一个`\`。&lt;br>
同样的问题也出现在多行公式组里进行转行时，使用 `\\\\\`，而不是通常的 `\\\`
&lt;/p>
&lt;p>惹出这么许多不明所以的问题, 最初就是下面这个公式 (就是我所认知的、通常表达下标的普通方式，
讽刺的是：不把它们放在 &lt;code>$$&lt;/code> 数学公式块里，我还必须添加转义字符，否则渲染不出这个效果😂):&lt;/p>
&lt;p>\tag{5.59}
\theta_{ML} = \underset{\theta}{\operatorname{argmax}} \mathbb{E}_{x \sim \hat{p}_{data}}{\log p_{model} {(x^i; \theta})}&lt;/p>
&lt;p>数学公式块里表达下标的语法，无端端要添加一个前置转义字符，这就是我所没有料到的。想必应该是Hugo没有做好关于转义字符的上下文解析问题，且先将就着吧。&lt;/p></description></item><item><title>利器4: Vim 编辑器 -- 只因为在键盘之中，方向键太遥远</title><link>/posts/thecli/thevim/2022-08-13-vim8/</link><pubDate>Sat, 13 Aug 2022 21:37:59 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/thecli/thevim/2022-08-13-vim8/</guid><description>&lt;h2 id="vim-初体验" >
&lt;div>
&lt;a href="#vim-%e5%88%9d%e4%bd%93%e9%aa%8c">
#
&lt;/a>
Vim 初体验
&lt;/div>
&lt;/h2>
&lt;p>“多年以后，面对显示屏，&amp;ldquo;逃离了巨硬·仍旧愤怒·懵懂菜鸟&amp;quot;将会回想起初次尝试 Vim 编辑器
而被困在里面叫天不应叫地不灵的那个遥远的下午”。&lt;/p>
&lt;p>那时候的我（2017），是个二十多岁的青年，刚刚认识终端和 Linux 大概是怎么一回事，
感觉恰似上天给我关了那扇“窗”，自己推开了 Linux 世界的大门。
世界新生伊始，许多事物还不知其名何处，对许多“拿来主义”的命令仍旧半信半疑，
简直就是一场大冒险 (没有性命之攸的那种)。&lt;/p>
&lt;p>当我发现在文本编辑器里的光标可以用 h,j,k,l 来进行左下上右移动时，“不懂，但我大受震撼”。&lt;/p>
&lt;p>（其实就是见识少，不是所有键盘都有独立的方向键，更不是操作系统就只一个 windows
，不过我是二十好几的人了才知道这个事情，用于连的话讲就是：“啊，这是一场侮辱”。）&lt;/p>
&lt;p>虽然第一次尝试 Vim 就被抛弃到了荒岛，好在我对这样一个新奇的世界，早有心理准备。
事实证明，要适应新环境，最好的武器不过是“一点好奇心和多点耐心”。从那以后，
感觉就好像“居住在兔子皮毛深处的微生物”竭力向毛尖爬去，“以便将魔术师看个清楚”。&lt;/p>
&lt;p>终端里能用的优秀工具多得让我觉得简直“就像是在海边拣贝壳的孩子&amp;rdquo;，而 Vim 编辑器无疑是我最喜爱的那一枚。
而在海边放贝壳的无疑是那些乐于分享的同道中人，我相信真正的进步来自于分享。&lt;/p>
&lt;p>后来当我大概明白 vimrc 文件是怎么一回事之后，我第一件事就是给它加上了这一句:&lt;/p>
&lt;p>&lt;code>set mouse=&lt;/code>&lt;/p>
&lt;p>其实当时是怀着对旧日那种凡事必得“鼠标点击拖拽”宣战的忐忑心态。&lt;/p>
&lt;p>后来怎么样了？&lt;/p>
&lt;p>后来我发现，其实不怎么需要“专门腾出一只手用鼠标操控”。
如果是在终端干活，你乐意的话，那就是：根本不需要。
如果你极端点，在哪里都不需要鼠标。
除非是你另一只手在忙点别的什么，或者是老板要“麻烦”你给“赶紧”修改一篇work文档，客户在线等那种&amp;hellip;&lt;/p>
&lt;h2 id="vim-编辑器" >
&lt;div>
&lt;a href="#vim-%e7%bc%96%e8%be%91%e5%99%a8">
#
&lt;/a>
Vim 编辑器
&lt;/div>
&lt;/h2>
&lt;h3 id="vim-是干啥的" >
&lt;div>
&lt;a href="#vim-%e6%98%af%e5%b9%b2%e5%95%a5%e7%9a%84">
##
&lt;/a>
Vim 是干啥的
&lt;/div>
&lt;/h3>
&lt;p>首先应该了解： Vim 适用于什么场景？&lt;/p>
&lt;blockquote>
&lt;p>“Vim是从 vi 发展出来的一个文本编辑器。
其代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。
和Emacs并列成为类Unix系统用户最喜欢的编辑器。”&lt;/p>
&lt;/blockquote>
&lt;p>平时我在浏览中（尤其是寻找一些功能插件过程）也看到有人发博客说他/她是用 Vim 进
行“写作”的（主要是关于 $\LaTeX$, $\TeX$, markdown 的插件），但我想如果是用来进
行文学创作这一类的工作的话，重点可能不在于编辑器，很简单，还没有“电脑”的时代就
已经诞生了太多优秀作品。
（想象大佬曹雪芹面对电脑屏幕“十年删改”《红楼梦》总觉得有点荒诞，
但是就算是有电脑，这难点肯定不在于删改（编辑器无关紧要），而在于文学创造。
极有可能他根本买不起电脑。）&lt;/p>
&lt;p>反过来却不一样，至少我们这年代，没有听说哪个成功的软件产品，它的代码是用手写在草稿纸上 &amp;hellip;
怪诞的是，面试的时候倒是有不少这种要手写代码啊伪代码这种事情，我觉得这多多少少有点黑色幽默。&lt;/p>
&lt;p>简而言之，vim是个编辑器，很多人用它来写代码，也有人用它来干其他。&lt;/p>
&lt;p>随着了解深入，慢慢就会接触到诸如“编辑器之战”、“编程语言之争”这一类话题。&lt;/p>
&lt;h3 id="编辑器之战" >
&lt;div>
&lt;a href="#%e7%bc%96%e8%be%91%e5%99%a8%e4%b9%8b%e6%88%98">
##
&lt;/a>
编辑器之战
&lt;/div>
&lt;/h3>
&lt;blockquote>
&lt;p>“编辑器之战是指计算机编程领域内，
两类文本编辑器 vi（以及衍生版本）和 Emacs 用户之间的对抗冲突。
这已经成为黑客文化和自由软件社区文化的一部分。&lt;/p>
&lt;/blockquote>
&lt;p>一些 Emacs 用户说：&lt;/p>
&lt;blockquote>
&lt;p>Vi 有两个模式，“不停地哔哔叫”和“搞砸一切”。&lt;/p>
&lt;/blockquote>
&lt;p>而据 Vi 用户称：&lt;/p>
&lt;blockquote>
&lt;p>一些 Emacs 用户由于修改键过多而使用脚踏板。&lt;/p>
&lt;/blockquote>
&lt;p>一些博客博文、影视作品也都会出现这些内容场景，而且大都是轻松欢乐的场景。比如，
《硅谷》里理查德和他“简直就是踩了狗屎运”才勾搭上的漂亮女友就为了 Vim 和 Emacs
、使用 Tab 还是 Space 进行代码缩进以及缩进风格而吵了起来，继而直接闹掰，
最后以理查德秀逗了的在用身体力行进行“缩进演示”中滚下楼梯而告终。
&amp;hellip;&lt;/p>
&lt;blockquote>
&lt;p>战火在两群用户之间多次点燃，他们互相蔑视，坚信自己的选择才是最完美的。
相比其他的IT领域战争（浏览器大战、操作系统之争、编程语言之争、代码缩进风格之战
等等)，编辑器的选择其实通常只是个人问题。 ”&lt;/p>
&lt;/blockquote>
&lt;p>如果不小心也卷入了这些战争，请记住：编辑器的选择其实通常只是个人问题。&lt;/p>
&lt;p>当然，实在吵得不可开交的时候，别忘了搬出编程语言之争里那句一锤定音的话题终结语：
“PHP 才是真好的编程语言，不接受任何反驳。”&lt;/p>
&lt;p>如果想了解更多，可以去 &lt;a href="https://zh.m.wikipedia.org/zh-hans/Vim">Vim 维基词条&lt;/a>
了解更多精彩内容。如果你甚至无法访问维基百科，那不是你的错，不过你得想办法。&lt;/p>
&lt;h2 id="vim-及其配置" >
&lt;div>
&lt;a href="#vim-%e5%8f%8a%e5%85%b6%e9%85%8d%e7%bd%ae">
#
&lt;/a>
vim 及其配置
&lt;/div>
&lt;/h2>
&lt;p>如果你是想入门而还在门口徘徊的，可以先在终端 (Terminal) 里输入 &lt;code>vimtutor&lt;/code>，
然后看看你感觉如何。如果你认真追随，你会发现一切自有道理。貌似还挺好玩。
嗯，咦，怎么退出这编辑器呢？&lt;/p>
&lt;h3 id="现代码仔如何在终端界面退出vim编辑器" >
&lt;div>
&lt;a href="#%e7%8e%b0%e4%bb%a3%e7%a0%81%e4%bb%94%e5%a6%82%e4%bd%95%e5%9c%a8%e7%bb%88%e7%ab%af%e7%95%8c%e9%9d%a2%e9%80%80%e5%87%bavim%e7%bc%96%e8%be%91%e5%99%a8">
##
&lt;/a>
现代码仔如何在终端界面退出vim编辑器
&lt;/div>
&lt;/h3>
&lt;p>如果你和我当初一样一头雾水&amp;hellip; 淡定淡定，输入 &lt;code>:q&lt;/code> ，按下 &lt;code>Enter&lt;/code> 即可退出。&lt;/p>
&lt;p>嗯，如果你正在输入，需要先按下 &lt;code>Esc&lt;/code>，然后输入 &lt;code>:q&lt;/code> 来退出。&lt;/p>
&lt;p>这个操作也不好使？八成你是在别的模式里，比如 &lt;code>Ex mode&lt;/code>，
八成它也会提示你输入 &lt;code>visual&lt;/code> 来返回到 &lt;code>normal mode&lt;/code>。&lt;/p>
&lt;p>如果不是这种情况，极有可能是你不小心按了 &lt;code>q&lt;/code> 进入命令录制，
通常要是你多按几次 &lt;code>q&lt;/code> 来观察，会发现有 &lt;code>recording @&lt;/code> 的提示，
这就是多命令录制无疑，重复操作：输入 &lt;code>:q&lt;/code> ，按下 &lt;code>Enter&lt;/code> 即可退出。&lt;/p>
&lt;p>如果都不是，并且“他X的按什么也没用”，先检查一下你的机器是否还在正常工作，
是，则重复以下操作：输入 &lt;code>:q&lt;/code>，按下 &lt;code>Enter&lt;/code>。&lt;/p>
&lt;p>如果你所有好奇心还没有被消耗殆尽，我来告诉你一个好消息：
vim 共有 &lt;a href="https://en.wikipedia.org/wiki/Vim_(text_editor)">12种模式&lt;/a>。&lt;/p>
&lt;p>这确实是个新世界。&lt;/p>
&lt;h2 id="vimrc" >
&lt;div>
&lt;a href="#vimrc">
#
&lt;/a>
vimrc
&lt;/div>
&lt;/h2>
&lt;p>应当注意：从第一次在终端输入 &lt;code>vim&lt;/code> 到开始了解和使用自己配置的 &lt;code>.vimrc&lt;/code>，
从前者到后者，每个人所经历的时间不太一样，毕竟每个人的生活和目的千差万别。
（倒不是说，刚开始使用 vim 就不能直接上手个人配置，而是想说明，
“步子迈大了，容易扯着蛋”；一旦放弃了探索和思考，容易一碰挫折就十分沮丧。）
但在很多文章里，这两者之间多半就是一个空行的距离。
（因此我决定在这个空行之前添加一点说明，以下的内容新手初看时不太明白实属正常）&lt;/p>
&lt;p>Vim 如此受欢迎，它的丰富的插件生态应该是一个重要的原因。为什么有这么多插件呢？
因为有这么多的需求。因为有那么多的插件，所以有了要管理插件（更新、删除等）的
插件。使用比较广泛的有：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/junegunn/vim-plug">vim-plug&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/VundleVim/Vundle.vim">Vundle&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/tpope/vim-pathogen">Pathogen&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/k-takata/minpac">minpac&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>它们的安装和使用条件都在各自的主页有详细说明，这里不再搬运。那到底用哪个呢？
你在阅读他们的说明的时候自己就会有答案，如果还是难以决定，我的建议就是像八戒
所说的那样：“待俺老猪一家家吃将去！”。（我自己嘛，吃过了三家）&lt;/p>
&lt;p>从 vim8.0 开始，vim 自带插件管理的功能特性（实际上，前述的 &lt;code>minpac&lt;/code> 就利用了
这些特性），我仅在这个功能出来的时候尝过新（满足好奇心而已，浅尝辄止），
因为已经习惯了所用的管理插件的插件：）(更新：后来我改变了主意)&lt;/p>
&lt;p>如果说管理插件的插件可以由 vim 自带的功能所提供，那么，有多少插件是必须的呢？&lt;/p>
&lt;p>有人作了很好的总结：
&lt;a href="https://thoughtbot.com/blog/how-to-do-90-of-what-plugins-do-with-just-vim">How to Do 90% of What Plugins Do (With Just Vim)&lt;/a>&lt;/p>
&lt;p>如果你崇尚极简主义，值得一试。（不是说就一定要如此，而是知道有的选择）&lt;/p>
&lt;p>这里提到的应该都理解为是“别人的”个人配置，而所谓“个人配置”，基本意思就是：
走过路过，可以随便错过。
看到钟意的，拿走不谢。看到不爽的，请去Pull Request，切勿乱喷粪。&lt;/p>
&lt;p>大佬&lt;a href="https://en.wikipedia.org/wiki/Linus_Torvalds">林纳斯·托瓦兹&lt;/a>早就看透了那些到处乱喷的键盘侠，他的至理名言说明了一切：&lt;/p>
&lt;blockquote>
&lt;p>&amp;ldquo;On the Internet, talk is cheap, show me the code.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;h2 id="vimrc-vimrc" >
&lt;div>
&lt;a href="#vimrc-vimrc">
#
&lt;/a>
vimrc (~/.vimrc)
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-vim" data-lang="vim">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34; ================================Part-1: Plugins============&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>call plug#begin(&lt;span style="color:#5af78e">&amp;#39;~/.vim/bundle&amp;#39;&lt;/span>) &lt;span style="color:#78787e">&amp;#34; reuse the bundle dir&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== tmux ===-------------------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;christoomey/vim-tmux-navigator&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; vim &amp;lt;-&amp;gt; tmux, pane dance&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;edkolev/tmuxline.vim&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; status line&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Coding enhancement ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;airblade/vim-gitgutter&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; shows git diff sign and more&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;tpope/vim-fugitive&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; awsome git wrapper!&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;tpope/vim-repeat&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; enhance . repeat&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;dense-analysis/ale&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; linters config&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;mileszs/ack.vim&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; cherrypick your strings&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;junegunn/fzf&amp;#39;&lt;/span>, { &lt;span style="color:#5af78e">&amp;#39;do&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;./install --all&amp;#39;&lt;/span> } | Plug &lt;span style="color:#5af78e">&amp;#39;junegunn/fzf.vim&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Python enhancement ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; Plug &amp;#39;Valloric/YouCompleteMe&amp;#39; &amp;#34; for completion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;davidhalter/jedi-vim&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; python auto-completion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Wiki/markdown enhancement ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;vimwiki/vimwiki&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; for personal wiki&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;mzlogin/vim-markdown-toc&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; for table_of_content&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;plasticboy/vim-markdown&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; couple with vim-instant-markdown&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;instant-markdown/vim-instant-markdown&amp;#39;&lt;/span>, {&lt;span style="color:#5af78e">&amp;#39;for&amp;#39;&lt;/span>: [&lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;markdown.pandoc&amp;#39;&lt;/span>]}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Latex support ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;lervag/vimtex&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; for LaTeX files&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;xuhdev/vim-latex-live-preview&amp;#39;&lt;/span>, { &lt;span style="color:#5af78e">&amp;#39;for&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;tex&amp;#39;&lt;/span> } &lt;span style="color:#78787e">&amp;#34; Lively Previewing&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Julia lang ===-------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;JuliaEditorSupport/julia-vim&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== for GnuPG ===-----------------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;jamessan/vim-gnupg&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; transparent editting .gpg files&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== Code/Project navigation ===-------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;easymotion/vim-easymotion&amp;#39;&lt;/span> &lt;span style="color:#78787e">&amp;#34; quickly move&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;preservim/nerdtree&amp;#39;&lt;/span>, { &lt;span style="color:#5af78e">&amp;#39;on&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;NERDTreeToggle&amp;#39;&lt;/span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34;-------------------=== local plugins (manually install and update) ===-----&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e">&amp;#34; &amp;#34; 中文跳转 (easymotion-like)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;~/.vim/bundle/vim-PinyinSearch&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>call plug#end() &lt;span style="color:#78787e">&amp;#34; required&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装和使用 vim-plug 的步骤：&lt;/p>
&lt;ol>
&lt;li>下载并保存到 &lt;code>~/.vim/autoload/&lt;/code> 目录下 （在终端操作）&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>curl -fLo ~/.vim/autoload/plug.vim --create-dirs &lt;span style="color:#5af78e">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">&lt;/span> https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>配置 &lt;code>~/.vimrc&lt;/code> 文件的相应内容（必须遵循的格式）：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>call plug#begin&lt;span style="color:#ff6ac1">(&lt;/span>&lt;span style="color:#5af78e">&amp;#39;~/.vim/bundle&amp;#39;&lt;/span>&lt;span style="color:#ff6ac1">)&lt;/span> &lt;span style="color:#5af78e">&amp;#34; reuse the bundle dir
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5af78e">Plug &amp;#39;tpope/vim-fugitive&amp;#39; &amp;#34;&lt;/span> awsome git wrapper!
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>call plug#end&lt;span style="color:#ff6ac1">()&lt;/span> &lt;span style="color:#5af78e">&amp;#34; required
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 &lt;code>plug#begin()&lt;/code> 和 &lt;code>plug#end()&lt;/code> 之间就是你想要安装和管理的插件的列表。
&lt;code>Plug 'tpope/vim-fugitive'&lt;/code> 就是指明想要安装并管理 vim-fugitive 这个插件。&lt;/p>
&lt;p>如果 &lt;code>plug#begin()&lt;/code> 括弧里为空，则默认是奖所有的插件安装到 &lt;code>.vim/plugged/&lt;/code>，
上文的我的配置中，我是指定了 &lt;code>.vim/bundle&lt;/code> 作为插件的目录
（因为我在使用 vim-plug 之前就已经在这个目录下存放了许多插件，简单复用而已）。&lt;/p>
&lt;p>vim-plug 会自动执行以下两个命令（许多插件需要这两个设定）：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>filetype indent on&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>syntax enable&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>如果你发现自己“完全”按照官方的指南进行安装，可是“插件死活不起作用”，极有可能是
因为你在某个地方设置了完全相反的设定（因为从别的地方 copy 一大段自己没有认真看
过的内容到自己的 .vimrc 文件里）。&lt;/p>
&lt;hr>
&lt;p>更详细的使用方法应该直接去 &lt;a href="https://github.com/junegunn/vim-plug">vim-plug&lt;/a>
的主页了解，那里不仅告诉大家应该怎么安装此插件，还给出各种情况的说明和例子。&lt;/p>
&lt;hr></description></item><item><title>利器1: Oh, My Tmux -- 键盘驱动(为主)的工作流</title><link>/posts/thecli/2022-08-07-tmux/</link><pubDate>Sun, 07 Aug 2022 21:17:59 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/thecli/2022-08-07-tmux/</guid><description>&lt;h2 id="tmuxhttpsgithubcomtmuxtmux" >
&lt;div>
&lt;a href="#tmuxhttpsgithubcomtmuxtmux">
#
&lt;/a>
&lt;a href="https://github.com/tmux/tmux">Tmux&lt;/a>
&lt;/div>
&lt;/h2>
&lt;p>&lt;a href="https://github.com/tmux/tmux">Tmux&lt;/a> 是一个终端多路复用器&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>：&amp;hellip;&lt;/p>
&lt;blockquote>
&lt;p>Tmux is a terminal multiplexer: it enables a number of terminals to be
created, accessed, and controlled from a single screen. tmux may be detached
from a screen and continue running in the background, then later reattached.&lt;/p>
&lt;/blockquote>
&lt;p>那到底什么是&lt;ruby>“终端”&lt;rt>terminal&lt;/rt>&lt;/ruby>？&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> 我回答不了这个问题，但我发现了一个很好的解释 &amp;ndash;
&lt;a href="https://unix.stackexchange.com/questions/4126/what-is-the-exact-difference-between-a-terminal-a-shell-a-tty-and-a-con">terminal&lt;/a>&lt;/p>
&lt;p>突然想起《统计学》关于“卡方检验”那一章的经典导语：&lt;/p>
&lt;blockquote>
&lt;p>不要问它的含义，宁可问如何使用它。&amp;ndash; 维特根斯坦&lt;/p>
&lt;/blockquote>
&lt;p>本着“拿来主义”精神，那就来粗略看看 Tmux 能如何使用吧：&lt;/p>
&lt;p>&lt;img alt="IMG_MyTmux &amp;ndash; (gif 失效)" src="https://fgg100y.github.io/img/posts/tmux/ssr_myTmuxDemo.gif">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>启动 Termainal (CTRL+Enter, 这是个人定义的快捷键)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>启动 Tmux 进入我的工作环境 (须知：我这里展示的不是初始化的 Tmux 启动)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>检查一下昨天写的博客写到哪里了 (貌似差不多了，写其他内容)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>切换到下一场“会话”(session) &amp;ndash; vimwiki (这里是我个人项目根目录)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>按进度今天应该介绍一下 Tmux 这个工具 (然后，就到这里了)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>现在阳光明媚（过一会儿就变毒辣），白天还是换到白色背景合适些&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;del>搬砖滴干活咯各位&lt;/del>&lt;br>
&lt;del>嗯，干活？更像是创作&lt;/del>&lt;br>
&lt;del>创作？这算哪门子的&amp;hellip;&lt;/del>&lt;br>
所以还是，干点活吧 ：）&lt;/p>
&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="tmux-的一些关键配置" >
&lt;div>
&lt;a href="#tmux-%e7%9a%84%e4%b8%80%e4%ba%9b%e5%85%b3%e9%94%ae%e9%85%8d%e7%bd%ae">
#
&lt;/a>
Tmux 的一些关键配置
&lt;/div>
&lt;/h2>
&lt;p>如果还没有安装 Tmux，命令行中安装起来也不费事 (Debian系列)：&lt;code>apt install tmux&lt;/code>&lt;/p>
&lt;p>以下的内容均围绕 &lt;code>~/.tmux.conf&lt;/code> 文件展开。如果没有就自己创建一个这文件。
默认这些代码框里的内容（等宽字体那些）是要添加到 &lt;code>~/.tmux.conf&lt;/code> 文件里。&lt;/p>
&lt;p>&amp;ldquo;#&amp;rdquo; 开头的语句是注释说明&lt;br>
&amp;ldquo;$&amp;rdquo; 开头的语句是要在命令行运行的命令&lt;br>
&amp;ldquo;:command&amp;rdquo; 以“冒号接命令名”开头的语句是要在vim命令模式运行的命令&lt;/p>
&lt;h2 id="默认快捷键修改-ctrl-b---ctrl-a" >
&lt;div>
&lt;a href="#%e9%bb%98%e8%ae%a4%e5%bf%ab%e6%8d%b7%e9%94%ae%e4%bf%ae%e6%94%b9-ctrl-b---ctrl-a">
#
&lt;/a>
默认快捷键修改: Ctrl-b -&amp;gt; Ctrl-a
&lt;/div>
&lt;/h2>
&lt;p>Tmux 的默认快捷键是 &lt;code>ctrl-b&lt;/code>，这在键盘上距离略微有点远 (对于我的短手指来说)，
因此我把它修改为 &lt;code>ctrl-a&lt;/code> 组合键。&lt;/p>
&lt;p>将下面语句加入 .tmux.conf 文件：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">set&lt;/span> -g prefix C-a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># # unbind the C-b&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>unbind C-b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># # ensure that we can send Ctrl-a to other apps (e.g., vim)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">bind&lt;/span> C-a send-prefix
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># # setting the delay between prefix and command&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">set&lt;/span> -s escape-time &lt;span style="color:#ff9f43">1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>既然是要用快捷键，那么重新加载 .tmux.conf 文件的自然也安排上：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># reload the .tmux.conf file with Prefix-r&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">bind&lt;/span> r source-file ~/.tmux.conf &lt;span style="color:#5af78e">\;&lt;/span> display &lt;span style="color:#5af78e">&amp;#34;tmuxconf reloaded!&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后，在命令行直接输入快捷组合键：&lt;code>Ctrl+a+r&lt;/code> 即可使配置生效 (&lt;code>+&lt;/code>号的意思是同时摁下)。&lt;/p>
&lt;h2 id="vimtmux-强强组合" >
&lt;div>
&lt;a href="#vimtmux-%e5%bc%ba%e5%bc%ba%e7%bb%84%e5%90%88">
#
&lt;/a>
vim/tmux 强强组合
&lt;/div>
&lt;/h2>
&lt;p>Tmux 支持多个终端窗格 (terminal panes)，每个窗格都是独立的终端，
因此，最明显的事情就是，你可以同时在一块屏幕上“监控”多个不同任务，意思是，
这些不同的任务在视觉上是“同时”呈现的（相对于重叠的 标签页(tab) 而言）。&lt;/p>
&lt;p>如果你恰好也喜欢用 vim 进行码字，也打开了 vim 编辑器 (vim 本身也有窗格功能)，
自然而然的，你肯定想以相同的快捷键来实现不同的 vim/tmux 窗格之间的切换。&lt;/p>
&lt;p>幸运的是，已经有人实现了这样的功能，并共享了，这就是
&lt;a href="https://github.com/christoomey/vim-tmux-navigator">vim-tmux-navigator&lt;/a>.&lt;/p>
&lt;p>vim 有丰富的插件生态，这是 vim 强大生命力的一个体现。
这么好的模式，自然值得借鉴。因此，tmux 也有一个用来管理插件的
&lt;a href="https://github.com/tmux-plugins/tpm">tpm&lt;/a>.&lt;/p>
&lt;p>需要在 vim 和 tmux 两个方面进行配置：&lt;/p>
&lt;ol>
&lt;li>在 vim 方面, 将以下语句加入 .vimrc 文件：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 如果你用的是 Vim-Plug 插件管理器的话&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Plug &lt;span style="color:#5af78e">&amp;#39;christoomey/vim-tmux-navigator&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后运行 &lt;code>:PlugInstall&lt;/code> 来安装这个插件。&lt;/p>
&lt;p>如果你是第一次配置 vim 插件，先去了解
&lt;a href="https://github.com/junegunn/vim-plug">Vim-Plug&lt;/a>.&lt;/p>
&lt;ol start="2">
&lt;li>在 tmux 方面，将下面语句加入 .tmux.conf 文件：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># tpm is a tmux-plugin manager. [details in its github repos]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">set&lt;/span> -g @plugin &lt;span style="color:#5af78e">&amp;#39;tmux-plugins/tpm&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># vim-tmux-navigator: Seamless navigation between tmux panes and vim splits&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">set&lt;/span> -g @plugin &lt;span style="color:#5af78e">&amp;#39;christoomey/vim-tmux-navigator&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># put this &amp;#39;run&amp;#39; command to the very end of .tmux.conf, says the tpm&amp;#39;s readme&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>run &lt;span style="color:#5af78e">&amp;#39;~/.tmux/plugins/tpm/tpm&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>加入这些内容之后，重新加载 tmux 环境, (在已经启动tmux的命令行运行以下命令)：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ tmux &lt;span style="color:#ff5c57">source&lt;/span> ~/.tmux.conf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="主题背景颜色切换" >
&lt;div>
&lt;a href="#%e4%b8%bb%e9%a2%98%e8%83%8c%e6%99%af%e9%a2%9c%e8%89%b2%e5%88%87%e6%8d%a2">
#
&lt;/a>
主题背景颜色切换
&lt;/div>
&lt;/h2>
&lt;p>在我的印象里，感觉黑色/暗色系一下子成了很多应用软件的默认背景色，
我在命令行过活很多年了，对此很是习惯，个人很少看到谁的Terminal是白色背景的。
主要应该是：1）配置了白天黑夜都友好的主题；2）不当回事儿。
但有时候，特别是光线充足的时候，我比较喜欢白色的背景。
所以，我需要能随心所欲切换背景色调。&lt;/p>
&lt;p>这个貌似没法不依赖于外部脚本来实现，至少我没有发现可行的办法。因此，你也需要
&lt;a href="https://www.seanh.cc/2021/01/02/change-between-light-and-dark-themes-in-tmux/">去下载这个脚本&lt;/a>&lt;/p>
&lt;p>Linux 环境氛围是这样的，不要盲目相信别人写的脚本，特别是那些你不认识的人。
相信开源和相信陌生人，毕竟不是同一件事。
意思就是，你在使用这些脚本之前好歹也要看看人家到底写了什么吧。
特别是这种都不超过一页内容的脚本。&lt;/p>
&lt;p>什么？你说你看不懂。事实是，没有人在一开始就什么都看得懂。比如说，
你看到脚本里有这么一句类似于windows上“清理垃圾”的命令： &lt;code>sudo rm -rf /*&lt;/code>，
那你就要保持警惕了。
据说，有些系统会阻止你这么干，但有些系统会“开心地”执行你的旨意；
反正我没试过，我也没有以任何方式暗示或鼓励你要这么清理系统垃圾。&lt;/p>
&lt;p>如果说你下载了那个脚本，放到你喜欢它待的位置，比如说， &lt;code>~/.tmux/bin/&lt;/code>，
然后将下面这条语句加入 &lt;code>~/.tmux.conf&lt;/code> 文件中。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">bind&lt;/span> T run-shell ~/.tmux/bin/toggle-theme
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="关于配置和插件以及管理插件的插件" >
&lt;div>
&lt;a href="#%e5%85%b3%e4%ba%8e%e9%85%8d%e7%bd%ae%e5%92%8c%e6%8f%92%e4%bb%b6%e4%bb%a5%e5%8f%8a%e7%ae%a1%e7%90%86%e6%8f%92%e4%bb%b6%e7%9a%84%e6%8f%92%e4%bb%b6">
#
&lt;/a>
关于配置和插件以及管理插件的插件
&lt;/div>
&lt;/h2>
&lt;p>以上内容分别对应着：&lt;/p>
&lt;p>1）直接对 tmux 进行基本配置；&lt;/p>
&lt;p>2）使用 tmux 插件管理器对 tmux 进行配置；&lt;/p>
&lt;p>3）借用 脚本程序 对 tmux 进行配置。&lt;/p>
&lt;p>毕竟，不是每个人都热衷于使用插件管理器，插件和主件之间的交互方式并不设限。你可以选择使用你觉得合适的方法来完成任务。
要是觉得现有的都不满意，无法满足你的特殊需求，手痒痒的，那就自己搞一个。
很多优秀的软件都是如此，它提供足够好的默认值，但也提供足够多的灵活性，让用户有的选。&lt;/p>
&lt;p>刘建明说“以前没的选，现在想选回做好人，给个机会”，陈永仁答“去同法官讲”。“有的选”这一点十分可贵。&lt;/p>
&lt;hr>
&lt;p>Last update: 2024-07-04&lt;/p>
&lt;blockquote>
&lt;p>USER: Tmux 是什么？
GPT4o: Tmux 是一个终端多路复用器 (terminal multiplexer)，允许用户在一个终端窗口内运行和管理多
个终端会话。它提供了一种方便的方法来分割一个物理终端窗口成多个虚拟终端，并在这些虚拟终端
之间自由切换。Tmux 的主要功能包括：&lt;/p>
&lt;ul>
&lt;li>会话管理：Tmux 可以创建、分离和重新附加会话，使用户可以在不同的终端会话之间快速切换。&lt;/li>
&lt;li>窗口分割：用户可以在一个Tmux会话中将窗口分割成多个窗格，每个窗格可以独立运行一个命令行程序。&lt;/li>
&lt;li>持久性：即使终端窗口关闭，Tmux 会话仍然会保持运行，这样用户可以稍后重新附加会话，继续工作。&lt;/li>
&lt;li>可定制性：Tmux 提供了丰富的配置选项和快捷键，用户可以根据自己的需求进行定制。&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>而如今，或许应该问问GPT4o&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>想知道怎么像这样标注名词吗？去看看&lt;a href="https://www.junyi.dev/posts/a-writing-trick/">这篇博文&lt;/a>&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>利器2: Vimwiki 之 安装和适配数据科学的一些配置</title><link>/posts/thecli/thevim/2022-07-15-vimwiki_part2/</link><pubDate>Sat, 06 Aug 2022 23:33:32 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/thecli/thevim/2022-07-15-vimwiki_part2/</guid><description>&lt;p>Last update: 2022-08-06 23:33:32&lt;/p>
&lt;h2 id="vimwiki-插件简介安装和一些设置" >
&lt;div>
&lt;a href="#vimwiki-%e6%8f%92%e4%bb%b6%e7%ae%80%e4%bb%8b%e5%ae%89%e8%a3%85%e5%92%8c%e4%b8%80%e4%ba%9b%e8%ae%be%e7%bd%ae">
#
&lt;/a>
vimwiki 插件简介、安装和一些设置
&lt;/div>
&lt;/h2>
&lt;p>在 vimwiki 里，所有的入口集中在指定的项目根目录下的 index.md 文档里。也就是要构
建的整个笔记系统（随便管它叫什么），index.md 可以成为它的整体框架以及各个主题的
索引。从这里可以去到各个主题，从各个主题的索引去到对应的内容，也可以从一个内容
去到另一个内容，内容可以是本地文档内/文档间，这完全取决于如何构建内容之间的连接。&lt;/p>
&lt;p>vimwiki 提供了必要的基础。但通常我们要写的文档并不是纯文本 (plain text) 而是带有
修饰语法的文本，比如 markdown, Tex/Latex 格式的文档。这两者的区别在于，前者是“
所见即所得”，意思就是你写出来的内容和最后呈现的内容一模一样；后者则更像是写代码，
最后呈现出来的和所写的内容一致（但大部分时候不会一模一样），有人称之为
“所想即所得”，听起来有点玄乎。直接用 plain text 格式不就完了，折腾这些干嘛？遗憾
的是，只要你想要写一些复杂一点的数学公式（求导的链式法则），那么，没有专门的编辑
器的话，最快能够得到规范的数学公式的方法就是 &amp;ndash; 手写。教科书内那些数学公式的呈现
效果基本都来自排版系统工具（Tex/Latex等）的支持。&lt;/p>
&lt;p>如果工作的内容涉及到较多的高等数学，并想自己编写的日志博客得到类似教科书式的数学
公式呈现，markdown 文档是相当友好的文本格式，而从 markdown 到最终效果的呈现之间，
需要我们作一些&lt;a href="https://fgg100y.github.io/posts/thecli/thevim/2022-07-15-vimwiki_part2/###数学公式的呈现">额外配置&lt;/a>。&lt;/p>
&lt;p>现在我只需要用 mardown 格式编写内容，在本地链接的文字上敲击回车键(命令模式下)，
就可以打开这个本地链接的内容文档，然后编辑内容或者发呆或者别的什么，敲击 Delete
键(命令模式下)回到之前跳转来的地方；当然也可以设置和使用其他组合键来去到其他地
方。在每个地方，都可以用浏览器展示当前文档的内容的最终呈现效果，比如使用默认的
&lt;code>&amp;lt;leader&amp;gt;+w+h+h&lt;/code> 快捷键就能在你的默认浏览器展示当前文档的内容，数学公式正是课本
上的那种它该有的样子，也可以像浏览百科网页时那样，自由跳转，来去自如。&lt;/p>
&lt;p>闲话少叙，直接上手。&lt;/p>
&lt;h3 id="安装-vimwiki-插件" >
&lt;div>
&lt;a href="#%e5%ae%89%e8%a3%85-vimwiki-%e6%8f%92%e4%bb%b6">
##
&lt;/a>
安装 vimwiki 插件
&lt;/div>
&lt;/h3>
&lt;p>(使用管理插件的 &lt;a href="https://github.com/junegunn/vim-plug">Vim-Plug&lt;/a> 插件来安装和管理)&lt;/p>
&lt;p>将下面的语句加入你自己的 vim 配置文件中，&lt;/p>
&lt;p>&lt;code>Plug 'vimwiki/vimwiki'&lt;/code>&lt;/p>
&lt;p>然后运行命令 &lt;code>:PlugInstall&lt;/code>&lt;/p>
&lt;p>如果你还不清楚这是什么意思，搜索: vimrc 或者 &lt;a href="https://vim.fandom.com/wiki/Open_vimrc_file">点击这里&lt;/a>&lt;/p>
&lt;h3 id="配置-vimwiki-插件" >
&lt;div>
&lt;a href="#%e9%85%8d%e7%bd%ae-vimwiki-%e6%8f%92%e4%bb%b6">
##
&lt;/a>
配置 vimwiki 插件
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>markdwon 格式&lt;/li>
&lt;/ul>
&lt;p>vimwiki 默认使用 .wiki 格式，但这个格式的语法没有 markdown 语法使用的广泛和普遍,
所以我个人是更倾向于使用 markdown 格式来编写文档。可以按照下面的做法进行相应配置：
将下面的语句加入 &lt;code>.vimrc&lt;/code>:&lt;/p>
&lt;p>&lt;code>let g:vimwiki_ext2syntax={'.md': 'markdown', '.markdown': 'markdown', '.mdown': 'markdown', '.rmd': 'markdown'}&lt;/code>&lt;/p>
&lt;p>这是几个较为常见的 markdown 文档的后缀，最后一种 &lt;code>rmd&lt;/code> 是 Rmardown 格式后缀。&lt;/p>
&lt;ul>
&lt;li>多个 index.md 文档&lt;/li>
&lt;/ul>
&lt;p>前面提到过，index.md 是 vimwiki 的默认入口，类似于一本书的主目录，或者电子菜单。
通常我们需要多个菜单，每个主题配一个菜单，从而使得内容更精简和自洽，而不是所有
的内容全都汇集并拥挤在同一个地方。在顶级菜单，只需要给出到各个主题的链接即可。
就像大饭店的电子菜单，客人对川菜感兴趣就点击“川菜”的目录即可，但没有必要将八大
菜系所有菜名全都拥挤到一个主菜单上。&lt;br>
同上，将下面的语句加入到 &lt;code>.vimrc&lt;/code> &lt;br>
(不要直接复制粘贴，然后指望它就马上见效 🙄 因为你的目录不会/也不需要和我的相同):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-vim" data-lang="vim">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">let&lt;/span> g:vimwiki_list = [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;index&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;index&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;path_html&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimwikiHtml&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;template_ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.html&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;template_default&amp;#39;&lt;/span>:&lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;template_path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/template/&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ &lt;span style="color:#5af78e">&amp;#39;custom_wiki2html&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/wiki2html.sh&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/LinuxTools&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/LinuxTools/vim8&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/LinuxTools/CLIs&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing/Julia&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing/Latex&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing/Python&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ {&lt;span style="color:#5af78e">&amp;#39;path&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;~/VimWiki/Programing/ShellScripts&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;syntax&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;markdown&amp;#39;&lt;/span>, &lt;span style="color:#5af78e">&amp;#39;ext&amp;#39;&lt;/span>: &lt;span style="color:#5af78e">&amp;#39;.md&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> \ ]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在上面这个例子中，每一个花括号的内容其实就是对应一个主题的菜单 (index.md)，根据
vimwiki 的默认快捷键, 比如， &lt;code>2&amp;lt;leader&amp;gt;ww&lt;/code> 就会直接打开 &lt;code>~/Vimwiki/LinuxTools/index.md&lt;/code> 这个文件。
那么，和以上的设置对应的目录结构是怎么样的呢？以下就是我个人 vimwiki 目录结构 (使用命令 &lt;code>tree -L 2&lt;/code>):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── index.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── LinuxTools
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── commonCommandLines.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── images
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── index.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── jupyterWithDSKernels.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── linux_oracle_client_sqlplus_install_and_connection_setup.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── linux_sqlserver_sqlcmd_install_and_connection_setup.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── newBashConfig.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── python_packages_management.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── tmux.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── vim8.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   └── vimwiki.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── mathjax
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── bower.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── composer.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── CONTRIBUTING.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── es5
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── LICENSE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── package.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   └── README.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── myvimwikidir.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── Programming
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── index.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── Julia
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── Latex
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── Python
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   └── ShellScripts
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── Session.vim
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── template
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   ├── default.html
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>│   └── markdown.html
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>└── wiki2html.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如前所述，根目录的 &lt;code>index.md&lt;/code> 是顶级主菜单，从这个文件内跳转到各个子主题。比如，
我个人感兴趣的、一直在学习的3大主题分别是：机器学习（未列出），编程和Linux工具。
而在 Programming 这个目录下的 &lt;code>index.md&lt;/code> 就是这个主题的主菜单，显然，这个主题
下还有‘Julia’，‘Latex’，‘Python’，‘ShellScripts’等几个内容。不用说，还可以设计
更细分的内容。每个主题都足够我喝上几壶的了 🍻 。毕竟，谁又说了构建比较完整的
知识体系是一朝一夕能完成的呢？正所谓，志不强者智不达。&lt;/p>
&lt;p>而 mathjax 目录，正是想要展现数学公式效果所依赖的本地包，接下来就讲这个的配置。&lt;/p>
&lt;h3 id="数学公式的呈现" >
&lt;div>
&lt;a href="#%e6%95%b0%e5%ad%a6%e5%85%ac%e5%bc%8f%e7%9a%84%e5%91%88%e7%8e%b0">
##
&lt;/a>
数学公式的呈现
&lt;/div>
&lt;/h3>
&lt;p>&lt;code>vimwiki2html&lt;/code> 命令和 &amp;ldquo;mathjax&amp;rdquo; 目录&lt;/p>
&lt;p>vimwiki 自带了一个 &lt;code>vimwiki2html&lt;/code> 命令，顾名思义，就是把 mardown/wiki 格式的源
文档转换成 html 格式的文档。但这个命令并不支持数学公式的渲染，得改造。这正是
&lt;a href="https://www.mathjax.org/">mathjax&lt;/a> 闪亮登场的地方。已经有人把 &lt;code>vimwiki2html&lt;/code>
命令所依赖的脚本作了相应的&lt;a href="https://gist.github.com/enpassant/0496e3db19e32e110edca03647c36541">升级版&lt;/a>，
它能将 markdown 文件转换为 html 文件，并支持数学公式的渲染。有些人走的&lt;a href="https://gist.github.com/maikeldotuk/54a91c21ed9623705fdce7bab2989742">更远&lt;/a>
但他们均假设没有所谓的什么“外网”访问限制云云。所以，还需要一点折中操作，那就是
‘本地化’。先哲说‘山不过来，我走过去’。网络时代刚好相反，既然访问不到，那就把它
复制回来（基本前提是开源，嗯，伟大的开源）。&lt;/p>
&lt;p>所谓本地化，就是：1）把 mathjax 复制到本地；2）配置 vimwiki 的命令脚本找到它。
以下是具体操作：&lt;/p>
&lt;ol>
&lt;li>在 vimwiki 的根目录下，执行以下命令：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>git clone https://github.com/mathjax/MathJax.git mathjax&lt;span style="color:#5af78e">`&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>下载并更改 &lt;code>wiki2html.sh&lt;/code> 文件的以下内容
(# 号开头的语句是被注释掉的原文，以备参考):&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># HAS_MATH=$(grep -o &amp;#34;\$\$.\+\$\$&amp;#34; &amp;#34;$INPUT&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># if [ ! -z &amp;#34;$HAS_MATH&amp;#34; ]; then&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># MATH=&amp;#34;--mathjax=https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># else&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># MATH=&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># fi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">HAS_MATH&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">$(&lt;/span>grep -o &lt;span style="color:#5af78e">&amp;#34;\$\$*\+\$\$&amp;#34;&lt;/span> &lt;span style="color:#5af78e">&amp;#34;&lt;/span>&lt;span style="color:#ff5c57">$INPUT&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&lt;/span>&lt;span style="color:#ff6ac1">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#78787e"># # load mathjax from local copy (in case the CDN not work)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> &lt;span style="color:#ff6ac1">[&lt;/span> -n &lt;span style="color:#5af78e">&amp;#34;&lt;/span>&lt;span style="color:#ff5c57">$HAS_MATH&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&lt;/span> &lt;span style="color:#ff6ac1">]&lt;/span>; &lt;span style="color:#ff6ac1">then&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">MATH&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;--mathjax=path2your-mathjax/es5/tex-chtml.js?config=TeX-AMS-MML_HTMLorMML&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">else&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff5c57">MATH&lt;/span>&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">fi&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意：&amp;ldquo;path2your-mathjax&amp;rdquo; 应该修改成你自己的路径，
比如我的路径是这样的：&amp;rsquo;/home/myacct/VimWiki/mathjax/es5/'&lt;/p>
&lt;p>我不太懂 html，我在这里的诉求就是能让转换后的 html 文档正常显示数学公式。
但后来发现，要实现这个目标，其实不一定非得先转换成 html 文件。&lt;/p>
&lt;h2 id="markdown-文档的即时展示-vim-instant-markdown" >
&lt;div>
&lt;a href="#markdown-%e6%96%87%e6%a1%a3%e7%9a%84%e5%8d%b3%e6%97%b6%e5%b1%95%e7%a4%ba-vim-instant-markdown">
#
&lt;/a>
markdown 文档的即时展示: &lt;code>vim-instant-markdown&lt;/code>
&lt;/div>
&lt;/h2>
&lt;p>前面说过，大部分的 markdown 并非“所见即所得”，但如果一个人的欲望正常，通常都想
要看看正在写的内容到底是什么显示效果，毕竟，早发现早治疗嘛（一气呵成的爽文自然
是有，但我更相信优秀的作品通常是修改出来的）。当然，早就有人把这种正常不过的
需求实现并共享了，那就是： &lt;a href="https://github.com/instant-markdown/vim-instant-markdown">vim instant markdown&lt;/a>
这也是一个 Vim 的插件，具体的安装和配置也简便，直接根据其 readme 文件进行即可。&lt;/p>
&lt;p>但其实“每改一个字就刷新一次”和“写完了所有内容才看上一眼最终效果”一样不甚妥贴，
前者使人分心，后者使人担心。因此，当想要检查某个段落（尤其是包含许多数学公式
的段落）的呈现效果时，调用命令 &lt;code>InstantMarkdwonPreview&lt;/code> ，停用则 &lt;code>InstantMarkdwonStop&lt;/code>。
我很喜欢这种快速反应，有仇就报，当场就报；知错就改，善莫大焉。
但如果觉得白纸黑字的预览网页版面过于朴素不够滋味，那么，可能你需要的是一个能够自定义的网页。&lt;/p>
&lt;h2 id="markdown-文档的即时展示-jekyll-site" >
&lt;div>
&lt;a href="#markdown-%e6%96%87%e6%a1%a3%e7%9a%84%e5%8d%b3%e6%97%b6%e5%b1%95%e7%a4%ba-jekyll-site">
#
&lt;/a>
markdown 文档的即时展示: jekyll-site
&lt;/div>
&lt;/h2>
&lt;p>&lt;code>vim-instant-markdown&lt;/code> 展示的就是文档的呈现内容，也仅仅就是内容而已。如果想要
更多，那么，备选方案就是静态网站生成器（如&lt;a href="https://jekyllrb.com/">jekyll&lt;/a>)，
顾名思义，就是这玩意儿直接给你打包生成网站需要的一揽子部件。
（网站意味着高度定制的自由，是不是听着就觉得开心？如果你够耐心看到这里，我就
估摸着你也应该也是个爱折腾的人，爱在机器上捣鼓各种工具的人想必也知道，所谓的
“高度定制”的另一个说法大约是说：来呀，折腾呀，快活呀）。&lt;/p>
&lt;p>你知道吗？从 &lt;code>vimwiki&lt;/code> 的编辑系统到 jekyll 博客网页，只需要一个命令：&lt;code>:Postit&lt;/code>&lt;/p>
&lt;p>当然了，这明显属于广告用语，和‘一天学会python，七天掌握机器学习’之类差不多。&lt;/p>
&lt;p>俗语有云：“前端一分钟，后端十年功”。&lt;code>Postit&lt;/code> 命令需要一些基础来支撑：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-viml" data-lang="viml">&lt;span style="display:flex;">&lt;span>command Postit :&lt;span style="color:#ff6ac1">execute&lt;/span> &lt;span style="color:#5af78e">&amp;#34;w!&amp;#34;&lt;/span> . &lt;span style="color:#5af78e">&amp;#34;Path_to_jekyllsite_root/_posts/&amp;#34;&lt;/span> . strftime(&lt;span style="color:#5af78e">&amp;#34;%Y-%m-%d-&amp;#34;&lt;/span>) . expand(&lt;span style="color:#5af78e">&amp;#34;%:t&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这语句要写在 &lt;code>.vimrc&lt;/code> 文件里，这个实际上是设置 vim 命令。&lt;/p>
&lt;p>注: 这个命令的实际意思是：将当前编辑的文件以 jekyll 的 post 文件的所要求格式
进行命名，并保存到你的 jekyll 项目的 _post/ 目录下。&lt;/p>
&lt;p>因为 jekyll 的 post 全部要求以“年-月-日-”作为文件名前缀 (比如：
“2022-02-02-好多二.md”)。命令中的 “.” 是 viml 语法中 &amp;ldquo;concatenate&amp;rdquo; 的意思。&lt;/p>
&lt;p>虽然谈不上难以忍受，但我个人不是很理解这种硬编码，文件命名格式为何非如此不可？
是bug还是feature，那就见仁见智了。我听说还有一个静态网站生成器名叫
&lt;a href="https://gohugo.io/">Hugo&lt;/a> 的，不知其手艺如何 &amp;hellip;&lt;/p>
&lt;hr>
&lt;p>刚开始使用 vimwiki 时，也是不停的摸索，数学公式的显示一直是个头疼的问题，毕竟，
从“歪果仁”那里借鉴来的默认配置需要能访问外网，而这个想必不是我们能够默认得了的，
只能先忍着那些令人不快的如同乱码的 latex 语句挂在页面上，
（尤其是，当你明明知道这些公式本可以优雅的展示，却不能够时，不快就变成了愤怒）。&lt;/p>
&lt;p>没有像作为新手时在不同的 Linux 发行版跳来跳去那般，我知道 vimwiki 就是我的菜，
以前使用 vimwiki 过程碰上的各种“暂时”的没有解决的问题，开始变得令人不能忍受，
特别是平时浏览其他网页时每每看到人家的的数学公式又多又靓，那简直就是一场侮辱。
我走了这么远，就差那么最后一步，我心不甘。所以我就折腾，一天，两天，三天 &amp;hellip;
我是贪婪的人，无法放弃一步之遥的诱惑，幸运的是我还是折腾到了我想要的“更多”。&lt;/p>
&lt;p>是的，距离太远可能直接放弃，而一步之遥最是销魂 😂&lt;/p>
&lt;p>其实，该庆幸的是我碰上的问题早就有人先碰上也先解决了，我只是找到了这个方法，
应该说是‘搜索’到了这个方法，并作了必要的调整。‘闻道有先后’的基础就是分享，
对于这些解决了实际问题的人，很是感激他们的分享，没有分享，大家的日子不会好过。&lt;/p></description></item><item><title>利器3: Jupyterlab and its Kernels</title><link>/posts/thecli/2022-07-22-jupyterwithdskernels/</link><pubDate>Fri, 22 Jul 2022 22:01:51 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/thecli/2022-07-22-jupyterwithdskernels/</guid><description>&lt;p>&lt;img alt="IMG_jupyterlab" src="images/jupyter_kernels.png">&lt;/p>
&lt;p>New machine needs to be tailored for a better personal workflow. And this is
about how &lt;a href="https://jupyter.org/">jupyter&lt;/a> can be a multi-language support
co-work platform for regular DataScience works. Also note that Julia community
has &lt;a href="https://github.com/fonsp/Pluto.jl">pluto&lt;/a> notebook, and R has its
&lt;a href="https://www.rstudio.com/">RStudio&lt;/a>.&lt;/p>
&lt;h1 id="jupyter-julia--python--r-all-in-one" >
&lt;div>
&lt;a href="#jupyter-julia--python--r-all-in-one">
##
&lt;/a>
JuPyteR: Julia + Python + R all in one
&lt;/div>
&lt;/h1>
&lt;p>1 check the Python came with system&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ which python3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If there is no python3 yet, install one:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ sudo apt install python3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that this would install the latest version of Python.&lt;/p>
&lt;p>2 Poetry or Virtualenv (Poetry is way tooooo slow 2021-12)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># create virtual envs:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>python3 -m venv dsvenv
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># install jupyterlab:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./dsvenv/bin/python -m pip install jupyterlab
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that this may create a venv without &lt;code>activate&lt;/code> scripts.
If this is the case, check &lt;a href="https://stackoverflow.com/questions/26215790/venv-doesnt-create-activate-script-python3">more discussion
here&lt;/a>&lt;/p>
&lt;p>3 &lt;a href="https://mirrors.tuna.tsinghua.edu.cn/CRAN/">install R&lt;/a>, then&lt;/p>
&lt;p>4 &lt;a href="https://julialang.org/downloads/platform/#linux_and_freebsd">install Julia&lt;/a>&lt;/p>
&lt;p>5 activate python&amp;rsquo;s dsvenv (source ./dsvenv/bin/activate), then&lt;/p>
&lt;p>a. Enter interactive R (REPL environment)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-R" data-lang="R">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># install &amp;#39;IRkernel&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#57c7ff">install.packages&lt;/span>(&lt;span style="color:#5af78e">&amp;#39;IRkernel&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># register the kernel in the current R installation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>IRkernel&lt;span style="color:#ff6ac1">::&lt;/span>&lt;span style="color:#57c7ff">installspec&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># exit&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#57c7ff">q&lt;/span>()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>b. Enter interactive Julia (./path-to/julia.1.6.5/bin/julia)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-Julia" data-lang="Julia">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">using&lt;/span> Pkg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Pkg&lt;span style="color:#ff6ac1">.&lt;/span>add(&lt;span style="color:#5af78e">&amp;#34;IJulia&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Optional: build IJulia&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Pkg&lt;span style="color:#ff6ac1">.&lt;/span>build(&lt;span style="color:#5af78e">&amp;#34;IJulia&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that if the path of binary of Julia somehow changed (reinstall etc),
one need to perform extra command &lt;code>Pkg.build(&amp;quot;IJulia&amp;quot;)&lt;/code> which tells jupyter
where to find the binary of Julia.&lt;/p>
&lt;p>6 launch jupyterlab server, and that&amp;rsquo;s it!&lt;/p></description></item><item><title>利器2: Vimwiki 之 如何用 vimwiki 记笔记</title><link>/posts/thecli/thevim/2022-07-15-vimwiki/</link><pubDate>Thu, 21 Jul 2022 23:37:31 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/thecli/thevim/2022-07-15-vimwiki/</guid><description>&lt;h2 id="个人维基-personal-wiki" >
&lt;div>
&lt;a href="#%e4%b8%aa%e4%ba%ba%e7%bb%b4%e5%9f%ba-personal-wiki">
#
&lt;/a>
个人维基 (personal wiki)
&lt;/div>
&lt;/h2>
&lt;p>阅读过《爱丽丝漫游奇境》的小伙伴应该会觉得熟悉，维基就像那个“兔子洞”，
每个词条都可以是一个通往其他奇境的大门，但它只对有好奇心的人才打开。
（或者说有好奇心的人才会打开它，尼奥要是没有选择红色💊，故事恐怕就没趣得多）。
这是在维基上阅读时常有的感受。（其他网站很多时候则搞的更像是“盘丝洞”。）&lt;/p>
&lt;p>每个人都有创作的冲动。
然而事实可能更简单:平时读书学习工作时喜欢东写西划总会留下一些‘笔记’。
对别人来说就是些胡涂乱画，可自己总觉得“珍贵” &amp;ndash; “娘不嫌儿丑”说的大概就是这个。
慢慢地，积累的内容越来越多，涉及的范围越来越广，也就显得越来越零碎。
（嗯，为什么不在开始的时候就规划好呢？爸妈通常都是提这种好问题的高手)。
不过这在我看来更像一种“马后炮”式的责问，总有一丢丢“似是而非”的感觉。
学习的过程更像一种探索过程，对大部分人来说，事先恐怕都无法清晰地知道,
书山的路通向何处，学海的舟引你走向哪里。对于不能预先知道细节的内容，
通常会在开始的时候冠以“我的笔记”这么一个目录，然后下设一些粗略的学科名称目录，
直到不再满意这样的安排。毫无疑问，下一步就是要用一种合适的方式将它们组织起来。&lt;/p>
&lt;p>相对独立的主题自成体系，不同主题之间关联的内容可以连接起来，
不仅在阅读时可以享受这种便捷的自由跳转，最好在设计和编写时也能如此。
对我而言，答案就是 &lt;a href="https://github.com/vimwiki/vimwiki">vimwiki&lt;/a>.&lt;/p>
&lt;p>阅读的时候自由跳转，这个好理解，可编写内容不都一篇一篇的来吗？
编写的时候也“胡崩乱跳”的，听起来可不怎么美妙，怕不是有毛病？不，不要误会，
这其实是指：1）同时在多个窗格(Pane)打开多个文档；2）在窗格之间进行“闪转腾挪”。&lt;/p>
&lt;p>如果是编写过比较复杂的模块的小伙伴可能会更深有感触，
这种不同文档之间的“旋转跳跃我开天眼”的要求其实并不过分,
只恨自己的屏幕不够多不够大放不下那段段优雅的代码
（据可靠的谣言称，有些程序猿一天80%的时间是在欣赏自己写的代码中度过）。&lt;/p>
&lt;p>最典型的莫过于从函数调用的地方，跳转到在那遥远的地方的函数定义模块，
如果这两个地方的关系隔着三五个或者更多的模块的时候，(可能也是需要重构的信号)
那么，如果不能同时将这几个‘密接’文档铺在眼前，而是一个看完再看另一个，
朋友，我不知道你的情况如何，反正我是很容易迷失在这茂密的代码丛林里，晕头转向。&lt;/p>
&lt;p>总而言之，
核心的问题在于如何组织这些文档，使得自己在构建个人‘知识库’的过程更丝滑畅快。&lt;/p>
&lt;p>维基的特点就是“你中有我，我中有他”，比如说，
在组织和构建关于“线性回归”内容，我希望有一个“入口”文档，称之为主题目录，
这个文档只对要写的章节内容进行罗列和简介，更像一种“顶级菜单” (top level manu) ，
这个菜单包含些什么菜呢？简介大概是这样的：&lt;/p>
&lt;ol>
&lt;li>简单线性回归
&lt;ul>
&lt;li>斜率和截距&lt;/li>
&lt;li>最小二乘法&lt;/li>
&lt;li>参数评估有多准
&lt;ul>
&lt;li>置信度区间&lt;/li>
&lt;li>假设检验&lt;/li>
&lt;li>P值: 有多少爱可以重来&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>多元线性回归
&lt;ul>
&lt;li>自变量和因变量到底有没有关系&lt;/li>
&lt;li>因变量和哪些自变量有什么关系&lt;/li>
&lt;li>模型拟合
&lt;ul>
&lt;li>残差(RSE)&lt;/li>
&lt;li>$R^2$ 统计量&lt;/li>
&lt;li>Adjusted $R^2$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>贝叶斯线性回归
&lt;ul>
&lt;li>是先验还是偏见？
&lt;ul>
&lt;li>我认为 $\Theta$ 不只一个&lt;/li>
&lt;li>贝叶斯定律&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>后验概率估计
&lt;ul>
&lt;li>MCMC&lt;/li>
&lt;li>吉布斯采样&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>广义线性回归
&lt;ul>
&lt;li>指数族分布：不只有正态分布&lt;/li>
&lt;li>最大熵：我来教你挑选分布&lt;/li>
&lt;li>链接函数：线性空间到非线性空间的映射&lt;/li>
&lt;li>汉密尔顿蒙特卡洛&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>这就是关于“线性回归”内容的主题目录，
列出来的每个点都可以设置为链接点（但不是必须这么做），
从这个主题目录，可以去到任何的单个文档，在每个文档里，
都可以设置指向其他文档的链接，或者指向网络资源的链接（事事亲为并非必要）。&lt;/p>
&lt;p>多年以来我已经或多或少地做了一些章节内容的笔记，缺的正是这样的一个主题目录。&lt;/p>
&lt;p>至于编辑内容的时候要不要在一块屏幕上“同时”并列展开多个文档，并“跳来跳去”，
可以说这只是一些人的特殊癖好，并不是非如此不可。
比如，24寸屏幕上如果只打开一个文档，我觉得是对空间的极大浪费；
但要知道，如果在13寸的屏幕上，有时我也进入 &lt;a href="https://github.com/junegunn/goyo.vim">goyo
模式&lt;/a> 。&lt;/p>
&lt;p>如果你点开前文 vimwiki 的链接，那你应该知道它是 Vim 的一个插件。&lt;/p>
&lt;p>如果你尚不清楚 Vim 是干什么的，或者仅仅听说 Vim 的学习曲线是“出了名的吓人”，
这是不对的，至少你可以看到：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">&lt;img alt="learning_curves" src="https://fgg100y.github.io/img/posts/vimwiki_intro/editors_learning_curves.jpg">&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">&lt;em>some text editors&amp;rsquo; learning curve&lt;/em>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Emacs 才是无可争议的 NO.1 😂&lt;/p>
&lt;p>如果不幸的是至今您仍旧只在不幸的操作系统过活，👉 是的，我指的就是巨硬系统。
不妨去&lt;a href="https://www.vim.org/download.php">下载 Gvim&lt;/a>来尝试别样的编辑的滋味，&lt;/p>
&lt;p>或者您是刚刚开启 Linux 幸福之路的人，或者想试一试 Vim ，
很简单，直接上手类型的，在 Terminal 中输入 &lt;code>vimtutor&lt;/code>，退出输入 &lt;code>:q&lt;/code>&lt;/p>
&lt;p>最好的 vim 学习材料会在输入 &lt;code>:help&lt;/code> 之后出现（但不一定是最好的入门材料）。
或许你会想看看一些入门的材料，比如 &lt;a href="http://vimcasts.org/">vimcast&lt;/a> 视频，
比如，年代略微久远的 &lt;a href="https://vim.swaroopch.com/">A Byte of Vim&lt;/a>，
内容及其详尽的 &lt;a href="http://www.oualline.com/vim-book.html">Vim Tutorial and Reference&lt;/a>&lt;/p>
&lt;hr>
&lt;p>Last update: 2024-07-04 Thu&lt;/p></description></item><item><title>Linear Regression: frequentist and bayesian</title><link>/posts/regressionmodels/linear_regression/</link><pubDate>Wed, 25 Aug 2021 13:49:40 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/regressionmodels/linear_regression/</guid><description>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>**Important Note**:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Almost all the contents (text, images) are came from these great books and
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>online resources:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Statistics, by David Freeman, Robert Pisani, and Roger Perves
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* 统计学, David Freeman *et.al* 著，魏宗舒 等译，中国统计出版社
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* 机器学习, 周志华 著 (大名鼎鼎的‘西瓜书’)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* An Introduction to Statistical Learning, by Gareth James, Daniela Witten,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Trevor Hastie, and Robert Tibshirani
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Deep Learning, a.k.a, the flower book, by Ian Goodfellow, Yoshua Bengio, and
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Aaron Courville
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Introduction to Machine Learning, Barnabas Poczos, Aarti Singh, CMU-10701
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Bayesian Methods, Nicholas Ruozzi, UT-DALLAS
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 style="text-align: center;">Linear Regression&lt;/h1>
&lt;h2 id="part-0-regression-101" >
&lt;div>
&lt;a href="#part-0-regression-101">
#
&lt;/a>
Part-0: Regression 101
&lt;/div>
&lt;/h2>
&lt;blockquote>
&lt;p>$\text{You&amp;rsquo;ve got to draw the line somewhere.}$&lt;/p>
&lt;/blockquote>
&lt;h3 id="introduction" >
&lt;div>
&lt;a href="#introduction">
##
&lt;/a>
Introduction
&lt;/div>
&lt;/h3>
&lt;p>The regression method describes how one variable depends on another. For example, take height and weight. Naturally, the taller men weighed more. How much of an increase in weight is associated with a unit increase in height? To get started, look at the scatter diagram (figure 1 on below). Height is plotted on the horizontal axis, and weight on the vertical. The summary statistics are&lt;/p>
&lt;p>$\text{average height} \approx 70 \ inches,\qquad SD \approx 3 \ inches$&lt;/p>
&lt;p>$\text{average height} \approx 70 \ inches, \qquad SD \approx 45 \ pounds, \qquad r \approx 0.40$&lt;/p>
&lt;p>The scales on the vertical and horizontal axes have been chosen so that one SD of height and one SD of weight cover the same distance on the page. This makes the SD line (dashed) rise at 45 degreed across the page. There is a fair amount of scatter around the line: $r$ is only 0.40.&lt;/p>
&lt;p>&lt;img alt="IMG: regression_line" src="images/stats_weight_height.png">&lt;/p>
&lt;p>Figure 1. Scatter diagram. Each point shows the height and weight for one of 471 men age 18-24 in a dataset. The vertical strip represents men who are about one SD above average in height. Those who are also one SD above average in weight would be plotted along the dashed SD line. Most of the men in the strip are below the SD line: they are only part of an SD above average in weight. The &lt;strong>solid&lt;/strong> regression line estimates average weight at each height.&lt;/p>
&lt;p>The vertical strip in figure 1 shows the men who were one SD above average in height were quite a bit less than one SD above average in weight. This is where the correlation of 0.40 comes in. Associated with an increase of one SD in height there is an increase of &lt;strong>only 0.40&lt;/strong> SDs in weight, on the average.&lt;/p>
&lt;p>To be more specific, take the men who are one SD above average in height:
$$
\text{average height} + SD\ \text{of height} = 70 \ in + 3 \ in = 73 \ in
$$
Their average weight will be above the overall average by $0.40 \times 45 \ lb = 18 \ lb$.&lt;/p>
&lt;p>So, the average weight of these men is around
$$
\text{average weight} + 0.40 \times (SD\ \text{of weight}) = 180 \ lb + 18 \ lb = 198 \ lb
$$
The point (73 inches, 198 pounds) is marked by a cross in figure 1 ( and the points that are 2SD above (76 in, 216 lb) and below (64 in, 144 lb) the average of height as well). All the points (height, estimate for average weight) fall on the solid line shown in figure 1. This is the &lt;em>regression line&lt;/em>. The line goes through the point of averages: men of average height should also be of average weight.&lt;/p>
&lt;p style="text-align:center;color:blue;">
The regression line estimates the average value for y corresponding to each value of x.
&lt;/p>
&lt;p>Along the regression line, associated with each increase of one SD in height there is an increase of only 0.40 SDs in weight. Remember where the 0.40 comes from. It is the correlation between height and weight. NOTE that: Two different SDs are involved here: the SD of $x$, to gauge change in $x$; and the SD of $y$, to gauge changes in $y$.&lt;/p>
&lt;p>This way of using the correlation coefficient to estimate the average value of $y$ for each value of $x$ is called the &lt;strong>regression method&lt;/strong>. The method can be stated as follows.
$$
\fbox{Associated with each increase of one SD in x there is an increase of only r SDs in y, on the average.}
$$&lt;/p>
&lt;blockquote>
&lt;p>Correlation: Like father, like son.&lt;/p>
&lt;blockquote>
&lt;p>If there is a strong association between two variables, then knowing one helps a lot in predicting the other. But when there is a weak association, information about one variable does not help much in guessing the other.&lt;/p>
&lt;/blockquote>
&lt;p>The correlation coefficient is a measure of linear association, or clustering around a line. The relationship between two variables can be summarized by&lt;/p>
&lt;ul>
&lt;li>the average of the $x$-values, the SD of the $x$-values,&lt;/li>
&lt;li>the average of the $y$-values, the SD of the $y$-values,&lt;/li>
&lt;li>the correlation coefficient $r$.&lt;/li>
&lt;/ul>
&lt;p>Computing the correlation coefficient&lt;/p>
&lt;p>Here is the procedure for computing the correlation coefficient.
$$
\boxed{\text{Convert each variable to standard units.} \\
\text{The average of the products gives the correlation coefficient.}}
$$&lt;/p>
&lt;p>$$
\fbox{Convert each variable to standard units.
The average of the products gives the correlation coefficient.}
$$&lt;/p>
&lt;p>Recall that &amp;ldquo;Convert each variable to standard units&amp;rdquo; means &lt;strong>standardization&lt;/strong>. Let $x = {1, 3, 4, 5, 7 }, y = {5, 9, 7, 1, 13 } $ be vectors of variables, the mean is given by
$$
\mu = \frac{1}{|a|} \sum_i a_i
$$
And the SD is the &amp;ldquo;r.m.s size of the deviation from the average&amp;rdquo;, can be given by
$$
\sigma = \sqrt{\frac{1}{|a|} \sum_i (a_i - \mu)^2}
$$
where $|a|$ is the number of data points, $a_i$ is the $i$-th data point in the data set.&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>Table 1. Computing $r$.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">x&lt;/th>
&lt;th style="text-align: center">y&lt;/th>
&lt;th style="text-align: center">x in standard units&lt;/th>
&lt;th style="text-align: center">y in standard units&lt;/th>
&lt;th style="text-align: center">Product&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">1&lt;/td>
&lt;td style="text-align: center">5&lt;/td>
&lt;td style="text-align: center">-1.5&lt;/td>
&lt;td style="text-align: center">-0.5&lt;/td>
&lt;td style="text-align: center">0.75&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">3&lt;/td>
&lt;td style="text-align: center">9&lt;/td>
&lt;td style="text-align: center">-0.5&lt;/td>
&lt;td style="text-align: center">0.5&lt;/td>
&lt;td style="text-align: center">-0.25&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">4&lt;/td>
&lt;td style="text-align: center">7&lt;/td>
&lt;td style="text-align: center">0.0&lt;/td>
&lt;td style="text-align: center">0.0&lt;/td>
&lt;td style="text-align: center">0.00&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">5&lt;/td>
&lt;td style="text-align: center">1&lt;/td>
&lt;td style="text-align: center">0.5&lt;/td>
&lt;td style="text-align: center">-1.5&lt;/td>
&lt;td style="text-align: center">-0.75&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">7&lt;/td>
&lt;td style="text-align: center">13&lt;/td>
&lt;td style="text-align: center">1.5&lt;/td>
&lt;td style="text-align: center">1.5&lt;/td>
&lt;td style="text-align: center">2.25&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>$$
\begin{eqnarray}
r
&amp;amp;=&amp;amp; \text{average of [(x in standard units) times (x in standard units)]} \\
\\
&amp;amp;=&amp;amp; \frac{0.75 - 0.25 + 0.00 -0.75 + 2.25}{5} = 0.40
\end{eqnarray}
$$&lt;/p>
&lt;p>This complete the solution.&lt;/p>
&lt;/blockquote>
&lt;h3 id="slope-and-intercept" >
&lt;div>
&lt;a href="#slope-and-intercept">
##
&lt;/a>
Slope and Intercept
&lt;/div>
&lt;/h3>
&lt;p>Does education pay? Figure 1 shows the relationship between income and education, for a sample of 562 men age 25-29 in 2005. The summary statistics are
$$
\begin{eqnarray}
\text{average education} &amp;amp;\approx&amp;amp; 12.5\ \text{years}, &amp;amp;\qquad&amp;amp; SD \approx 3\ \text{years} \\
\text{average income} &amp;amp;\approx&amp;amp; $30000,\ &amp;amp;\qquad&amp;amp; SD \approx $24000, \qquad r \approx 0.25
\end{eqnarray}
$$
The regression estimates for average income at each educational level fall along the regression line shown in the figure. The line slopes up, showing that on the average, income does go up with education.&lt;/p>
&lt;p>&lt;img alt="Do education pay" src="./images/stats_education_income.png">&lt;/p>
&lt;p>Any line can be described in terms of its slope and intercept. The y-intercept is the height of the line when $x$ is $0$. And the slope is the rate at which $y$ increases, per unit increase in $x$. Slope and intercept are illustrated in figure 2.&lt;/p>
&lt;p>&lt;img alt="IMG: slopeNintercept" src="images/stats_slope_intercept.png">&lt;/p>
&lt;p>&lt;strong>How do you get the slope of the regression line?&lt;/strong> Take the income-education example.
Associated with an increase of one SD in education, there is an increase of $r$ SDs in
income. On this basis, 3 extra years (one SD) of education are worth an extra
$r \times SD = 0.25 \times 24000 = 6000$ of income, on the average. So each extra year in
worth \$6000 / 3 = \$2000. The slope of the regression line is \$2000 per year.&lt;/p>
&lt;p>&lt;img alt="IMG: slopeNintercept2" src="images/stats_slope_intercept2.png">&lt;/p>
&lt;p>The intercept of the regression line is the height when $x = 0$, corresponding to men with $0$ years of education. There men are 12.5 years below average in education.
Each year costs \$2000 -- that is what the slope says. A man with no education should have an income which is below average by
$$
12.5\ \text{years} \times 2000\ \text{per year} = 25000.
$$
His income should be $\$30000 - \$25000 = \$5000$. That is the intercept (figure 3): the predicted value of $y$ when $x = 0$.&lt;/p>
&lt;hr>
&lt;p style="text-align:justify;color:blue;">
Associated with a unit increase in x there is some average change in y. The slope of the regression line estimates this change. The formula for the slope is
&lt;/p>
&lt;p>$$
{r \times SD\ \text{of y} \over SD\ \text{of x}}
$$&lt;/p>
&lt;p style="text-align:justify;color:blue;">
The intercept of the regression line is just the predicted value for y when x is 0.
&lt;/p>
&lt;hr>
&lt;p>The equation of a line can be written in terms of the slope and intercept:
$$
y = \text{slope} \times x + \text{intercept},
$$
which is called the &lt;em>regression equation&lt;/em>. There is nothing new here. The regression equation is just a way of predicting $y$ from $x$ by the regression method.&lt;/p>
&lt;p>The regression line becomes unreliable when you are far from the center of the data, so a &lt;em>negative&lt;/em> intercept is not too disturbing (when the calculation results in some negative value which may seen absurd).&lt;/p>
&lt;p style="text-align:justify;color:blue;">
If you run an observational study, the regression line only describes the data that you see. The line cannot be relied on for predicting the results of interventions.
&lt;/p>
&lt;h3 id="the-least-squares" >
&lt;div>
&lt;a href="#the-least-squares">
##
&lt;/a>
The Least Squares
&lt;/div>
&lt;/h3>
&lt;p>Sometimes the points on a scatter diagram seem to be following a line. The problem discussed in this section is &lt;strong>how to find the line which best fits the points&lt;/strong>. Usually, this involves a compromise: moving the line closer to some points will increase it distance from others. To resolve the conflict, two steps are necessary.&lt;/p>
&lt;ul>
&lt;li>First, define an average distance from the line to all the points.&lt;/li>
&lt;li>Second, move the line around until this average distance is as small as possible.&lt;/li>
&lt;/ul>
&lt;p>To be more specific, suppose the line will be used to predict $y$ from $x$. Then the error made at each point is the vertical distance from the point to the line (a.k.a, the &lt;strong>residual&lt;/strong>, means the difference between the $i$th observed and the $i$th response that is predicted by linear model). In statistics, the usual way to define the average distance is by taking the root-mean-square of the errors. This measure of average distance is called the &lt;em>r.m.s error of the line&lt;/em>. (It was first proposed by Gauss)&lt;/p>
&lt;p>The second problem, how to move the line around to minimize the r.m.s error, was also solved by Gauss:&lt;/p>
&lt;hr>
&lt;p style="text-align:center;color:blue;">
Among all lines, the one that makes the smallest r.m.s error in predicting y form x is the regression line.
&lt;/p>
&lt;hr>
&lt;blockquote>
&lt;p>Recall that:&lt;/p>
&lt;p>The r.m.s error for regression says how far typical points are above or below the regression line.
$$
r.m.s\ error = \sqrt{\frac{1}{n} \sum^n_i (y_i - \hat{y_i})^2}
$$
where $n$ is the number of data points, $y_i$ the $i$-th actual value, $\hat{y_i}$ the corresponding predicted value.&lt;/p>
&lt;p>And the r.m.s error for the regression line of $y$ on $x$ can also be figured as
$$
\sqrt{1 - r^2} \times SD_y
$$
where $r$ is the correlation coefficient&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> between $x$ and $y$.&lt;/p>
&lt;/blockquote>
&lt;p>For this reason, the regression line is often called &lt;em>least squares line&lt;/em>: the errors are squared to compute the r.m.s error, and the regression line makes the r.m.s error as small as possible.&lt;/p>
&lt;p>In other words, the least squares approaches choose $\beta_0$ (the intercept) and $\beta_1$ (the slope) to minimize the &lt;em>residual sum of squares&lt;/em> (RSS) which is defined as
$$
RSS = e_1^2 + e_2^2 + \cdots + e_n^2 = \sum^n_{i=1} (y_i - \hat{y_i})^2
$$
where $e = y_i - \hat{y_i}$ is called the &lt;strong>residual&lt;/strong>. Obviously, the r.m.s error is the root of the mean of RSS.&lt;/p>
&lt;p>Linear regression is a very simple approach for supervised learning. In particular, linear regression is a useful tool for predicting a quantitative response. Many fancy statistical learning approaches can be seen as generalizations or extensions of linear regression.&lt;/p>
&lt;p>$\color{Green}{\text{Example}}$&lt;/p>
&lt;p>According to Hooke&amp;rsquo;s law, the amount of stretch is proportional to the weight $x$. The new length of the spring is
$$
y = mx + b.
$$
In this equation, $m \in \mathbb{R}$ and $b \in \mathbb{R}$ are constants which depend on the spring. Their values are unknown, and have to be estimated using &lt;strong>experimental data&lt;/strong>.&lt;/p>
&lt;center>
Table 1. Data on Hooke's law.
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">Weight (kg)&lt;/th>
&lt;th style="text-align: left">Length (cm)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">0&lt;/td>
&lt;td style="text-align: left">439.00&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">2&lt;/td>
&lt;td style="text-align: left">439.12&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">4&lt;/td>
&lt;td style="text-align: left">439.21&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">6&lt;/td>
&lt;td style="text-align: left">439.31&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">8&lt;/td>
&lt;td style="text-align: left">439.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">10&lt;/td>
&lt;td style="text-align: left">439.50&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/center>
The correlation coefficient[^1] for the data in table 1 is 0.999, very close to 1 indeed. So the points almost form a straight line (figure 5), just as Hooke's law predicts. The minor deviations from linearity are probably due to measurement error; neither the weights nor the length have been measured with perfect accuracy. (Nothing ever is. [When it comes to measurement])
&lt;p>&lt;img alt="Hooke&amp;rsquo;s law" src="images/stats_hookes_law.png">&lt;/p>
&lt;p>Our goal is to estimate $\hat{m}$ and $\hat{b}$ in the equation of Hooke&amp;rsquo;s law for this spring:
$$
y = \hat{m} x + \hat{b}
$$
The graph of this equation is a perfect straight line. If the points in figure 5 happened to fall exactly on some line, the slope&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> of that line would estimate $m$, and its intercept would estimate $b$. However, the points do not line up perfectly. Many different lines could be drawn across the scatter diagram, each having a slightly different slope and intercept.&lt;/p>
&lt;p>Which line should be used? Hooke&amp;rsquo;s equation predicts the length from weight. As discussed above, it is natural to choose $m$ and $b$ so as to minimize the r.m.s error, the line $y = \hat{m} x + \hat{b}$ which does the job is the &lt;strong>regression line&lt;/strong>. This is the &lt;em>method of least squares&lt;/em>. In other words, $m$ in Hooke&amp;rsquo;s law should be estimated as the slope of the regression line, and $b$ as its intercept. These are called &lt;em>least squares estimate&lt;/em>, because they minimize root-mean-square error.&lt;/p>
&lt;p>Let&amp;rsquo;s do the arithmetic (in python code):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> numpy &lt;span style="color:#ff6ac1">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># X the weight data; y the length data&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>X &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array([&lt;span style="color:#ff9f43">0&lt;/span>, &lt;span style="color:#ff9f43">2&lt;/span>, &lt;span style="color:#ff9f43">4&lt;/span>, &lt;span style="color:#ff9f43">6&lt;/span>, &lt;span style="color:#ff9f43">8&lt;/span>, &lt;span style="color:#ff9f43">10&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>array([&lt;span style="color:#ff9f43">439.00&lt;/span>, &lt;span style="color:#ff9f43">439.12&lt;/span>, &lt;span style="color:#ff9f43">439.21&lt;/span>, &lt;span style="color:#ff9f43">439.31&lt;/span>, &lt;span style="color:#ff9f43">439.40&lt;/span>, &lt;span style="color:#ff9f43">439.50&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># mean and Standard Deviation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ---------------------------&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># avg = sum(X) / len(X)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mu_x &lt;span style="color:#ff6ac1">=&lt;/span> X&lt;span style="color:#ff6ac1">.&lt;/span>mean()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mu_y &lt;span style="color:#ff6ac1">=&lt;/span> y&lt;span style="color:#ff6ac1">.&lt;/span>mean()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(&lt;span style="color:#5af78e">f&lt;/span>&lt;span style="color:#5af78e">&amp;#34;The means of X and y: &lt;/span>&lt;span style="color:#5af78e">{&lt;/span>mu_x, mu_y&lt;span style="color:#5af78e">}&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># The means of X and y: (5.0, 439.25666666666666)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># std is the &amp;#34;r.m.s size of the deviation from the average&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>SD_x &lt;span style="color:#ff6ac1">=&lt;/span> X&lt;span style="color:#ff6ac1">.&lt;/span>std()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>SD_y &lt;span style="color:#ff6ac1">=&lt;/span> y&lt;span style="color:#ff6ac1">.&lt;/span>std()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(&lt;span style="color:#5af78e">f&lt;/span>&lt;span style="color:#5af78e">&amp;#34;The SDs of X and y: &lt;/span>&lt;span style="color:#5af78e">{&lt;/span>SD_x, SD_y&lt;span style="color:#5af78e">}&lt;/span>&lt;span style="color:#5af78e">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># The SDs of X and y: (3.415650255319866, 0.16799470891138593)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># convert X into standard unit form&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>X_standard_unit &lt;span style="color:#ff6ac1">=&lt;/span> (X &lt;span style="color:#ff6ac1">-&lt;/span> mu_x) &lt;span style="color:#ff6ac1">/&lt;/span> SD_x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># convert y into standard unit form&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_standard_unit &lt;span style="color:#ff6ac1">=&lt;/span> (y &lt;span style="color:#ff6ac1">-&lt;/span> mu_y) &lt;span style="color:#ff6ac1">/&lt;/span> SD_y
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># correlation coefficient is the average of the products&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r &lt;span style="color:#ff6ac1">=&lt;/span> (X_standard_unit&lt;span style="color:#ff6ac1">.&lt;/span>dot(y_standard_unit)) &lt;span style="color:#ff6ac1">/&lt;/span> &lt;span style="color:#ff5c57">len&lt;/span>(X_standard_unit)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># r = 0.999167257319307&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># the slope&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>m_hat &lt;span style="color:#ff6ac1">=&lt;/span> (r &lt;span style="color:#ff6ac1">*&lt;/span> SD_y) &lt;span style="color:#ff6ac1">/&lt;/span> SD_x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># m_hat = 0.0491428571428563&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># the intercept, this is the *predicted length* when weight is 0,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>b_hat &lt;span style="color:#ff6ac1">=&lt;/span> mu_y &lt;span style="color:#ff6ac1">-&lt;/span> (mu_x &lt;span style="color:#ff6ac1">*&lt;/span> m_hat)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># b_hat = 439.0109523809524&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>this gives us: $\hat{m} \approx 0.05$ per kg and $\hat{b} \approx 439.01$ cm.&lt;/p>
&lt;p>The length of the spring under no load is estimated as 439.01 cm. And each kilogram of load causes the spring to stretch by about 0.05 cm. Of course, even Hooke&amp;rsquo;s law has its limits: beyond some point, the spring will break. &lt;strong>Extrapolating beyond the data is risky&lt;/strong>.&lt;/p>
&lt;p>The method of least squares and the regression method involve the same mathematics; but the contexts may be different. In some fields, investigators talk about &amp;ldquo;least squares&amp;rdquo; when they are estimating parameters &amp;ndash; unknown constants of nature like $m$ and $b$ in Hooke&amp;rsquo;s law. In other fields, investigators talk about regression when they are studying the relationship between two variables, like income and education, using non-experimental data.&lt;/p>
&lt;p>&lt;strong>A technical point:&lt;/strong> The least squares estimate for the length of the spring under no load was 439.01 cm. This is a tiny bit longer than the measured length at no load (439.00 cm). A statistician might trust the least squares estimate over the measurement. Why? Because the least squares estimate takes advantage of all six measurements, not just once: some of the measurement error is likely to cancel out. Of course, the six measurements are tied together by a good theory &amp;ndash; Hooke’s law. Without the theory, the least squares estimate wouldn’t be worth much.&lt;/p>
&lt;h3 id="assessing-the-accuaracy-of-the-coefficient-estimates" >
&lt;div>
&lt;a href="#assessing-the-accuaracy-of-the-coefficient-estimates">
##
&lt;/a>
Assessing the Accuaracy of the Coefficient Estimates
&lt;/div>
&lt;/h3>
&lt;p>Assume that the &lt;em>true&lt;/em> relationship (e.g., the Hooke’s law) between $X$ and $Y$ takes the form $Y = f(X) + \epsilon$ for some unknown function $f$, where $\epsilon$ is a mean-zero random error term. If $f$ is to be approximated by a linear function, then we can write this relationship as
$$
Y = \beta_0 + \beta_1 X + \epsilon.
$$
This is the &lt;em>population regression line&lt;/em>. Here $\beta_0$ is the intercept (the expected value of $Y$ when $X$ = 0) and the $\beta_1$ the slop (the average increase in $Y$ associated with a one-unit increase in $X$). The $\epsilon$ (error term, typically assumed to be independent of $X$) is a catch-all for what we miss with this simple model: the true relationship is probably not linear, there may be other variables that cause variation in $Y$, and there may be measurement error.&lt;/p>
&lt;p>The model of &lt;em>population regression line&lt;/em> is the best linear approximation to the true relationship between $X$ and $Y$ (NOTE that the assumption of linearity is often a useful working model. However, it may be not true in reality). The true relationship is generally not known for real data, but the least squares line can always be computed using the cofficient estimation methods. A natural question is as follows: how accurate is the least square line as an estimate of the population regression line?&lt;/p>
&lt;p>The analogy between linear regression and estimation of the mean of a random variable is an apt one based on the concept of &lt;em>bias&lt;/em>. If we use the sample mean $\hat{\mu}$ to estimate $\mu$, this estimate is &lt;em>unbiased&lt;/em>, in the sense that on average, we expect $\hat{\mu}$ to equal $\mu$, if we could average a huge number of estimates of $\mu$ obtained from a huge number of sets of observations. Hence, an unbiased estimator does not &lt;em>systematically&lt;/em> over- or under-estimate the true parameter. The property of unbiasedness holds for the least squares coefficient estimates as well: if we estimate $\beta_0$ and $\beta_1$ on the basis of a particular data set, then our estimates won&amp;rsquo;t be exactly equal to $\beta_0$ and $\beta_1$. But if we could average the estimates obtained over a huge number of date sets, then the average would be spot on!&lt;/p>
&lt;p>So how far off will that single estimate of $\hat{\mu}$ be? In general, we answer this question by computing the &lt;em>standard error&lt;/em> of $\hat{\mu}$, written as $SE(\hat{\mu})$. We have the well-known formula
$$
Var(\hat{\mu}) = SE(\hat{\mu})^2 = {\sigma^2 \over n},
$$
where $\sigma$ is the standard deviation of each of the realizations $y_i$ of $Y$. NOTE that this formula holds iff the $n$ observations are uncorrelated. To compute the standard errors associated with $\hat{\beta_0}$ and $\hat{\beta_1}$, we use the following formulas:
$$
SE(\hat{\beta_0})^2 =
\sigma^2 [{1 \over n} + \frac{\bar{x}^2}{\sum^n_{i=1}(x_i - \bar{x})^2}],
&lt;br>
SE(\hat{\beta_1})^2 =\frac{\sigma^2}{\sum^n_{i=1}(x_i - \bar{x})^2}
$$
where $\sigma^2 = Var(\epsilon)$. In general, $\sigma^2$ is not known, but can be estimated from the data. This estimate of $\sigma$ is known as the &lt;em>residual standard error&lt;/em>, and is given by the formula
$$
\sigma = RSE = \sqrt{RSS / (n-2)}
$$&lt;/p>
&lt;h4 id="confidence-interval" >
&lt;div>
&lt;a href="#confidence-interval">
###
&lt;/a>
Confidence Interval
&lt;/div>
&lt;/h4>
&lt;p>Standard errors can be used to compute the &lt;em>confidence intervals&lt;/em>. A 95% confidence interval is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameters. The range is defined in terms of lower and upper limits computed from the sample of data.&lt;/p>
&lt;p>For linear regression, the 95% confidence interval for $\beta_1$ approximately takes the form
$$
\hat{\beta_1} \pm 2 \cdot SE(\hat{\beta_1}).
$$
That is, there is approximately a 95% chance the true value of $\beta_1$ would be in this range.&lt;/p>
&lt;p>Similarly, for $\beta_0$, its 95% confidence interval takes the form
$$
\hat{\beta_0} \pm 2 \cdot SE(\hat{\beta_0}).
$$
NOTE that here we make an assumption that the errors are Gaussian. And the factor of $2$ in the formula will vary slightly depending on the number of observations $n$ in the linear regression.&lt;/p>
&lt;h4 id="hypothesis-tests" >
&lt;div>
&lt;a href="#hypothesis-tests">
###
&lt;/a>
Hypothesis tests
&lt;/div>
&lt;/h4>
&lt;p>Standard errors can also be used to perform &lt;em>hypothesis tests&lt;/em> on the coefficients. The most common hypothesis test involves testing the &lt;em>null hypothesis&lt;/em> of
$$
H_0 : \text{There is no relationship between X and Y}
$$
versus the &lt;em>alternative hypothesis&lt;/em>
$$
H_a : \text{There is some relationship between X and Y}.
$$
Mathematically, this corresponds to testing
$$
H_0 : \beta_1 = 0
$$
versus
$$
H_a : \beta_1 \ne 0,
$$
since if $\beta_1 = 0$ then the linear regression model reduces to $Y = \beta_0 + \epsilon$, and $X$ is not associated with $Y$.&lt;/p>
&lt;p>To test the null hypothesis, we need to determine whether $\hat{\beta_1}$, our estimate for $\beta_1$, is sufficiently far from zero that we can be confident that $\beta_1$ is non-zero. How far is far enough? This is of course depends on the accuracy of $\hat{\beta_1}$ &amp;ndash; that is, it depends on $SE(\hat{\beta_1})$:&lt;/p>
&lt;ul>
&lt;li>If $SE(\hat{\beta_1})$ is small, then even relatively small values of $\hat{\beta_1}$ may provide strong evidence that $\beta_1 \ne 0$;&lt;/li>
&lt;li>if $SE(\hat{\beta_1})$ is large, then $\hat{\beta_1}$ must be large in absolute value in order for us to reject the null hypothesis.&lt;/li>
&lt;/ul>
&lt;p>In practice, we compute a &lt;em>t-statistic&lt;/em>, given by
$$
t = \frac{\hat{\beta_1} - 0}{SE(\hat{\beta_1})},
$$
which measures the number of standard deviations that $\hat{\beta_1}$ is away from $0$.&lt;/p>
&lt;p>If there really is no relationship between $X$ and $Y$, then we expect that &lt;em>t-statistic&lt;/em> will have a $t$-distribution with $n-2$ degrees of freedom. Consequently, it is a simple matter to compute the probability of observing any number equal to $|t|$ or larger in absolute value, assuming $\beta_1 = 0$. We call this probability the &lt;em>p-value&lt;/em>.&lt;/p>
&lt;p>&lt;strong>p-value interpretation&lt;/strong>&lt;/p>
&lt;p>Roughly speaking, we interpret the p-value as follows: a small p-value indicates that it is unlikely to observe such a substantial association between the predictor and the response due to chance, in the absence of any real relationship between $X$ and $Y$. Hence we &lt;em>reject the null hypothesis&lt;/em>, and declare a relationship to exist between $X$ and $Y$, if the p-value is small enough. Typical p-value cutoffs for rejecting the null hypothesis are 5% or 1%, when $n = 30$, these correspond to &lt;em>t-statistics&lt;/em> of around $2$, and $2.75$, respectively.&lt;/p>
&lt;blockquote>
&lt;p>A small p-value indicates that a particular sample is unlikely if the null hypothesis
is true. It is akin to a jury concluding that it was unlikely that it would have been
presented with this set of evidence if the defendant were innocent, and therefore
reaching a guilty verdict. Of course, that doesn&amp;rsquo;t mean that the defendant is actually
guilty. Perhaps the jury was presented with misleading evidence.
Analogously, a low p-value might be attributable to the null hypothesis actually being
false, or it could simply be that the sample is unrepresentative of the population from
which it is drawn, i.e., the evidence is misleading.&lt;/p>
&lt;/blockquote>
&lt;p>More info about p-value see &amp;ldquo;21.2 Beware of P-values&amp;rdquo; in the book of Prof. John Guttag &amp;lt;&amp;lt;Introduction to computation and programming using python&amp;gt;&amp;gt;.&lt;/p>
&lt;h3 id="assessing-the-accuracy-of-the-model" >
&lt;div>
&lt;a href="#assessing-the-accuracy-of-the-model">
##
&lt;/a>
Assessing the Accuracy of the Model
&lt;/div>
&lt;/h3>
&lt;p>Once we have rejected the null hypothesis in favor of the altervative hypothesis, it is natrual to want to quantify &lt;em>the extent to which the model fits the data&lt;/em>. The quality of a linear regression fit is typically assessed using two related quantities: the &lt;em>residual standard error&lt;/em> ($RSE$) and the $R^2$ statistic.&lt;/p>
&lt;h4 id="residual-standard-error" >
&lt;div>
&lt;a href="#residual-standard-error">
###
&lt;/a>
Residual Standard Error
&lt;/div>
&lt;/h4>
&lt;p>From the model $Y = \beta_0 + \beta_1 X + \epsilon$ that associated with each observation is an error term $\epsilon$. Due to the presence of these error terms, even if we knew the true regression line (i.e., $\beta$s were known), we would not be perfectly predict $Y$ from $X$. The $RSE$ is an estimate of the standard deviation of $\epsilon$. Roughly speaking, it is the average amount that the response will deviate from the true regression line. It is computed using the formula
$$
RSE
= \sqrt{{1 \over n-2} RSS}
= \sqrt{{1 \over n-2} \sum^n_{i=1}(y_i - \hat{y_i})^2}.
$$
NOTE that $RSE$ is slightly different from &lt;em>r.m.s error&lt;/em> which the latter using the number of all samples ($n$) as denominator while the former using $n-2$.&lt;/p>
&lt;p>The $RSE$ is considered a measure of the &lt;em>lack of fit&lt;/em> of the model to the data. The smaller $RSE$ the better the model fitted to the data.&lt;/p>
&lt;h4 id="r2-statistic" >
&lt;div>
&lt;a href="#r2-statistic">
###
&lt;/a>
$R^2$ Statistic
&lt;/div>
&lt;/h4>
&lt;p>The $RSE$ provides an absolute measure of lack of fit of the model to the data. But since it is measured in the units of $Y$, it is not always clear what consititues a good $RSE$. The $R^2$ statistic provides an alternative measure of fit. It takes the form of a &lt;em>proportion&lt;/em>, the proportion of variance explained, and so it always takes on a value between $0$ and $1$, and is independent of the scale of $Y$.&lt;/p>
&lt;p>To calculate $R^2$, we use the formula
$$
R^2 = \frac{TSS - RSS}{TSS} = 1 - \frac{RSS}{TSS}
$$
where $TSS = \sum(y_i - \bar{y})^2$ is the &lt;em>total sum of squares&lt;/em>. Hence $R^2$ measures the &lt;em>proportion of variability in $Y$ that can be explained using $X$&lt;/em>.&lt;/p>
&lt;h3 id="multiple-linear-regression" >
&lt;div>
&lt;a href="#multiple-linear-regression">
##
&lt;/a>
Multiple Linear Regression
&lt;/div>
&lt;/h3>
&lt;p>Simple linear regression[^3] is a useful approach for predicting a response on the basis of a single predictor variable. But in practice we often have more than one predictor. One option is to run multiple separate simple linear regression, each of which uses a different feature as a predictor. However, this approach is not entirely satisfactory[^4].&lt;/p>
&lt;p>Instead of fitting a separate simple linear regression model for each predictor, a better approach is to extend the simple linear regression model[^5] so that it can directly accommodate multiple predictors. We can do this by giving each predictor a separate slope coefficient in a single model. In general, suppose we have $p$ distinct predictors. Then the multiple linear regression model takes the form&lt;/p>
&lt;p>$$
\tag{3.19}
\label{mlr}
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + + \beta_p X_p + \epsilon
$$&lt;/p>
&lt;p>where $X_j$ represents the $j$-th predictor and $\beta_j$ quantifies the association
between that variable and the response. We interpret $\beta_j$ as the &lt;em>average&lt;/em> effect
on $Y$ of a unit increase in $X_j$, &lt;strong>holding all other predictors fixed&lt;/strong>[^6].&lt;/p>
&lt;p>As was the case in the simple linear regression setting, the regression coefficients
$\beta_0, \beta_1, \ldots, \beta_p$ in ($\ref{mlr}$) are unknown, and must be estimated.
Given estimates $\hat{\beta_0}, \hat{\beta_1}, \ldots, \hat{\beta_p}$, we can make
predictions using the formula&lt;/p>
&lt;p>$$
\tag{3.21}
\label{mlrpred}
\hat{y} = \hat{\beta_0} + \hat{\beta_1} x_1 + \hat{\beta_2} x_2 + \cdots + \hat{\beta_p} x_p.
$$&lt;/p>
&lt;p>Then parameters are estimated using the same &lt;strong>least squares&lt;/strong> approach that we saw in
the context of simple linear regression. We choose $\beta_0, \beta_1, \ldots, \beta_p$
to minimize the &lt;strong>sum of squared residuals&lt;/strong>&lt;/p>
&lt;p>$$
\begin{eqnarray}
RSS
&amp;amp;=&amp;amp; \sum^n_{i=1}(y_i - \hat{y}_i)^2 \\
\tag{3.22} \label{rss}
&amp;amp;=&amp;amp; \sum^n_{i=1} \big( y_i - (\hat{\beta_0} + \hat{\beta_1} x_1 + \hat{\beta_2} x_2 + \cdots + \hat{\beta_p} x_p) \big)^2
\end{eqnarray}
$$&lt;/p>
&lt;p>The values $\hat{\beta_0}, \hat{\beta_1}, \ldots, \hat{\beta_p}$ that minimize
($\ref{rss}$) are the multiple least squares regression coefficient estimates. Unlike
the simple linear regression coefficient estimation (the Python code block in previous
section), the multiple regression coefficient estimates have somewhat complicated forms
that are most easily represented using matrix algebra (see detail in section of Normal
equation).&lt;/p>
&lt;p>When we perform multiple linear regression, we usually are interested in answering a few important questions.&lt;/p>
&lt;hr>
&lt;ol>
&lt;li>Is at least one of the predictors $X_1, X_2, \ldots, X_p$ useful in predicting the response?&lt;/li>
&lt;li>Do all the predictors help to explain $Y$, or is only a subset of the predictors useful?&lt;/li>
&lt;li>How well does the model fit the data?&lt;/li>
&lt;li>Given a set of predictor values, what response value should we predict, and how accurate is our prediction?&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>We now address each of these questions in turn.&lt;/p>
&lt;h4 id="one-is-there-a-relationship-between-the-response-and-predictions" >
&lt;div>
&lt;a href="#one-is-there-a-relationship-between-the-response-and-predictions">
###
&lt;/a>
One: Is There a Relationship Between the Response and Predictions?
&lt;/div>
&lt;/h4>
&lt;p>Recall that in the simple linear regression setting, in order to determine whether there is a relationship between the response and the predictor we can simply check whether the slope equals $0$. In the multiple regression setting with $p$ predictors, we need to ask whether all of the regression coefficients are zero. We also use a &lt;strong>hypothesis test&lt;/strong> to answer this question. We test the &lt;strong>null hypothesis&lt;/strong>,
$$
H_0:\beta_0 = \beta_1 = \ldots = \beta_p = 0
$$
versus the alternative
$$
H_{\alpha}: \text{at least one } \beta_j \text{ is non-zero}
$$
This hypothesis test is performed by computing the &lt;strong>F-statistic&lt;/strong>,
$$
\tag{3.23}
F = \frac{(TSS - RSS) / p}{RSS / (n - p -1)}
$$
where, as with simple linear regression, $TSS = \sum(y_i - \bar{y})^2$ and $RSS = \sum(y_i - \hat{y})^2$ where $\bar{y} = {1 \over n} \sum^n_{i=1} y_i$ is the sample mean. If the linear model assumptions are correct, one can show that
$$
E {RSS / (n - p - 1) } = \sigma^2
$$
and that, provided $H_0$ is true,
$$
E {(TSS - RSS) / p } = \sigma^2
$$
Hence, when there is no relationship between the response and predictors, one would expect the F-statistic to take on a value close to $1$. On the other hand, if $H_{\alpha}$ is true, then $E {(TSS - RSS) / p } &amp;gt; \sigma^2$, so we expect the F-statistic to be greater than $1$.&lt;/p>
&lt;p>However, what if the F-statistic had been closer to $1$? How large does the F-statistic need to be before we can reject $H_0$ and conclude that there is a relationship? It turns out that the answer depends on the values of $n$ and $p$.&lt;/p>
&lt;ul>
&lt;li>When $n$ is large, an F-statistic that is just a little larger than 1 might still provide evidence against $H_0$.&lt;/li>
&lt;li>Inctrast, a larger F-statistic is needed to reject $H_0$ if $n$ is small.&lt;/li>
&lt;/ul>
&lt;p>When $H_0$ is true, and the errors $\epsilon_i$ have normal distribution, the F-statistic follows an F-distribution[^7]. For any given value of $n$ and $p$, any statistical software package can be used to compute the p-value[^8] associated with F-statistic using this distribution. Based on this p-value, we determine whether or not to reject $H_0$.&lt;/p>
&lt;p>Sometimes we want to test that a particular subset of $q$ of the coefficients are zero. This corresponds to a null hypothesis
$$
H_0 = \beta_{p-q+1} = \beta_{p-q+2} = \cdots = \beta_{p} = 0,
$$
where for convenience we have put the variables chosen for omission at the end of the list. In this case we fit a second model that uses all the variables except those last $q$. Suppose that the residual sum of squares for that model is $RSS_0$. Then the appropriate F-statistic is
$$
\tag{3.24} \label{ftest2}
F = \frac{(RSS_0 - RSS) / q}{RSS / (n - p -1)}.
$$
For each individual predictor a t-statistic and a p-value can be obtain, these statistics provide information about whether each individual predictor is related to the response, after adjusting for the other predictors. It turns out that each of these are exactly equivalent to the F-test that omits that single variable from the model, leaving all the others in (means $q=1$ in equation $\ref{ftest2}$). So it reports the &lt;em>partial effect&lt;/em> of adding that variable to the model.&lt;/p>
&lt;p>Given these individual p-values for each variable, why do we need to look at the over F-statistic? After all, it seems likely that if any one of the p-values for the individual variables is very small, then &lt;em>at least one of the predictors is related to the response&lt;/em>. However, this logic is flawed, especially when the number of predictors $p$ is large.&lt;/p>
&lt;p>For instance, consider an example in which $p = 100$ and $H_0:\beta_0 = \beta_1 = \ldots = \beta_p = 0$ is true, so no variable is truly associated with the response. In this situation, about &lt;strong>5%&lt;/strong> of the p-values associated with each variable will be below 0.05 by chance. &lt;strong>In other words, we expect to see approximately five small p-values even in the absence of any true association between the predictors and the response. In fact, we are almost guaranteed that we will observe at least one p-value below 0.05 by chance!&lt;/strong>&lt;/p>
&lt;p>Hence, if we use individual t-statistic and the associated p-value in order to confirm the association between any predictor and the response, there is a very high chance that we will incorrectly conclude that there is a relationship.&lt;/p>
&lt;p>However, the F-statistic does not suffer from this problem because it adjusts for the number of predictors. If $H_0$ is true, there is only a 5% chance that the F-statistic will result in a p-value below 0.05, regardless of the number of predictors or the number of observations.&lt;/p>
&lt;p>Note that when $p$ is larger than $n$, we cannot even fit the multiple linear regression model using least squares. Less flexible least squares models, such as forward stepwise selection, ridge regression, lasso regression and principal components regression, are particular useful for performing regression in the high-dimensional setting.&lt;/p>
&lt;h4 id="two-deciding-on-important-variable" >
&lt;div>
&lt;a href="#two-deciding-on-important-variable">
###
&lt;/a>
Two: Deciding on Important Variable
&lt;/div>
&lt;/h4>
&lt;p>If we conclude on the basis of the F-statistic and its associated p-value that at least one of the predictors is related to the response, then it is natural to wonder which are the guilty ones. The task of determining which predictors are associated with the response, in order to fit a single model involving only those predictors, is referred to as &lt;strong>variable selection&lt;/strong>.&lt;/p>
&lt;p>Ideally, we would like to preform variable selection by trying out a lot of different models, each containing a different subset of the predictors. Unfortunately, there are a total $2^p$ models that contain subsets of $p$ variables (Note that even with a moderate value of $p$, say, $p=30$, then $2^{30}=1,073,741,824$ models make this infeasible). We need an automated and efficient approach to choose a smaller set of models to consider. There are three classical approaches for this task:&lt;/p>
&lt;ul>
&lt;li>Forward selection. We begin with the &lt;strong>null model&lt;/strong> (which contains only the intercept). We then fit $p$ simple linear regressions and add to the null model the variable that results in the lowest $RSS$, and then add to that model the variable which results in the lowest $RSS$ for the new two-variable model. This approach is continued until some stopping rule is satisfied.&lt;/li>
&lt;li>Backward selection. We start with all variables in the model, and remove the variable with largest p-value. The new ($p - 1$)-variable model is fit, and the variable with the largest p-value is removed. This procedure continues until a stopping rule is reached (such as when all remaining variables have a p-value below some threshold).&lt;/li>
&lt;li>Mixed selection. We start with no variables in the model, and as with forward selection, we add the variable that provides the best fit. We continue to add variables one-by-one. If at any point the p-value for one of the variables in the model rises above a certain threshold, then we remove that variable from the model. We continue to perform forward and backward steps until all variable in the model have a low p-value, and all the variables outside the model have a large p-value if added to the model.&lt;/li>
&lt;/ul>
&lt;p>Backward selection cannot be used when $p &amp;gt; n$, forward selection is a greedy approach, and might include variable early that later become redundant. Mixed selection can remedy this.&lt;/p>
&lt;h4 id="three-model-fit" >
&lt;div>
&lt;a href="#three-model-fit">
###
&lt;/a>
Three: Model Fit
&lt;/div>
&lt;/h4>
&lt;p>Two of the most common numerical measures of model fit are the $RSE$ and the $R^2$. Recall that in simple regression, $R^2$ is the square of the correlation coefficient between predictor and the response. In multiple linear regression, it turns out that it equals the square of the correlation coefficient between the response and the fitted model (this implies that the fitted model maximizes this correlation among all possible linear model).&lt;/p>
&lt;p>To calculate $R^2$, we use the formula
$$
\begin{eqnarray}
R^2
&amp;amp;=&amp;amp; \frac{\sum(y_i - \bar{y})^2 - \sum(y_i - \hat{y})^2}{\sum(y_i - \bar{y})^2} \\
\\
&amp;amp;=&amp;amp; \frac{TSS - RSS}{TSS} \\
\\
\tag{3.17}
&amp;amp;=&amp;amp; 1 - {RSS \over TSS},
\end{eqnarray}
$$
where ($\bar{y} = {1 \over n} \sum^n_{i=1} y_i$) is the sample mean, $\hat{y}$ is defined in ($\ref{mlrpred}$).&lt;/p>
&lt;p>An $R^2$ value close to 1 indicates that the model explains a large portion of the variance in the response variable. It turns out that $R^2$ will always increase when more variables are added to the model, even they are only weakly associated with the response. This is due to the fact that with more variable to the least squares equations must allow us to fit the training data more accurately (though not necessarily the testing data, a.k.a., over fitting).&lt;/p>
&lt;p>In general, $RSE$ is defined as
$$
\tag{3.25}
RSE = \sqrt{{1 \over {n - p - 1}} RSS}
$$
Thus model with more variables can have higher $RSE$ if the decrease in $RSS$ is small relative to the increase in $p$.&lt;/p>
&lt;h5 id="adjusted-r2-from-wikihttpsenwikipediaorgwikicoefficient_of_determinationadjusted_r2" >
&lt;div>
&lt;a href="#adjusted-r2-from-wikihttpsenwikipediaorgwikicoefficient_of_determinationadjusted_r2">
####
&lt;/a>
Adjusted $R^2$ &lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2">(From wiki)&lt;/a>
&lt;/div>
&lt;/h5>
&lt;p>The use of an adjusted $R^2$ (one common notation is $\bar{R}^2$; another is $R_{adj}^2$)
is an attempt to account for the phenomenon of the $R^2$ automatically and spuriously
increasing when extra explanatory variables are added to the model. There are many
different ways of adjusting, by far the most used one, to the point that it is typically
just referred to as &lt;em>adjusted $R^2$&lt;/em>, is the correction prosposed by Mordecai Ezekiel,
and adjusted $R^2$ is defined as
$$
\bar{R}^2 = 1 - (1 - R^2){\frac{n-1}{n-p-1}}
$$
where $p$ is the total number of explantory variables in the model (not including the constant term), and $n$ is the sample size. It can also be written as
$$
\bar{R}^2 = 1 - \frac{RSS / df_e}{TSS / df_t}
$$
where $df_t$ is the &lt;em>degrees of freedom&lt;/em> $n-1$ of the estimate of the population variance of the dependent variable, and the $df_e$ is the degrees of freedom $n-p-1$ of the estimate of the underlying population error variance.&lt;/p>
&lt;p>The adjusted $R^2$ can be negative, and its value will always be less than or equal to that of $R^2$. Unlike $R^2$, the adjusted $R^2$ increases only when the increase in $R^2$ (due to the inclusion of a new variable) is more than one would expect to see by chance. If a set of explanatory variables with a predtermined hierarchy of importance are introduced into a regression one at a time, with the adjusted $R^2$ computed each time, the level at which adjusted $R^2$ reaches a maximum, and decreases afterward, would be the regression with ideal combination of having the best fit without excess/unnecessary terms.&lt;/p>
&lt;blockquote>
&lt;p>Degrees of Freedom &lt;a href="https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)">(From wiki)&lt;/a>:&lt;br>
The number of &lt;em>degrees of freedom&lt;/em> is the number of values in the final calculation of a statistic that are free to vary.
Estimates of statistical parameters can be based upon different amounts of information or data. The number of independent pieces of information that go into the estimate of a parameter are called the degrees of freedom.
Mathematically, degrees of freedom is the number of dimensions of the domain of a random vector, or essentially the number of &amp;ldquo;free&amp;rdquo; components (how many components need to be know before the vector is fully determined).
Suppose we have a sample of independent normally distributed observations, ${X_1, X_2, \ldots, X_n}$. This can be represented as an n-dimensional random vector:
$X^T$. Since this random vector can lie anywhere in n-dimensional space, it has $n$ degrees of freedom.
Now let $\bar{X}$ be the sample mean. The random vector can be decomposed as the sum of the sample mean plus a vector of residuals:&lt;/p>
&lt;/blockquote>
&lt;p>$$
\begin{pmatrix}
X_{1} \\
\vdots \\
X_{n} \\
\end{pmatrix}
= \bar{X} \cdot
\begin{pmatrix}
1 \\
\vdots \\
1 \\
\end{pmatrix}
+
\begin{pmatrix}
X_{1} - \bar{X} \\
\vdots \\
X_{n} - \bar{X} \\
\end{pmatrix}
$$&lt;/p>
&lt;p>The first vector on the right-hand side is constrained to be a multiple of the vector of $1$&amp;rsquo;s, and the only free quantity is $\bar{X}$. It therefore has only one degree of freedom.
The second vector is constrained by the relation $\sum(X_i - \bar{X}) = 0$. The first $n-1$ components of this vector can be anything. However, once you know the first $n-1$ components, the constraint tells you the value of the $n$th component. Therefore, this vector has $n-1$ degrees of freedom.&lt;/p>
&lt;h4 id="four-prediction" >
&lt;div>
&lt;a href="#four-prediction">
###
&lt;/a>
Four: Prediction
&lt;/div>
&lt;/h4>
&lt;p>Once we have fit the multiple regression model, it is straightforward to apply the fitted model $\hat{y} = \hat{f}(X) = \hat{\beta} X$ (a more verbose version see $\ref{mlrpred}$) in order to predict the response based on the values of the predictors. However, there are three sorts of uncertainty associated with this prediction.&lt;/p>
&lt;ol>
&lt;li>The coefficient estimate is the least squares estimation of the true coefficient which is unknown. The inaccuracy in the coefficient estimates is related to the &lt;em>reducible error&lt;/em>[^9]. We can compute a &lt;strong>confidence interval&lt;/strong> in order to determine how close $\hat{y}$ will be to $f(X)$.&lt;/li>
&lt;li>In practice assuming a linear model for $f(X)$ is almost always an approximation of reality, so if the true pattern is non-linear, there is an additional reducible error called &lt;em>model bias&lt;/em>.&lt;/li>
&lt;li>Even if we knew $f(X)$ &amp;ndash; that is, we knew the true value of $\beta$ &amp;ndash; the response value cannot be predicted perfectly, because of the random error $\epsilon$ in the model ($\ref{mlrpred}$), this is the &lt;em>irreducible error&lt;/em>.&lt;/li>
&lt;/ol>
&lt;h3 id="summary" >
&lt;div>
&lt;a href="#summary">
##
&lt;/a>
Summary
&lt;/div>
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>The regression line can be specified by two descriptive statistics: the &lt;em>slope&lt;/em> and the &lt;em>intercept&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Among all lines, the regression line for $y$ on $x$ makes the smallest r.m.s error in predicting $y$ from $x$. For that reason, the regression line is often called the &lt;em>least squares line&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With a controlled experiment, the slope can tell you the average change in $y$ that would be caused by a change in $x$. With an observational study, however, the slope cannot be relied on to predict the results of interventions. It takes a lot of hard work to draw causal inferences from observational data, with or without regression.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If the average of $y$ depends on $x$ in a non-linear way, the regression line can be quite misleading.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Multiple regression is a powerful technique, but it is not a substitute for understanding. (Such as the poor investigator would fit a multiple regression equation of the form $ predicted\ area = a + b \times perimeter + c \times diagonal$ to predict the area of a rectangle).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="part-i-how-to-learn" >
&lt;div>
&lt;a href="#part-i-how-to-learn">
#
&lt;/a>
Part-I: How to learn
&lt;/div>
&lt;/h2>
&lt;p>Linear regression is of course an extremely simple and limited learning algorithm, but it provides an example of how a learning algorithm can work.&lt;/p>
&lt;h3 id="normal-equation" >
&lt;div>
&lt;a href="#normal-equation">
##
&lt;/a>
Normal Equation
&lt;/div>
&lt;/h3>
&lt;p>The goal is to build a system that can take a vector $x \in \mathbb{R^n}$ as input and predict the value of a scalar $y \in \mathbb{R}$ as its output. The output of linear regression is a linear function of the input. Let $\hat{y}$ be the value that our model predicts $y$ should take on. We define the output to be
$$
\begin{equation}
\tag{5.3}
\hat{y} = w^{\mathsf{T}}x
\end{equation}
$$&lt;/p>
&lt;p>where $w \in \mathbb{R^n}$ is a vector of &lt;strong>parameters&lt;/strong>.&lt;/p>
&lt;p>We thus have a definition of our task &lt;em>T&lt;/em> : to predict $y$ from $x$ by outputting $\hat{y}=w^{\mathsf{T}}x$.&lt;/p>
&lt;p>Next we need a definition of our performance measure, &lt;em>P&lt;/em>. One way of measuring the performance of the model is to compute the &lt;strong>mean squared error (MSE)&lt;/strong> of the model on the test set. If $\hat{y}^{(test)}$ gives the predictions of the model on the test set, then the MSE is given by
$$
\tag{5.4}
MSE_{test} = \frac{1}{m} \sum_i{(\hat{y}^{(test)} - {y}^{(test)})^2_i}
$$
Intuitively, one can see that this error measure decreases to 0 when $\hat{y}^{(test)} = {y}^{(test)}$. We can also see that
$$
\tag{5.5}
MSE_{test} = \frac{1}{m} ||{\hat{y}^{(test)} - {y}^{(test)}}||^2_2
$$
so the error increases whenever the Euclidean distance between the predictions and the targets increases.&lt;/p>
&lt;blockquote>
&lt;p>In machine learning, we usually measure the size of vectors using a function called a &lt;strong>norm&lt;/strong>. Formally, the $L^p$ norm is given by
$$
||x||_p = \bigg(\sum_i |x_i|^p \bigg)^{\frac{1}{p}}
$$
for $p \in \mathbb{R}, p \geq 1$.&lt;/p>
&lt;p>The $L^2$ norm, with $p = 2$, is known as the &lt;strong>Euclidean norm&lt;/strong>, often denoted simply as $||x||$. It is also common to measure the size of a vector using the squared $L^2$ norm, which can be calculated simply as $x^{\mathsf{T}}x$.&lt;/p>
&lt;/blockquote>
&lt;p>To make a machine learning algorithm, we need to design an algorithm that will improve the weights $w$ in a way that reduces $MSE_{test}$ when the algorithm is allowed to gain experience by observing a training set ($X^{(train)}, y^{(train)}$).&lt;/p>
&lt;p>One intuitive way of doing this is (to minimize $MSE_{test}$) just to minimize the MSE on the training set, $MSE_{train}$ . (Does this make any sense? Keep on reading.)&lt;/p>
&lt;p>To minimize $MSE_{train}$ , we can simply solve for where its gradient is &lt;strong>0&lt;/strong>:
$$
\begin{eqnarray}
\tag{5.6}
\nabla_w MSE_{train} = 0 \\
&amp;amp; \Rightarrow &amp;amp; \frac{1}{m} \nabla_w ||{\hat{y}^{(test)} - {y}^{(test)}}||^2_2 = 0 \\
&amp;amp; \Rightarrow &amp;amp; \frac{1}{m} \nabla_w ||{\hat{y}^{(train)} - {y}^{(train)}}||^2_2 = 0 \\
&amp;amp; \Rightarrow &amp;amp; \frac{1}{m} \nabla_w ||{X^{(train)}w - y^{(train)}}||^2_2 = 0 \\
&amp;amp; \Rightarrow &amp;amp; \nabla_w \big({X^{(train)}w - y^{(train)}}\big)^{\mathsf{T}} \big({X^{(train)}w - y^{(train)}}\big) = 0
\end{eqnarray}
$$&lt;/p>
&lt;p>$$
\tag{5.10}
\Rightarrow \nabla_w \big( w^{\mathsf{T}} X^{(train)\mathsf{T}} X^{(train)}w - 2w^{\mathsf{T}} X^{(train)\mathsf{T}} y^{(train)} + y^{(train)\mathsf{T}} y^{(train)} \big) = 0 \
$$&lt;/p>
&lt;p>$$
\tag{5.11}
\Rightarrow 2X^{(train)\mathsf{T}} X^{(train)}w - 2X^{(train)\mathsf{T}} y^{(train)} = 0 \
$$&lt;/p>
&lt;p>$$
\tag{5.12}
\Rightarrow w = \big(X^{(train)\mathsf{T}} X^{(train)}\big)^{-1} X^{(train)\mathsf{T}} y^{(train)}
$$&lt;/p>
&lt;p>The system of equations whose solution is given by equation 5.12 is known as the &lt;strong>normal equation&lt;/strong>. Evaluating equation 5.12 constitutes a simple learning algorithm.&lt;/p>
&lt;blockquote>
&lt;p>链式法则(Chain Rule)是计算复杂导数时的重要工具。简单地说，若函数 $f(x) = g(h(x))$，则有
$$
\tag{A.31}
\frac{\partial{f(x)}}{\partial{x}} = \frac{\partial{g(h(x))}}{\partial{h(x)}} \cdot \frac{\partial{h(x)}}{\partial{x}}.
$$&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>例如在计算下式时，将$(Ax - b)$看作一个整体可简化计算：
$$
\begin{align*}
&amp;amp;\frac{\partial}{\partial{x}}(Ax - b)^{\mathsf{T}} W(Ax - b) \\
&amp;amp;= \frac{\partial{(Ax - b)}}{\partial{x}} \cdot 2W(Ax - b) \\
&amp;amp;= 2AW(Ax - b)
\end{align*}
$$&lt;/p>
&lt;/blockquote>
&lt;p>It is worth noting that the term &lt;strong>linear regression&lt;/strong> is often used to refer to a slightly more sophisticated model with one additional parameter &amp;ndash; an intercept term $b$. In this model&lt;/p>
&lt;p>$$
\tag{5.13}
\hat{y} = w^{\mathsf{T}}x + b
$$&lt;/p>
&lt;p>so the mapping from parameters to predictions is still a linear function but the mapping from features to predictions is now an &lt;strong>affine function&lt;/strong> (which is in the form of equation 5.13, it means that the plot of model&amp;rsquo;s predictions still looks like a line, but it need not pass though the origin). One can continue to use the model with only weights but augment $x$ with an extra entry that is always set to 1. Then the weight corresponding to the extra 1 entry plays the role of the bias parameter (i.e., the intercept term, $b$, a.k.a., the bias term).&lt;/p>
&lt;blockquote>
&lt;p>The intercept term $b$ is often called the &lt;strong>bias&lt;/strong> parameter of the affine transformation. This terminology derives from the point of view that the output of the transformation is biased toward being $b$ in the absence of any input.&lt;/p>
&lt;p>This term is different from the idea of a statistical bias, in which a statistical estimation algorithm&amp;rsquo;s expected estimate of a quantity is not equal to the true quantity.&lt;/p>
&lt;/blockquote>
&lt;h3 id="gradient-based-method" >
&lt;div>
&lt;a href="#gradient-based-method">
##
&lt;/a>
Gradient-based method
&lt;/div>
&lt;/h3>
&lt;p>Example: Linear Least Squares&lt;/p>
&lt;p>Suppose we want to find the value of $x$ that minimizes&lt;/p>
&lt;p>$$
\tag{4.21}
f(x) = \frac{1}{2}||Ax - b||^2_2
$$&lt;/p>
&lt;p>Specialized linear algebra algorithms can solve this problem efficiently; however, we can also explore how to solve it using gradient-based optimization as a simple example of how these techniques work.&lt;/p>
&lt;p>First, we need to obtain the gradient (Recall the Chain Rule):&lt;/p>
&lt;p>$$
\tag{4.42}
\nabla_x f(x) = A^{\mathsf{T}} (Ax - b) = A^{\mathsf{T}}Ax - A^{\mathsf{T}}b
$$&lt;/p>
&lt;p>We can then follow this gradient downhill, taking small steps.&lt;/p>
&lt;hr>
&lt;p>Algorithm 4.1 An algorithm to minimize $f(x) = \frac{1}{2}||Ax - b||^2_2$ with respect to $x$ using gradient descent, starting from an arbitrary value of $x$.&lt;/p>
&lt;hr>
&lt;p>Set the step size ($\epsilon$, a.k.a., learning rate) and tolerance ($\delta$) to small, positive numbers.&lt;/p>
&lt;p>&lt;strong>while&lt;/strong> $||A^{\mathsf{T}}Ax - A^{\mathsf{T}}b||_2 &amp;gt; \delta$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>$x \leftarrow x - \epsilon (A^{\mathsf{T}}Ax - A^{\mathsf{T}}b)$&lt;/p>
&lt;p>&lt;strong>end while&lt;/strong>&lt;/p>
&lt;hr>
&lt;blockquote>
&lt;p>关于梯度下降法(Gradient Descent)&lt;/p>
&lt;p>梯度下降法是一种常用的一阶(first-order)优化方法, 是求解无约束优化问题最简单,最经典的方法之一.&lt;/p>
&lt;p>考虑无约束优化问题$min_x f(x)$,其中$f(x)$为连续可微函数.若能构造一个序列$x^0, x^1, x^2, \ldots$ 满足
$$
\tag{B.15}
\label{eq_ngd}
f(x^{(t+1)}) &amp;lt; f(x^{(t)}), t = 0,1,2,\ldots
$$
则不断执行该过程即可收敛到局部极小点.欲满足式($\ref{eq_ngd}$),根据泰勒展式有
$$
\tag{B.16}
f(x + \Delta x) \simeq f(x) + \Delta x^{\mathsf{T}} \nabla f(x)
$$
于是,欲满足$f(x + \Delta x) &amp;lt; f(x)$,可选择
$$
\tag{B.17}
\Delta x = - \epsilon \nabla f(x)
$$
其中步长(step size)$\epsilon$是一个小常数.这就是梯度下降法.&lt;/p>
&lt;p>若目标函数$f(x)$满足一些条件,则通过选取合适的步长,就能确保通过梯度下降收敛到局部极小点.例如,若$f(x)$满足L-Lipschitz条件(亦即,对于任意$x$,存在常数$L$使得$||\nabla f(x)|| \leq L$成立),则将步长设置为$1/(2L)$即可确保收敛到局部极小点.当目标函数是凸函数时,局部极小点就是全局最小点,此时,梯度下降法可确保收敛到全局最优解.&lt;/p>
&lt;p>当目标函数$f(x)$二阶连续可微时,可将式($B.16$)替换成更为精确的二阶泰勒展式,这样就得到了牛顿法(Newton&amp;rsquo;s method).牛顿法是典型的二阶方法,其迭代轮数远小于梯度下降法.但牛顿法使用了二阶导数$\nabla^2 f(x)$ (second derivative),其每轮迭代中涉及到海森矩阵(Hessian matrix)的求逆,计算复杂度相当高,尤其在高维问题中几乎不可行.其次,牛顿法仅适用于附近点有局部极小点的情况(也就是,海森矩阵为正定矩阵,也就是海森矩阵所有的特征值都是正数),若附近点是鞍点(saddle point)则牛顿法失效.然而,梯度下降却不会被鞍点困住.若能以较低的计算代价寻找海森矩阵的近似逆矩阵,则可以显著降低计算开销,这就是拟牛顿法(quai-Newton method).&lt;/p>
&lt;/blockquote>
&lt;h3 id="newtons-method" >
&lt;div>
&lt;a href="#newtons-method">
##
&lt;/a>
Newton&amp;rsquo;s method
&lt;/div>
&lt;/h3>
&lt;p>Sometimes we need to find all the partial derivatives of a function whose input and output are both vectors. The matrix containing all such partial derivatives is known as a &lt;strong>Jacobian matrix&lt;/strong>. Specifically, if we have a function $f: \mathbb{R}^m \rightarrow \mathbb{R}^n$, then the Jacobian matrix $\mathbf{J} \in \mathbb{R}^{m \times n}$ of $f$ is defined such that $J_{i, j} = \frac{\partial}{\partial x_j}f(x)_i$.&lt;/p>
&lt;p>We are also sometimes interested in a derivative of a derivative. This is known as a &lt;strong>second derivative&lt;/strong>. For example, for a function $f : \mathbb{R}^n \rightarrow \mathbb{R}$, the derivative with respect to $x_i$ of the derivative of $f$ with respect to $x_j$ is denoted as $\frac{\partial^2}{\partial x_i \partial x_j}f$.&lt;/p>
&lt;p>In a single dimension, we can denote $\frac{d^2}{d x^2}$ by $f&amp;rsquo;&amp;rsquo;(x)$. The second derivative tells us how the first derivative will change when we vary the input. This is important because it tells us whether a gradient step will cause as much of an improvement as we would expect based on the gradient alone. We can think of the second derivative as measuring &lt;strong>curvature&lt;/strong>.&lt;/p>
&lt;p>Suppose we have a quadratic function (or in practice it can be approximated well as quadratic, at least locally). If such a function has:&lt;/p>
&lt;ul>
&lt;li>Second derivative of zero: there is no curvature, it is a flat line, its value can be predict using only the gradient. If the gradient is 1, set the step size of $\epsilon$ along the negative gradient, then the cost function will decrease by $\epsilon$.&lt;/li>
&lt;li>Second derivative is negative: the function curves downward, decrease by more than $\epsilon$.&lt;/li>
&lt;li>Second derivative is positive: the function curves upward, decrease by less than $\epsilon$.&lt;/li>
&lt;/ul>
&lt;p>When our function has multiple input dimensions, there are many second derivatives. These derivatives can be collected together into a matrix called the &lt;strong>Hessian matrix&lt;/strong>. The Hessian matrix $H(f)(x)$ is defined such that&lt;/p>
&lt;p>$$
\tag{4.6}
H(f)(x)_{i, j} = \frac{\partial^2}{\partial x_i \partial x_j}f(x).
$$&lt;/p>
&lt;p>Equivalently, the Hessian is the Jacobian of the gradient.&lt;/p>
&lt;p>The (directional) second derivative tells us how well we can expect a gradient descent step to perform. We can make a second-order Taylor series approximation to the function $f(x)$ around the current point $x^{(0)}$:&lt;/p>
&lt;p>$$
\tag{4.8}
f(x) \approx f(x^{(0)}) + (x - x^{(0)})^{\mathsf{T}}g + \frac{1}{2} (x - x^{(0)})^{\mathsf{T}}H(x - x^{(0)}),
$$&lt;/p>
&lt;p>where $g$ is the gradient and $H$ is the Hessian at $x^{(0)}$. If we use a learning rate of $\epsilon$, then the new point $x$ will be given by $x^{(0)} - \epsilon g$. Substituting this into our approximation, we obtain&lt;/p>
&lt;p>$$
\tag{4.9}
f(x^{(0)} - \epsilon g) \approx f(x^{(0)}) - \epsilon g^{\mathsf{T}}g + \frac{1}{2} \epsilon^2 g^{\mathsf{T}}Hg.
$$&lt;/p>
&lt;p>There are three terms here:&lt;/p>
&lt;ul>
&lt;li>the original value of the function&lt;/li>
&lt;li>the expected improvement due to the slope of the function&lt;/li>
&lt;li>and the correction we must apply to account for the curvature of the function&lt;/li>
&lt;/ul>
&lt;p>When this last term is too large, the gradient descent step can actually move uphill.&lt;/p>
&lt;p>When $g^{\mathsf{T}}Hg$ is zero or negative, the Taylor series approximation predicts that increase $\epsilon$ forever will decrease $f$ forever. In practice, the Taylor series is unlikely to remain accurate for large $\epsilon$, so one must resort to more heuristic choices of $\epsilon$ in this case.&lt;/p>
&lt;p>When $g^{\mathsf{T}}Hg$ is positive, solving for the optimal step size that decrease the Taylor series approximation of the function the most yields&lt;/p>
&lt;p>$$
\tag{4.10}
\epsilon^* = \frac{g^{\mathsf{T}}g}{g^{\mathsf{T}}Hg}.
$$&lt;/p>
&lt;p>In the worst case, when $g$ aligns with the eigenvector of $H$ corresponding to the maximal eigenvalue $\lambda_{max}$, then this optimal step size is given by $\frac{1}{\lambda_{max}}$. (The eigenvalues of the Hessian determine the scale of the learning rate, if the function we minimized can be approximated well by a quadratic function.)&lt;/p>
&lt;p>Using the eigendecomposition of the Hessian matrix, we can generalize the &lt;strong>second derivative test&lt;/strong> to multiple dimensions. At a critical point, where $\nabla_x f(x) = 0$, we can examine the eigenvalues of the Hessian to determine whether the critical point is a local maximum, local minimum, or saddle point.&lt;/p>
&lt;ul>
&lt;li>when the Hessian is positive definite (all its eigenvalues are positive): local minimum.&lt;/li>
&lt;li>when the Hessian is negative definite (all its eigenvalues are negative): local maximum.&lt;/li>
&lt;li>the test is inconclusive whenever all the nonzero eigenvalues have the same sign but at least one eigenvalue is zero.&lt;/li>
&lt;/ul>
&lt;p>In multiple dimensions, there is a different second derivative for each direction at a single point. The &lt;strong>condition number&lt;/strong> of the Hessian at this point measures how much the second derivative differ from each other. When the Hessian has a poor condition number, gradient descent performs poorly. This is because in one direction, the derivative increases rapidly, while in another direction, it increases slowly, Gradient descent is unaware of this change in the derivative, so it does not know that it needs to explore preferentially in the direction where the derivative remains negative for longer.&lt;/p>
&lt;p>Poor condition number also makes choosing a good step size difficult. The step size must be small enough to avoid overshooting the minimum and going uphill in directions with strong positive curvature. This usually means that the step size is too small to make significant progress in other directions with less curvature.&lt;/p>
&lt;p>This issue can be resolved by using information from the Hessian matrix to guide the search. The simplest method for doing so is known as &lt;strong>Newton&amp;rsquo;s method&lt;/strong>. Newton&amp;rsquo;s method is based on using a second-order Taylor series expansion to approximate $f(x)$ near some point $x^{(0)}$:&lt;/p>
&lt;p>$$
\tag{4.11}
f(x) \approx f(x^{(0)}) + (x - x^{(0)})^{\mathsf{T}} \nabla_x f(x^{(0)}) + \frac{1}{2}(x - x^{(0)})^{\mathsf{T}}H(f)(x^{(0)})(x - x^{(0)})
$$&lt;/p>
&lt;p>If we solve for the critical point of this function, we obtain&lt;/p>
&lt;p>$$
\tag{4.12}
x^* = x^{(0)} - H(f)(x^{(0)})^{-1} \nabla_x f(x^{(0)})
$$&lt;/p>
&lt;p>When $f$ is a positive definite quadratic function, Newton&amp;rsquo;s method consist of applying equation 4.12 once to jump to the minimum of the function directly. When $f$ is not truly quadratic but can be locally approximated as a positive definite quadratic, Newton&amp;rsquo;s method consists of applying equation 4.12 multiple times. NOTE that Newton&amp;rsquo;s method is only appropriate when the nearby critical point is a minimum (all the eigenvalues of the Hessian are positive), whereas gradient is not attracted to saddle points unless the gradient points toward them.&lt;/p>
&lt;h2 id="part_ii-why-that--work" >
&lt;div>
&lt;a href="#part_ii-why-that--work">
#
&lt;/a>
Part_II: Why that Work
&lt;/div>
&lt;/h2>
&lt;h3 id="linear-regression-as-maximum-likelihood" >
&lt;div>
&lt;a href="#linear-regression-as-maximum-likelihood">
##
&lt;/a>
Linear Regression as Maximum Likelihood
&lt;/div>
&lt;/h3>
&lt;p>Previously, we motivated linear regression as an algorithm that learns to take an input $x$ and produce an output value $\hat{y}$. The mapping from $x$ to $\hat{y}$ is chosen to minimize mean squared error, a criterion that we introduced more or less arbitrarily. We now revisit linear regression from the point of view of maximum likelihood estimation.&lt;/p>
&lt;p>Instead of producing a single prediction $\hat{y}$, we now think of the model as producing a conditional distribution $p(y | x)$. We can imagine that with an infinitely large training set, we might see several training examples with the same input value $x$ but different values of $y$. The goal of the learning algorithm is now to fit the distribution $p(y | x)$ to all those different $y$ values that are all compatible with $x$.&lt;/p>
&lt;p>To derive the same linear regression algorithm we obtained before, we &lt;strong>define&lt;/strong> $p(y | x) = \mathcal{N}(y; \hat{y}(x; w), \sigma^2)$. In this example, we assume that the variance is fixed to some constant $\sigma^2$ chosen by user.&lt;/p>
&lt;p>Since the examples are assumed to be i.i.d., the conditional log-likelihood is given by&lt;/p>
&lt;p>$$
\begin{split}
&amp;amp;\sum^m_{i=1} log \ p(y^{(i)}|x^{(i)}; \theta) \\
&amp;amp;= -m \ log \ \sigma - \frac{m}{2} log(2 \pi) - \sum^m_{i=1} \frac{||\hat{y}^{(i)} - {y}^{(i)}||^2}{2 \sigma^2},
\end{split}
$$&lt;/p>
&lt;p>where $\hat{y}^{(i)}$ is the output of the linear regression on the $i$-th input $x^{(i)}$ and m is the number of the training examples. Comparing the log-likelihood with the mean squared error,&lt;/p>
&lt;p>$$
MSE_{train} = \frac{1}{m} \sum^m_{i=1} ||\hat{y}^{(i)} - {y}^{(i)}||^2,
$$&lt;/p>
&lt;p>we immediately see that maximizing the log-likelihood with respect to $w$ yields the same estimate of the parameters $w$ as does minimizing the mean squared error. The two criteria have different values but the same location of the optimum.&lt;/p>
&lt;p>This justifies the use of MSE as a maximum likelihood estimation procedure.&lt;/p>
&lt;h4 id="maximum-likelihood-estimation" >
&lt;div>
&lt;a href="#maximum-likelihood-estimation">
###
&lt;/a>
Maximum Likelihood Estimation
&lt;/div>
&lt;/h4>
&lt;p>Rather than guessing that some function might make a good estimator and then analyzing its bias and variance, we would like to have some principle from which we can derive specific functions that are good estimators for different models.&lt;/p>
&lt;p>The most common such principle is the maximum likelihood principle.&lt;/p>
&lt;p>Consider a set of m examples $\mathbb{X} = {x^{(1)}, \cdots, x^{(m)}}$ are i.i.d from true but unknown data-generating distribution $p_{data}(\mathbf{x})$.&lt;/p>
&lt;p>Let $p_{model}(\mathbf{x}; \mathbf{\theta})$ be a parametric family of probability distribution over the same space indexed by $\mathbf{\theta}$. In other words, $p_{model}({x}; \mathbf{\theta})$ maps any configuration $x$ to a real number estimating the true probability $p_{data}({x})$.&lt;/p>
&lt;p>The maximum likelihood estimator for $\mathbf{\theta}$ is then defined as&lt;/p>
&lt;p>$$
\begin{eqnarray}
\mathbf{\theta_{ML}}
\tag{5.56}
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} {p_{model}(\mathbb{x}; \mathbf{\theta})} \\
\tag{5.57}
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} \prod^m_{i=1}{p_{model}(x^{(i)}; \mathbf{\theta})}
\end{eqnarray}
$$&lt;/p>
&lt;p>This product over many probabilities can be inconvenient for various reasons. Such as it&amp;rsquo;s prone to numerical underflow. We observe that taking the logarithm of the likelihood does not change its argmax but does conveniently transform a product into a sum:&lt;/p>
&lt;p>$$
\tag{5.58}
\mathbf{\theta_{ML}} = \underset{\mathbf{\theta}}{\operatorname{argmax}} \sum^m_{i=1}{\text{log} \ p_{model}(x^{(i)}; \mathbf{\theta})}
$$&lt;/p>
&lt;p>Because the argmax does not change when we rescale the cost function, we can divide by
$m$ to obtain a version of the criterion that is expressed as an expectation with
respect to the empirical distribution $\hat{p}_{data}$ defined by the training data:&lt;/p>
&lt;p>FIXME: \mathbb in equation(5.59, 5.60, 5.61) not work.&lt;/p>
&lt;p>$$
\tag{5.59}
\mathbf{\theta_{ML}} = {\underset{\mathbf{\theta}}{\operatorname{argmax}}}\
\mathbb{E}_{\mathbf{x} \sim \hat{p}_{data}} {\text{log} p_{model}(x^{(i)}; \mathbf{\theta})}
$$&lt;/p>
&lt;p>One way to interpret maximum likelihood estimation is to view it as minimizing the
dissimilarity between the empirical distribution $\hat{p}_{data}$, defined by the
training set and the model distribution, with the degree of dissimilarity between the
two measured by the KL divergence. The KL divergence is given by&lt;/p>
&lt;p>$$
\tag{5.60}
D_{KL}(\hat{p}_{data} || p_{model}) = \mathbb{E}_{\mathbf{x} \sim \hat{p}_{data}} {[\log \hat{p}_{data}(x) - \log {p}_{model}(x)]}.
$$&lt;/p>
&lt;p>The term on the left is a function only of the data-generating process, not the model.
This means when we train the model to minimize the KL divergence, we need only minimize&lt;/p>
&lt;p>$$
\tag{5.61}
-\mathbb{E}_{\mathbf{x} \sim \hat{p}_{data}} {[\text{log} \hat{p}_{data}(x)]},
$$&lt;/p>
&lt;p>which is of course the same as the maximization in equation 5.59.&lt;/p>
&lt;p>Minimizing this KL divergence corresponds exactly to minimizing the cross-entropy between the distributions. Any loss consisting of a negative log-likelihood is a cross-entropy between the empirical distribution and the model distribution. For example, MSE is the cross-entropy between the empirical distribution and a Gaussian model.&lt;/p>
&lt;p>We can thus see maximum likelihood as an attempt to make the model distribution match the empirical distribution $\hat{p}_{data}$. While the optimal $\mathbf{\theta}$ is the same regardless of whatever we are maximizing the likelihood or minimizing the KL divergence, the values of the objective functions are different.&lt;/p>
&lt;p>In software, we often phrase both as minimizing a cost function.&lt;/p>
&lt;p>Maximum likelihood thus becomes minimization of the negative log-likelihood (NLL), or equivalently, minimization of the cross-entropy.&lt;/p>
&lt;p>关于KL散度&lt;/p>
&lt;p>KL散度(Kullback-Leibler divergence), 亦称相对熵(relative entropy)或信息散度(information divergence), 可用于度量两个概率分布之间的差异. 给定两个连续型概率分布$P$和$Q$, 二者之间的KL散度定义为&lt;/p>
&lt;p>$$
\label{eq_kld} \tag{C.34}
KL(P||Q) = \int^{\infty}_{-\infty} p(x) \text{log}\frac{p(x)}{q(x)} dx,
$$&lt;/p>
&lt;p>其中,$p(x)$和$q(x)$分别是$P$和$Q$的概率密度函数.&lt;/p>
&lt;p>KL散度满足非负性, 即&lt;/p>
&lt;p>$$
\tag{C.35}
KL(P||Q) \geq 0,
$$&lt;/p>
&lt;p>当且仅当$P=Q$时$KL(P||Q)=0$. 但是, KL散度不满足对称性, 即&lt;/p>
&lt;p>$$
\tag{C.36}
KL(P||Q) \neq KL(Q||P),
$$&lt;/p>
&lt;p>因此, KL散度不是一个度量(metric).&lt;/p>
&lt;p>若将KL散度的定义($\ref{eq_kld}$)展开, 可得&lt;/p>
&lt;p>$$
\begin{eqnarray}
KL(P||Q)
&amp;amp;=&amp;amp; \int^{\infty}_{-\infty} p(x)\log p(x)dx - \int^{\infty}_{-\infty} p(x)\log q(x)dx \\
\tag{C.37}
&amp;amp;=&amp;amp; -H(P) + H(P, Q),
\end{eqnarray}
$$&lt;/p>
&lt;p>其中$H(P)$为熵(entropy), $H(P,Q)$为交叉熵(cross-entropy).&lt;/p>
&lt;h3 id="bayesian-linear-regression" >
&lt;div>
&lt;a href="#bayesian-linear-regression">
##
&lt;/a>
Bayesian Linear Regression
&lt;/div>
&lt;/h3>
&lt;p>So far we have discussed &lt;strong>frequentist statistics&lt;/strong> and approaches based on estimating a single value of $\theta$, then making all predictions thereafter based on that one estimate. An other approach is to consider all possible values of $\theta$ when making a prediction. The latter is the domain of &lt;strong>Bayesian statistics&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>Freqentist: the true parameter value $\theta$ is fixed but unknown, while the point estimate $\hat{\theta}$ is a random variable on account of it being a function of the dataset (which is seen as random).&lt;/li>
&lt;li>Bayesian: the Bayesian uses probability to reflect degrees of certainty in states of knowledge. The dataset is directly observed and so is not random. On the other hand, the true parameter $\theta$ is unknown or uncertain and thus is represented as random variable.&lt;/li>
&lt;/ul>
&lt;p>Before observing the data, we represent our knowledge of $\theta$ using the &lt;strong>prior probability distribution&lt;/strong>, $p(\theta)$ (a.k.a., &amp;ldquo;the prior&amp;rdquo;). Generally, the machine learning practitioner selects a prior distribution that quite broad (i.e., with high entropy, such as uniform distribution) to reflect a high degree of uncertainty in the value of $\theta$ before observing any data.&lt;/p>
&lt;p>Now consider that we have a set of data samples {$x^{(1)}, \ldots, x^{(m)}$}. We can recover the effect of data on our belief about $\theta$ by combining the data likelihood $p(x^{(1)}, \ldots, x^{(m)} | \theta)$ with the prior via Bayes&amp;rsquo; rule:
$$
\tag{5.67}
p(\theta | x^{(1)}, \ldots, x^{(m)}) = \frac{p(x^{(1)}, \ldots, x^{(m)} | \theta) p(\theta)}{p(x^{(1)}, \ldots, x^{(m)})}
$$&lt;/p>
&lt;p>In the scenarios where Bayesian estimation is typically used, the prior begins as a relatively uniform or Gaussian distribution with high entropy, and the observation of the data usually causes the posterior to lose entropy and concentrate around a few highly likely values of the parameters.&lt;/p>
&lt;p>Bayesian estimation offers two important differences from MLE:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Unlike the MLE approach that makes predictions using a point estimate of $\theta$, the Bayesian approach is to make predictions using a full distribution over $\theta$. For example, after observing $m$ examples, the predicted distribution over the next data sample, $x^{(m+1)}$, is given by
$$
\tag{5.68}
p(x^{(m+1)} | x^{(1)}, \ldots, x^{(m)}) = \int p(x^{(m+1)} | \theta) p(\theta | x^{(1)}, \ldots, x^{(m)}) d \theta
$$
Here each value of $\theta$ with positive probability density contributes to the prediction of the next example, with the contribution weighted by the posterior density itself.&lt;/p>
&lt;p>After having observed {$x^{(1)}, \ldots, x^{(m)}$}, if we are still uncertain about the value of $\theta$, then this uncertainty is incorporated into any predictions we might make.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The prior has an influence by shifting probability mass density towards regions of the parameter space that are preferred a priori. In practice, the prior often expresses a preference for models that are simpler or more smooth.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Critics of the Bayesian approach identify the prior as a source of subjective human judgment affecting the predictions.&lt;/p>
&lt;p>Bayesian methods typically generalize much better when limited training data is available but typically suffer from high computational cost when the number of training examples is large.&lt;/p>
&lt;p>&lt;strong>$\color{Green}{\mathbf{Example}}$&lt;/strong>&lt;/p>
&lt;p>Here we consider the Bayesian estimation approach to learning the linear regression parameters. In linear regression, we learn a linear mapping from an input vector $x \in \mathbb{R}^n$ to predict the value of a scalar $y \in \mathbb{R}$. The prediction is parameterized by the vector $w \in \mathbb{R}^n$:
$$
\tag{5.69}
\hat{y} = w^{\mathsf{T}}x.
$$
Given a set of $m$ training samples ($X^{(train)}, y^{(train)}$), we can express the prediction of $y$ over the entire training set as
$$
\tag{5.70}
\hat{y}^{(train)} = X^{(train)}w.
$$
Expressed as a Gaussian conditional distribution on $y^{(train)}$, we have
$$
\begin{eqnarray}
p(y^{(train)} | X^{(train)}, w)
\tag{5.71}
&amp;amp;=&amp;amp; \mathcal{N}(y^{(train)} ; X^{(train)}w, I) \\
\tag{5.72}
&amp;amp;\varpropto&amp;amp; \text{exp} \bigg(
- \frac{1}{2}(y^{(train)} - X^{(train)}w)^{\mathsf{T}} (y^{(train)} - X^{(train)}w)
\bigg),
\end{eqnarray}
$$
where we follow the standard MSE formulation in assuming that the Gaussian variance on $y$ is one.&lt;/p>
&lt;p>In what follows, to reduce the notational burden, we refer to ($X^{(train)}, y^{(train)}$) as simply ($X, y$).&lt;/p>
&lt;p>To determine the posterior distribution over the model parameter vector $w$, we first need to specify a prior distribution. For real-valued parameters it is common to use a Gaussian as a prior distribution,
$$
\tag{5.73}
p(w) = \mathcal{N}(w; \mu_0, \Lambda_0) \varpropto \text{exp} \bigg(
-\frac{1}{2}(w - \mu_0)^{\mathsf{T}} \Lambda^{-1} (w - \mu_0) \bigg),
$$
where $\mu_0$ and $\Lambda_0$ are the prior distribution mean vector and covariance matrix respectively. (We assume a diagonal covariance matrix $\Lambda_0 = diag(\lambda_0)$, unless there is a reason to use a particular covariance structure.)&lt;/p>
&lt;p>With the prior thus specified, we can now proceed in determining the &lt;strong>posterior&lt;/strong> distribution over the model parameters:
$$
\begin{eqnarray}
p(w | X, y)
\tag{5.74}
&amp;amp;\varpropto&amp;amp; p(y | X, w)p(w) \\
\tag{5.75}
&amp;amp;\varpropto&amp;amp;
\text{exp} \bigg(- \frac{1}{2}(y - Xw)^{\mathsf{T}} (y - Xw) \bigg) \text{exp} \bigg(-\frac{1}{2}(w - \mu_0)^{\mathsf{T}} \Lambda^{-1} (w - \mu_0) \bigg) \\
\tag{5.76}
&amp;amp;\varpropto&amp;amp; \text{exp} \bigg(-\frac{1}{2} \big( -2y^{\mathsf{T}}Xw + w^{\mathsf{T}}X^{\mathsf{T}}Xw + w^{\mathsf{T}} \Lambda_0^{-1}w - 2\mu_0^{\mathsf{T}}\Lambda_0^{-1}w \big) \bigg)
\end{eqnarray}
$$
We now define $\Lambda_m = (X^{\mathsf{T}}X + \Lambda_0^{-1})^{-1}$ and $\mu_m = \Lambda_m (X^{\mathsf{T}}y + \Lambda_0^{-1} \mu_0)$. Using these new variables, we find that the posterior may be rewritten as a Gaussian distribution:
$$
\begin{eqnarray}
p(w | X, y)
\tag{5.77}
&amp;amp;\varpropto&amp;amp;
\text{exp} \bigg(- \frac{1}{2}(w - \mu_m)^{\mathsf{T}} \Lambda_m^{-1}(w - \mu_m) + \frac{1}{2} \mu_m^{\mathsf{T}}\Lambda_m^{-1}\mu_m \bigg) \\
\tag{5.78}
&amp;amp;\varpropto&amp;amp; \text{exp} \bigg(-\frac{1}{2} (w - \mu_m)^{\mathsf{T}} \Lambda_m^{-1}(w - \mu_m) \bigg)
\end{eqnarray}
$$
All terms that do not include the parameter vector $w$ have been omitted; they are implied by the fact that the distribution must be normalized to integrate to 1.&lt;/p>
&lt;p>Equation 3.23 shows how to normalize a multivariate Gaussian distribution:
$$
\tag{3.23}
\mathcal{N}(x; \mu, \Sigma) = \sqrt{\frac{1}{(2\pi)^n \text{det}(\Sigma)}} \text{exp} \bigg(-\frac{1}{2} (x - \mu)^{\mathsf{T}} \Sigma^{-1}(x - \mu) \bigg).
$$
When we wish to evaluate the PDF several times for many different values of the parameters, the covariance is not a computationally efficient way to parametrize the distribution, since we need to invert $\Sigma$ to evaluate the PDF. We can instead use a &lt;strong>precision matrix $\beta$&lt;/strong>:
$$
\tag{3.24}
\mathcal{N}(x; \mu, \beta^{-1}) = \sqrt{\frac{\text{det}(\beta)}{(2\pi)^n}} \text{exp} \bigg(-\frac{1}{2} (x - \mu)^{\mathsf{T}} \beta (x - \mu) \bigg).
$$&lt;/p>
&lt;h4 id="maximum-a-posteriori-map-estimation" >
&lt;div>
&lt;a href="#maximum-a-posteriori-map-estimation">
###
&lt;/a>
Maximum A Posteriori (MAP) Estimation
&lt;/div>
&lt;/h4>
&lt;p>While the most principled approach is to make predictions using the full Bayesian posterior distribution over the parameter $\theta$, it is still often desirable to have a single point estimate. One common reason for desiring a point estimate is that most operations involving the Bayesian posterior for most interesting models are intractable, and a point estimate offers a tractable approximation.&lt;/p>
&lt;p>Rather than simply returning to the MLE, we can still gain some of the benefit of the Bayesian approach by allowing the prior to influence the choice of the point estimate. One rational way to do this id to choose the &lt;strong>maximum a posteriori&lt;/strong> (MAP) point estimate. The MAP estimate chooses the point of maximal posterior probability ( or maximal probability density in the more common case of continuous $\theta$):
$$
\tag{5.79}
\theta_{MAP}
= \underset{\mathbf{\theta}}{\operatorname{argmax}} {p(\mathbf{\theta} | x)}
= \underset{\mathbf{\theta}}{\operatorname{argmax}} {\text{log} \ p(x | \mathbf{\theta})} + \text{log} \ p(\mathbf{\theta})
$$
We recognize, on the righthand side, $\text{log} \ p(x | \mathbf{\theta})$, that is, the standard log-likelihood term, and $\text{log} \ p(\mathbf{\theta})$, corresponding to the prior distribution.&lt;/p>
&lt;p>As an example, consider a linear regression model with a Gaussian prior on the weights $w$. If this prior is given by $\mathcal{N}(w; 0, \frac{1}{\lambda}I^2)$, then the log-prior term in equation 5.79 is proportional to the familiar $\lambda w^{\mathsf{T}}w$ weight decay penalty, plus a term that does not depend on $w$ and does not affect the learning process. MAP Bayesian inference with a Gaussian prior on the weights thus corresponds to weight decay.&lt;/p>
&lt;h3 id="mle-and-map-殊途同归" >
&lt;div>
&lt;a href="#mle-and-map-%e6%ae%8a%e9%80%94%e5%90%8c%e5%bd%92">
##
&lt;/a>
MLE and MAP: 殊途同归
&lt;/div>
&lt;/h3>
&lt;h4 id="binary-variables" >
&lt;div>
&lt;a href="#binary-variables">
###
&lt;/a>
Binary Variables
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Coin flipping: heads = 1, tails = 0 with bias $\mu$
$$
p(X = 1 | \mu) = \mu
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bernoulli Distribution
$$
Bern(x | \mu) = \mu^x \cdot (1 - \mu)^{1 - x} \\
\mathbf{E}[X] = \mu \\
var(X) = \mu \cdot (1 - \mu)
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>N coin flips: $X_1, \ldots, X_N$
$$
p(\Sigma_i X_i = m | N, \mu) = {N \choose m} \mu^m (1 - \mu)^{N - m} \\
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Binomial Distribution
$$
p(m | N, \mu) = {N \choose m} \mu^m (1 - \mu)^{N - m} \\
\mathbf{E}[\Sigma_i X_i] = N \mu \\
var[\Sigma_i X_i] = N \mu (1 - \mu)
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="the-bias-of-a-coin" >
&lt;div>
&lt;a href="#the-bias-of-a-coin">
###
&lt;/a>
The Bias of a Coin
&lt;/div>
&lt;/h4>
&lt;p>Suppose that we have a coin, and we would like to figure out what the probability is that it will flip up heads.&lt;/p>
&lt;ul>
&lt;li>How should we estimate the bias?&lt;/li>
&lt;/ul>
&lt;p>With these coin flips result: &lt;strong>[tail, head, tail, head, head]&lt;/strong>, our estimate of the bias is: 3/5 (&amp;ldquo;the frequency of heads&amp;rdquo;).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>why is this a good estimate of the bias?&lt;/p>
&lt;p>- how good is this estimation?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$P(Heads) = \theta, \ P(Tails) = 1 - \theta$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Flips are i.i.d.&lt;/p>
&lt;ul>
&lt;li>Independent events&lt;/li>
&lt;li>Identically distributed according to Binomial distribution&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Our training data consists of $\alpha_H$ heads and $\alpha_T$ tails
$$
p(D | \theta) = \theta^{\alpha_H} \cdot (1 - \theta)^{\alpha_T}
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="mle" >
&lt;div>
&lt;a href="#mle">
###
&lt;/a>
MLE
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Data: Observed set of $\alpha_H$ heads and $\alpha_T$ tails&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Hypothesis: Coin flips follow a binomial distribution&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Learning: Find the &amp;ldquo;best&amp;rdquo; $\theta$&lt;/p>
&lt;p>Maximum Likelihood Estimation: Choose $\theta$ to maximize probability of $D$ given $\theta$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{eqnarray}
\hat{\theta}
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} \ P(D | \theta) \\
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} \ \text{ln} \ P(D | \theta) \\
&amp;amp;=&amp;amp; \underset{\mathbf{\theta}}{\operatorname{argmax}} \ \text{ln} \ \theta^{\alpha_H} \cdot (1 - \theta)^{\alpha_T}
\end{eqnarray}
$$&lt;/p>
&lt;ul>
&lt;li>Set derivative to zero, and solve!&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{eqnarray}
\frac{d}{d\theta} \text{ln} \ P(D | \theta)
&amp;amp;=&amp;amp; \frac{d}{d\theta} [\text{ln} \ \theta^{\alpha_H} \cdot (1 - \theta)^{\alpha_T}] \\
&amp;amp;=&amp;amp; \frac{d}{d\theta} [\alpha_H \text{ln} \ \theta + \alpha_T \text{ln} (1 - \theta)] \\
&amp;amp;=&amp;amp; \alpha_H \frac{d}{d\theta} \text{ln} \ \theta + \alpha_T \frac{d}{d\theta} \text{ln} \ (1 - \theta) \\
&amp;amp;=&amp;amp; \frac{\alpha_H}{\theta} - \frac{\alpha_T}{1 - \theta} = 0 \\
\\
\Rightarrow \hat{\theta}_{MLE} &amp;amp;=&amp;amp; \frac{\alpha_H}{\alpha_H + \alpha_T}
\end{eqnarray}
$$&lt;/p>
&lt;p>As we can see now, that&amp;rsquo;s exactly the &amp;ldquo;Frequency of the heads&amp;rdquo;! In other words, the frequency of heads is exactly the &lt;strong>maximum likelihood estimator&lt;/strong> for this problem.&lt;/p>
&lt;h4 id="map" >
&lt;div>
&lt;a href="#map">
###
&lt;/a>
MAP
&lt;/div>
&lt;/h4>
&lt;p>Suppose we have 5 coin flips all of which are heads, Our estimate of the bias is: ???&lt;/p>
&lt;ul>
&lt;li>MLE would give $\theta_{MLE} = 1$&lt;/li>
&lt;li>This event occurs with probability $1 / 2^5 = 1/32$ for a fair coin&lt;/li>
&lt;li>Are we willing to commit to such a strong conclusion with such little evidence?&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Priors&lt;/strong> are a Bayesian mechanism that allow us to take into account &amp;ldquo;prior&amp;rdquo; knowledge about our belief in the outcome. Rather than estimating a single $\theta$, consider a distribution over possible values of $\theta$ given the data:&lt;/p>
&lt;ul>
&lt;li>Without any data observed, our best guess of $\theta$ is obeyed a Beta(2, 2),&lt;/li>
&lt;li>After we see some data (such as observed flips:[tails, tails]), we update our prior to Beta(3, 2).&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Bayesian Learning&lt;/strong>
$$
\begin{eqnarray}
\tag{L1}
p(\theta | D) = \frac{p(D | \theta) \ p(\theta)}{p(D)} \\
\tag{L2} \label{eq_map}
\Rightarrow p(\theta | D) \varpropto p(D | \theta) \ p(\theta)
\end{eqnarray}
$$
where&lt;/p>
&lt;ul>
&lt;li>$p(\theta | D)$ is the posterior,&lt;/li>
&lt;li>$p(D | \theta)$ is the data likelihood,&lt;/li>
&lt;li>$p(\theta)$ is the prior,&lt;/li>
&lt;li>$p(D)$ is the normalization factor.&lt;/li>
&lt;/ul>
&lt;p>We update the prior according to the observed data to get the posterior by applying Bayes rule.&lt;/p>
&lt;p>&lt;strong>Picking Priors&lt;/strong>&lt;/p>
&lt;p>How do we pick a good prior distribution?&lt;/p>
&lt;ul>
&lt;li>Priors could represent expert domain knowledge&lt;/li>
&lt;li>Statisticians choose them to make the posterior distribution &amp;ldquo;nice&amp;rdquo; (conjugate priors, which makes the posterior the same form as the prior)&lt;/li>
&lt;/ul>
&lt;p>What is a good prior for the bias in the coin flipping problem?&lt;/p>
&lt;ul>
&lt;li>Truncated Gaussian (tough to work with)&lt;/li>
&lt;li>Beta distribution (works well for binary random variables)&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Coin Flips with Beta Distribution&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Likelihood function: $p(D | \theta) = \theta^{\alpha_H} (1 - \theta)^{\alpha_T}$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prior: $p(\theta) = \frac{\theta^{\beta_H - 1} (1 - \theta)^{\beta_T - 1}}{B(\beta_H, \beta_T)} \sim Beta(\beta_H, \beta_T)$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Posterior:
$$
\begin{eqnarray}
p(\theta | D)
&amp;amp;\varpropto&amp;amp; \theta^{\alpha_H}(1 - \theta)^{\alpha_T} \theta^{\beta_H - 1}(1 - \theta)^{\beta_T - 1} \\
&amp;amp;=&amp;amp; \theta^{\alpha_H + \beta_H - 1}(1 - \theta)^{\alpha_T + \beta_T - 1} \\
&amp;amp;=&amp;amp; Beta(\alpha_H + \beta_H, \alpha_T + \beta_T)
\end{eqnarray}
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>MAP Estimation&lt;/strong>&lt;/p>
&lt;p>Choosing $\theta$ to maximize the posterior distribution is called &amp;ldquo;maximum a posteriori (MAP)&amp;rdquo; estimation
$$
\theta_{MAP} = \underset{\mathbf{\theta}}{\operatorname{argmax}} \ {p(\mathbf{\theta} | D)}
$$
The only difference between $\theta_{MLE}$ and $\theta_{MAP}$ is that one assumes a &lt;strong>uniform&lt;/strong> prior (MLE) and the other allows an arbitrary prior.&lt;/p>
&lt;blockquote>
&lt;p>Recall that:&lt;/p>
&lt;p>With uniform prior $p(\theta) \varpropto 1$, according to $\ref{eq_map}$, the posterior $p(\theta | D) \varpropto p(D | \theta)$.&lt;/p>
&lt;/blockquote>
&lt;p>Suppose we have 5 coin flips all of which are heads,&lt;/p>
&lt;ul>
&lt;li>
&lt;p>MLE would give $\theta_{MLE} = 1$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MLE with a Beta(2, 2) prior gives $\theta_{MAP} = \frac{5 + 2 - 1}{5+2+0+2 - 2} = \frac{6}{7} \approx .857$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>As we see more data, the effect of the prior diminishes
$$
\begin{eqnarray}
\theta_{MAP}
&amp;amp;=&amp;amp; \frac{\alpha_H + \beta_H - 1}{\alpha_H + \beta_H + \alpha_T + \beta_T - 2} \\
\\
&amp;amp;\approx&amp;amp; \frac{\alpha_H}{\alpha_H + \alpha_T} \ (\text{for large number of observations})
\end{eqnarray}
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="sample-complexity" >
&lt;div>
&lt;a href="#sample-complexity">
###
&lt;/a>
Sample Complexity
&lt;/div>
&lt;/h4>
&lt;p>How many coin flips do we need in order to guarantee that our learned parameter does not differ too much from the true parameter (with high probability)? Say, I want to know the coin parameter $\theta$, within $\epsilon = 0.1$ error with probability at least $1 - \delta = 0.95$.&lt;/p>
&lt;p>Using the Chernoff bound, we have
$$
p(|\theta_{true} - \theta_{MLE}| \geq \epsilon) \leq 2e^{-2N \epsilon^2} \\
\delta \geq 2e^{-2N \epsilon^2} \Rightarrow N \geq \frac{1}{2\epsilon^2} \text{ln} \frac{1}{\delta}
$$&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Convert each variable to standard units. The average of the products gives the correlation coefficient (may be more intuitively in the python code)&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Associated with a unit increase in $x$ there is some average change in $y$. The slope of the regression line estimates this change. The formula for the slope is $\frac{r \times SD_y}{SD_x}$. And the intercept of the regression line is just the predicted value for $y$ when $x$ is $0$.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Book Notes: Probability and Information Theory</title><link>/posts/lossfunctions/probability_information_theory/</link><pubDate>Fri, 07 Aug 2020 21:17:59 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/lossfunctions/probability_information_theory/</guid><description>&lt;h1 id="probability-and-information-theory" >
&lt;div>
&lt;a href="#probability-and-information-theory">
##
&lt;/a>
Probability and Information Theory
&lt;/div>
&lt;/h1>
&lt;p>Probability theory is a mathematical framework for representing uncertain statements. It provides a means of quantifying uncertainty as well as axioms (公理) for deriving new uncertain statements. In artificial intelligence applications, we use probability theory in two major ways:&lt;/p>
&lt;ul>
&lt;li>The laws of probability tell us how AI systems should reason, so we design our algorithms to compute or approximate various expressions derived using probability theory;&lt;/li>
&lt;li>We can use probability and statistics to theoretically analyze the behavior of proposed AI systems.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>While probability theory allows us to make uncertain statements and to reason in the presence of uncertainty, information theory enables us to quantify the amount of uncertainty in a probability distribution.&lt;/strong>&lt;/p>
&lt;h2 id="why-probability" >
&lt;div>
&lt;a href="#why-probability">
#
&lt;/a>
Why Probability?
&lt;/div>
&lt;/h2>
&lt;p>Machine learning must aways deal with uncertain quantities and sometimes stochastic (nondeterministic) quantities. Uncertainty and stochasticity can arise from many sources. There are three possible sources of uncertainty:&lt;/p>
&lt;ul>
&lt;li>Inherent stochasticity in the system being modeled. For example, most interpretations of quantum mechanics describe the dynamics of subatomic particles as being probabilistic.&lt;/li>
&lt;li>Incomplete observability. Even deterministic systems can appear stochastic when we cannot observe all the variables that drive the behavior of the system. For example, there are three doors, two doors lead to a goat while a third leads to a car. The show contestant was asked to choose among three doors and wins the prize. The outcome given the contestant&amp;rsquo;s choice is deterministic, but from the contestant&amp;rsquo;s point of view, the outcome is uncertain.&lt;/li>
&lt;li>Incomplete modeling. When we use a model that must discard some of the information we have observed, the discarded information results in uncertainty in the model&amp;rsquo;s predictions.&lt;/li>
&lt;/ul>
&lt;p>While it should be clear that we need a means of representing and reasoning about uncertainty, it is not immediately obvious that probability theory can provide all the tools we want for AI applications. Probability theory was originally developed to analyze the frequencies of events. It is easy to see how probability theory can be used to study events like drawing a certain hand of cards in a poker game. These kinds of events are often repeatable. When we say that an outcome has a probability $p$ of occurring, it means that if we repeated the experiment (e.g., drawing a hand of cards, flipping a coin) infinitely many times, then proportion $p$ of the repetitions would result in that outcome. This kind of reasoning does not seem immediately applicable to propositions that are not repeatable. If a doctor analyzes a patient and says that the patient has a 40 percent chance of having the flu, this means something very different &amp;ndash; we cannot make infinitely many replicas of the patient, nor is there any reason to believe that different replicas of the patient would present with the same symptoms yet have varying underlying conditions. In the case of the doctor diagnosing the patient, we use probability to represent a &lt;strong>degree of belief&lt;/strong>, with $1$ indicating absolute certainty that the patient has the flu and $0$ indicating absolute certainty that the patient does not have the flu. The former kind of probability, related directly to the rates at which events occur, is known as &lt;strong>frequentist probability&lt;/strong>, while the latter, related to qualitative levels of certainty, is known as &lt;strong>Bayesian probability&lt;/strong>.&lt;/p>
&lt;p>Probability can be seen as the extension of logic to deal with uncertainty. Logic provides a set of formal rules for determining what propositions (命题) are implied to be true or false given the assumption that some other set of propositions is true of false. Probability theory provides a set of formal rules for determining the likelihood of a proposition being true given the likelihood of other propositions.&lt;/p>
&lt;h2 id="random-variables" >
&lt;div>
&lt;a href="#random-variables">
#
&lt;/a>
Random Variables
&lt;/div>
&lt;/h2>
&lt;p>A &lt;strong>random variable&lt;/strong> is a variable that can take on different values randomly. On its own, a random variable is just a description of the states that are possible; it must be coupled with probability distribution that specifies how likely each of these states are.&lt;/p>
&lt;p>&lt;em>Quantitative&lt;/em> random variables may be discrete or continuous. This is not a hard-and-fast distinction, but it is a useful one. For a discrete variable, the values can only differ by fixed amounts. Family size is discrete. Two families can differ in size by 0 or 1 or 2, and so on. Nothing in between is possible. Age, on the other hand, is a continuous variable. This doesn&amp;rsquo;t refer to the fact that a person is continuously getting older; it just means that the difference in age between two people can be arbitrarily small &amp;ndash; a year, a month, a day, a hour, $\ldots$ And there are variables are &lt;em>qualitative&lt;/em> : examples are marital status (single, married, widowed, divorced, separated) and employment status (employed, unemployed, not in the labor force). Finally, the terms &lt;em>qualitative, quantitative, discrete&lt;/em>, and &lt;em>continuous&lt;/em> are also used to describe data &amp;ndash; qualitative data are collected on a qualitative variable, and so on.&lt;/p>
&lt;p>&lt;img alt="random variables" src="./images/stats_random_variables.png">&lt;/p>
&lt;h2 id="probability-distributions" >
&lt;div>
&lt;a href="#probability-distributions">
#
&lt;/a>
Probability Distributions
&lt;/div>
&lt;/h2>
&lt;p>A &lt;strong>probability distribution&lt;/strong> is a description of how likely a random variable or set of random variables is to take on each of its possible states. The way we describe probability distributions depends on whether the variables are discrete or continuous.&lt;/p>
&lt;h3 id="discrete-variables-and-probability-mass-functions-pmf" >
&lt;div>
&lt;a href="#discrete-variables-and-probability-mass-functions-pmf">
##
&lt;/a>
Discrete Variables and Probability Mass Functions (PMF)
&lt;/div>
&lt;/h3>
&lt;p>A probability distribution over discrete variables may be described using a &lt;strong>Probability Mass Functions (PMF)&lt;/strong>. We typically denote probability mass functions with a capital $P$. Often we associate each random variable with different probability mass function and the reader must infer which PMF to use based on the identity of the random variable, rather than on the name of the function; $P(\bf{x})$ is usually not the same as $P(\bf{y})$.&lt;/p>
&lt;p>The PMF maps from a state of a random variable to the probability of that random variable taking on that state. The probability that $\mathbf{x} = x$ is denoted explicitly as $P(\mathbf{x}=x)$ or $P(x)$ in brevity, with a probability of $1$ indicating that $\mathbf{x} = x$ is certain and a probability of $0$ indicating that $\mathbf{x} = x$ is impossible. Sometimes we define a variable first, then use $\sim$ notation: $\mathbf{x} \sim P(\mathbf{x})$.&lt;/p>
&lt;p>PMF can act on many variables at the same time. Such a probability distribution over many variables is known as a &lt;strong>join probability distribution&lt;/strong>. $P(\mathbf{x} = x, \mathbf{y} = y)$ denotes the probability that $\mathbf{x}=x, \mathbf{y}=y$ simultaneously. We may also write $P(x, y)$ for brevity.&lt;/p>
&lt;p>To be a PMF on a random variable $\bf{x}$, a function $P$ must satisfy the following properties:&lt;/p>
&lt;ul>
&lt;li>The domain of $P$ must be the set of all possible states of $\bf{x}$.&lt;/li>
&lt;li>$\forall x \in \mathbf{x}, 0 \le P(x) \le 1$. An impossible event has probability $0$, and no state can be less probable than that. Likewise, an event that is guaranteed to happen has probability $1$, and no state can have a greater chance of occurring.&lt;/li>
&lt;li>$\sum_{x \in \mathbf{x}} P(x) = 1$. We refer to this property as being &lt;strong>normalized&lt;/strong>. Without this property, we could obtain probabilities greater than one by computing the probability of one of many events occurring.&lt;/li>
&lt;/ul>
&lt;p>For example, consider a single discrete random variable $\bf{x}$ with $k$ different states. We can place a &lt;strong>uniform distribution&lt;/strong> on $\bf{x}$ &amp;ndash; that is, make each of its states equally likely &amp;ndash; by setting its PMF to
$$
\tag{3.1}
P(\mathbf{x}=x_i) = {1 \over k}
$$
for all $i$. We can see that this fits the requirements for a probability mass function. The value $1 \over k$ is positive because $k$ is positive integer. We also see that
$$
\tag{3.2}
\sum_i P(\mathbf{x}=x_i) = \sum_i {1 \over k} = {k \over k} = 1,
$$
so the distribution is properly normalized.&lt;/p>
&lt;h3 id="continuous-variables-and-probability-density-functions-pdf" >
&lt;div>
&lt;a href="#continuous-variables-and-probability-density-functions-pdf">
##
&lt;/a>
Continuous Variables and Probability Density Functions (PDF)
&lt;/div>
&lt;/h3>
&lt;p>When working with continuous random variables, we describe probability distributions using a &lt;strong>Probability Density Functions (PDF)&lt;/strong> rather than a PMF. To be a Probability Density Function, a function $p$ must satisfy the following properties:&lt;/p>
&lt;ul>
&lt;li>The domain of $p$ must be the set of all possible states of $\bf{x}$.&lt;/li>
&lt;li>$\forall x \in \mathbf{x}, p(x) \ge 0$. Note that we do not require $p(x) \le 1$.&lt;/li>
&lt;li>$\int p(x)dx = 1$.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>A probability density function $p(x)$ does not give the probability of a specific state directly; instead the probability of landing inside an infinitesimal region with volume $\delta x$ is given by $p(x) \delta x$.&lt;/strong> Specifically, the probability that $x$ lies in some set $\mathbb{S}$ is given by the integral of density function $p(x)$ over that set. In the univariate example, the probability that $x$ lies in the interval $[a, b]$ is given by $\int_{[a, b]}p(x)dx$.&lt;/p>
&lt;p>For an example of a PDF corresponding to a specific probability density over a continuous random variable, consider a uniform distribution on an interval of the real numbers. We can do this with a function $u(x; a, b)$, where $a$ and $b$ are the endpoints of the interval, with $b &amp;gt; a$. The &amp;ldquo;$;$&amp;rdquo; notation means &amp;ldquo;parametrized by&amp;rdquo;; we consider $x$ to be the argument of the function, while $a$ and $b$ are parameters that define the function. To ensure that there is no probability mass outside the interval, we say $u(x; a, b) = 0\ \text{for all}\ x \notin [a, b]$. Within $[a, b]$, $u(x; a, b) = {1 \over b-a}$. we can see that this is non-negative everywhere. Additionally, it integrates to $1$. We often denote that $x$ follows the uniform distribution on $[a, b]$ by writing $\mathbf{x} \sim U(a, b)$.&lt;/p>
&lt;h3 id="marginal-probability" >
&lt;div>
&lt;a href="#marginal-probability">
##
&lt;/a>
Marginal Probability
&lt;/div>
&lt;/h3>
&lt;p>Sometimes we know the probability distribution over a set of variables and we want to know the probability distribution over just a subset of them. The probability distribution over the subset is known as the &lt;strong>marginal probability distribution&lt;/strong>.&lt;/p>
&lt;p>For example, suppose we have discrete random variables $\bf{x}$ and $\bf{y}$ , and we know $P(\bf{x}, y)$. We can find $P(\bf{x})$ with &lt;strong>sum rule&lt;/strong>:
$$
\tag{3.3}
\forall x \in \mathbf{x}, P(\mathbf{x} = x) = \sum_y P(\mathbf{x}=x, \mathbf{y}=y) .
$$
The name &amp;ldquo;marginal probability&amp;rdquo; comes from the process of computing marginal probabilities on paper. When the values of $P(\bf{x}, y)$ are written in a grid with different values of $x$ in rows and different values of $y$ in columns, it is natural to sum across a row of the grid, then write $P(\bf{x})$ in the marginal of the paper just to the right of the row (see Table 4.1 from the book [Doing Bayesian Data Analysis]).&lt;/p>
&lt;p>&lt;img alt="discrete marginal probability" src="./images/DBDA_marginal_probability.png">&lt;/p>
&lt;p>For continuous variables, we need to use integration instead of summation:
$$
\tag{3.4}
p(x) = \int p(x, y)dy .
$$&lt;/p>
&lt;h3 id="conditional-probability" >
&lt;div>
&lt;a href="#conditional-probability">
##
&lt;/a>
Conditional Probability
&lt;/div>
&lt;/h3>
&lt;p>In many cases, we are interested in the probability of some event, given that some other event has happened. This is called a &lt;strong>conditional probability&lt;/strong>. We denote the conditional probability that $\mathbf{y}=y$ given $\mathbf{x}=x$ as $P(\mathbf{y}=y | \mathbf{x}=x)$. This conditional probability can be computed with the formula
$$
\tag{3.5}
P(\mathbf{y}=y | \mathbf{x}=x) = \frac{P(\mathbf{y}=y , \mathbf{x}=x)}{P(\mathbf{x}=x)} .
$$
The conditional probability is only defined when $P(\mathbf{x}=x) &amp;gt; 0$. We cannot compute the conditional probability conditioned on an event that never happens.&lt;/p>
&lt;p>It is important not to confuse conditional probability with computing what would happen if some action were undertaken. The conditional probability that a person is from Germany given that they speak German is quite high, but if a randomly selected person is taught to speak German, their country of origin does not change. Computing the consequences of an action is called making an &lt;strong>intervention query&lt;/strong>. Intervention queries are the domain of &lt;strong>causal modeling&lt;/strong>.&lt;/p>
&lt;h3 id="the-chain-rule-of-conditional-probability" >
&lt;div>
&lt;a href="#the-chain-rule-of-conditional-probability">
##
&lt;/a>
The Chain Rule of Conditional Probability
&lt;/div>
&lt;/h3>
&lt;p>Any join probability distribution over many random variables may be decomposed into conditional distribution over only one variable:
$$
\tag{3.6}
P(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(n)}) = P(\mathbf{x}^{(1)}) \prod^n_{i=2} P(\mathbf{x}^{(i)} | \mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(i-1)}) .
$$
This observation is known as the &lt;strong>chain rule&lt;/strong>, or &lt;strong>product rule&lt;/strong>, of probability. It follows immediately from the definition of conditional probability in equation 3.5.&lt;/p>
&lt;p>For example, applying the definition twice, we get
$$
\begin{eqnarray}
P(a, b, c) &amp;amp;=&amp;amp; P(a | b, c) P(b, c) \
\
P(b, c) &amp;amp;=&amp;amp; P(b | c) P(c) \
\
P(a, b, c) &amp;amp;=&amp;amp; P(a | b, c) P(b | c) P(c) .
\end{eqnarray}
$$&lt;/p>
&lt;h3 id="independence-and-conditional-independence" >
&lt;div>
&lt;a href="#independence-and-conditional-independence">
##
&lt;/a>
Independence and Conditional Independence
&lt;/div>
&lt;/h3>
&lt;p>Two random variables $\bf{x}$ and $\bf{y}$ are &lt;strong>independent&lt;/strong> if their probability distribution can be expressed as a product of two factors, one involving only $\bf{x}$ and one involving only $\bf{y}$ :
$$
\tag{3.7}
\forall x \in \mathbf{x}, y \in\mathbf{y}, p(\mathbf{x}=x, \mathbf{y}=y) = p(\mathbf{x}=x) p(\mathbf{y}=y) .
$$
Two random variables $\bf{x}$ and $\bf{y}$ are &lt;strong>conditional independent&lt;/strong> given a random variable $z$ if the conditional probability distribution over $\bf{x}$ and $\bf{y}$ factorizes in this way for every value of $z$ :
$$
\tag{3.8}
\forall x \in \mathbf{x}, y \in\mathbf{y}, z \in \mathbf{z},
p(\mathbf{x}=x, \mathbf{y}=y | \mathbf{z}=z) =
p(\mathbf{x}=x | \mathbf{z}=z) p(\mathbf{y}=y | \mathbf{z}=z) .
$$
We can denote &lt;strong>independent&lt;/strong> and &lt;strong>conditional independent&lt;/strong> with compact notation:&lt;/p>
&lt;ul>
&lt;li>$\bf{x} \perp y$ means that $\bf{x}$ and $\bf{y}$ are independent,&lt;/li>
&lt;li>$\bf{x} \perp y | z$ means that $\bf{x}$ and $\bf{y}$ are conditional independent given $z$.&lt;/li>
&lt;/ul>
&lt;h3 id="expectation-variance-and-covariance" >
&lt;div>
&lt;a href="#expectation-variance-and-covariance">
##
&lt;/a>
Expectation, Variance and Covariance
&lt;/div>
&lt;/h3>
&lt;p>The &lt;strong>expectation&lt;/strong>, or &lt;strong>expected value&lt;/strong>, of some function $f(x)$ with respect to a probability distribution $P(\mathbf{x})$ is the average, or mean value, that $f$ takes on when $x$ is drawn from $P$. For discrete variables this can be computed with summation:
$$
\tag{3.9}
\mathbb{E}&lt;em>{\mathbf{x} \sim P} [f(x)] = \sum_x P(x)f(x),
$$
while for continuous variables, it is computed with an integral:
$$
\tag{3.10}
\mathbb{E}&lt;/em>{\mathbf{x} \sim P} [f(x)] = \int p(x)f(x)dx,
$$
Expectations are linear, for example,
$$
\tag{3.11}
\mathbb{E}&lt;em>{\mathbf{x}} [\alpha f(x) + \beta g(x)] =
\alpha \mathbb{E}&lt;/em>{\mathbf{x}}[f(x)] + \beta \mathbb{E}_{\mathbf{x}}[g(x)] ,
$$
when $\alpha$ and $\beta$ are not dependent on $x$.&lt;/p>
&lt;p>The &lt;strong>variance&lt;/strong> gives a measure of how much the values of a function of a random variable $\bf{x}$ vary as we sample different values of $x$ from its probability distribution:
$$
\tag{3.12}
\text{Var}(f(x)) = \mathbb{E}[(f(x) - \mathbb{E}[f(x)])^2] .
$$
When the variance is low, the values of $f(x)$ cluster near their expected value. The square root of the variance is known as the &lt;strong>standard deviation&lt;/strong>.&lt;/p>
&lt;p>The &lt;strong>covariance&lt;/strong> gives some sense of how much two values are linearly related to each other, as well as the scale of these variables:
$$
\tag{3.13}
\text{Cov}(f(x), g(y)) = \mathbb{E} \bigg[\big(
f(x) - \mathbb{E}[f(x)])\ (g(y) - \mathbb{E}[g(y)]
\big)\bigg] .
$$
High absolute values of the covariance mean that the values change very much and are both far from their respective means at the same time.&lt;/p>
&lt;ul>
&lt;li>If the sign of the covariance is positive, both variables tend to take on relatively high values simultaneously,&lt;/li>
&lt;li>If the sign of the covariance is negative, one variable tend to take on relatively high values and the other takes on a relatively low values and vice versa.&lt;/li>
&lt;/ul>
&lt;p>The notions of covariance and dependence are related but distinct concepts.&lt;/p>
&lt;ul>
&lt;li>Two independent variables have zero covariance, and two variables have nonzero covariance are dependent.&lt;/li>
&lt;li>Zero covariance means there must be no linear dependence, While independent also excludes nonlinear relationships between two variables.&lt;/li>
&lt;li>It is possible for two variables to be dependent but have zero covariance.&lt;/li>
&lt;/ul>
&lt;p>The &lt;strong>covariance matrix&lt;/strong> of a random vector $x \in \R^n$ is an $n \times n$ matrix, such that
$$
\tag{3.14}
\text{Cov}(\mathbf{x})_{i, j} = \text{Cov}(\mathbf{x}_i, \mathbf{x}_j) .
$$
The diagonal elements of the covariance give the variance:
$$
\tag{3.15}
\text{Cov}(\mathbf{x}_i, \mathbf{x}_i) = \text{Var}(\mathbf{x}_i) .
$$&lt;/p>
&lt;h3 id="common-probability-distribution" >
&lt;div>
&lt;a href="#common-probability-distribution">
##
&lt;/a>
Common Probability Distribution
&lt;/div>
&lt;/h3>
&lt;h4 id="bernoulli-distribution" >
&lt;div>
&lt;a href="#bernoulli-distribution">
###
&lt;/a>
Bernoulli Distribution
&lt;/div>
&lt;/h4>
&lt;p>The Bernoulli Distribution is a distribution over a single binary random variable. It is controlled by a single parameter $\phi \in [0, 1]$, which gives the probability of the random variable being equal to $1$. It has the following properties:
$$
\begin{eqnarray}
\tag{3.16}
P(\mathbf{x} = 1) &amp;amp;=&amp;amp; \phi \
\
\tag{3.17}
P(\mathbf{x} = 0) &amp;amp;=&amp;amp; 1 - \phi \
\
\tag{3.18}
P(\mathbf{x} = x) &amp;amp;=&amp;amp; \phi^{x} (1 - \phi)^{1-x} \
\
\tag{3.19}
\mathbb{E}&lt;em>\mathbf{x}[\mathbf{x}] &amp;amp;=&amp;amp; \phi \
\
\tag{3.20}
\text{Var}&lt;/em>\mathbf{x}(\mathbf{x}) &amp;amp;=&amp;amp; \phi (1 - \phi)
\end{eqnarray}
$$&lt;/p>
&lt;h4 id="gaussian-distribution" >
&lt;div>
&lt;a href="#gaussian-distribution">
###
&lt;/a>
Gaussian Distribution
&lt;/div>
&lt;/h4>
&lt;p>The most commonly used distribution over real numbers is the normal distribution, also known as the Gaussian distribution:
$$
\tag{3.21}
\mathcal{N}(x; \mu, \sigma^2) = \sqrt{{1 \over {2 \pi \sigma^2}}} \exp \bigg(-{1 \over {2 \sigma^2}} (x - \mu)^2 \bigg).
$$
The two parameters $\mu \in \R$ and $\sigma \in (0, \infin)$ control the normal distribution.&lt;/p>
&lt;p>When we evaluate the PDF, we need to square and invert $\sigma$. When we need to frequently evaluate the PDF with different parameter values, a more efficient way of parametrizing the distribution is to use a parameter $\beta \in (0, \infin)$ to control the &lt;strong>precision&lt;/strong>, or inverse variance, of the distribution:
$$
\tag{3.22}
\mathcal{N}(x; \mu, \beta^{-1}) = \sqrt{{\beta \over {2 \pi}}} \exp \bigg(-{1 \over 2} \beta (x - \mu)^2 \bigg).
$$
&lt;img alt="bell curve" src="./images/DL_gaussian_distribution.png">&lt;/p>
&lt;p>Normal distributions are a sensible choice for many applications, for two major reasons:&lt;/p>
&lt;ul>
&lt;li>First, many distributions we wish to model are truly close to being normal distributions. The &lt;strong>central limit theorem&lt;/strong> shows that the sum of many independent random variables is approximately normally distributed. This means that in practice, many complicated systems can be modeled successfully as normally distributed noise, even if the system can be decomposed into parts with more structured behavior.&lt;/li>
&lt;li>Second, out of all possible probability distributions with the same variance, the normal distribution encodes the maximum amount of uncertainty over the real numbers. We can thus think of the normal distribution as being the one that inserts the least amount of prior knowledge into a model.&lt;/li>
&lt;/ul>
&lt;p>The normal distribution generalizes to $\R^n$, in which case it is known as the &lt;strong>multivariate normal distribution&lt;/strong>. It may be parametrized with a positive definite symmetric matrix $\Sigma$ :
$$
\tag{3.23}
\mathcal{N}(x; \mu, \Sigma) = \sqrt{{1 \over {(2 \pi)^n |\Sigma|}}}
\exp \bigg(-{1 \over 2} (x - \mu)^{\mathsf{T}} \Sigma^{-1} (x - \mu) \bigg).
$$
The parameter $\mu$ still gives the mean of the distribution, though now it is vector valued. The parameter $\Sigma$ gives the covariance matrix of the distribution. $|\Sigma|$ denotes the &lt;strong>determinant&lt;/strong> of $\Sigma$ .&lt;/p>
&lt;p>As in the univariate case, when we wish to evaluate the PDF multiple times with more efficient computation, we need to invert $\Sigma$ , and instead use a &lt;strong>precision matrix $\beta$&lt;/strong> :
$$
\tag{3.24}
\mathcal{N}(x; \mu, \beta^{-1}) = \sqrt{{|\beta| \over (2 \pi)^n}} \exp \bigg(-{1 \over 2} (x - \mu)^{\mathsf{T}} \beta (x - \mu) \bigg).
$$
We often fix the covariance matrix to be a diagonal matrix. An even simpler version is the &lt;strong>isotropic&lt;/strong> Gaussian distribution, whose covariance matrix is a scalar times the identity matrix.&lt;/p>
&lt;h4 id="exponential-and-laplace-distributions" >
&lt;div>
&lt;a href="#exponential-and-laplace-distributions">
###
&lt;/a>
Exponential and Laplace Distributions
&lt;/div>
&lt;/h4>
&lt;p>In the context of deep learning, we often want to have a probability distribution with a sharp point at $x = 0$. To accomplish this, we can use the &lt;strong>exponential distribution&lt;/strong>:
$$
\tag{3.25}
p(x; \lambda) = \lambda \mathbf{1}&lt;em>{x \ge 0} \exp(- \lambda x) .
$$
The exponential distribution uses the &lt;strong>indicator function&lt;/strong> $\mathbf{1}&lt;/em>{x \ge 0}$ to assign probability zero to all negative values of $x$.&lt;/p>
&lt;p>A closely related probability distribution that allows us to place a sharp peak of probability mass at an arbitrary point $\mu$ is the &lt;strong>Laplace distribution&lt;/strong>
$$
\tag{3.26}
\text{Laplace}(x; \mu, \gamma) = {1 \over 2\gamma} \exp(- {|x - \mu| \over \gamma}).
$$&lt;/p>
&lt;h2 id="information-theory" >
&lt;div>
&lt;a href="#information-theory">
#
&lt;/a>
Information Theory
&lt;/div>
&lt;/h2>
&lt;p>Information theory is a branch of applied mathematics that resolves around quantifying how much information is present in a signal. In the context of machine learning, we can apply information theory to characterize probability distributions or quantify similarity between probability distributions.&lt;/p>
&lt;p>The basic intuition behind information theory is that learning that an unlikely event has has occurred is more informative than learning that a likely event has occurred. A message saying &amp;ldquo;the sun rose this morning&amp;rdquo; is so uninformative (to human being on the earth) as to be unnecessary to send, but a message saying &amp;ldquo;there are a solar eclipse this morning&amp;rdquo; is very informative.&lt;/p>
&lt;p>We would like to quantify information in a way that formalizes this intuition.&lt;/p>
&lt;ul>
&lt;li>Likely events should have low information content, and in the extreme case, events that are guaranteed to happen should have no information content whatsoever.&lt;/li>
&lt;li>Less likely events should have higher information content.&lt;/li>
&lt;li>Independent events should have additive information. For example, finding out that a tossed coin has come up as heads twice should convey twice as much information as finding out that a tossed coin has come up as head once.&lt;/li>
&lt;/ul>
&lt;p>To satisfy all three of these properties, we define the &lt;strong>self-information&lt;/strong> of an event $\mathbf{x} = x$ to be
$$
\tag{3.48}
I(x) = - \log P(x) .
$$
In this series, we always use log to mean the natural logarithm, with base $e$. Our definition of $I(x)$ is therefore written in units of &lt;strong>nats&lt;/strong>. One nat is the amount of information gained by observing an event of probability $1 \over e$. Other texts use base-2 logarithms and units called &lt;strong>bits&lt;/strong> or &lt;strong>shannons&lt;/strong>; information measured in bits is just a rescaling of information measured in nats.&lt;/p>
&lt;p>When $\bf{x}$ is continuous, an event with unit density still has zero information, despite not being an event that is guaranteed to occur.&lt;/p>
&lt;h3 id="entropy" >
&lt;div>
&lt;a href="#entropy">
##
&lt;/a>
Entropy
&lt;/div>
&lt;/h3>
&lt;p>Self-information deals only with a single outcome. We can quantify the amount of uncertainty in an entire probability distribution using the &lt;strong>Shannon entropy&lt;/strong>,
$$
\tag{3.49}
H(\mathbf{x})
= \mathbb{E}&lt;em>{\mathbf{x} \sim P}[I(x)]
= - \mathbb{E}&lt;/em>{\mathbf{x} \sim P}[\log P(x)],
$$
also denoted $H(P)$. In other words, the Shannon entropy of a distribution is the expected amount of information in an event drawn from that distribution. It gives a lower bound on the number of nats needed on average to encode symbols drawn from a distribution $P$. Distributions that are nearly deterministic (where outcome is nearly certain) have low entropy; distributions that are closer to uniform have high entropy. When $\bf{x}$ is continuous, the Shannon entropy is known as the &lt;strong>differential entropy&lt;/strong>.&lt;/p>
&lt;p>&lt;img alt="Shannon entropy" src="./images/DL_binary_Shannon_entropy.png">&lt;/p>
&lt;h3 id="kl-divergence" >
&lt;div>
&lt;a href="#kl-divergence">
##
&lt;/a>
KL divergence
&lt;/div>
&lt;/h3>
&lt;p>If we have two separate probability distributions $P(x)$ and $Q(x)$ over the same random variable $\bf{x}$, we can measure how different these two distributions are using the &lt;strong>Kullback-Leibler (KL) divergence&lt;/strong>:
$$
\tag{3.50} \label{eq_kld}
D_{KL}(P || Q)
= \mathbb{E}&lt;em>{\mathbf{x} \sim P} \bigg[\log {P(x) \over Q(x)} \bigg]
= \mathbb{E}&lt;/em>{\mathbf{x} \sim P}[\log P(x) - \log Q(x)] .
$$&lt;/p>
&lt;p>In the case of discrete variables, it is the extra amount of information (in bits or nats) needed to send a message containing symbols drawn from probability distribution $P$, when we use a code that was designed to minimize the length of messages drawn from probability distribution $Q$.&lt;/p>
&lt;p>The KL divergence has many useful properties, most notably being non-negative. The KL divergence is $0$ if and only if $P$ and $Q$ are the same distribution in the case of discrete variables, or equal &amp;ldquo;almost everywhere&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&amp;rdquo; in the case of continuous variables. Because the KL divergence is non-negative and measures the difference between two distributions, it is often conceptualized as measuring some sort of distance between these distributions. It is not a true distance measure because it is not symmetric: $D_{KL}(P || Q) \ne D_{KL}(Q || P)$ for some $P$ and $Q$. This asymmetriy means that there are important consequences to the choice of whether to use $D_{KL}(P || Q)$ or $D_{KL}(Q || P)$. See figure 3.6 for more detail.&lt;/p>
&lt;p>&lt;img alt="KL divergence" src="./images/DL_kl_divergence.png">&lt;/p>
&lt;p>A quantity that is closely related to the KL divergence is the &lt;strong>cross-entropy&lt;/strong> $H(P, Q) = H(P) + D_{KL}(P||Q)$, which is similar to the KL divergence ($\ref{eq_kld}$) but lacking the term on the left:
$$
\tag{3.51}
H(P, Q) = - \mathbb{E}_{\mathbf{x} \sim P} \log Q(x) .
$$
Minimizing the cross-entropy with respect to $Q$ is equivalent to minimizing the KL divergence, because $Q$ does not participate in the omitted term.&lt;/p>
&lt;p>When computing many of these quantities, it is common to encounter expressions of the form $0\log0$. By convention, in the context of information theory, we treat these expressions as $\lim_{x \rightarrow 0} x \log x = 0$.&lt;/p>
&lt;h3 id="kl-散度" >
&lt;div>
&lt;a href="#kl-%e6%95%a3%e5%ba%a6">
##
&lt;/a>
KL 散度
&lt;/div>
&lt;/h3>
&lt;p>KL 散度，也称为相对熵(relative entropy)或信息散度(information divergence)，可用于度量两个概率分布之间的差异。给定两个(连续型)概率分布 $P$ 和 $Q$ ，二者之间的 KL 散度定义为
$$
\tag{C.34}
KL(P||Q) = \int^{\infin}_{-\infin} p(x) \log {p(x) \over q(x)} dx,
$$
其中，$p(x)$ 和 $q(x)$ 分别为 $P$ 和 $Q$ 的概率密度函数。KL 散度满足非负性，但不满足对称性，因此 KL 散度不是一个度量(metric)&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>。&lt;/p>
&lt;p>若将 KL 散度的定义展开，可得
$$
\begin{eqnarray}
KL(P||Q)
&amp;amp;=&amp;amp; \int^{\infin}&lt;em>{-\infin} p(x) \log {p(x)} dx - \int^{\infin}&lt;/em>{-\infin} p(x) \log {q(x)} dx \
\
\tag{C.37}
&amp;amp;=&amp;amp; -H(P) + H(P,Q)
\end{eqnarray}
$$
其中，$H(P)$ 为熵(entropy)，$H(P,Q)$ 为 $P$ 和 $Q$ 得交叉熵(cross-entropy)。在信息论中，熵 $H(P)$ 表示对来自 $P$ 的随机变量进行编码所需要的最小字节数，而交叉熵 $H(H,Q)$ 则表示使用基于 $Q$ 的编码对来自 $P$ 的变量进行编码所需要的 “额外” 的字节数；显然，额外字节数必然非负，当且仅当 $P = Q$ 时额外字节数为零。&lt;/p>
&lt;h2 id="density-estimation" >
&lt;div>
&lt;a href="#density-estimation">
#
&lt;/a>
Density Estimation
&lt;/div>
&lt;/h2>
&lt;h3 id="histogram" >
&lt;div>
&lt;a href="#histogram">
##
&lt;/a>
Histogram
&lt;/div>
&lt;/h3>
&lt;blockquote>
&lt;p>&amp;ldquo;In a (standard) histogram, the areas of the blocks represent percentages.&amp;rdquo;&lt;/p>
&lt;p>&amp;ldquo;With the density scale on the vertical axis, the areas of the blocks come out in percent. The area under the histogram over an interval equals the percentage of cases in that interval. The total area under the histogram is 100%.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;p>A &lt;strong>histogram&lt;/strong> is a plot designed to show the distribution of values in a set of data. The values are first sorted, and then divided into a fixed number of equal-width bins. A plot is then drawn that shows the number of elements in each bin. (Note that the histograms in Figure 15.20 were not turn the counts into normalized probability density.)&lt;/p>
&lt;p>&lt;img alt="histograms" src="./images/ICPP_histograms_coin_flips.png">&lt;/p>
&lt;p>A histogram is a depiction of a &lt;strong>frequency distribution&lt;/strong>. It tells us how often a random variable has taken on a value in some range, e.g., how often the fraction of times a coin came up heads was between 0.4 and 0.5. It also provides information about the relative frequency of various ranges. For example, we can easily see that the fraction of heads falls between 0.4 and 0.5 far more frequently than it falls between 0.3 and 0.4 (see the one in the left in Figure 15.20). Notice that while the means in both plots (Figure 15.20) are about the same, the standard deviations are quite different. The spread of outcomes is much tighter when we flip the coin 1000 times per trail than when we flip the coin 100 times per trial&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>A &lt;strong>probability distribution&lt;/strong> captures the notion of relative frequency by giving the probability of a random value taking on a value within a range. Probability distributions fall into two groups: discrete probability distributions and continuous probability distributions, depending upon whether they define the probability distribution for a discrete or a continuous random variable.&lt;/p>
&lt;p>&lt;strong>Discrete probability distributions&lt;/strong> are easier to describe. Since there are a finite number of values that the variable can take on, the distribution can be described by simply listing the probability of each value.&lt;/p>
&lt;p>&lt;strong>Continuous probability distributions&lt;/strong> are trickier. Since there are an infinite number of possible values, the probability that a continuous random variable will take on a specific value is usually 0. For example, the probability that a car is traveling at exactly 81.3457283 miles per hour is probably 0. Mathematicians like to describe continuous probability distributions using a &lt;strong>Probability Density Function (PDF)&lt;/strong>. A &lt;strong>PDF&lt;/strong> describes the probability of a random variable lying between two values. Think of the PDF as defining a curve where the values on the x-axis lie between the minimum and maximum value of the random variable. Under the assumption that $x_1$ and $x_2$ lie in the domain of the random variable, the probability of the variable having a value between $x_1$ and $x_2$ is the area under the PDF curve between $x_1$ and $x_2$ .&lt;/p>
&lt;p>&lt;img alt="pdf" src="./images/ICPP_probability_density_functions.png">&lt;/p>
&lt;p>The &lt;code>random.random()&lt;/code> returns a value lies in interval [0, 1]. The area under the curve of PDF for &lt;code>random.random()&lt;/code> from 0 to 1 is 1. On the other hand, if we consider the area under the part of the curve between 0.2 and 0.4, it is 0.2 ($(0.4 - 0.2) \times 1.00$). Similarly, the area under the curve for &lt;code>random.random()+random.random()&lt;/code> from 0 to 2 is also 1, and the area under the curve from 0 to 1 is 0.5. Notice that the same length of interval has the same probability in PDF for &lt;code>random.random()&lt;/code> while some intervals are more probable than others in PDF for &lt;code>random.random()+random.random()&lt;/code>.&lt;/p>
&lt;h3 id="histogram-for-density-estimation" >
&lt;div>
&lt;a href="#histogram-for-density-estimation">
##
&lt;/a>
Histogram for density estimation
&lt;/div>
&lt;/h3>
&lt;p>Density estimation can be used of probability distributions (such Gaussian, Beta, Dirichlet distributions) having specific functional forms governed by a small number of parameters whose values are to be determined from a data set. This is called the &lt;em>parametric&lt;/em> approach to density modeling. An important limitation of this approach is that the chosen density might be a poor model of the distribution that generates the data, which can result in poor predictive performance. For instance, if the process that generates the data is multimodal (多峰的), then this aspect of the distribution can never be captured by a Gaussian, which is necessarily unimodal&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>We consider some &lt;em>nonparametric&lt;/em> approaches to density estimation that make few assumptions about the form of the distribution. Here we focus mainly on simple frequentist methods. Let&amp;rsquo;s start with a discussion of histogram methods for density estimation, we explore the properties of histogram density model, focusing on the case of a single continuous variable $x$.&lt;/p>
&lt;p>Standard histograms simply partition $x$ into distinct bins of with $\Delta_i$ and then count the number $n_i$ of observations of $x$ falling in bin $i$. In order to turn this count into a normalized probability density, we simply divide by the total number $N$ of observations and by the width $\Delta_i$ of the bins to obtain probability values for each bin given by
$$
\tag{2.241}
p_i = \frac{n_i}{N \Delta_i}
$$
for which it is easily seen that $\int p(x)dx = 1$. This gives a model for the density $p(x)$ that is constant over the width of each bin, and often the bins are chosen to have the same width $\Delta_i = \Delta$.&lt;/p>
&lt;p>&lt;img alt="histogram models" src="./images/PRML_histogram_models.png">&lt;/p>
&lt;p>From above figure, we can see that&lt;/p>
&lt;ul>
&lt;li>when $\Delta$ is very small (top right), the resulting density model is very spiky (lost a lot of structure of underlying distribution),&lt;/li>
&lt;li>if $\Delta$ is too large (bottom right), the result is a model that is too smooth (fails to capture the bimodal property of the green curve).&lt;/li>
&lt;/ul>
&lt;p>The best results are obtained for some intermediate value of $\Delta$ (middle right). In principle, a histogram density model is also dependent on the choice of edge location for the bins, though this is typically much less significant than the value of $\Delta$.&lt;/p>
&lt;p>Note that the histogram method has the property that once the histogram has been computed, the data set itself can be discarded, which can be advantageous if the data set is large. Also, the histogram approach is easily applied if the data points are arriving sequentially.&lt;/p>
&lt;p>In practice, the histogram technique can be useful for obtaining a quick visualization of data in one or two dimensions but is unsuited to most density estimation applications. The limitations are&lt;/p>
&lt;ul>
&lt;li>the estimated density has discontinuities that are due to the bin edges,&lt;/li>
&lt;li>in a space of high dimensionality, the number of bins (M) are exponential scaling with the number of dimension (D), which is $M^D$. The quantity of data needed to provide meaningful estimates of local probability density would be prohibitive.&lt;/li>
&lt;/ul>
&lt;p>Two widely used nonparametric techniques for density estimation, &lt;strong>kernel estimators&lt;/strong> and &lt;strong>nearest neighbors&lt;/strong>, which have better scaling with dimensionality than the simple histogram model.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>technical view of continuous variables [more advance mathematics knowledge required].&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>度量(metric)应满足四个基本性质：非负性($dist(x_i,x_j) \ge 0$)；同一性($dist(x_i, x_j)=0 \iff x_i=x_j$)；对称性($dist(x_i, x_j) = dist(x_j, x_i)$)；直递性($dist(x_i, x_j) \le dist(x_i, x_k) + dist(x_k, x_j)$)&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>Recall that this is also an example of the law of the average.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>Consider Gaussian Mixture Models in this case.&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Book Notes: semi-supervised clustering methods</title><link>/posts/ml101/clusteringmethods/semi-supervised_clustering/</link><pubDate>Mon, 13 Jul 2020 12:11:47 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/ml101/clusteringmethods/semi-supervised_clustering/</guid><description>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>注明：
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>原理部分的内容均来自周志华的西瓜书，真正的大师之作。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>其他内容来自开源包文档、开源电子书、ipynb文档等。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="半监督聚类-semi-supervised-clustering" >
&lt;div>
&lt;a href="#%e5%8d%8a%e7%9b%91%e7%9d%a3%e8%81%9a%e7%b1%bb-semi-supervised-clustering">
#
&lt;/a>
半监督聚类 （semi-supervised clustering）
&lt;/div>
&lt;/h2>
&lt;p>聚类是一种典型的无监督学习任务，然而在现实聚类任务中我们往往能获得一些额外的监督信息，于是可以通过半监督聚类来利用额外监督信息以获得更好的聚类效果。&lt;/p>
&lt;p>聚类任务中获得额外监督信息大致有两种类型：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>样本约束：&lt;/p>
&lt;p>必连 (must-link): 指的是样本必属于同一个簇&lt;/p>
&lt;p>勿连 (cannot-link): 样本必不属于同一个簇&lt;/p>
&lt;/li>
&lt;li>
&lt;p>样本标签：&lt;/p>
&lt;p>监督信息来自少量带有标签的样本&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="约束k均值算法-pseudo-code" >
&lt;div>
&lt;a href="#%e7%ba%a6%e6%9d%9fk%e5%9d%87%e5%80%bc%e7%ae%97%e6%b3%95-pseudo-code">
##
&lt;/a>
约束$k$均值算法 (pseudo-code)
&lt;/div>
&lt;/h3>
&lt;p>约束$k$均值算法 (Constrained k-means) 是利用第一类监督信息的代表。给定样本集 $D={x_1, x_2, \ldots, x_m}$ 以及 “必连” 关系集合 $\cal{M}$ 和 “勿连” 关系集合 $\cal{C}$ ，$(x_i, x_j) \in \cal{M}$ 表示 $x_i, x_j$ 必属于同簇，$(x_i, x_j) \in \cal{C}$ 表示 $x_i, x_j$ 必不属于同簇。该算法是 $k$-means 算法的扩展，它在聚类过程中要确保样本的约束得到满足，否则返回错误提示，算法如下：&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>： 样本集 $D = {x_1, x_2, \ldots, x_m}$;&lt;/p>
&lt;p>​ 必连约束集合 $\cal{M}$ ;&lt;/p>
&lt;p>​ 勿连约束集合 $\cal{C}$ ;&lt;/p>
&lt;p>​ 聚类簇数 $k$.&lt;/p>
&lt;p>过程：&lt;/p>
&lt;p>01: 从 $D$ 中随机选取 $k$ 个样本作为初始均值向量 ${\mu_1, \mu_2, \ldots, \mu_k}$;&lt;/p>
&lt;p>02: &lt;strong>repeat&lt;/strong>&lt;/p>
&lt;p>03: $C_j = \phi (1 \le j \le k)$;&lt;/p>
&lt;p>04: &lt;strong>for&lt;/strong> $i = 1, 2, \ldots, m$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>05: 计算样本 $x_i$ 与各个均值向量 $\mu_j (1 \le j \le k)$ 的距离： $d_{ij} = ||x_i - \mu_j||_2$;&lt;/p>
&lt;p>06: $\cal{K} = {1, 2, \ldots, k}$;&lt;/p>
&lt;p>07: $\text{is_merged} = false$;&lt;/p>
&lt;p>08: &lt;strong>while&lt;/strong> $\neg\ \text{is_merged}$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>09: 基于 $\cal{K}$ 找出与样本 $x_i$ 距离最近的簇： $r = argmin_{j \in \cal{K}}\ d_{ij}$;&lt;/p>
&lt;p>10: 检测将 $x_i$ 划入聚类簇 $C_r$ 是否会违背 $\cal{K}$ 与 $\cal{C}$ 中的约束；&lt;/p>
&lt;p>11： &lt;strong>if&lt;/strong> $\neg\ \text{is_voilated}$ &lt;strong>then&lt;/strong>&lt;/p>
&lt;p>12: $C_r = C_r \cup {x_i}$;&lt;/p>
&lt;p>13: $\text{is_merged} = true$&lt;/p>
&lt;p>14: &lt;strong>else&lt;/strong>&lt;/p>
&lt;p>15: $\cal{K} = K \setminus {r}$;&lt;/p>
&lt;p>16: &lt;strong>if&lt;/strong> $\cal{K} = \phi$ &lt;strong>then&lt;/strong>&lt;/p>
&lt;p>17: &lt;strong>break&lt;/strong> 并返回错误提示&lt;/p>
&lt;p>18: &lt;strong>end if&lt;/strong>&lt;/p>
&lt;p>19: &lt;strong>end if&lt;/strong>&lt;/p>
&lt;p>20: &lt;strong>end while&lt;/strong>&lt;/p>
&lt;p>21: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>22: &lt;strong>for&lt;/strong> $j = 1, 2, \ldots, k$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>23: $\mu_j = {1 \over |C_j|} \sum_{x \in C_j} x$;&lt;/p>
&lt;p>24: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>25: &lt;strong>until&lt;/strong> 均值向量均为更新&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>：簇划分 ${C_1, C_2, \ldots, C_k}$&lt;/p>
&lt;hr>
&lt;hr>
&lt;h3 id="约束种子-k-均值算法-pseudo-code" >
&lt;div>
&lt;a href="#%e7%ba%a6%e6%9d%9f%e7%a7%8d%e5%ad%90-k-%e5%9d%87%e5%80%bc%e7%ae%97%e6%b3%95-pseudo-code">
##
&lt;/a>
约束种子 $k$ 均值算法 (pseudo-code)
&lt;/div>
&lt;/h3>
&lt;p>约束种子 $k$ 均值算法 (Constrained Seed k-means) 利用第二种监督信息，即少量有标记样本（此处样本标记指的是簇标记‘cluster label’，而不是类别标记‘class label’）。给定样本集 $D = {x_1, x_2, \ldots, x_m}$，假定少量的有标记样本为 $S = \cup^k_{j=1} S_j \subset D$，其中，$S_j \ne \phi$ 为隶属于第 $j$ 个聚类簇的样本。这样的监督信息利用起来很容易：直接将他们作为‘种子’，用他们初始化 $k$ 均值算法的 $k$ 个聚类中心，并且在聚类簇迭代更新过程中不改变种子样本的簇隶属关系。其算法描述如下：&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>: 样本集 $D = {x_1, x_2, \ldots, x_m}$;&lt;/p>
&lt;p>​ 少量有标记样本 $S = \cup^k_{j=1} S_j$;&lt;/p>
&lt;p>​ 聚类簇数 $k$.&lt;/p>
&lt;p>过程:&lt;/p>
&lt;p>01: &lt;strong>for&lt;/strong> $j = 1, 2, \ldots, k$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>02: $\mu_j = {1 \over |S_j|} \sum_{x \in S} x$&lt;/p>
&lt;p>03: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>04: &lt;strong>repeat&lt;/strong>&lt;/p>
&lt;p>05: $C_j = \phi (1 \le j \le k)$;&lt;/p>
&lt;p>06: &lt;strong>for&lt;/strong> $j = 1, 2, \ldots, k$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>07: &lt;strong>for all&lt;/strong> $x \in S_j$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>08: $C_j = C_j \cup {x}$&lt;/p>
&lt;p>09: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>10: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>11: &lt;strong>for all&lt;/strong> $x_i \in D \setminus S$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>12: 计算样本 $x_i$ 与各个均值向量 $\mu_j (1 \le j \le k)$ 的距离： $d_{ij} = ||x_i -\mu_j||_2$;&lt;/p>
&lt;p>13: 找出与样本 $x_i$ 距离最近的簇： $r = argmin_{j \in {1, 2, \ldots, k}} d_{ij}$;&lt;/p>
&lt;p>14: 将样本 $x_i$ 划入相应的簇： $C_r = C_r \cup {x_i}$&lt;/p>
&lt;p>15: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>16: &lt;strong>for&lt;/strong> $j = 1, 2, \ldots, k$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>17: $\mu_j = {1 \over |C_j|} \sum_{x \in C_j} x$;&lt;/p>
&lt;p>18: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>19: &lt;strong>until&lt;/strong> 均值向量均未更新&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>: 簇划分 ${C_1, C_2, \ldots, C_k}$&lt;/p>
&lt;hr></description></item><item><title>Book Notes: clustering methods</title><link>/posts/ml101/clusteringmethods/prototype-based_clustering/</link><pubDate>Sat, 13 Jun 2020 16:11:47 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/ml101/clusteringmethods/prototype-based_clustering/</guid><description>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>注明：
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>原理部分的内容均来自周志华的西瓜书，真正的大师之作。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>其他内容来自开源包文档、开源电子书、ipynb文档等。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="原型聚类" >
&lt;div>
&lt;a href="#%e5%8e%9f%e5%9e%8b%e8%81%9a%e7%b1%bb">
#
&lt;/a>
原型聚类
&lt;/div>
&lt;/h2>
&lt;p>原型&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>聚类也称为 “基于原型的聚类(prototype-based clustering)”，此类算法假设聚类结构能够通过一组原型刻画，在现实聚类任务中极为常用。通常情形下，算法先对原型进行初始化，然后对原型进行迭代更新求解。采用不同的原型表示、不同的求解方式，将产生不同的算法。&lt;/p>
&lt;h3 id="k-均值聚类算法" >
&lt;div>
&lt;a href="#k-%e5%9d%87%e5%80%bc%e8%81%9a%e7%b1%bb%e7%ae%97%e6%b3%95">
##
&lt;/a>
$k$ 均值聚类算法
&lt;/div>
&lt;/h3>
&lt;p>给定样本集 $D = {x_1, \ldots, x_m }$ ，“$k$ 均值($k$-means)” 算法针对聚类所得簇划分 $\mathcal{C} = {C_1, \ldots, C_k }$ 最小化平方误差
$$
\tag{9.24}
E = \sum^k_{i=1} \sum_{x \in C_i} ||x - \mu_i||^2_2 ,
$$
其中，$\mu_i = {1 \over |C_i|} \sum_{x \in C_i} x$ 是簇 $C_i$ 的均值向量。直观来看，式(9.24)在一定程度上刻画了簇内样本围绕簇均值向量的紧密程度，$E$ 值越小则簇内样本相似度越高。&lt;/p>
&lt;p>最小化式(9.24)并不容易，找到它的最优解需考察样本集 $D$ 的所有可能簇划分，这是一个 NP 难问题&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> 。因此，$k$ 均值算法采用了贪心策略，通过迭代优化来近似求解式(9.24)。算法流程如下，其中第1行对均值向量进行初始化，在第4-8行与第9-16行依次对当前簇划分及均值向量迭代更新，若迭代更新后聚类结果保持不变，则在第18行将当前的簇划分结果返回。&lt;/p>
&lt;hr>
&lt;p>&lt;code>k 均值算法流程&lt;/code>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>：样本集 $D = {x_1, \ldots, x_m }$ ；&lt;/p>
&lt;p>​ 聚类簇数 $k$&lt;/p>
&lt;p>&lt;strong>过程&lt;/strong>：&lt;/p>
&lt;p>1: 从 $D$ 中随机选择 $k$ 个样本作为初始均值向量 ${\mu_1, \ldots, \mu_k }$&lt;/p>
&lt;p>2: &lt;strong>repeat&lt;/strong>&lt;/p>
&lt;p>3: 令 $C_i = \phi \quad (1 \le i \le k)$&lt;/p>
&lt;p>4: &lt;strong>for&lt;/strong> $j = 1, 2, \ldots, m$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>5: 计算样本 $x_j$ 与各个均值向量 $\mu_i \ (1 \le i \le k)$ 的距离：$d_{ji} = ||x_j - \mu_i||_2$ ；&lt;/p>
&lt;p>6: 根据距离最近的均值向量确定 $x_j$ 的簇标记&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>：$\lambda_j = \text{argmin}&lt;em>{i \in {1, 2, \ldots, k}} d&lt;/em>{ji}$ ；&lt;/p>
&lt;p>7: 将样本 $x_j$ 划入相应的簇：$C_{\lambda_j} = C_{\lambda_j} \cup {x_j}$ ；&lt;/p>
&lt;p>8: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>9: &lt;strong>for&lt;/strong> $i = 1, 2, \ldots, k$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>10: 计算新均值向量：$\mu_i&amp;rsquo; = {1 \over |C_i|} \sum_{x \in C_i} x$ ；&lt;/p>
&lt;p>11: &lt;strong>if&lt;/strong> $\mu_i&amp;rsquo; \ne \mu_i$ &lt;strong>then&lt;/strong>&lt;/p>
&lt;p>12: 将当前均值向量 $\mu_i$ 更新为 $\mu_i'$&lt;/p>
&lt;p>13: &lt;strong>else&lt;/strong>&lt;/p>
&lt;p>14: 保持当前均值向量不变&lt;/p>
&lt;p>15: &lt;strong>end if&lt;/strong>&lt;/p>
&lt;p>16: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>17: &lt;strong>until&lt;/strong> 当前均值向量均未更新&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>：簇划分 $\mathcal{C} = {C_1, C_2, \ldots, C_k }$&lt;/p>
&lt;hr>
&lt;h3 id="k-means-in-action" >
&lt;div>
&lt;a href="#k-means-in-action">
##
&lt;/a>
K-Means in Action
&lt;/div>
&lt;/h3>
&lt;h4 id="finding-the-optimal-number-of-clusters" >
&lt;div>
&lt;a href="#finding-the-optimal-number-of-clusters">
###
&lt;/a>
Finding the optimal number of clusters
&lt;/div>
&lt;/h4>
&lt;p>In general, it will not be easy to know how to set $k$, and the result might be quite bad if you set it to the wrong value (see Figure 9-7).&lt;/p>
&lt;p>&lt;img alt="cluster No." src="./images/handson_cluster_numbers.png">&lt;/p>
&lt;p>You might be thinking that we could just pick the model with lowest inertia. Unfortunately, the inertia is not a good performance metric when trying to choose $k$ because it keeps getting lower as we increase $k$. Indeed, the more clusters there are, the closer each instance will be to its closest centroid, and therefore the lower the inertia will be (see Figure 9-8: a plot of the inertia as a function of $k$).&lt;/p>
&lt;p>&lt;img alt="cluster inertia" src="./images/handson_cluster_inertia.png">&lt;/p>
&lt;p>This technique for choosing the best value for the number of clusters is rather coarse. A more precise approach (but more computationally expensive) is to use the &lt;strong>silhouette score&lt;/strong>, which is the mean silhouette coefficient (轮廓系数) over all the instances. An instance&amp;rsquo;s silhouette coefficient is equal to $(b - a) / \max(a, b)$, where $a$ is the mean distance to the other instances in the same cluster (i.e., the mean intra-cluster distance) and $b$ is the mean nearest-cluster distance (i.e., the mean distance to the instances of the next cluster, defined as the one that minimizes $b$, excluding the instance&amp;rsquo;s own cluster).&lt;/p>
&lt;p>The silhouette coefficient can vary between -1 and +1.&lt;/p>
&lt;ul>
&lt;li>silhouette coefficient close to +1 means that the instance is well inside its own cluster and far from other clusters&lt;/li>
&lt;li>silhouette coefficient close to 0 means that it is close to a cluster boundary&lt;/li>
&lt;li>silhouette coefficient close to -1 means that the instance may have been assigned to the wrong cluster&lt;/li>
&lt;/ul>
&lt;p>To compute the silhouette score, you can use sklearn&amp;rsquo;s &lt;code>silhouette_score()&lt;/code> function:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> sklearn.metrics &lt;span style="color:#ff6ac1">import&lt;/span> silhouette_score
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># give it all the instances in the dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># and the labels they were assigned&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>silhouette_score(X, kmeans_model&lt;span style="color:#ff6ac1">.&lt;/span>labels_)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can also compare the silhouette scores for different numbers of clusters (see Figure 9-9):&lt;/p>
&lt;p>&lt;img alt="silhouette scores" src="./images/handson_cluster_silhouette_scores.png">&lt;/p>
&lt;p>As the Figure 9-9 shows, this visualization is much richer than the previous one: although it confirms that $k = 4$ is a very good choice, it also underlines the fact that $k = 5$ is quite good as well, and much better than $k &amp;gt; 5$. This is not visible when comparing the inertias.&lt;/p>
&lt;p>&lt;strong>silhouette diagram&lt;/strong>&lt;/p>
&lt;p>An even more informative visualization is obtained when you plot every instance&amp;rsquo;s silhouette coefficient, sorted by the cluster they are assigned to and by the value of the coefficient. This is called a &lt;em>silhouette diagram&lt;/em> (see Figure 9-10). Each diagram contains one knife shape per cluster. The shape&amp;rsquo;s height indicates the number of instances the cluster contains, and its width represents the sorted silhouette coefficients of the instances in the cluster (wider is better). The dashed line indicated the mean silhouette coefficient.&lt;/p>
&lt;p>&lt;img alt="silhouette coefficient sorted" src="./images/handson_cluster_silhouette_coefficients_sorted.png">&lt;/p>
&lt;p>The dashed line represents the mean silhouette score for each number of clusters. When most of the instances in a cluster have a lower coefficient than this score, then the cluster is rather bad since this means its instances are much too close to other clusters (such as when $k = 3, k = 6$). But when $k =4$ or $k = 5$ , the clusters look pretty good: most instances extend beyond the dashed line. When $k = 4$ , the cluster at index 1 is rather big. When $k = 5$ , all clusters have similar sizes. So, even though the overall silhouette score from $k=4$ is slightly greater than for $k=5$ , it seems like a good idea to use $k=5$ to get clusters of similar sizes.&lt;/p>
&lt;h4 id="limits-of-k-means" >
&lt;div>
&lt;a href="#limits-of-k-means">
###
&lt;/a>
Limits of K-Means
&lt;/div>
&lt;/h4>
&lt;p>Despite its many merits, most notably being fast and scalable, K-Means is not perfect. As we saw, it is necessary to run the algorithm several times to avoid suboptimal solutions, plus you need to specify the number of clusters, which can be quite a hassle. Moreover, K-Means does not behave very well when the clusters have varying sizes, different densities, or non-spherical shapes (see Figure 9-11).&lt;/p>
&lt;p>&lt;img alt="cluster shapes" src="./images/handson_cluster_shapes.png">&lt;/p>
&lt;p>As Figure 9-11 shows, neither of these solutions is any good (the solution on the right is just terrible even though its inertia is lower). So, depending on the data, different clustering algorithms may perform better. On these types of elliptical clusters, &lt;em>Gaussian mixture models&lt;/em> work great.&lt;/p>
&lt;h3 id="学习向量量化" >
&lt;div>
&lt;a href="#%e5%ad%a6%e4%b9%a0%e5%90%91%e9%87%8f%e9%87%8f%e5%8c%96">
##
&lt;/a>
学习向量量化
&lt;/div>
&lt;/h3>
&lt;p>与 $k$ 均值算法类似，“学习向量量化(Learning Vector Quantization, LVQ)” 也是试图找到一组原型向量来刻画聚类结构，但与一般聚类算法不同的是，LVQ 假设数据样本带有类别标记&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup> ，学习过程利用样本的这些监督信息来辅助聚类。&lt;/p>
&lt;p>给定样本集 $D = {(x_1, y_1), \ldots, (x_m, y_m) }$ ，每个样本 $x_j$ 是由 $n$ 个属性描述的特征向量 $(x_{j1}; x_{j2}; \ldots;x_{jn})$ ， $y_j \in \mathcal{Y}$ 是样本 $x_j$ 的类别标记。LVQ 的目标是学得一组 $n$ 维原型向量 ${p_1, p_2, \ldots, p_q }$ ，每个原型向量代表一个聚类簇，簇标记 $t_i \in \mathcal{Y}$ 。&lt;/p>
&lt;p>&lt;code>LVQ 算法&lt;/code> 描述如下：算法第1行先对原型向量进行初始化，例如对第q个簇可以从类别标记为 $t_q$ 的样本中随机选取一个作为原型向量。算法第2-12行对原型向量进行迭代优化。在每一轮迭代中，算法随机选取一个有标记的训练样本，找出与其距离最近的原型向量，并根据两者的类别标记是否一致来对原型向量进行相应的更新。在第12行中，若算法的停止条件已满足（例如达到最大迭代轮数，或原型向量趋于稳定），则将当前原型向量作为最终结果返回。&lt;/p>
&lt;hr>
&lt;p>&lt;code>LVQ 算法&lt;/code>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>：样本集 $D = {(x_1, y_1), \ldots, (x_m, y_m) }$ ；&lt;/p>
&lt;p>​ 原型向量个数 $q$ ，各原型向量预设类别标记 ${ t_1, t_2, \ldots, t_q}$ ；&lt;/p>
&lt;p>​ 学习率 $\eta \in (0, 1)$ .&lt;/p>
&lt;p>&lt;strong>过程&lt;/strong>：&lt;/p>
&lt;p>01: 初始化一组原型向量 ${p_1, p_2, \ldots, p_q }$&lt;/p>
&lt;p>02: &lt;strong>repeat&lt;/strong>&lt;/p>
&lt;p>03: 从样本集 $D$ 随机选取样本 $(x_j, y_j)$ ；&lt;/p>
&lt;p>04: 计算样本 $x_j$ 与 $p_i (1 \le i \le q)$ 的距离：$d_{ji} = ||x_j - p_i||_2$ ；&lt;/p>
&lt;p>05: 找出与 $x_j$ 距离最近的原型向量 $p_{i*}$ ，$i* = \text{argmin}&lt;em>{i \in {1, 2, \ldots, q}} d&lt;/em>{ji}$ ；&lt;/p>
&lt;p>06: &lt;strong>if&lt;/strong> $y_j = t_{i*}$ &lt;strong>then&lt;/strong>&lt;/p>
&lt;p>07: $p&amp;rsquo; = p_{i*} + \eta \cdot (x_j - p_{i*})$&lt;/p>
&lt;p>08: &lt;strong>else&lt;/strong>&lt;/p>
&lt;p>09: $p&amp;rsquo; = p_{i*} - \eta \cdot (x_j - p_{i*})$&lt;/p>
&lt;p>10: &lt;strong>end if&lt;/strong>&lt;/p>
&lt;p>11: 将原型向量 $p_{i*}$ 更新为 $p'$&lt;/p>
&lt;p>12: &lt;strong>until&lt;/strong> 满足停止条件&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>：原型向量 ${p_1, p_2, \ldots, p_q }$&lt;/p>
&lt;hr>
&lt;p>显然，LVQ 的关键是第6-10行，即如何更新原型向量。直观上看，对样本 $x_j$ ，若最近的原型向量 $p_{i*}$ 与 $x_j$ 的类别标记相同，则令 $p_{i*}$ 与 $x_j$ 的方向靠拢，如&lt;code>LVQ 算法&lt;/code> 第7行所示，此时新原型向量为
$$
\tag{9.25}
p&amp;rsquo; = p_{i*} + \eta \cdot (x_j - p_{i*}) ,
$$
$p&amp;rsquo;$ 与 $x_j$ 之间的距离为
$$
\begin{eqnarray}
||p&amp;rsquo; - x_j||&lt;em>2
&amp;amp;=&amp;amp; ||p&lt;/em>{i*} + \eta \cdot (x_j - p_{i*}) - x_j||&lt;em>2 \
\
\tag{9.26}
&amp;amp;=&amp;amp; (1 - \eta) \cdot ||p&lt;/em>{i*} - x_j||&lt;em>2 .
\end{eqnarray}
$$
令学习率 $\eta \in (0, 1)$ ，则原型向量 $p&lt;/em>{i*}$ 在更新为 $p&amp;rsquo;$ 之后将更接近 $x_j$ 。&lt;/p>
&lt;p>类似的，若 $p_{i*}$ 与 $x_j$ 的类别标记不同，则更新后的原型向量与 $x_j$ 之间的距离将增大 $(1 + \eta) \cdot ||p_{i*} - x_j||_2$ ，从而更远离 $x_j$ 。&lt;/p>
&lt;p>在学得一组原型向量 ${p_1, p_2, \ldots, p_q }$ 后，即可实现对样本空间 $\cal{X}$ 的簇划分。对任意样本 $x$ ，它将被划入与其距离最近的原型向量所代表的簇中；换言之，每个原型向量 $p_i$ 定义了一个与之相关的一个区域 $R_i$&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup> ，该区域中每个样本与 $p_i$ 的距离不大于它与其他原型向量 $p_{i&amp;rsquo;} (i \ne i&amp;rsquo;)$ 的距离，即
$$
\tag{9.27}
R_i = {x \in \mathcal{X} \quad \text{so that} \quad ||x - p_i||&lt;em>2 \le ||x - p&lt;/em>{i&amp;rsquo;}||_2, i&amp;rsquo; \ne i } .
$$
由此形成了对样本空间 $\cal{X}$ 的簇划分 ${R_1, R_2, \ldots, R_q }$ ，该划分通常称为 “Voronoi 剖分(Voronoi tessellation)” 。&lt;/p>
&lt;h2 id="高斯混合聚类gmm" >
&lt;div>
&lt;a href="#%e9%ab%98%e6%96%af%e6%b7%b7%e5%90%88%e8%81%9a%e7%b1%bbgmm">
#
&lt;/a>
高斯混合聚类(GMM)
&lt;/div>
&lt;/h2>
&lt;p>与 $k$ 均值、LVQ 用原型向量类刻画聚类结构不同，高斯混合(Mixture-of-Gaussian) 聚类算法采用概率模型来表达聚类原型。&lt;/p>
&lt;blockquote>
&lt;p>简单回顾 | 多元高斯分布&lt;/p>
&lt;p>多元高斯分布的定义：对 $n$ 维样本空间 $\cal{X}$ 中随机向量 $x$ ，若 $x$ 服从高斯分布，其概率密度函数为
$$
\tag{9.28}
p(x) = {1 \over {(2 \pi)^{n \over 2} |\Sigma|^{1 \over 2}}} \exp {\bigg(-{1\over2}(x - \mu)^{\mathsf{T}} \Sigma^{-1} (x - \mu) \bigg)} ,
$$
其中，$\exp(x) = e^x$ ，$\mu$ 是 $n$ 维均值向量，$\Sigma$ 是 $n \times n$ 的协方差矩阵(并且是“对称正定矩阵”， 正定矩阵意思是其eigenvalues都大于零)，$|\Sigma|$ 是其行列式，$\Sigma^{-1}$ 是其逆矩阵。由式(9.28)可看出，高斯分布完全由均值向量 $\mu$ 和协方差矩阵 $\Sigma$ 这两个参数确定。为了明确显示高斯分布与相应参数的依赖关系，将概率密度函数记为 $p(x | \mu, \Sigma)$ 。&lt;/p>
&lt;/blockquote>
&lt;p>我们可以定义高斯混合分布&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>
$$
\tag{9.29}
p_{\cal{M}} (x) = \sum^k_{i=1} \alpha_i \cdot p(x | \mu_i, \Sigma_i) ,
$$
该分布共由 $k$ 个混合成分组成，每个混合成分对应一个高斯分布。其中 $\mu_i$ 与 $\Sigma_i$ 是第 $i$ 个高斯混合成分的参数，而 $\alpha_i &amp;gt; 0$ 为相应的 “混合系数(mixture coefficient)” ，且有 $\sum^k_{i=1} \alpha_i = 1$ 。&lt;/p>
&lt;p>假设样本的生成过程由高斯混合分布给出：首先，根据 $\alpha_1, \alpha_2, \ldots, \alpha_k$ 定义的先验分布选择高斯混合成分，其中 $\alpha_i$ 为选择第 $i$ 个混合成分的概率；然后，根据被选择的混合成分的概率密度函数进行采样，从而生成相应的样本。&lt;/p>
&lt;p>若训练集 $D = {x_1, \ldots, x_m }$ 由上述过程生成，令随机变量 $z_j \in {1, 2, \ldots, k }$ 表示生成样本 $x_j$ 的高斯混合成分，其取值未知。显然，$z_j$ 的先验概率 $P(z_j = i)$ 对应于 $\alpha_i (i = 1, 2, \ldots, k)$ 。根据贝叶斯定理，$z_j$ 的后验概率分布对应于
$$
\begin{eqnarray}
p_{\mathcal{M}}(z_j = i | x_j)
&amp;amp;=&amp;amp; \frac{P(z_j = i) \cdot p_{\mathcal{M}}(x_j | z_j = i)}{p_{\mathcal{M}}(x_j)} \
\
\tag{9.30} \label{eq_bayes_posterior}
&amp;amp;=&amp;amp; \frac{\alpha_i \cdot p(x_j | \mu_i, \Sigma_i) }{\sum^k_{l=1} \alpha_l \cdot p(x_j | \mu_l, \Sigma_l)} .
\end{eqnarray}
$$
换言之，$p_{\mathcal{M}}(z_j = i | x_j)$ 给出了样本 $x_j$ 由第 $i$ 个高斯混合成分生成的后验概率。为方便叙述，将其简记为 $\gamma_{ji} (i = 1, 2, \ldots, k)$ 。&lt;/p>
&lt;p>当高斯混合分布(式9.29)已知时，高斯混合聚类将把样本集 $D$ 划分为 $k$ 个簇 $\mathcal{C} = {C_1, \ldots, C_k }$ ，每个样本 $x_j$ 的簇标记 $\lambda_j$ 如下确定：
$$
\tag{9.31} \label{eq_cluster_idx}
\lambda_j
= \underset{i \in {1, 2, \ldots, k }}{\operatorname{argmax}} \gamma_{ji} .
$$
因此，从原型聚类的角度来看，高斯混合聚类是采用概率模型(高斯分布)对原型进行刻画，簇划分则由原型对应后验概率确定。&lt;/p>
&lt;p>那么，对于式(9.29)，模型参数 ${\alpha_i, \mu_i, \Sigma_i | 1 \le i \le k }$ 如何求解呢？显然，给定样本集 $D$ ，可采用极大似然估计，即最大化似然(对数似然)
$$
\begin{eqnarray}
LL(D)
&amp;amp;=&amp;amp; \ln \bigg(\prod^m_{j=1} p_{\mathcal{M}}(x_j) \bigg) \
\
\tag{9.32}
&amp;amp;=&amp;amp; \sum^m_{j=1} \ln \bigg(\sum^k_{i=1} \alpha_i \cdot p(x_j | \mu_i, \Sigma_i) \bigg) ,
\end{eqnarray}
$$
常用 EM 算法&lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup> 进行迭代优化求解，得到
$$
\tag{9.34}
\mu_i = \frac{\sum^m_{j=1} \gamma_{ji} x_j}{\sum^m_{j=1} \gamma_{ji}} ,
$$
即各&lt;strong>混合成分的均值&lt;/strong>可通过样本加权平均来估计，样本权重是每个样本属于该成分的后验概率。类似的，对&lt;strong>混合成分的协方差矩阵&lt;/strong>有
$$
\tag{9.35}
\Sigma_i = \frac{\sum^m_{j=1} \gamma_{ji}(x_j - \mu_i)(x_j - \mu_i)^{\mathsf{T}}}{\sum^m_{j=1} \gamma_{ji}} .
$$
对应混合系数 $\alpha_i$ ，除了要最大化 $LL(D)$ ，还需要满足 $\alpha_i \le 0,\sum^k_{i=1} \alpha_i = 1$ 。考虑解 $LL(D)$ 的拉格朗日形式
$$
\tag{9.36}
LL(D) + \lambda \bigg(\sum^k_{i=1} \alpha_i - 1 \bigg) ,
$$
其中 $\lambda$ 为拉格朗日乘子。由式(9.36)对 $\alpha_i$ 的导数为 0，有
$$
\tag{9.37}
\sum^m_{j=1} \frac{p(x_j | \mu_i, \Sigma_i)}{\sum^k_{l=1} \alpha_l \cdot p(x_j | \mu_l, \Sigma_l)} + \lambda = 0 ,
$$
两边同乘以 $\alpha_i$ ，对所有样本求和可知 $\lambda = -m$ ，有
$$
\tag{9.38}
\alpha_i = {1 \over m} \sum^m_{j=1} \gamma_{ji} ,
$$
即每个&lt;strong>高斯成分的混合系数&lt;/strong>由样本属于该成分的平均后验概率确定。&lt;/p>
&lt;p>由上述推导即可获得高斯混合模型的 EM 算法：在每步迭代中，先根据当前参数来计算每个样本属于每个高斯混合成分的后验概率 $\gamma_{ji}$ （E 步），再根据式(9.34)、(9.35)和(9.38)更新模型参数 ${\alpha_i, \mu_i, \Sigma_i | 1 \le i \le k }$ （M 步）。&lt;/p>
&lt;hr>
&lt;p>&lt;code>高斯混合聚类算法&lt;/code>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>：样本集 $D = {x_1, \ldots, x_m }$ ；&lt;/p>
&lt;p>​ 高斯混合成分个数 $k$ 。&lt;/p>
&lt;p>&lt;strong>过程&lt;/strong>：&lt;/p>
&lt;p>01: 初始化高斯混合分布的模型参数 ${\alpha_i, \mu_i, \Sigma_i | 1 \le i \le k }$&lt;/p>
&lt;p>02: &lt;strong>repeat&lt;/strong>&lt;/p>
&lt;p>03: &lt;strong>for&lt;/strong> $j = 1, 2, \ldots, m$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>04: 根据式($\ref{eq_bayes_posterior}$)计算样本 $x_j$ 由各混合成分生成的后验概率，即 $\gamma_{ji} = p_{\mathcal{M}}(z_j = i | x_j) (1 \le i \le k)$&lt;/p>
&lt;p>05: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>06: &lt;strong>for&lt;/strong> $i = 1, 2, \ldots, k$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>07: 计算新的均值向量：$\mu_i&amp;rsquo; = \frac{\sum^m_{j=1} \gamma_{ji} x_j}{\sum^m_{j=1} \gamma_{ji}}$&lt;/p>
&lt;p>08: 计算新的协方差矩阵：$\Sigma_i&amp;rsquo; = \frac{\sum^m_{j=1} \gamma_{ji}(x_j - \mu_i)(x_j - \mu_i)^{\mathsf{T}}}{\sum^m_{j=1} \gamma_{ji}}$&lt;/p>
&lt;p>09: 计算新的混合系数：$\alpha_i&amp;rsquo; = {1 \over m} \sum^m_{j=1} \gamma_{ji}$&lt;/p>
&lt;p>10: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>11: 将模型参数 ${\alpha_i, \mu_i, \Sigma_i | 1 \le i \le k }$ 更新为 ${\alpha_i&amp;rsquo;, \mu_i&amp;rsquo;, \Sigma_i&amp;rsquo; | 1 \le i \le k }$&lt;/p>
&lt;p>12: &lt;strong>until&lt;/strong> 满足停止条件&lt;/p>
&lt;p>13: $C_i = \phi (1 \le i \le k)$&lt;/p>
&lt;p>14: &lt;strong>for&lt;/strong> $j = 1, 2, \ldots, m$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>15: 根据式($\ref{eq_cluster_idx}$)确定 $x_j$ 的簇标记 $\lambda_j$ ;&lt;/p>
&lt;p>16: 将 $x_j$ 划入相应的簇：$C_{\lambda_j} = C_{\lambda_j} \cup {x_j }$&lt;/p>
&lt;p>17: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>：簇划分 $\mathcal{C} = {C_1, C_2, \ldots, C_k }$&lt;/p>
&lt;hr>
&lt;h3 id="gaussian-mixture-models-in-action" >
&lt;div>
&lt;a href="#gaussian-mixture-models-in-action">
##
&lt;/a>
Gaussian Mixture Models in Action
&lt;/div>
&lt;/h3>
&lt;p>A &lt;em>Gaussian mixture model (GMM)&lt;/em> is a probabilistic model that assumes that the instances were generated from a mixture of several Gaussian distributions whose parameters are unknown. All the instances generated from a single Gaussian distribution from a cluster that typically looks like an ellipsoid with different shape, sizes, density and orientation.&lt;/p>
&lt;p>There are several GMM variants. In the simplest variant, implemented in the &lt;code>GaussianMixture&lt;/code> class, you must know in advance the number $k$ of Gaussian distributions. The dataset $\bf{X}$ is assumed to have been generated through the following probabilistic process:&lt;/p>
&lt;ul>
&lt;li>For each instance, a cluster is picked randomly from among $k$ clusters. The probability of choosing the $j^{th}$ cluster is defined by the cluster&amp;rsquo;s weight, $\phi^{(j)}$. The index of the cluster chosen for the $i^{th}$ instance is noted as $z^{(i)}$ .&lt;/li>
&lt;li>If $z^{(i)} = j$, meaning the $i^{th}$ instance has been assigned to the $j^{th}$ cluster, the location $\bf{x}^{(i)}$ of this instance is sampled randomly from the Gaussian distribution with mean $\mathbf{\mu}^{(j)}$ and covariance matrix $\mathbf{\Sigma}^{(j)}$ . This is noted $\mathbf{x}^{(i)} \sim \mathcal{N}(\mathbf{\mu}^{(j)}, \mathbf{\Sigma}^{(j)})$.&lt;/li>
&lt;/ul>
&lt;p>This generative process can be represented as a graphical model (Figure 9-16).&lt;/p>
&lt;p>&lt;img alt="gmm" src="./images/handson_cluster_gmm.png">&lt;/p>
&lt;h4 id="gmm-for-clustering" >
&lt;div>
&lt;a href="#gmm-for-clustering">
###
&lt;/a>
GMM for Clustering
&lt;/div>
&lt;/h4>
&lt;p>So, what can you do with such a model? Well, given the dataset $\bf{X}$ , you typically want to start by estimating the weights $\phi$ and all the distribution parameters $\mathbf{\mu}^{(1)}$ to $\mathbf{\mu}^{(k)}$ and $\mathbf{\Sigma}^{(1)}$ to $\mathbf{\Sigma}^{(k)}$ . Sklearn&amp;rsquo;s &lt;code>GaussianMixture&lt;/code> class makes this super easy:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> sklearn.mixture &lt;span style="color:#ff6ac1">import&lt;/span> GaussianMixture
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># This class relies on the Expectation-Maximization(EM) algorithm,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># which has many similarities with K-Means algorithm:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># it also initializes the cluster parameters randomly,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># then it repeats two steps until convergence:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># * first assigning instances to clusters (E step)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># * then updating the clusters (M step)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Think of EM as a generalization of K-Means that not only finds&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># * the clusters (mu_1 to mu_k), but also&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># * their size, shape, and orientation (Sigma_1 to Sigma_k), as well as&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># * their relative weights (phi_1 to phi_k)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Unlike K-Means, EM uses soft clustering assignments, not hard assignments,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># unfortunately, just like K-Means, EM can end up converging to poor solutions,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># so it needs to be run several times, keeping only the best solution. This is&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># why we set n_init=10. (By default, n_init=1)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gmm &lt;span style="color:#ff6ac1">=&lt;/span> GaussianMixture(n_components&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">3&lt;/span>, n_init&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">10&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gmm&lt;span style="color:#ff6ac1">.&lt;/span>fit(X)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(gmm&lt;span style="color:#ff6ac1">.&lt;/span>converged_) &lt;span style="color:#78787e"># True or False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(gmm&lt;span style="color:#ff6ac1">.&lt;/span>n_iter_) &lt;span style="color:#78787e"># how many EM iterations using&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(gmm&lt;span style="color:#ff6ac1">.&lt;/span>weights_) &lt;span style="color:#78787e"># cluster weights&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(gmm&lt;span style="color:#ff6ac1">.&lt;/span>means_) &lt;span style="color:#78787e"># means vectors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff5c57">print&lt;/span>(gmm&lt;span style="color:#ff6ac1">.&lt;/span>covariances_) &lt;span style="color:#78787e"># covariance matrices&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># now that the gmm can easily&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 1. assign each instance to the most likely cluster (hard clustering)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># 2. estimate the probability that it belongs to a particular cluster (soft clustering)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>res_hc &lt;span style="color:#ff6ac1">=&lt;/span> gmm&lt;span style="color:#ff6ac1">.&lt;/span>predict(X) &lt;span style="color:#78787e"># hard clustering&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>res_sc &lt;span style="color:#ff6ac1">=&lt;/span> gmm&lt;span style="color:#ff6ac1">.&lt;/span>predict_proba(x) &lt;span style="color:#78787e"># soft clustering&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># estimate the density of the model at any given location&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>log_pdf_scores &lt;span style="color:#ff6ac1">=&lt;/span> gmm&lt;span style="color:#ff6ac1">.&lt;/span>score_samples(X)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pdf_values &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>exp(log_pdf_scores)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># these pdf_values are not probabilities, but probability densities,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># to estimate the probability that an instance will fall within a&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># particular region, one would have to integrate the PDF over that region.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># A GMM is a generative model, meaning you can sample new instances form it&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># (note that they are ordered by cluster index):&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>X_new, y_new &lt;span style="color:#ff6ac1">=&lt;/span> gmm&lt;span style="color:#ff6ac1">.&lt;/span>sample(&lt;span style="color:#ff9f43">6&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Figure 9-17 shows the cluster means, the decision boundaries (dashed lines), and the density contours of this model.&lt;/p>
&lt;p>&lt;img alt="trained gmm" src="./images/handson_trained_gmm.png">&lt;/p>
&lt;p>It seems the algorithm clearly found an excellent solution. Of course, we made its task easy by generating the data using a set of 2D Gaussian distributions (real life data is not always so Gaussian and low-dimensional). We also gave the algorithm the correct number of clusters.&lt;/p>
&lt;p>When there are many dimensions, or many clusters, or few instances, EM can struggle to converge to the optimal solution. In such cases, we might need to reduce the difficulty of the task by limiting the number of parameters that the algorithm has to learn. One way to do this is to constraints the covariance matrices (limited the range of shapes and orientations the clusters can have) by setting the &lt;code>covariance_type&lt;/code> hyperparameter to one of the following values:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>covariance_type=&amp;quot;spherical&amp;quot;&lt;/code> :&lt;/p>
&lt;p>All clusters must be spherical, but can have different diameters (i.e., different variances)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>covariance_type=&amp;quot;diag&amp;quot;&lt;/code> :&lt;/p>
&lt;p>Clusters can take on any ellipsoidal shape of any size, but ellipsoid&amp;rsquo;s axes must parallel to the coordinate axes&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>covariance_type=&amp;quot;tied&amp;quot;&lt;/code> :&lt;/p>
&lt;p>All the cluster must have the same ellipsoidal shape, size, and orientation (i.e., all share one covariance matrix)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>covariance_type=&amp;quot;full&amp;quot;&lt;/code> : (by default)&lt;/p>
&lt;p>This means that each cluster can take on any shape, size, and orientation. If there is a large numbers of features, it will not scale well.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="constrained gmm" src="./images/handson_constrained_gmm.png">&lt;/p>
&lt;h4 id="gmm-for-anomaly-detection" >
&lt;div>
&lt;a href="#gmm-for-anomaly-detection">
###
&lt;/a>
GMM for Anomaly Detection
&lt;/div>
&lt;/h4>
&lt;p>&lt;em>Anomaly detection&lt;/em> (a.k.a., &lt;em>outlier detection&lt;/em>) is the task of detecting instances that deviate strongly from the norm. Using GMM for anomaly detection is quite simple: any instance located in a low-density region can be considered an anomaly. So one must define what density threshold to use.&lt;/p>
&lt;p>For example, in a manufacturing company that tries to detect defective products, the ratio of defective products is usually well known. Say it is equal to 4%. You then set the density threshold ($\rho$) to be the value that results in having 4% of the instances located in areas below $\rho$:&lt;/p>
&lt;ul>
&lt;li>If getting too many false positives (good products flagged as defective), lower the value of $\rho$&lt;/li>
&lt;li>If getting too many false negatives (defective products not flag as defective), lower the value of $\rho$&lt;/li>
&lt;/ul>
&lt;p>This is the usual precision/recall trade-off&lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup> .&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># defective products example&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>densities &lt;span style="color:#ff6ac1">=&lt;/span> gmm&lt;span style="color:#ff6ac1">.&lt;/span>score_samlpe(X)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>density_threshold &lt;span style="color:#ff6ac1">=&lt;/span> np&lt;span style="color:#ff6ac1">.&lt;/span>percentile(densities, &lt;span style="color:#ff9f43">4&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>anomalies &lt;span style="color:#ff6ac1">=&lt;/span> X[densities &lt;span style="color:#ff6ac1">&amp;lt;&lt;/span> density_threshold]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img alt="anomaly detection" src="./images/handson_gmm_anomaly_detection.png">&lt;/p>
&lt;h4 id="selecting-the-number-of-clusters" >
&lt;div>
&lt;a href="#selecting-the-number-of-clusters">
###
&lt;/a>
Selecting the Number of Clusters
&lt;/div>
&lt;/h4>
&lt;p>With K-Means, we could use the inertia or the silhouette score to select the appropriate number of clusters. But with GMM, it is not possible to use these metrics because they are not reliable when the clusters are not spherical or have different sizes. Instead, we can try to find the model that minimizes a &lt;em>theoretical information criterion&lt;/em>, such the &lt;em>Bayes information criterion (BIC)&lt;/em> or the &lt;em>Akaike information criterion (AIC)&lt;/em>, defined as follows
$$
\begin{eqnarray}
BIC &amp;amp;=&amp;amp; \log(m)p - 2 \log(\hat{L}) \
\
AIC &amp;amp;=&amp;amp; 2p - 2 \log(\hat{L})
\end{eqnarray}
$$
where $m$ is the number of instances, $p$ is the number of parameters learned by the model, and $\hat{L}$ is the maximized value of the &lt;em>likelihood function&lt;/em> of the model.&lt;/p>
&lt;p>Both the $BIC$ and $AIC$ penalize models that have more parameters to learn (e.g., more clusters) and reward models that fit the data well. They often end up selecting the same model. When they differ, $BIC$ tends to select simpler model (fewer parameters) while not fit the data quite as well as $AIC$ (especially true for larger datasets).&lt;/p>
&lt;p>To compute the $BIC$ and $AIC$ , call the &lt;code>bic()&lt;/code> and &lt;code>aic()&lt;/code> methods:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># gmms contains gmm trained with different k&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">for&lt;/span> gmm &lt;span style="color:#ff6ac1">in&lt;/span> gmms:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bic_scores&lt;span style="color:#ff6ac1">.&lt;/span>append(gmm&lt;span style="color:#ff6ac1">.&lt;/span>bic(x))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> aic_scores&lt;span style="color:#ff6ac1">.&lt;/span>append(gmm&lt;span style="color:#ff6ac1">.&lt;/span>aic(x))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img alt="bic aic metrics" src="./images/handson_gmm_bic_aic_metrics.png">&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>“原型” 是指样本空间中具有代表性的点。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>NP hardness problem (&lt;a href="https://wikimili.com/en/NP_(complexity)">non-deterministic polynomial-time&lt;/a> hardness): wait&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>$\lambda_j$ 实际是 ${1, 2, \ldots, k }$ 中的某个数，是 $k$ 个不同聚类簇 $\cal{C}$ 的下标，因为 $\text{argmin}_{i \in {1, 2, \ldots, k}} (\text{expression}_i)$ 函数就是返回使得 $\text{expression}$ 最小的那个 $i$ 。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>SOM 是基于无标记样本的聚类算法，而 LVQ 可看作 SOM 基于监督信息的扩展。SOM（Self-Organizing Map, 自组织映射）网络是一种竞争型学习(competitive learning) 的无监督神经网络，它能将高维输入数据映射到低维空间(通常二维) ，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层的邻近神经元。&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5">
&lt;p>竞争型学习是神经网络中常用的一种无监督学习策略，在使用该策略时，网络的输出神经元互相竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制（“胜者通吃(winner-take-all)原则”）。&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6">
&lt;p>若将 $R_i$ 中样本全用原型向量 $p_i$ 表示，则可实现数据的 “有损压缩(lossy compression)”，这称为 “向量量化( vector quantization)” ；LVQ 由此而得名。&amp;#160;&lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7">
&lt;p>$p_{\cal{M}} (·)$ 也是概率密度函数，$\int {p_{\cal{M}}(x)dx} = 1$.&amp;#160;&lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8">
&lt;p>Expectation-Maximization 算法(EM，期望最大化算法) 是常用的估计参数隐变量的利器，它是一种迭代式的方法，其核心思想是：若模型参数 $\Theta$ 已知，则可根据训练数据推断出最优隐变量 $\mathbf{Z}$ 的值（E 步）；反之，若 $\mathbf{Z}$ 的值已知，则可方便地对参数 $\Theta$ 做极大似然估计（M 步）。进一步，若我们不是取 $\mathbf{Z}$ 的期望，而是基于$\Theta$ 计算隐变量 $\mathbf{Z}$ 的概率分布 $P(\bf{Z} | X, \Theta)$ ，则 EM 算法的两个步骤是：以当前参数 $\Theta^t$ 推断 $P(\bf{Z} | X, \Theta^t)$ ，并计算对数似然 $LL(\bf{\Theta} | X, Z)$ 关于 $\bf{Z}$ 的期望，即 $\mathbb{E}(\Theta | \Theta^t)$（E 步）；寻找参数最大化期望似然，即 $\Theta^{t+1} = \text{argmax}_{\Theta} \mathbb{E}(\Theta | \Theta^t)$ （M 步）。EM 算法可看作用 “坐标下降法” 来最大化对数似然下界的过程。&amp;#160;&lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9">
&lt;p>Evaluate model performance in classification task.&amp;#160;&lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Book Notes: Deep-Forest Model</title><link>/posts/ml101/treebasedmodels/deepforest/</link><pubDate>Sat, 31 Aug 2019 14:11:27 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/ml101/treebasedmodels/deepforest/</guid><description>&lt;h1 id="deep-foresthttpsarxivorgabs170208835" >
&lt;div>
&lt;a href="#deep-foresthttpsarxivorgabs170208835">
##
&lt;/a>
&lt;a href="https://arxiv.org/abs/1702.08835">Deep Forest&lt;/a>
&lt;/div>
&lt;/h1>
&lt;ul>
&lt;li>online paper, follow the link to all the details.&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>In this paper, we extend our preliminary study which proposes the &lt;a href="https://fgg100y.github.io/">gcForest&lt;/a> (multi-Grained Cascade Forest) approach for constructing deep forest, a non-NN style deep model. This is a novel decision tree ensemble, with a cascade structure which enables representation learning by forests. Its representational learning ability can be further enhanced by multi-grained scanning, potentially enabling gcForest to be contextual or structural aware. The cascade levels can be automatically determined such that the model complexity can be determined in a data-dependent way rather than manually designed before training; this enables gcForest to work well even on small-scale data, and enables users to control training costs according to computational resource available. Moreover, the gcForest has much fewer hyper-parameters than DNNs. Even better news is that its performance is quite robust to hyper-parameter settings; our experiments show that in most cases, it is able to get excellent performance by using the default setting, even across different data from different domains.&lt;/p>
&lt;/blockquote>
&lt;h2 id="inspiration-from-dnns1" >
&lt;div>
&lt;a href="#inspiration-from-dnns1">
#
&lt;/a>
Inspiration from DNNs&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>
&lt;/div>
&lt;/h2>
&lt;p>It is widely recognized that the &lt;em>representation learning&lt;/em> ability is crucial for the success of deep neural networks. We believe&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> that the model complexity itself cannot explain the success of DNNs (e.g., large flat networks are not as successful as deep ones) and the &lt;em>layer-by-layer processing&lt;/em> is what really crucial for representation learning in DNNs. Figure 1 provides an illustration&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;img alt="layer-by-layer_processing" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\df_crucial_of_representation_learning.png">&lt;/p>
&lt;p>Learning models, e.g., decision trees and Boosting machines, which also conduct layer-by-layer processing, why they are not as successful as DNNs? We believe that the most important distinguishing factor is that, in contrast to DNNs where new features are generated as illustrated in Figure 1, decision trees and Boosting machines always work on the original feature representation without creating new features during the learning process, or in other words, there is no in-model feature transformation. Moreover, DTs and Boosting machines can only have limited model complexity.&lt;/p>
&lt;p>Overall, we conjecture that behind the mystery of DNNs there are three crucial characteristics, i.e., layer-by-layer processing, in-model feature transformation, and sufficient model complexity. We will try to endow these characteristics to our non-NN style deep model.&lt;/p>
&lt;h2 id="inspiration-from-ensemble-learning" >
&lt;div>
&lt;a href="#inspiration-from-ensemble-learning">
#
&lt;/a>
Inspiration from Ensemble Learning
&lt;/div>
&lt;/h2>
&lt;p>It is well known that an ensemble (multiple learners are trained and combined) can usually achieve better generalization performance than single learners.&lt;/p>
&lt;p>To construct a good ensemble, the individual learners should be &lt;em>accurate&lt;/em> and &lt;em>diverse&lt;/em>. Combining only accurate learners is often inferior to combining some accurate learners with some relatively weaker ones, because the complementarity is more important than pure accuracy. Here is the equation derived from &lt;em>error-ambiguity decomposition&lt;/em>&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>:
$$
\tag{1}
E = \bar{E} - \bar{A},
$$
where $E$ denotes the error of an ensemble, $\bar{E}$ denotes the average error of individual classifiers in the ensemble, and $\bar{A}$ denotes the average &lt;em>ambiguity&lt;/em>, later called &lt;em>diversity&lt;/em>, among the individual classifiers. Eq. 1 reveals that, the more accurate and more diverse the individual classifiers, the better the ensemble. However, it could not be taken as an objective function for optimization, because the &lt;em>ambiguity&lt;/em> term is mathematically defined in the derivation and cannot be operated directly&lt;sup id="fnref1:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>. Actually, &lt;em>&amp;ldquo;what is diversity?&amp;rdquo;&lt;/em> remains the holy grail problem in ensemble learning.&lt;/p>
&lt;p>In practice, the basic strategy of diversity enhancement is to inject randomness based on some heuristics during the training process. Roughly speaking, there are four major category of mechanisms&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>data sample manipulation&lt;/strong>: which works by generating different data samples to trian individual learners.&lt;/p>
&lt;p>E.g., bootstrap sampling is exploited by Bagging; sequential importance sampling is adopted by AdaBoost.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>input feature manipulation&lt;/strong>: which works by generating different feature subspaces to train individual learners.&lt;/p>
&lt;p>E.g., the Random Subspace approach randomly picks a subset of features.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>learning parameter manipulation&lt;/strong>: which works by using different parameter settings of the base learning algorithm to generate diverse individual learners.&lt;/p>
&lt;p>E.g., different initial selections can be applied to individual neural networks; different split selections can be applied to individual decision trees.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>output representation manipulation&lt;/strong>: which works by using different output representations to generate diverse individual learners.&lt;/p>
&lt;p>E.g., the ECOC approach employs error-correcting output codes; the Flipping Output method randomly changes the labels of some training instances.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Note that, however, these mechanisms are not always effective. More information about ensemble learning can be found in the book Ensemble Methods&lt;sup id="fnref1:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Next we give you, the gcForest, which can be viewed as a decision tree ensemble approach that utilizes almost all categories of mechanisms for diversity enhancement.&lt;/p>
&lt;h2 id="the-gcforest-approach" >
&lt;div>
&lt;a href="#the-gcforest-approach">
#
&lt;/a>
The gcForest Approach
&lt;/div>
&lt;/h2>
&lt;p>First introduce the cascade forest structure, and then the multi-grained scanning, followed by the overall architecture.&lt;/p>
&lt;h3 id="cascade-forest-structure" >
&lt;div>
&lt;a href="#cascade-forest-structure">
##
&lt;/a>
Cascade Forest Structure
&lt;/div>
&lt;/h3>
&lt;p>Representation learning in DNNs mostly relies on the layer-by-layer processing of raw features. Inspired by this recognition, gcForest employs a cascade structure, as illustrated in Figure 2, where each level of cascade receives feature information processed by its preceding level, and outputs its processing result to the next level.&lt;/p>
&lt;p>&lt;img alt="cascade-forest structure" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\df_cascade_forest_structure.png">&lt;/p>
&lt;p>Each level is an ensemble of decision tree forests, i.e., an &lt;em>ensemble&lt;/em> of &lt;em>ensembles&lt;/em>. Here, we include different types of forests to encourage the &lt;em>diversity&lt;/em>, because diversity is crucial for ensemble construction.&lt;/p>
&lt;p>For simplicity, suppose that we use two completely-random tree forests and two random forests. Each completely-random tree forest contains 500 completely-random trees, generated by randomly selecting a feature for split at each node of the tree, and growing tree until pure leaf, i.e., each leaf node contains only the same class of instances. Similarly, each random forest contains 500 trees, by randomly selecting $\sqrt{d}$ number of features as candidate ($d$ is the number of input features) and choosing the one with the best &lt;em>gini&lt;/em> value for split. (Note that the number of trees in each forest is a hyper-parameter.)&lt;/p>
&lt;p>Given an instance, each forest will produce an estimate of class distribution, by counting the percentage of different classes of training examples at the leaf node where concerned instance falls, and then averaging across all trees in the same forest, as illustrated in Figure 3, where red color highlights paths along which the instance traverses to leaf nodes.&lt;/p>
&lt;p>&lt;img alt="class-vector generation" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\df_class-vector_generation.png">&lt;/p>
&lt;p>The estimated class distribution forms a class vector, which is then concatenated with the original feature vector to be input to the next level of cascade. For example, suppose there are three classes, then each of the four forests will produce a three-dimensional class vector; thus the next level of cascade will receive 12 ($= 3 \times 4$) augmented features.&lt;/p>
&lt;p>Note that here we take the simplest form of class vectors, i.e., the class distribution at the leaf nodes into which the concerned instance falls. The more complex form of class vectors can be constructed by getting more distributions such as class distribution of the parent nodes which express prior distribution, the sibling nodes which express complementary distribution, etc.&lt;/p>
&lt;p>To reduce the risk of over-fitting, class vector produced by each forest is generated by $k$-fold cross validation. In detail, each instance will be used as training data for $k - 1$ times, resulting $k - 1$ class vectors, which are then averaged to produce the final class vector as augmented features for the next level of cascade. After expanding a new level, the performance of the whole cascade can be estimated on validation set, and the training procedure will terminate if there is no significant performance gain; thus, the number of cascade levels is automatically determined. Note that the training error rather than cross validation error can also be used to control the cascade growth when the training cost is concerned or limited computation resource available.&lt;/p>
&lt;h3 id="multi-grained-scanning" >
&lt;div>
&lt;a href="#multi-grained-scanning">
##
&lt;/a>
Multi-Grained Scanning
&lt;/div>
&lt;/h3>
&lt;p>DNNs are powerful in handling feature relationships, e.g., convolutional-NN are effective on image data where spatial relationships among the raw pixels are critical; recurrent-NN are effective on sequence data where sequential relationships are critical. Inspired by this recognition, we enhance cascade forest with a procedure of multi-grained scanning.&lt;/p>
&lt;p>&lt;img alt="sliding-windows scanning" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\df_sliding-windows_scanning.png">&lt;/p>
&lt;p>As Figure 4 illustrates, sliding windows are used to scan the raw features. Suppose there are 400 raw features and a window size of 100 features is used. For sequence data, a 100-dimensional feature vector will be generated by sliding the window for one feature; in total 301 feature vectors are produced. If the raw features are with spacial relationships, such as a $20 \times 20$ panel of 400 image pixels, then a $10 \times 10$ window will produce 121 feature vectors. All feature vectors extracted from positive/negative training examples are regarded as positive/negative instances, which will then be used to generate class vectors like in Section [Cascade Forest Structure](###Cascade Forest Structure): the instance extracted from the same size of windows will be used to train a completely-random tree forest and a random forest, and then the class vectors are generated and concatenated as transformed features. As Figure 4 illustrates, suppose that there are 3 classes and a 100-dimensional window is used; then, 301 three-dimensional class vectors are produced by each forest, leading to a 1860-dimensional transformed feature vector corresponding to the original 400-dimensional raw feature vector.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>convolution operations&lt;/strong>: padding and strides&lt;/p>
&lt;p>when the input shape is $(n_h \times n_w)$, the &lt;em>convolution kernel&lt;/em>&amp;rsquo;s shape is $(k_h \times k_w)$,&lt;/p>
&lt;p>&lt;strong>with no padding and stride (default with $s_h = s_w = 1$)&lt;/strong>, then output shape will be:
$$
(n_h - k_h + 1, n_w - k_w + 1),
$$
&lt;strong>with padding (add $p_h$ rows and $p_w$ columns ) and stride $(s_h = s_w = 1)$,&lt;/strong> then output shape will be:
$$
(n_h - k_h + p_h + 1, n_w - k_w + p_w + 1),
$$
&lt;strong>with padding (add $p_h$ rows and $p_w$ columns ) and stride $(s_h, s_w)$,&lt;/strong> then output shape will be:
$$
\bigg((n_h-k_h+p_h+s_h)/s_h, (n_w-k_w+p_w+s_w)/s_w \bigg)
$$&lt;/p>
&lt;p>If we set $p_h=k_h-1$ and $p_w=k_w-1$, then the output shape will be simplified to:
$$
\bigg((n_h+s_h-1)/s_h, (n_w+s_w-1)/s_w \bigg)
$$&lt;/p>
&lt;p>Going a step further, if the input height and width are divisible by the strides on the height and width, then the output shape will be:
$$
\bigg((n_h/s_h)， (n_w/s_w)\bigg)
$$&lt;/p>
&lt;hr>
&lt;p>For the instances extracted from the windows, we simply assign them with the label of the original training example. Here, some label assignments are inherently incorrect. For example, suppose the original training example is a positive image about &amp;ldquo;car&amp;rdquo;; it is clearly that many extracted instances do not contain a car, and therefore, they are incorrectly labeled as positive. This is actually related to the Flipping Output method&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>, a representative of output representation manipulation for ensemble diversity enhancement.&lt;/p>
&lt;p>Note that when transformed feature vectors are too long to be accommodated, feature sampling can be performed, e.g., by subsampling the instances generated by sliding window scanning, since completely-random trees do not rely on feature split selection whereas random forests are quite insensitive to inaccurate feature split selection. Such a feature sampling process is also related to the Random Subspace method&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>, a representative of input feature manipulation for ensemble diversity enhancement.&lt;/p>
&lt;p>Figure 4 shows only one size of sliding window. By using multiple sizes of sliding windows, differently grained feature vectors will be generated, as show in Figure 5.&lt;/p>
&lt;p>&lt;img alt="multi-grained scanning" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\df_multi-grained_scanning.png">&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>DNNs, in a more technically view, is &amp;ldquo;multiple layers of parameterized differentiable nonlinear modules that can be trained by back-propagation.&amp;rdquo; Also note that back-propagation requires differentiability.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>There is no rigorous justification yet.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning. MIT Press, Cambridge, MA, 2016.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>A. Krogh and J. Vedelsby. Neural network ensembles, cross validation, and active learning. In G. Tesauro, D. S.Touretzky, and T. K. Leen, editors, Advances in Neural Information Processing Systems 7, pages 231{238. 1995.&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&amp;#160;&lt;a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5">
&lt;p>Z.-H. Zhou. Ensemble Methods: Foundations and Algorithms. CRC, Boca Raton, FL, 2012.&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&amp;#160;&lt;a href="#fnref1:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6">
&lt;p>L. Breiman. Randomizing outputs to increase prediction accuracy. Machine Learning, 40(3):113–120, 2000.&amp;#160;&lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7">
&lt;p>T. K. Ho. The random subspace method for constructing decision forests. IEEE Trans. Pattern Analysis and Machine Intelligence, 20(8):832–844, 1998.&amp;#160;&lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Book Notes: Tree-based Models</title><link>/posts/ml101/treebasedmodels/treemodels/</link><pubDate>Sat, 31 Aug 2019 11:11:27 +0800</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/ml101/treebasedmodels/treemodels/</guid><description>&lt;h1 id="tree-based-models" >
&lt;div>
&lt;a href="#tree-based-models">
##
&lt;/a>
Tree-based models
&lt;/div>
&lt;/h1>
&lt;h2 id="part-i-theorist-views" >
&lt;div>
&lt;a href="#part-i-theorist-views">
#
&lt;/a>
Part-I: Theorist views
&lt;/div>
&lt;/h2>
&lt;p>&lt;strong>基本术语和符号约定&lt;/strong>&lt;/p>
&lt;p>一般地，令 $D = {x_1, x_2, \ldots, x_m }$ 表示包含 $m$ 个示例的数据集，每个示例由 $d$ 个属性描述，则每个示例 $x_i = (x_{i1}, x_{i2}, \ldots, x_{id})$ 是 $d$ 维样本空间 $\mathcal{X}$ 的一个向量&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>，$x_i \in \mathcal{X}$, 其中 $x_{ij}$ 是 $x_i$ 在第 $j$ 个属性上的取值， $d$ 称为样本 $x_i$ 的“维数”（dimensionality）。&lt;/p>
&lt;p>要建立一个关于“预测(prediction)”的模型，单有示例数据（也称为样本，sample）还不行，我们还需要获得训练样本的“结果”信息，例如，一个描述西瓜的记录“（（色泽=青绿；根蒂=蜷缩；敲声=浊响），好瓜）”。这里，关于示例结果的信息，例如 “好瓜” ，称为 “标记(label)”；拥有了标记信息的示例，则称之为 &amp;ldquo;样例(example)&amp;quot;。&lt;/p>
&lt;p>一般地，用 $(x_i, y_i)$ 表示第 $i$ 个样例，其中 $y_i \in \mathcal{Y}$ 是示例 $x_i$ 的标记， $\mathcal{Y}$ 是所有标记的集合，亦称“标记空间(label space)”或“输出空间”。&lt;/p>
&lt;p>如果我们想要预测的是离散值，例如 “好瓜” “坏瓜”，此类学习任务称为 “分类(classification)”；如果要预测的是连续值， 例如西瓜的成熟度0.9，0.4，此类学习任务称为 “回归(regression)”。二分类(binary classification)任务中，通常令 $\mathcal{Y} = {-1, +1 }$ 或 $\mathcal{Y} = {0, 1 }$；对于多分类(multi-class classification), $|\mathcal{Y}| &amp;gt; 2$；对回归任务，$\mathcal{Y} = \R$，$\R$ 为实数集。&lt;/p>
&lt;h2 id="decision-tree" >
&lt;div>
&lt;a href="#decision-tree">
#
&lt;/a>
Decision Tree
&lt;/div>
&lt;/h2>
&lt;h3 id="决策树生成算法" >
&lt;div>
&lt;a href="#%e5%86%b3%e7%ad%96%e6%a0%91%e7%94%9f%e6%88%90%e7%ae%97%e6%b3%95">
##
&lt;/a>
决策树生成算法
&lt;/div>
&lt;/h3>
&lt;p>一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点；叶结点对应于决策结果，其他每个结点对应于一个属性测试；每个结点包含的样本集合根据属性测试的结果被划分到子结点中；根结点包含样本全集。从根结点到每个叶结点的路径对应了一个判定测试序列。&lt;/p>
&lt;p>决策树学习的目的是为了产生一棵泛化性能强的决策树，亦即处理未见示例（unseen samples）的能力强的决策树。其基本流程遵循简单且直观的“分而治之”（divide-and-conquer）策略，如&lt;code>决策树学习基本算法&lt;/code>所示。&lt;/p>
&lt;hr>
&lt;p>&lt;code>决策树学习基本算法&lt;/code>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>： 训练集 $D = {(x_1, y_1), \dots, ({x_m, y_m}) }$; \
属性集 $A = {a_1, \ldots, a_d }$&lt;/p>
&lt;p>&lt;strong>过程&lt;/strong>： 函数 $\text{TreeGenerate}(D, A)$&lt;/p>
&lt;p>1: 生成结点 $\text{node}$;&lt;/p>
&lt;p>2: &lt;strong>if&lt;/strong> $D$ 中样本全属于同一类别 $C$ &lt;strong>then&lt;/strong>&lt;/p>
&lt;p>3: 将 $\text{node}$ 标记为 $C$ 类叶结点；&lt;strong>return&lt;/strong>&lt;/p>
&lt;p>4: &lt;strong>end if&lt;/strong>&lt;/p>
&lt;p>5: &lt;strong>if&lt;/strong> $A = \phi$ &lt;strong>OR&lt;/strong> $D$ 中样本在$A$ 上取值相同 &lt;strong>then&lt;/strong>&lt;/p>
&lt;p>6: 将 $\text{node}$ 标记为叶结点，其类别标记为 $D$ 中样本数量最多的类；&lt;strong>return&lt;/strong>&lt;/p>
&lt;p>7: &lt;strong>end if&lt;/strong>&lt;/p>
&lt;p>&lt;strong>8&lt;/strong>: 从 $A$ 中选择最优划分属性 $a_*$;&lt;/p>
&lt;p>9: &lt;strong>for&lt;/strong> 属性 $a_&lt;em>$ 的每一个值 $a_&lt;/em>^v$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>10: 为 $\text{node}$ 生成一个分支；令 $D_v$ 表示 $D$ 中在 $a_&lt;em>$ 上取值为 $a_&lt;/em>^v$ 的样本子集；&lt;/p>
&lt;p>11: &lt;strong>if&lt;/strong> $D_v$ 为空 &lt;strong>then&lt;/strong>&lt;/p>
&lt;p>12: 将分支结点标记为叶结点，其类别标记为 $D$ 中样本数量最多的类；&lt;strong>return&lt;/strong>&lt;/p>
&lt;p>13: &lt;strong>else&lt;/strong>&lt;/p>
&lt;p>14: 以 $\text{TreeGenerate}(D_v, A - a_*)$ 为分支结点&lt;/p>
&lt;p>15: &lt;strong>end if&lt;/strong>&lt;/p>
&lt;p>16: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>： 以 $\text{node}$ 为根结点的一棵决策树&lt;/p>
&lt;hr>
&lt;p>显然，决策树的生成时一个递归过程，在&lt;code>决策树基本算法&lt;/code>中，有三种情形会导致递归返回：&lt;/p>
&lt;ol>
&lt;li>当前结点包含的样本全部属于同一类别 （无需进一步划分）&lt;/li>
&lt;li>当前属性集为空，或是所有样本在所有属性上取值相同 （无法进一步划分）&lt;/li>
&lt;li>当前结点包含的样本集合为空 （不能进一步划分）&lt;/li>
&lt;/ol>
&lt;p>在第2种情形下，我们把当前结点标记为叶结点，并将其类别设定为该结点中样本数量最多的类别；在第3种情形下，同样把当前结点标记为叶结点，但将其类别设定为其父结点所含样本最多的类别，注意这两种情形处理实质不同：情形2中是利用当前结点的后验分布，而情形3中则是把父结点的样本分布作为当前结点的先验分布。&lt;/p>
&lt;blockquote>
&lt;p>《The hundred-Page Machine Learning》&lt;/p>
&lt;p>&lt;img alt="build tree the 1st split" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\looPagesML_dtree_build.png">&lt;/p>
&lt;p>The ID3 learning algorithm works as follows. Let $\cal{S}$ denotes a set of labeled examples. In the begining, the decision tree only has a start noed (root node) that contains all examples: $\mathcal{S} = {(\mathbb{x}&lt;em>i, y_i) }^N_i$. Start with a constant model $f&lt;/em>{ID3}$ :
$$
\tag{6}
f_{ID3} = {1 \over |\mathcal{S}|} \sum_{(\mathbb{x},y) \in \mathcal{S}} y .
$$
The prediction given by the above model, $f_{ID3}(\mathbb{x})$, would be the same for any input $\mathbb{x}$. The corresponding decision tree is shown in fig4(a).&lt;/p>
&lt;p>The we search through all features $j = 1, \ldots, D$ and all thresholds $t$, and split the set $\cal{S}$ into two subsets:&lt;/p>
&lt;ul>
&lt;li>$\mathcal{S}_{_} = {(\mathbb{x},y) | (\mathbb{x},y) \in \mathcal{S}, x^{(j)} &amp;lt; t }$ and&lt;/li>
&lt;li>$\mathcal{S}_{+} = {(\mathbb{x},y) | (\mathbb{x},y) \in \mathcal{S}, x^{(j)} \ge t }$ .&lt;/li>
&lt;/ul>
&lt;p>The new two subsets would go to two new leaf nodes (or inter nodes), and we evaluate, for all possible pairs $(j, t)$ how good the split with pieces $\mathcal{S}&lt;em>{_}$ and $\mathcal{S}&lt;/em>{+}$ is (see the followed section &lt;a href="https://fgg100y.github.io/posts/ml101/treebasedmodels/treemodels/###划分选择">划分选择&lt;/a>). Finally, we pick the best such values $(j, t)$ for splitting $\cal{S}$ into $\mathcal{S}&lt;em>{_}$ and $\mathcal{S}&lt;/em>{+}$ , from two new leaf nodes, and continue recursively on $\mathcal{S}&lt;em>{_}$ and $\mathcal{S}&lt;/em>{+}$ (or quit if reach some criterion). A decision tree after one split is illustrated in fig4(b).&lt;/p>
&lt;/blockquote>
&lt;h3 id="划分选择" >
&lt;div>
&lt;a href="#%e5%88%92%e5%88%86%e9%80%89%e6%8b%a9">
##
&lt;/a>
划分选择
&lt;/div>
&lt;/h3>
&lt;p>决策树学习的关键是如何选择最优划分属性（&lt;code>决策树基本算法&lt;/code> 第8行）。一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的“纯度”（purity）越来越高。&lt;/p>
&lt;h4 id="信息增益" >
&lt;div>
&lt;a href="#%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a">
###
&lt;/a>
信息增益
&lt;/div>
&lt;/h4>
&lt;p>“信息熵”（information entropy）是度量样本集合纯度最常用的一种指标。假定当前样本集合 $D$ 中第 $k$ 类样本所占的比例为 $p_k \ (k=1, \ldots, |\mathcal{Y}|)$，则 $D$ 信息熵定义为
$$
\tag{4.1}
\text{Ent}{(D)} = - \sum^{|\mathcal{Y}|}_{k=1} p_k \text{log}_2 p_k.
$$
$\text{Ent}(D)$ 的值越小，则 $D$ 的纯度越高。&lt;/p>
&lt;p>假定离散属性 $a$ 有 $V$ 个可能的取值 ${a^1, \ldots, a^V }$，若使用 $a$ 来对样本集 $D$ 进行划分，则会产生 $V$ 个分支结点，其中第 $v$ 个分支结点包含了 $D$ 中所有在属性 $a$ 上取值为 $a^v$ 的样本，记为 $D^v$。我们根据式(4.1)计算出 $D^v$ 的信息熵，再考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重 ${|D^v| \over |D|}$，即样本数越多的分支结点的影响越大，于是可以计算出用属性 $a$ 对样本集 $D$ 进行划分所获得的“信息增益(information gain)”
$$
\tag{4.2}
\text{Gain}(D, a) = \text{Ent}(D) - \sum^V_{v=1} {|D^v| \over |D|} \text{Ent}(D^v).
$$
一般而言，信息增益越大，则意味着使用属性 $a$ 来进行划分所获得的“纯度提升”越大。因此，我们可以用信息增益来进行决策树的划分属性选择，即选择属性 $a_* = argmax_{(a \in A)} \text{Gain}(D, a)$。&lt;/p>
&lt;p>$\color{Green}{\bold{例子}}$&lt;/p>
&lt;p>&lt;img alt="xgs d2.0" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\xgs_tree_dataset1.png">&lt;/p>
&lt;p>以表4.1中的西瓜数据集2.0为例。该数据集包含17个训练样例，用以学习一棵能预测没有尝过的是不是好瓜的决策树。显然，分类的类别共两类（是好瓜，不是好瓜），$|\mathcal{Y}| = 2$。在决策树开始学习时，根结点包含 $D$ 中所有的样例，其中正例占 $p_1 = 8 / 17$ ，反例占 $p_1 = 9 / 17$。于是，根据式(4.1)可计算出根结点的信息熵为
$$
\text{Ent}(D) = - \sum^2_{k=1} p_k \text{log}_2 p_k = - \bigg({8 \over 17}\text{log}_2 {8 \over 17} + {9 \over 17}\text{log}_2 {9 \over 17} \bigg) \approx 0.998 .
$$
然后，我们要计算出当前属性集合｛色泽，根蒂，敲声，纹理，脐部，触感｝中每个属性的信息增益。以属性 “色泽” 为例，它有3个可能的取值：｛青绿，乌黑，浅白｝。若使用该属性对 $D$ 进行划分，则可得到3个子集，分别记为：$D^1 (色泽=青绿)，D^2 (色泽=乌黑)，D^3 (色泽=浅白）$。&lt;/p>
&lt;p>由表4.1可得，子集 $D^1$ 包含编号为｛1，4，6，10，13，17｝的6个样例，其中正例占 $p_1 = 3 / 6$ ，反例占 $p_2 = 3 / 6$；子集 $D^2$ 包含编号为｛2，3，7，8，9，15｝的6个样例，其中正例占 $p_1 = 4 / 6$ ，反例占 $p_2 = 2 / 6$；子集 $D^3$ 包含编号为｛5，11，12，14，16｝的5个样例，其中正例占 $p_1 = 1 / 5$ ，反例占 $p_2 = 4 / 5$。根据式(4.1)可计算出用 “色泽” 划分之后所得到的3个分支结点的信息熵为
$$
\begin{eqnarray}
\text{Ent}(D^1) &amp;amp;=&amp;amp; - \bigg({3 \over 6}\text{log}_2 {3 \over 6} + {3 \over 6}\text{log}_2 {3 \over 6} \bigg) = 1.000, \
\text{Ent}(D^2) &amp;amp;=&amp;amp; - \bigg({4 \over 6}\text{log}_2 {4 \over 6} + {2 \over 6}\text{log}_2 {2 \over 6} \bigg) = 0.918, \
\text{Ent}(D^3) &amp;amp;=&amp;amp; - \bigg({1 \over 5}\text{log}_2 {1 \over 5} + {4 \over 5}\text{log}&lt;em>2 {4 \over 5} \bigg) = 0.772, \
\end{eqnarray}
$$
于是，根据式(4.2)可计算出属性 “色泽” 的信息增益为
$$
\begin{eqnarray}
\text{Gain}(D, 色泽)
&amp;amp;=&amp;amp; \text{Ent}(D) - \sum^3&lt;/em>{v=1} {|D^v| \over |D|} \text{Ent}(D^v) \
&amp;amp;=&amp;amp; 0.998 - \bigg({6 \over 17} \times 1.000 + {6 \over 17} \times 0.918 + {5 \over 17} \times 0.772 \bigg) \
&amp;amp;=&amp;amp; 0.109 .
\end{eqnarray}
$$
类似的，我们可以计算出其他属性的信息增益：
$$
\text{Gain}(D, 根蒂) = 0.143;\text{Gain}(D, 敲声) = 0.141 \
\text{Gain}(D, 纹理) = 0.381;\text{Gain}(D, 脐部) = 0.289 \
\text{Gain}(D, 触感) = 0.006.\qquad \qquad \qquad \qquad \quad \ &lt;br>
$$
显然，属性 “纹理” 的信息增益最大，于是它被选为划分属性。图4.3给出了基于 “纹理” 对根结点进行划分的结果，各分支结点所包含的样例子集显示在结点中。&lt;/p>
&lt;p>&lt;img alt="tree first split" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\xgs_tree1.png">&lt;/p>
&lt;p>然后，决策树学习算法将对每个分支结点做进一步划分。以图4.3中第一个分支结点（“纹理=清晰”）为例，该结点包含的样例集合 $D^1$ 中有编号为 ｛1，2，3，4，5，6，8，10，15｝的9个样例，可用属性集合为 ｛色泽，根蒂，敲声，脐部，触感｝&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>。基于 $D^1$ 计算出各个属性的信息增益：
$$
\text{Gain}(D, 根蒂) = 0.458;\text{Gain}(D, 敲声) = 0.331 \
\text{Gain}(D, 色泽) = 0.043;\text{Gain}(D, 脐部) = 0.458 \
\text{Gain}(D, 触感) = 0.458.\qquad \qquad \qquad \qquad \quad \ &lt;br>
$$
“根蒂”、“脐部”、“触感” 3个属性均取得最大的信息增益，可任选其中之一作为划分属性。类似的，对每个分支结点进行上述操作，最终得到的决策树如图4.4所示。&lt;/p>
&lt;p>&lt;img alt="tree first split" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\xgs_tree2.png">&lt;/p>
&lt;h4 id="增益率" >
&lt;div>
&lt;a href="#%e5%a2%9e%e7%9b%8a%e7%8e%87">
###
&lt;/a>
增益率
&lt;/div>
&lt;/h4>
&lt;p>在上面的例子中，我们有意忽略了表4.1中的 “编号” 这一列。如果把 “编号” 也作为一个候选划分属性，则根据式(4.2)可计算出它的信息增益为$0.998$，远大于其他候选划分属性。这很容易理解：“编号” 将产生17个分支，每个分支结点仅包含一个样本，这些分支结点的纯度已达到最大。然而，这样的决策树显然不具有泛化能力，无法对新样本进行有效预测。&lt;/p>
&lt;p>实际上，信息增益准则对可取值数目较多的属性有所偏好。为减少这种偏好可能带来的不利影响，C4.5决策树算法使用 “增益率(gain ratio)” 来选择最优划分属性。采用与式4.2相同的符号表示，增益率定义为
$$
\tag{4.3}
\text{Gain_ratio}(D, a) = \frac{\text{Gain}(D, a)}{\text{IV}(a)},
$$
其中
$$
\tag{4.4}
\text{IV}(a) = - \sum^V_{v=1} {|D^v| \over |D|} \text{log}_2 {|D^v| \over |D|}
$$
称为属性 $a$ 的 “固有值(intrinsic value)”。属性 $a$ 的可能取值数目越多（即 $V$ 越大），则 ${\text{IV}(a)}$ 的值也越大。&lt;/p>
&lt;p>注：增益率准则对可取值数目较少的属性有所偏好，因此，C4.5算法并不是直接选择增益率最大的候选划分属性，而是使用一个&lt;strong>启发式&lt;/strong>：先从候选划分属性中找出 &lt;em>信息增益&lt;/em> 高于平均水平的属性，再从中选择 &lt;em>增益率&lt;/em> 最大的。&lt;/p>
&lt;h4 id="基尼指数" >
&lt;div>
&lt;a href="#%e5%9f%ba%e5%b0%bc%e6%8c%87%e6%95%b0">
###
&lt;/a>
基尼指数
&lt;/div>
&lt;/h4>
&lt;p>CART(Classification and Regression Tree) 决策树使用基尼指数（Gini index）来选择划分属性。数据集D的纯度可用基尼指数来度量：
$$
\begin{eqnarray}
Gini(D)
&amp;amp;=&amp;amp; \sum^{|\mathcal{Y}|}&lt;em>{k=1} \sum&lt;/em>{k&amp;rsquo; \ne k} p_k p_{k&amp;rsquo;} \
&amp;amp;=&amp;amp; 1 - \sum^{|\mathcal{Y}|}&lt;em>{k=1} {p&lt;/em>{k}}^2.
\end{eqnarray}
$$
直观来说，$Gini(D)$反映了从数据集$D$中随机抽取两个样本，其类别标记不一致的概率。因此$Gini(D)$越小，则数据集$D$的纯度越高。&lt;/p>
&lt;p>属性 $a$ 的基尼指数定义为
$$
\text{Gini_index}(D, a) = \sum^{V}&lt;em>{v=1} \frac{|D^v|}{|D|}Gini(D^v)
$$
于是，我们候选属性集合$A$中，选择那个使得划分后基尼指数最小的属性作为最优划分属性，即$a^* = argmin&lt;/em>{(a \in A)} \text{Gini_index}(D, a)$.&lt;/p>
&lt;blockquote>
&lt;p>《hands-on Machine Learning with sklearn, Keras and tensorflow》&lt;/p>
&lt;p>The CART Training Algorithm&lt;/p>
&lt;p>&lt;strong>1. Classification Task&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Sklearn&lt;/strong> uses the CART algorithm to train Decision Tree (i.e., &amp;ldquo;growing&amp;rdquo; tree). The algorithm works by first splitting the training set into two subsets using a single feature $k$ and a threshold $t_k$ (e.g., &amp;ldquo;petal length $\le$ 2.45 cm&amp;rdquo; which is a feature in iris data). How does it choose $k$ and $t_k$ ? It searches for the pair ($k$, $t_k$) that produces the purest subsets (weighted by their size).
$$
\tag{6.2}
J(k, t_k) = {m_{left} \over m} G_{left} + {m_{right} \over m} G_{right}
$$
where&lt;/p>
&lt;ul>
&lt;li>$m_{left/right}$ is the number of instances in the left/right subset,&lt;/li>
&lt;li>$G_{left/right}$ measures the impurity of the left/right subset.&lt;/li>
&lt;/ul>
&lt;p>Equation 6.2 gives the cost function for classification task that the algorithm tries to minimize.&lt;/p>
&lt;p>Once the CART algorithm has successfully split the training set in two, it splits the subsets using the same logic, then the sub-subsets, and so on, recursively. It stops recursing once it reaches the maximum depth (&lt;code>max_depth&lt;/code>), or if it cannot find a split that will reduce impurity. There are other additional stopping conditions hyperparameters such as &lt;code>min_samples_split&lt;/code>, &lt;code>min_samples_leaf&lt;/code>, &lt;code>min_weight_fraction_leaf&lt;/code>, and &lt;code>max_leaf_nodes&lt;/code>. Increasing &lt;code>min_*&lt;/code> hyperparameters or reducing &lt;code>max_*&lt;/code> hyperparameters will regularize the model.&lt;/p>
&lt;p>&lt;strong>2. Regresssion Task&lt;/strong>&lt;/p>
&lt;p>The CART algorithm works mostly the same as earlier, except that instead of trying to split the training set in a way that minimizes impurity, it now tries to split the training set in a way that minimizes the MSE.
$$
\tag{6.2}
J(k, t_k) = {m_{left} \over m} \text{MSE}&lt;em>{left} + {m&lt;/em>{right} \over m} \text{MSE}_{right}
$$
where&lt;/p>
&lt;ul>
&lt;li>$MSE_{node} = \sum_{i \in node} (\hat{y}_{node} - y^{(i)})$ ,&lt;/li>
&lt;li>$\hat{y}&lt;em>{node} = {1 \over m&lt;/em>{node}} \sum_{i \in node} y^{(i)}$&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>3. Instability&lt;/strong>&lt;/p>
&lt;p>Decision Trees produce orthogonal decision boundaries (all splits are perpendicular to an axis), which makes them sensitive to trianing set rotation (The model on the right of figure 6-7 will not generalize well). Ony way to limit this problem is to use Principal Component Analysis (PCA), which often results in a better orientation of the training data.&lt;/p>
&lt;p>&lt;img alt="dtree instability" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\hands-onML_dtree_instability.png">&lt;/p>
&lt;p>More generally, the main issue with Decision Trees is that they are very sensitive to small variations in the training data&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>. Actually, since the training algorithm used by Sklearn is stochastic (means it randomly selects the set of features to evaluate at each node), it may produces very different models even on the same training data (unless you set the &lt;code>random_state&lt;/code> hyperparameter).&lt;/p>
&lt;/blockquote>
&lt;h3 id="剪枝处理" >
&lt;div>
&lt;a href="#%e5%89%aa%e6%9e%9d%e5%a4%84%e7%90%86">
##
&lt;/a>
剪枝处理
&lt;/div>
&lt;/h3>
&lt;p>剪枝 (pruning)是决策树学习算法对付 “过拟合” 的主要手段。在决策树学习过程中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，以致于把训练集自身的一些特点当作所有数据都具有的一般性质从而导致过拟合。因此，通过主动去掉一些分支来降低过拟合的风险。&lt;/p>
&lt;p>决策树剪枝的基本策略有 &lt;strong>预剪枝(prepruning)&lt;/strong> 和 &lt;strong>后剪枝(post-pruning)&lt;/strong> 。&lt;/p>
&lt;p>预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能的提升，则停止划分，并将当前结点标记为叶结点。&lt;/p>
&lt;p>后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能的提升，则将该子树替换为叶结点。&lt;/p>
&lt;p>&lt;strong>如何判断决策树泛化性能是否提升呢？&lt;/strong> 这可以使用常用的性能评估方法进行，如 “留出法”、“交叉验证法” 以及 “自助法” 等方法。&lt;/p>
&lt;p>预剪枝会使得决策树的很多分支没有 “展开”，这不仅能降低过拟合的风险，还会显著减少训练和测试的时间开销。但另一方面，有些分支的当前划分虽不能提升泛化性能（甚至可能导致泛化性能暂时下降），但在其基础上进行的后续划分却有可能使得泛化性能显著提高；预剪枝基于 “贪心” 本质禁止这些分支展开，这给预剪枝决策树带来欠拟合的风险。&lt;/p>
&lt;p>后剪枝决策树通常会比预剪枝决策树保留更多的分支。一般情形下，后剪枝决策树欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝决策树的训练时间开销则大得多。&lt;/p>
&lt;h3 id="连续值属性和缺失值" >
&lt;div>
&lt;a href="#%e8%bf%9e%e7%bb%ad%e5%80%bc%e5%b1%9e%e6%80%a7%e5%92%8c%e7%bc%ba%e5%a4%b1%e5%80%bc">
##
&lt;/a>
连续值属性和缺失值
&lt;/div>
&lt;/h3>
&lt;p>&lt;strong>连续值处理&lt;/strong>&lt;/p>
&lt;p>由于连续属性的可取值数目不再有限，因此，不能直接根据连续属性的可取值来对结点进行划分。此时，&lt;strong>连续属性离散化&lt;/strong>技术可派上用场。最简单的策略是采用二分法(bi-partition)对连续属性进行处理，这正是C4.5决策树算法中采用的机制。&lt;/p>
&lt;p>给定样本集 $D$ 和连续属性 $a$，假定 $a$ 在 $D$ 上出现了 $n$ 个不同的取值，将这些取值从小到大进行排序，记为 {$a^1, \ldots, a^n$}。基于划分点 $t$ 可将 $D$ 分为子集 $D^-_t$ 和 $D^+&lt;em>t$ ，其中 $D^-&lt;em>t$ 包含哪些在属性 $a$ 上取值不大于 $t$ 的样本，而 $D^+&lt;em>t$ 则包含那些大于 $t$ 的样本。显然，对相邻的属性取值 $a^i$ 与 $a^{i+1}$ 来说，$t$ 在区间 [$a^i, a^{i+1}$) 中取任意值所产生的划分结果相同。因此，对连续属性 $a$，我们可考察包含 $n - 1$ 个元素的候选划分点集合
$$
\tag{4.7}
T_a = \bigg{{a^i + a^{i+1} \over 2} | 1 \le i \le n-1 \bigg},
$$
即把区间 [$a^i, a^{i+1}$) 的中位点作为候选划分点&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>。然后我们就可以像离散属性值一样来考虑这些划分点，选取最优的划分点进行样本集合的划分。例如，可对式4.2稍加改造：
$$
\begin{eqnarray}
\text{Gain}(D, a)
&amp;amp;=&amp;amp; \text{max}&lt;/em>{(t \in T_a)} \text{Gain}(D, a, t) \
\tag{4.8}
&amp;amp;=&amp;amp; \text{max}&lt;/em>{(t \in T_a)} \text{Ent}(D) - \sum&lt;/em>{\lambda \in {-, + }} {|D^{\lambda}_t| \over |D|} \text{Ent}(D^{\lambda}_t),
\end{eqnarray}
$$
其中，$\text{Gain}(D, a, t)$ 是样本集 $D$ 基于划分点 $t$ 二分后的信息增益。于是，我们就可选择使 $\text{Gain}(D, a, t)$ 最大化的划分点。&lt;/p>
&lt;p>&lt;strong>缺失值处理&lt;/strong>&lt;/p>
&lt;p>现实任务中常会遇到不完整样本，即样本的某些属性值缺失。在属性数目较多的情形下，往往会有大量样本出现缺失值。如果简单地放弃不完整样本，仅使用无缺失值的样本进行学习，显然是对数据信息的极大浪费。&lt;/p>
&lt;p>我们需要解决两个问题：&lt;/p>
&lt;ol>
&lt;li>如何在属性值缺失的情况下进行划分属性的选择？&lt;/li>
&lt;li>给定划分属性，如果样本在该属性上的值缺失，如何对样本进行划分？&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>The real handling approaches to missing data does not use data point with missing values in the evaluation of a split. However, when child nodes are created and trained, those instances are distributed somehow.&lt;/p>
&lt;p>I know about the following approaches to distribute the missing value instances to child nodes:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>simply ignoring the missing values (like ID3 and other old algorithms does) or treating the missing values as another category (in case of a nominal feature). Those approachs were used in the early stages of decision tree development.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>all goes to the node which already has the biggest number of instances (CART, but not its primary rule)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>distribute to all children, but with diminished weights, proportional with the number of instances from each child node (C4.5 and others)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>distribute randomly to only one single child node, eventually according with a categorical distribution (various implementations of C4.5 and CART for faster funing time)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>build, sort and use surrogates to distribute instances to a child node, where surrogates are input features which resembles best how the test feature send data instances to left or right child node (CART, if that fails, the majority rule is used)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>This answer was copied from &lt;a href="https://stats.stackexchange.com/questions/96025/how-do-decision-tree-learning-algorithms-deal-with-missing-values-under-the-hoo">here&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;h3 id="多变量决策树" >
&lt;div>
&lt;a href="#%e5%a4%9a%e5%8f%98%e9%87%8f%e5%86%b3%e7%ad%96%e6%a0%91">
##
&lt;/a>
多变量决策树
&lt;/div>
&lt;/h3>
&lt;p>如果我们把每个属性视为坐标空间中的一个坐标轴，则 $d$ 个属性描述的样本就对应了 $d$ 维空间中的一个数据点，对样本分类意味着在这个坐标空间中寻找不同样本之间的分类边界。&lt;/p>
&lt;p>决策树所形成的分类边界有一个明显的特点：轴平行(axis-parallel)，即它的分类边界由若干个与坐标轴平行的分段组成。&lt;/p>
&lt;p>&lt;img alt="data3a" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\xgs_tree_dataset3a.png">&lt;/p>
&lt;p>以表4.5中的西瓜数据$3.0 \alpha$为例，将它作为训练集学习得图4.10所示的决策树，其分类边界如图4.11所示。&lt;/p>
&lt;p>&lt;img alt="tree3a" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\xgs_tree3a2.png">&lt;/p>
&lt;p>显然，分类边界的每一段都是与坐标轴平行的。这样的分类边界使得学习结果有较好的可解释性，因为每一段划分都直接对应了某个属性取值。但在学习任务的真实分类边界比较复杂时，必须使用很多段划分才能获得较好的近似，如图4.12所示；此时的决策树会相当复杂，由于需要进行大量属性测试，预测时间开销会很大。&lt;/p>
&lt;p>&lt;img alt="tree3a3" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\xgs_tree3a3.png">&lt;/p>
&lt;p>如果能够使用斜的划分边界，如图4.12中的红色线段所示，则决策树模型将大为简化。&lt;/p>
&lt;p>&lt;strong>“多变量决策树”(multivariate decision tree)&lt;/strong> 就是能实现这样的 “斜划分” 甚至更复杂划分的决策树。以实现斜划分的多变量决策树为例，在此类决策树中，非叶结点不再是仅对某个属性，而是对属性的线性组合进行测试；换言之，每个非叶结点是一个形如 $\sum^d_{i=1} w_i a_i = t$ 的线性分类器，其中 $w_i$ 是属性 $a_i$ 的权重， $w_i$ 和 $t$ 可以在该结点所含的样本集和属性集上学得&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>。于是，与传统的 “单变量决策树(univariate decision tree)” 不同，在多变量决策树的学习过程中，不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分类器。&lt;/p>
&lt;p>例如对西瓜数据$3.0 \alpha$，我们可以学得图4.13这样的多变量决策树，其分类边界如图4.14所示。&lt;/p>
&lt;p>&lt;img alt="tree3a4" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\xgs_tree3a4.png">&lt;/p>
&lt;h3 id="阅读材料" >
&lt;div>
&lt;a href="#%e9%98%85%e8%af%bb%e6%9d%90%e6%96%99">
##
&lt;/a>
阅读材料
&lt;/div>
&lt;/h3>
&lt;p>在&lt;strong>信息增益、增益率、基尼指数&lt;/strong>之外，人们还设计了许多其他的准则用于决策树划分选择，然而有实验研究表明&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>，这些准则虽然对决策树的尺寸有较大影响，但对泛化性能的影响很有限；对信息增益和基尼指数进行的理论分析&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>也显示出，它们仅在 $2%$ 的情况下会有所不同。而剪枝方法和剪枝程度对决策树的泛化性能影响显著，有实验研究&lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup>表明，在数据带有噪声时，通过剪枝甚至可将决策树的泛化性能提高 $25%$。&lt;/p>
&lt;p>多变量决策树算法主要有 $OC1$&lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup>，$OC1$ 算法先贪心地寻找每个属性的最优权值，在局部优化的基础上再对分类边界进行随机扰动以试图找到更好的边界；Brodley and Utgoff&lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup> 则直接引入了线性分类器学习的最小二乘法。还有一些算法试图在决策树的叶结点上嵌入神经网络，以结合这两种学习机制的优势，例如 “感知机树(Perceptron tree)”&lt;sup id="fnref:11">&lt;a href="#fn:11" class="footnote-ref" role="doc-noteref">11&lt;/a>&lt;/sup> 在每个叶结点上训练一个感知机，也有直接在叶结点上嵌入多层神经网络的模型&lt;sup id="fnref:12">&lt;a href="#fn:12" class="footnote-ref" role="doc-noteref">12&lt;/a>&lt;/sup>。&lt;/p>
&lt;p>有一些决策树学习算法可进行 “增量学习(incremental learning)”，即在接收到新样本后可对已学得的模型进行调整，而不用完全重新学习。主要机制是通过调整分支路径上的划分属性次序来对树进行部分重构，代表性算法有ID4&lt;sup id="fnref:13">&lt;a href="#fn:13" class="footnote-ref" role="doc-noteref">13&lt;/a>&lt;/sup>、ID5R&lt;sup id="fnref:14">&lt;a href="#fn:14" class="footnote-ref" role="doc-noteref">14&lt;/a>&lt;/sup>、ITI&lt;sup id="fnref:15">&lt;a href="#fn:15" class="footnote-ref" role="doc-noteref">15&lt;/a>&lt;/sup>等。增量学习可有效降低每次接收到新样本后的训练时间开销，但多步增量学习后的模型会与基于全部数据训练而得的模型有较大差别。&lt;/p>
&lt;h2 id="集成学习ensemble" >
&lt;div>
&lt;a href="#%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0ensemble">
#
&lt;/a>
集成学习(Ensemble)
&lt;/div>
&lt;/h2>
&lt;p>根据个体学习器的生成方式，目前集成学习&lt;sup id="fnref:16">&lt;a href="#fn:16" class="footnote-ref" role="doc-noteref">16&lt;/a>&lt;/sup>方法大致可分为两大类，&lt;/p>
&lt;ul>
&lt;li>个体学习器之间存在强依赖关系、必须串行生成的序列化方法，代表算法Boosting&lt;sup id="fnref:17">&lt;a href="#fn:17" class="footnote-ref" role="doc-noteref">17&lt;/a>&lt;/sup>;&lt;/li>
&lt;li>个体学习器之间不存在强依赖关系、可同时生成的并行化方法，代表算法Bagging和 “随机森林”.&lt;/li>
&lt;/ul>
&lt;p>想要得到泛化性能强的集成，集成中的个体学习器应尽可能相互独立；虽然 “独立” 在现实任务中无法做到，但可以设法使基学习器尽可能具有较大的差异。&lt;/p>
&lt;p>给定一个训练数据集，一种可能的做法是对训练样本进行采样，产生出若干个不同的子集，再从每个数据子集中训练出一个基学习器。这样，由于训练数据不同，我们获得的基学习器可望具有比较大的差异。然而，为获得好的集成，我们同时还希望个体学习器不能太差。如果采样出的每个子集都完全不同，则意味着每个基学习器只用到了一小部分训练数据，甚至可能不足以进行有效学习，这就无法保证产出比较好的基学习器。为解决这个问题，我们可考虑使用互相有交叠的采样子集。&lt;/p>
&lt;p>&lt;img alt="hard voting classifier" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\hands-onML_ensemble_majority_vote.png">&lt;/p>
&lt;p>&lt;em>Figure 7-2. Hard voting classifier predictions. Copy from the book《hands-on Machine Learning with sklearn, Keras and tensorflow》&lt;/em>&lt;/p>
&lt;h3 id="bagging" >
&lt;div>
&lt;a href="#bagging">
##
&lt;/a>
BAGGING
&lt;/div>
&lt;/h3>
&lt;p>Bagging (Bootstrap AGGregatING) 是并行式集成学习方法最著名的代表。从名字即可看出，它直接基于自助采样法&lt;sup id="fnref:18">&lt;a href="#fn:18" class="footnote-ref" role="doc-noteref">18&lt;/a>&lt;/sup>。因此，我们知道初始训练集中约有 $63.2%$ 的样本出现在采样集中。我们可以采样出 $T$ 个含 $m$ 个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。这就是Bagging的基本流程。&lt;/p>
&lt;p>在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务采用简单平均法。&lt;/p>
&lt;hr>
&lt;p>Bagging 算法&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>: 训练集 $D = {(x_1, y_1), \ldots, (x_m, y_m) }$;&lt;/p>
&lt;p>​ 基学习算法 $\mathcal{L}$;&lt;/p>
&lt;p>​ 训练轮数 $T$.&lt;/p>
&lt;p>&lt;strong>过程&lt;/strong>：&lt;/p>
&lt;p>1: &lt;strong>for&lt;/strong> $t = 1, \ldots, T$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>2: $h_t = \mathcal{L} (D, D_{bs})$&lt;/p>
&lt;p>3: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>: $H(x) = \text{argmax}&lt;em>{(y \in \mathcal{Y})} \sum^T&lt;/em>{t=1} \mathbf{I}(h_t(x) = y)$&lt;/p>
&lt;hr>
&lt;p>其中，$D_{bs}$ 是自助采样产生的样本分布。&lt;/p>
&lt;p>从偏差-方差分解的角度看，Bagging主要关注降低方差，因此因此它在不剪枝决策树、神经网络等易受到样本扰动的学习器上效用更为明显。&lt;/p>
&lt;blockquote>
&lt;p>《hands-on Machine Learning with sklearn, Keras and tensorflow》&lt;/p>
&lt;p>&lt;strong>Bagging and Pasting&lt;/strong>&lt;/p>
&lt;p>One way to get a diverse set of classifiers is to use very different training algorithms (such as SVMs, LR, DTs etc). Another approach is to use the same training algorithm for every predictor and train them on different random subsets of the training set. When sampling is performed &lt;strong>with replacement&lt;/strong>, this method is called &lt;strong>bagging&lt;/strong>, when sampling is preformed &lt;strong>without replacement&lt;/strong>, it is called &lt;strong>pasting&lt;/strong>.&lt;/p>
&lt;p>In other words, both bagging and pasting allow training instances to be sampled several times across multiple predictiors, but only bagging allows training instances to be sampled several times for the same predictor. This sampling and training process is represented in Figure 7-4.&lt;/p>
&lt;p>&lt;img alt="bagging pasting" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\hands-onML_ensemble_bagging_pasting.png">&lt;/p>
&lt;p>Once all predictors are trained, the ensemble can make a prediction for a new instance by simply aggregating the predictions all predictors. The aggregation function is typically&lt;/p>
&lt;ul>
&lt;li>the &lt;em>statistical mode&lt;/em>&lt;sup id="fnref:19">&lt;a href="#fn:19" class="footnote-ref" role="doc-noteref">19&lt;/a>&lt;/sup> for classification, or&lt;/li>
&lt;li>the &lt;em>statistical average&lt;/em> for regression.&lt;/li>
&lt;/ul>
&lt;p>Generally, the net result is that the ensemble has a similar bias but a lower variance than single predictor trained on the original train set.&lt;/p>
&lt;/blockquote>
&lt;h4 id="随机森林-rf" >
&lt;div>
&lt;a href="#%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97-rf">
###
&lt;/a>
随机森林 RF
&lt;/div>
&lt;/h4>
&lt;p>随机森林是Bagging的一个扩展变体。RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。具体来说，传统决策树在选择划分属性时是在当前结点的属性集（假定有 $d$ 个属性）中选择一个最优属性；而在 RF 中，对基决策树的每个结点，先从该结点的属性集中随机选择一个包含 $k$ 个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这里的参数 $k$ 控制了随机性的引入程度：&lt;/p>
&lt;ul>
&lt;li>$k = d$, 则基决策树的构建与传统决策树相同；&lt;/li>
&lt;li>$k = 1$, 则是随机选择一个属性用于划分；一般推荐 $k = \text{log}_2 d$.&lt;/li>
&lt;/ul>
&lt;p>可以看出，随机森林对Bagging只做了小改动，但是与Bagging中基学习器的 “多样性” 仅通过样本扰动而来不同，随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动，这就使得最终集成的泛化性能可通过个体学习器之间差异程度的增加而进一步提升。&lt;/p>
&lt;p>值得一提的是，随机森林的训练效率通常优于Bagging，因为在个体决策树的构建过程中，Bagging 使用的是 “确定型” 决策树，在选择划分属性时要对结点的所有属性进行考察，而随机森林使用的 “随机型” 决策树则只需考察一个属性子集。&lt;/p>
&lt;blockquote>
&lt;p>《hands-on Machine Learning with sklearn, Keras and tensorflow》&lt;/p>
&lt;p>&lt;strong>1. Random Forest&lt;/strong>&lt;/p>
&lt;p>A Random Forest is an ensemble of Decision Trees, generally trained via the bagging method (or sometimes pasting), typically with &lt;code>max_samples&lt;/code> set to the size of the training set. Instead of building a &lt;code>BaggingClassifier&lt;/code> and passing it a &lt;code>DecisionTreeClassifier&lt;/code>, you can instead use the &lt;code>RandomForestClassifier&lt;/code> class, which is more convenients and optimized for Decision Trees&lt;sup id="fnref:20">&lt;a href="#fn:20" class="footnote-ref" role="doc-noteref">20&lt;/a>&lt;/sup> (similarly, there is a &lt;code>RandomForestRegressor&lt;/code> class for regression tasks).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> sklearn.ensemble &lt;span style="color:#ff6ac1">import&lt;/span> RandomForestClassifier
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rf_clf &lt;span style="color:#ff6ac1">=&lt;/span> RandomForestClassifier(n_estimators&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">500&lt;/span>, max_leaf_nodes&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">16&lt;/span>, n_jobs&lt;span style="color:#ff6ac1">=-&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rf_clf&lt;span style="color:#ff6ac1">.&lt;/span>fit(X_train, y_train)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_pred &lt;span style="color:#ff6ac1">=&lt;/span> rf_clf&lt;span style="color:#ff6ac1">.&lt;/span>predict(X_test)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With a few exceptions, a &lt;code>RandomForestClassifier&lt;/code> has all the hypeparameters of a &lt;code>DecisionTreeClassifier&lt;/code> (to control how trees are grown), plus all the hypeparameters of a &lt;code>BaggingClassifier&lt;/code> to control the ensemble itself.&lt;/p>
&lt;p>&lt;strong>2. Extra-Trees&lt;/strong>&lt;/p>
&lt;p>When you are growing a tree in a Random Forest, at each node only a random subset of the features (the $k$ set) is considered for splitting. It is possible to make trees even more random by also using random thresholds (the $t_k$ value) for each feature rather than searching for the best possible thresholds (like regular Decision Trees do).&lt;/p>
&lt;p>A forest with such extremely random trees is called an &lt;em>Extremely Randomized Trees&lt;/em> ensemble (or &lt;em>Extra-Trees&lt;/em> for short). Once again, this technique trades more bias for a lower variance. It also makes &lt;em>Extra-Trees&lt;/em> much faster to train than regular Random Forests&lt;sup id="fnref:21">&lt;a href="#fn:21" class="footnote-ref" role="doc-noteref">21&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>It is hard to tell in advance whether a &lt;code>RandomForestClassifier&lt;/code> will preform better or worse than an &lt;code>ExtraTreesClassifier&lt;/code> . Generally, the only way to know is to try both and compare them using cross-validation (tuning the hyperparameters uisng grid search).&lt;/p>
&lt;/blockquote>
&lt;h3 id="boosting" >
&lt;div>
&lt;a href="#boosting">
##
&lt;/a>
BOOSTING
&lt;/div>
&lt;/h3>
&lt;blockquote>
&lt;p>from 《A Gentle Introduction to Gradient Boosting》, &lt;a href="mailto:chengli@ccs.neu.edu">chengli@ccs.neu.edu&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>What is Gradient Boosting&lt;/strong>&lt;/p>
&lt;p style="text-align: center;color=green;font-size=20">
Gradient Boosting = Gradient Descent + Boosting
&lt;/p>
&lt;h4 id="adaboost" >
&lt;div>
&lt;a href="#adaboost">
###
&lt;/a>
AdaBoost
&lt;/div>
&lt;/h4>
&lt;p>&lt;img alt="adaboost" src="./images/adaboost.png">&lt;/p>
&lt;p>AdaBoost training:&lt;/p>
&lt;ul>
&lt;li>Fit an additive model (ensemble) $\sum_t \rho_t h_t(x)$ in a forward stage-wise manner.&lt;/li>
&lt;li>In each stage, introduce a weak learner to compensate the &lt;em>shortcomings&lt;/em> of existing weak learners.&lt;/li>
&lt;li>In AdaBoost, &lt;em>shortcomings&lt;/em> are identified by high-weight data points.&lt;/li>
&lt;/ul>
&lt;p>$$
H(x) = \sum_t \rho_t h_t(x)
$$
&lt;img alt="adaboost" src="./images/adaboost2.png">&lt;/p>
&lt;p style="text-align: center">
Figure: AdaBoost. Source: Figure 1.2 of [Schapire and Freund, 2012]
&lt;/p>
&lt;h4 id="gradient-boosting" >
&lt;div>
&lt;a href="#gradient-boosting">
###
&lt;/a>
Gradient Boosting
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>Fit an additive model (ensemble) $\sum_t \rho_t h_t(x)$ in a forward stage-wise manner.&lt;/li>
&lt;li>In each stage, introduce a weak learner to compensate the &lt;em>shortcomings&lt;/em> of existing weak learners.&lt;/li>
&lt;li>In Gradient Boosting, &lt;em>shortcomings&lt;/em> are identified by &lt;strong>gradients&lt;/strong>. (Recall that&lt;strong>hight-weight&lt;/strong> data points for adaboost)&lt;/li>
&lt;li>Both high-weight data points and gradients tell us how to improve our model.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>AdaBoost &amp;amp;&amp;amp; Gradient Boosting&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Invent Adaboost, the rst successful boosting algorithm
[Freund et al., 1996, Freund and Schapire, 1997]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Formulate Adaboost as gradient descent with a special loss
function[Breiman et al., 1998, Breiman, 1999]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Generalize Adaboost to Gradient Boosting in order to handle
a variety of loss functions
[Friedman et al., 2000, Friedman, 2001]&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="gradient-boosting-for-regression" >
&lt;div>
&lt;a href="#gradient-boosting-for-regression">
###
&lt;/a>
Gradient Boosting for Regression
&lt;/div>
&lt;/h4>
&lt;p>Given $D = {(x_1,y_1), (x_2,y_2), \ldots, (x_n,y_n)}$, and the task is to fit a model $F(x)$ to minimize square loss.&lt;/p>
&lt;p>Suppose your friend wants to help you and gives you a model $F$. You check his model and find that the model is good but not perfect. There are some mistakes: $F(x_1)=0.8$, while $y_1=0.9$, $F(x_2)=1.8$, while $y_2=1.9$, and so on. How can you improve this model? With following rules:&lt;/p>
&lt;ul>
&lt;li>You are not allowed to remove anything from $F$ or change any parameter in $F$.&lt;/li>
&lt;li>You can add an additional model (regression tree) $h$ to $F$, so the new prediction will be $F(x) + h(x)$.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Simple solution:&lt;/strong>&lt;/p>
&lt;p>You wish to improve the model such that
$$
\begin{eqnarray}
F(x_1) + h(x_1) &amp;amp;=&amp;amp; y_1 \
F(x_2) + h(x_2) &amp;amp;=&amp;amp; y_2 \
\cdots \
F(x_n) + h(x_n) &amp;amp;=&amp;amp; y_n \
\end{eqnarray}
$$&lt;/p>
&lt;p>Or equivalently, you wish
$$
\begin{eqnarray}
h(x_1) &amp;amp;=&amp;amp; y_1 - F(x_1) \
h(x_2) &amp;amp;=&amp;amp; y_2 - F(x_2) \
\cdots \
h(x_n) &amp;amp;=&amp;amp; y_n - F(x_n) \
\end{eqnarray}
$$
Can any regression tree $h$ achieve this goal prefectly? Maybe not.&lt;/p>
&lt;p>But some regression tree might be able to do this approximately. But how?&lt;/p>
&lt;p>Just fit a regression tree $h$ to the &lt;strong>residuals&lt;/strong>&lt;sup id="fnref:22">&lt;a href="#fn:22" class="footnote-ref" role="doc-noteref">22&lt;/a>&lt;/sup> data :&lt;/p>
&lt;p>$(x_1,y_1 - F(x_1)), (x_2,y_2 - F(x_2)), \ldots, (x_n,y_n - F(x_n)),$&lt;/p>
&lt;p>which are the parts that existing model $F$ connot do well.&lt;/p>
&lt;p>The role of $h$ is to compensate the shortcoming of existing model $F$.&lt;/p>
&lt;p>If the the new model $F+h$ is still not satisfactory, we can add another regression tree $g$ to fit data:&lt;/p>
&lt;p>$(x_1,y_1 - F(x_1) - h(x_1)), (x_2,y_2 - F(x_2) - h(x_2)), \ldots, (x_n,y_n - F(x_n) - h(x_n)),$&lt;/p>
&lt;p>which are the parts that existing model $F+h$ connot do well.&lt;/p>
&lt;p>Repeat this process utill we are satisfied.&lt;/p>
&lt;p>Q: We are improving the predictions of training data, is the procedure also useful for test data?&lt;/p>
&lt;p>A: Yes! Because we are building a model, and the model can be applied to test data as well.&lt;/p>
&lt;p>Q: &lt;strong>How is this related to gradient descent?&lt;/strong>&lt;/p>
&lt;h4 id="relationship-to-the-gradient-descent" >
&lt;div>
&lt;a href="#relationship-to-the-gradient-descent">
###
&lt;/a>
Relationship to the Gradient Descent
&lt;/div>
&lt;/h4>
&lt;p>Minimize a function by moving in the opposite direction of the gradient.
$$
\theta_i := \theta_i - \rho{\partial{J} \over \partial{\theta_i}}
$$
&lt;img alt="gd" src="./images/gradient_descent.png">&lt;/p>
&lt;p>Figure: Gradient Descent. Source: &lt;a href="http://en.wikipedia.org/wiki/Gradient_descent">http://en.wikipedia.org/wiki/Gradient_descent&lt;/a>&lt;/p>
&lt;p>Recall that the task is to minimize the square loss, the loss function
$$
L(y, F(x)) = {1 \over 2} (y - F(x))^2
$$
And we want to minimize
$$
J = \sum_i L(y_i, F(x_i))
$$
by adjusting $F(x_i), F(x_2), \ldots, F(x_n)$.&lt;/p>
&lt;p>Notice that $F(x_i), F(x_2), \ldots, F(x_n)$ are just some numbers. We can treat $F(x_i)$ as parameters and take derivatives
$$
\frac{\partial{J}}{\partial{F(x_i)}}
= \frac{\partial{\sum_i L(y_i, F(x_i))}}{\partial{F(x_i)}}
= \frac{\partial{L(y_i, F(x_i))}}{\partial{F(x_i)}}
= F(x_i) - y_i
$$
So we can interpret residuals as negative gradients:
$$
y_i - F(x_i) = - \frac{\partial{J}}{\partial{F(x_i)}}.
$$
And we get:
$$
\begin{eqnarray}
F(x_i) &amp;amp;:=&amp;amp; F(x_i) + h(x_i) \
F(x_i) &amp;amp;:=&amp;amp; F(x_i) + y_i - F(x_i) \
F(x_i) &amp;amp;:=&amp;amp; F(x_i) - 1 \frac{\partial{J}}{\partial{F(x_i)}} \
\end{eqnarray}
$$
This is exactly how the gradients update iteratively when $\rho=1$:
$$
\theta_i := \theta_i - \rho{\partial{J} \over \partial{\theta_i}}
$$
For regression with &lt;strong>square loss&lt;/strong>,
$$
\begin{eqnarray}
\text{residual} &amp;amp;\Leftrightarrow&amp;amp; \text{negative gradient} \
\text{fit h to residual} &amp;amp;\Leftrightarrow&amp;amp; \text{fit h to negative gradient} \
\text{update F based on residual} &amp;amp;\Leftrightarrow&amp;amp; \text{update F based on negative gradient} \
\end{eqnarray}
$$
So we are actually updating our model using &lt;strong>gradient descent&lt;/strong>!&lt;/p>
&lt;h4 id="loss-functions-for-regression-problem" >
&lt;div>
&lt;a href="#loss-functions-for-regression-problem">
###
&lt;/a>
Loss Functions for Regression Problem
&lt;/div>
&lt;/h4>
&lt;p>Square loss is:&lt;/p>
&lt;ol>
&lt;li>Easy to deal with mathematically, while&lt;/li>
&lt;li>Not robust to outliers.&lt;/li>
&lt;/ol>
&lt;p>The consequence is that it pay too much attention to outliers, and try hard to incorporate outliers into the model, leads to degrade the overall performance.&lt;/p>
&lt;p>Other commomly use loss functions are:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Absolute loss (more robust to outliers):
$$
L(y, F) = |y - F|
$$
Negative gradient:
$$&lt;/p>
&lt;ul>
&lt;li>g(x_i)
= - \frac{\partial{L(y_i, F(x_i))}}{\partial{F(x_i)}}
= \text{sign}(y_i - F(x_i))
$$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Huber loss (more robust to outliers):
$$
L(y, F) = \left{
\begin{array}{ll}
{1 \over 2}(y - F)^2, &amp;amp;|y - F| \le \delta;&amp;amp; \
\delta(|y - F| - {\delta \over 2}), &amp;amp;|y - F| &amp;gt; \delta;&amp;amp; \
\end{array} \right.
$$
Negative gradient:
$$
\begin{eqnarray}&lt;/p>
&lt;ul>
&lt;li>g(x_i)
&amp;amp;=&amp;amp; - \frac{\partial{L(y_i, F(x_i))}}{\partial{F(x_i)}} \
\
&amp;amp;=&amp;amp; \left{
\begin{array}{ll}
y_i - F(x_i), &amp;amp;|y_i - F(x_i)| \le \delta;&amp;amp; \
\delta\ \text{sign}(y_i - F(x_i)), &amp;amp;|y_i - F(x_i)| &amp;gt; \delta;&amp;amp; \
\end{array} \right.
\end{eqnarray}
$$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>example:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">$y_i$&lt;/th>
&lt;th style="text-align: center">0.5&lt;/th>
&lt;th style="text-align: center">1.2&lt;/th>
&lt;th style="text-align: center">2&lt;/th>
&lt;th style="text-align: center">$5^*$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">$F(x_i)$&lt;/td>
&lt;td style="text-align: center">0.6&lt;/td>
&lt;td style="text-align: center">1.4&lt;/td>
&lt;td style="text-align: center">1.5&lt;/td>
&lt;td style="text-align: center">1.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">Square loss&lt;/td>
&lt;td style="text-align: center">0.005&lt;/td>
&lt;td style="text-align: center">0.02&lt;/td>
&lt;td style="text-align: center">0.125&lt;/td>
&lt;td style="text-align: center">5.445&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">Absolute loss&lt;/td>
&lt;td style="text-align: center">0.1&lt;/td>
&lt;td style="text-align: center">0.2&lt;/td>
&lt;td style="text-align: center">0.5&lt;/td>
&lt;td style="text-align: center">3.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">Huber loss ($\delta=0.5$)&lt;/td>
&lt;td style="text-align: center">0.005&lt;/td>
&lt;td style="text-align: center">0.02&lt;/td>
&lt;td style="text-align: center">0.125&lt;/td>
&lt;td style="text-align: center">1.525&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="regression-with-loss-function-l-general-procedure" >
&lt;div>
&lt;a href="#regression-with-loss-function-l-general-procedure">
###
&lt;/a>
Regression with loss function $L$: general procedure
&lt;/div>
&lt;/h4>
&lt;hr>
&lt;p>Give any differentiable loss function $L$,&lt;/p>
&lt;p>start with an initial model, say $F(x) = \frac{\sum^n_{i=1} y_i}{n}$,&lt;/p>
&lt;p>iterate until converge:&lt;/p>
&lt;p>​ calculate negative gradients $- g(x_i) = - \frac{\partial{L(y_i, F(x_i))}}{\partial{F(x_i)}}$,&lt;/p>
&lt;p>​ fit a regression tree $h$ to negative gradients $-g(x_i)$,&lt;/p>
&lt;p>​ $F := F + \rho h$&lt;/p>
&lt;hr>
&lt;p>In general, &lt;em>negative gradients&lt;/em> not equal to &lt;em>residuals&lt;/em>, and we should follow negative gradients rather than residuals because &lt;em>negative gradient&lt;/em> pays less attention to outliers.&lt;/p>
&lt;h4 id="summary-of-the-section" >
&lt;div>
&lt;a href="#summary-of-the-section">
###
&lt;/a>
Summary of the Section
&lt;/div>
&lt;/h4>
&lt;ul>
&lt;li>Fit an additive model $F=\sum_t {\rho_t h_t}$ in a forward stage-wise manner.&lt;/li>
&lt;li>In each stage, introduce a new regression tree $h$ to compensate the shortcomings of existing model.&lt;/li>
&lt;li>The &lt;em>shortcomings&lt;/em> are identified by negative gradients.&lt;/li>
&lt;li>For any loss function, we can derive a gradient boosting algorithm.&lt;/li>
&lt;li>Absolute loss and Huber loss are more robust to outliers than square loss.&lt;/li>
&lt;/ul>
&lt;p>NOTE that the things not covered:&lt;/p>
&lt;p>How to choose a proper learning rate for each gradient boosting algorithm. See [Friedman, 2001]&lt;/p>
&lt;hr>
&lt;h4 id="gradient-boosting-for-classification" >
&lt;div>
&lt;a href="#gradient-boosting-for-classification">
###
&lt;/a>
Gradient Boosting for Classification
&lt;/div>
&lt;/h4>
&lt;p>&lt;strong>Problem:&lt;/strong>&lt;/p>
&lt;p>Recognize the given hand written capital letter. &lt;a href="http://archive.ics.uci.edu/ml/datasets/Letter+Recognition">dataset size: 20000 x 16&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Multi-class classification&lt;/p>
&lt;/li>
&lt;li>
&lt;p>26 classes. A, B, &amp;hellip;, Z&lt;/p>
&lt;/li>
&lt;li>
&lt;p>features:&lt;/p>
&lt;p>1 horizontal position of box;
2 vertical position of box;
3 width of box;
4 height of box;
5 total number on pixels;
6 mean x of on pixels in box;
7 mean y of on pixels in box;
8 mean x variance;&lt;/p>
&lt;p>9 mean y variance；&lt;/p>
&lt;p>10 mean x y correlation;&lt;/p>
&lt;p>11 mean of x * x * y;&lt;/p>
&lt;p>12 mean of x * y * y;&lt;/p>
&lt;p>13 mean edge count left to right;&lt;/p>
&lt;p>14 correlation of x-ege with y;&lt;/p>
&lt;p>15 mean edge count bottom to top;&lt;/p>
&lt;p>16 correlation of y-ege with x.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Feature Vector= (2; 1; 3; 1; 1; 8; 6; 6; 6; 6; 5; 9; 1; 7; 5; 10)
Label = G&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Model:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>26 score functions (our models): $F_A, F_B, \ldots, F_Z$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$F_A(x)$ assigns a score for class A.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>scores are used to calculate probabilities:
$$
\begin{eqnarray}
P_A(x) &amp;amp;=&amp;amp; \frac{\exp(F_A(x))}{\sum^Z_{c=A}\exp(F_c(x))} \
\
P_B(x) &amp;amp;=&amp;amp; \frac{\exp(F_B(x))}{\sum^Z_{c=A}\exp(F_c(x))} \
\
\cdots \
\
P_Z(x) &amp;amp;=&amp;amp; \frac{\exp(F_Z(x))}{\sum^Z_{c=A}\exp(F_c(x))} \
\end{eqnarray}
$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>predicted label = class that has the highest probability.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Loss function for each data point:&lt;/strong> step by step&lt;/p>
&lt;ol>
&lt;li>
&lt;p>turn the label $y_i$ into a (true) probability distribution $Y_c(x_i)$,&lt;/p>
&lt;p>For example: $y_5=\text{G}$,&lt;/p>
&lt;p>$Y_A(x_5)=0, Y_B(x_5)=0, \ldots, Y_G(x_5)=1, \ldots, Y_Z(x_5)=0$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>calculate the predicted probability distribution $P_c(x_i)$ based on the current model $F_A, F_B, \ldots, F_Z$.&lt;/p>
&lt;p>$P_A(x_5)=0.03, P_B(x_5)=0.05, \ldots, P_G(x_5)=0.3, \ldots, P_Z(x_5)=0.05$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>calculate the difference between the true probability distribution and the predicted distribution. One of the ways is to use KL-divergence to measure the difference.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>The Goal:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>minimize the total loss (KL-divergence)&lt;/li>
&lt;li>for each data point, we wish the predicted probability distribution to match the true probability distribution as closely as possible.&lt;/li>
&lt;li>we achieve this goal by adjusting our models $F_A, F_B, \ldots, F_Z$.&lt;/li>
&lt;/ul>
&lt;h4 id="gradient-boosting-for-classification-general-procedure" >
&lt;div>
&lt;a href="#gradient-boosting-for-classification-general-procedure">
###
&lt;/a>
Gradient Boosting for classification: general procedure
&lt;/div>
&lt;/h4>
&lt;hr>
&lt;p>start with initial models $F_A, F_B, \ldots, F_Z$.&lt;/p>
&lt;p>iterate until converge:&lt;/p>
&lt;p>​ calculate negative gradients for class A: $-g_A(x_i)= - \frac{\partial{L}}{\partial{F_A(x_i)}}$&lt;/p>
&lt;p>​ &amp;hellip;&lt;/p>
&lt;p>​ calculate negative gradients for class Z: $-g_Z(x_i)= - \frac{\partial{L}}{\partial{F_Z(x_i)}}$&lt;/p>
&lt;p>​ fit a regression tree $h_A$ to negative gradients $-g_A(x_i)$&lt;/p>
&lt;p>​ &amp;hellip;&lt;/p>
&lt;p>​ fit a regression tree $h_Z$ to negative gradients $-g_Z(x_i)$&lt;/p>
&lt;p>​ $F_A := F_A + \rho_A h_A$&lt;/p>
&lt;p>​ &amp;hellip;&lt;/p>
&lt;p>​ $F_Z := F_Z + \rho_Z h_Z$&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Classification VS Regression&lt;/strong>: The Differences&lt;/p>
&lt;ul>
&lt;li>$F_A, F_B, \ldots, F_Z$ &lt;strong>vs&lt;/strong> $F$&lt;/li>
&lt;li>a matrix of parameters to optimize &lt;strong>vs&lt;/strong> a column of parameters to optimize&lt;/li>
&lt;li>a matrix of gradients &lt;strong>vs&lt;/strong> a column of gradients&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;/blockquote>
&lt;h2 id="part-ii-engineering-views" >
&lt;div>
&lt;a href="#part-ii-engineering-views">
#
&lt;/a>
Part-II: Engineering views
&lt;/div>
&lt;/h2>
&lt;h2 id="sklearn-random-forest-model" >
&lt;div>
&lt;a href="#sklearn-random-forest-model">
#
&lt;/a>
Sklearn Random-forest model
&lt;/div>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>sklearn&lt;span style="color:#ff6ac1">.&lt;/span>ensemble&lt;span style="color:#ff6ac1">.&lt;/span>RandomForestClassifier(n_estimators&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">100&lt;/span>, &lt;span style="color:#ff6ac1">*&lt;/span>, criterion&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#39;gini&amp;#39;&lt;/span>, max_depth&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>, min_samples_split&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">2&lt;/span>, min_samples_leaf&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1&lt;/span>, min_weight_fraction_leaf&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">0.0&lt;/span>, max_features&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#5af78e">&amp;#39;auto&amp;#39;&lt;/span>, max_leaf_nodes&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>, min_impurity_decrease&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">0.0&lt;/span>, min_impurity_split&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>, bootstrap&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">True&lt;/span>, oob_score&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">False&lt;/span>, n_jobs&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>, random_state&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>, verbose&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">0&lt;/span>, warm_start&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">False&lt;/span>, class_weight&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>, ccp_alpha&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">0.0&lt;/span>, max_samples&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>A random forest classifier.&lt;/p>
&lt;p>A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the &lt;code>max_samples&lt;/code> parameter if &lt;code>bootstrap=True&lt;/code> (default), otherwise the whole dataset is used to build each tree.&lt;/p>
&lt;h3 id="feature_importances_" >
&lt;div>
&lt;a href="#feature_importances_">
##
&lt;/a>
feature_importances_
&lt;/div>
&lt;/h3>
&lt;p>Sklearn measures a feature&amp;rsquo;s importance by looking at how much the tree nodes that use that feature reduce impurity on average (across all trees in the forest). More precisely, it is a weighted average, where each node&amp;rsquo;s weight is equal to the number of training samples that are associated with it.&lt;/p>
&lt;p>&lt;code>feature_importances_&lt;/code> is a impurity-based feature importances.&lt;/p>
&lt;p>The higher, the more importance the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.&lt;/p>
&lt;p>Warning: impurity-based feature importance can be misleading for high cardinality features (many unique values). see [permutation_importance](###permutation importance) as an alternative.&lt;/p>
&lt;p>Tree-based models measure the feature importances based on the &lt;a href="https://fgg100y.github.io/posts/ml101/treebasedmodels/treemodels/#MDI">mean decrease in impurity&lt;/a>. Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy(i.e., imformation gain) or Mean Square Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data (hold-out set, validation set, etc).&lt;/p>
&lt;p>Furthermore, impurity-based feature importance for trees are &lt;strong>strongly biased&lt;/strong> and &lt;strong>favor high cardinality features&lt;/strong> (typically numerical features) over low cardinality features such as binary features or categorical variables with a small number of possible categories. &lt;a href="https://fgg100y.github.io/posts/ml101/treebasedmodels/treemodels/####增益率">(see this explanation)&lt;/a>.&lt;/p>
&lt;p>The following example highlights the limitations of impurity-based feature importance in contrast to permutation-based feature importance:&lt;/p>
&lt;p>&lt;a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py">Permutation importance vs Random Forest Feature Importance (MDI)&lt;/a>&lt;/p>
&lt;h3 id="permutation-importance" >
&lt;div>
&lt;a href="#permutation-importance">
##
&lt;/a>
permutation importance
&lt;/div>
&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>sklearn&lt;span style="color:#ff6ac1">.&lt;/span>inspection&lt;span style="color:#ff6ac1">.&lt;/span>permutation_importance(estimator, X, y, &lt;span style="color:#ff6ac1">*&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scoring&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n_repeats&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">5&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n_jobs&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> random_state&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">None&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Permutation importance for feature evaluation.&lt;/p>
&lt;p>The &lt;code>estimator&lt;/code> is required to be a fitted estimator. &lt;code>X&lt;/code> can be the data set used to train the estimator or a hold-out set. The permutation importance of a feature is calculated as follows.&lt;/p>
&lt;p>First, a baseline metric, defined by [scoring](#Scoring Parameter), is evaluated on a (potentially different) dataset defined by &lt;code>X&lt;/code>. Next, a feature column from the validation set is permuted(&lt;a href="https://fgg100y.github.io/posts/ml101/treebasedmodels/treemodels/####How-it-work">How&lt;/a>) and the metric is evaluated again.&lt;/p>
&lt;p>The permutation importance is defined to be difference between the baseline metric and metric from permutating the feature column.&lt;/p>
&lt;hr>
&lt;p>Algorithm 1. Permutation importance&lt;/p>
&lt;hr>
&lt;p>Inputs: fitted predictive model $m$, tabular dataset (training or validation) $D$.&lt;/p>
&lt;p>Compute the reference score $s$ of the model $m$ on data $D$ (for instance the accuracy for a classifier or the $R^2$ for a regressor).&lt;/p>
&lt;p>&lt;strong>For&lt;/strong> each feature $j$ (column of $D$):&lt;/p>
&lt;p>​ &lt;strong>For&lt;/strong> each repetition $k$ in $1, \ldots, K$:&lt;/p>
&lt;p>​ Randomly shuffle column $j$ of dataset $D$ to generate a corrupted version of the data named $\tilde{D}_{k,j}$.&lt;/p>
&lt;p>​ Compute the score $s_{k,j}$ of model $m$ on corrupted data $\tilde{D}_{k,j}$.&lt;/p>
&lt;p>​ Compute importance $i_j$ for feature $f_j$ defined as:
$$
i_j = s - {1 \over K} \sum^K_{k=1}s_{k,j}.
$$&lt;/p>
&lt;hr>
&lt;h4 id="how-it-work" >
&lt;div>
&lt;a href="#how-it-work">
###
&lt;/a>
How it work
&lt;/div>
&lt;/h4>
&lt;p>Consider this: We want to predict a person&amp;rsquo;s height when they become 20 years old, using data that is available at age 10. Our data includes useful features (height at age 10), features with little predictive power (socks owned), as well as some other features we won&amp;rsquo;t focus on this explanation.&lt;/p>
&lt;p>&lt;strong>Permutation importance is calculated after a model has been fitted.&lt;/strong> so we won&amp;rsquo;t change the model or change what predictions we&amp;rsquo;d get for a given value of height, sock-count, etc.&lt;/p>
&lt;p>Instead we will ask the following question:&lt;/p>
&lt;p style="text-align:left;color:blue;">
"if I randomly shuffle a single column of the validation set data, leaving the target (or lable) and all other columns in place, how would that affect the accuracy of predictions in that now-shuffled data?"
&lt;/p>
&lt;p>Randomly re-ordering a single column should cause less accuracy predictions, since the resulting data no longer corresponds to anything observed in the real world. Model accuracy especially suffers if we shuffle a column that the model relied on heavily for predictions. In this case, shuffling &lt;code>height at age 10&lt;/code> would cause terrible predictions while shuffling &lt;code>socks-owned&lt;/code> wouldn&amp;rsquo;t sufffer nearly as much.&lt;/p>
&lt;h3 id="misleading-values-on-strongly-correlated-features" >
&lt;div>
&lt;a href="#misleading-values-on-strongly-correlated-features">
##
&lt;/a>
Misleading values on strongly correlated features
&lt;/div>
&lt;/h3>
&lt;p>When two features are correlated and one of the feature is permuted, the model will still have access to the feature through its correlated feature. This will result in a lower importance value for both features, where they might actually be important.&lt;/p>
&lt;p>One way to handle this is to cluster features that are correlated and only keep one feature from each cluster. This strategy is explored in the following example:&lt;/p>
&lt;p>&lt;a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py">Permutation Importance with Multicollinear or Correlated Features&lt;/a>.&lt;/p>
&lt;h3 id="does-modeling-with-random-forests-require-cross-validation" >
&lt;div>
&lt;a href="#does-modeling-with-random-forests-require-cross-validation">
##
&lt;/a>
Does modeling with Random Forests require cross-validation?
&lt;/div>
&lt;/h3>
&lt;p style="text-align:center;color:blue;">
"Random forests provide free cross-validation."
&lt;/p>
&lt;p>The &lt;code>RandomForestClassifier&lt;/code> is trained using &lt;em>bootstrap aggregation&lt;/em>, where each new tree is fit from a bootstrap sample of the training observations $z_i = (x_i, y_i)$. The out-of-bag (OOB) error is the average error for each $z_i$ calculated using predictions from the tress that do not contain $z_i$ in their respective bootstrap sample. This allows the &lt;code>RandomForestClassifier&lt;/code> to be fit and validated whilst being trained.&lt;/p>
&lt;blockquote>
&lt;p>By principle since it randomizes the variable selection during each tree split, it&amp;rsquo;s not prone to overfit unlike other models. However if you want to use CV using nfolds in sklearn you can still use the concept of hold-out set such as &lt;code>oob_score=True&lt;/code> which shows model performance with or without using CV.&lt;/p>
&lt;/blockquote>
&lt;h3 id="sklearn-boosting" >
&lt;div>
&lt;a href="#sklearn-boosting">
##
&lt;/a>
Sklearn Boosting
&lt;/div>
&lt;/h3>
&lt;blockquote>
&lt;p>from book 《Hands-onML》.&lt;/p>
&lt;p>Boosting (original called &lt;em>hypothesis boosting&lt;/em>) refers to any Ensemble method that can combine several weak learners into a strong learner. The general idea most boosting methods is to train predictors sequentially, each trying to correct its predecessor. The most popular boosting methods by far are&lt;/p>
&lt;ul>
&lt;li>AdaBoost (short for Adaptive Boosting) and&lt;/li>
&lt;li>Gradient Boosting.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>1. AdaBoost&lt;/strong>&lt;/p>
&lt;p>One way for a new predictor to correct its predecessor is to pay a bit more attention to the training instances that the predecessor underfitted. This results in new predictors focusing more and more on the hard case. This technique used by AdaBoost.&lt;/p>
&lt;p>For example, when training an AdaBoost classifier, the algorithm first train a base classifier (such as a Decision Tree) and uses it to make predictions on the train set. The algorithm then increase the relative weight of misclassified training instances. Then it trains a second classifier, using the updated weights, and again makes predictions on the training set, updates the instance weights, and so on (see Figure 7-7).&lt;/p>
&lt;p>&lt;img alt="adaboost" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\hands-onML_ensemble_adaboost.png">&lt;/p>
&lt;p>Once all predictors are trained, the ensemble makes predictions very much like bagging or pasting, except that predictors have different weights depending on their overall accuracy on their corresponding weighted training set.&lt;/p>
&lt;p>There is one important drawback to this sequential learning technique: it cannot be parallelized (or only partially), since each predictor can only be trained after the previous predictor has ben trained and evaluated. As a result, it does not scale as well as bagging or pasting.&lt;/p>
&lt;p>&lt;strong>2. Gradient Boosting&lt;/strong>&lt;/p>
&lt;p>Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor. However, instead of tweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the new predictor to the &lt;em>residual errors&lt;/em> made by the previous predictor.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># Gradient Tree Boosting for regression task,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># a.k.a., Gradient Boosted Regression Trees (GBRT)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> sklearn.tree &lt;span style="color:#ff6ac1">import&lt;/span> DecisionTreeRegressor
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dtree_reg1 &lt;span style="color:#ff6ac1">=&lt;/span> DecisionTreeRegressor(max_depth&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dtree_reg1&lt;span style="color:#ff6ac1">.&lt;/span>fit(X, y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># train a second regressor on the residual errors made by the previous predictor&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y2 &lt;span style="color:#ff6ac1">=&lt;/span> y &lt;span style="color:#ff6ac1">-&lt;/span> dtree_reg1&lt;span style="color:#ff6ac1">.&lt;/span>predict(X)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dtree_reg2 &lt;span style="color:#ff6ac1">=&lt;/span> DecisionTreeRegressor(max_depth&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dtree_reg2&lt;span style="color:#ff6ac1">.&lt;/span>fit(X, y2)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># train a third regressor on the residual errors made by the previous predictor&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y3 &lt;span style="color:#ff6ac1">=&lt;/span> y2 &lt;span style="color:#ff6ac1">-&lt;/span> dtree_reg2&lt;span style="color:#ff6ac1">.&lt;/span>predict(X)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dtree_reg3 &lt;span style="color:#ff6ac1">=&lt;/span> DecisionTreeRegressor(max_depth&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dtree_reg3&lt;span style="color:#ff6ac1">.&lt;/span>fit(X, y3)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#78787e"># ensemble contains three trees which makes predictions on a new instance simply by adding up the predictions of all the trees&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_pred &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">sum&lt;/span>(tree&lt;span style="color:#ff6ac1">.&lt;/span>predict(X_new) &lt;span style="color:#ff6ac1">for&lt;/span> tree &lt;span style="color:#ff6ac1">in&lt;/span> (dtree_reg1, dtree_reg2, dtree_reg3))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>A simpler way to train GBRT ensembles is to use sklearn &lt;code>GradientBoostingRegressor&lt;/code> class. Much like the &lt;code>RandomForestRegressor&lt;/code> class, it has hyperparameters to control the growth of Decision Trees.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> sklearn.ensemble &lt;span style="color:#ff6ac1">import&lt;/span> GradientBoostingRegressor
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gbrt &lt;span style="color:#ff6ac1">=&lt;/span> GradientBoostingRegressor(max_depth&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">2&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n_estimators&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">3&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> learning_rate&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">1.0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gbrt&lt;span style="color:#ff6ac1">.&lt;/span>fit(X, y)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img alt="gbrt model fitting" src="d:\\JupyterNotebook\\fmhPlayground\\NotesDS\\treeBasedModels\\images\\hands-onML_ensemble_gradient_boosting.png">&lt;/p>
&lt;p>The &lt;code>learning_rate&lt;/code> hyperparameter scales the contribution of each tree.&lt;/p>
&lt;p>If you set it to a low value, such as 0.1, you will need more trees in the ensemble to fit the training set, but the predictions will usually better. This is a regularization technique called &lt;strong>shrinkage&lt;/strong>. In order to find the optimal number of trees, you can use early stopping which can simply implemented by setting&lt;code>warm_start=True&lt;/code> :&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">import&lt;/span> numpy &lt;span style="color:#ff6ac1">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> sklearn.model_selection &lt;span style="color:#ff6ac1">import&lt;/span> train_test_split
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">from&lt;/span> sklearn.metrics &lt;span style="color:#ff6ac1">import&lt;/span> mean_square_error
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>X_train, y_train, X_test, y_test &lt;span style="color:#ff6ac1">=&lt;/span> train_test_split(X, y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gbrt &lt;span style="color:#ff6ac1">=&lt;/span> GradientBoostingRegressor(max_depth&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">2&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> warm_start&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff6ac1">True&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ff6ac1">def&lt;/span> &lt;span style="color:#57c7ff">early_stop_gbrt&lt;/span>(model, n_estimators&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">200&lt;/span>, n_rounds&lt;span style="color:#ff6ac1">=&lt;/span>&lt;span style="color:#ff9f43">5&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train_data&lt;span style="color:#ff6ac1">=&lt;/span>(X_train, y_train),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> val_data&lt;span style="color:#ff6ac1">=&lt;/span>(X_test, y_test),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> min_val_error &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff5c57">float&lt;/span>(&lt;span style="color:#5af78e">&amp;#34;inf&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> error_going_up &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">for&lt;/span> n &lt;span style="color:#ff6ac1">in&lt;/span> &lt;span style="color:#ff5c57">range&lt;/span>(&lt;span style="color:#ff9f43">1&lt;/span>, n_estimators):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#ff6ac1">.&lt;/span>n_estimators &lt;span style="color:#ff6ac1">=&lt;/span> n
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#ff6ac1">.&lt;/span>fit(train_data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y_pred &lt;span style="color:#ff6ac1">=&lt;/span> model&lt;span style="color:#ff6ac1">.&lt;/span>predict(val_data[&lt;span style="color:#ff9f43">0&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> val_error &lt;span style="color:#ff6ac1">=&lt;/span> mean_square_error(val_data[&lt;span style="color:#ff9f43">1&lt;/span>], y_pred)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> val_error &lt;span style="color:#ff6ac1">&amp;lt;&lt;/span> min_val_error:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> min_val_error &lt;span style="color:#ff6ac1">=&lt;/span> val_error
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> error_going_up &lt;span style="color:#ff6ac1">=&lt;/span> &lt;span style="color:#ff9f43">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> error_going_up &lt;span style="color:#ff6ac1">+=&lt;/span> &lt;span style="color:#ff9f43">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">if&lt;/span> error_going_up &lt;span style="color:#ff6ac1">==&lt;/span> n_round:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">break&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ff6ac1">return&lt;/span> model
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gbrt &lt;span style="color:#ff6ac1">=&lt;/span> early_stop_gbrt(gbrt)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that there is an optimized implementation of Gradient Boosting out there called &amp;ldquo;XGBoost&amp;rdquo; which stands for Extreme Gradient Boosting, it is a popular Python library aimed to be extremely fast, scalable, and portable.&lt;/p>
&lt;/blockquote>
&lt;h3 id="plot-the-decision-tree" >
&lt;div>
&lt;a href="#plot-the-decision-tree">
##
&lt;/a>
Plot the decision tree
&lt;/div>
&lt;/h3>
&lt;p>To be continue &amp;hellip;&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>由 $d$ 个属性张成的 $d$ 维空间中，每个示例都可以在这个空间中找到自己的坐标位置，每个空间中的点对应一个坐标向量，因此：一个示例就是一个“特征向量”（feature vector）。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>上一步的划分属性“纹理”，不再作为候选划分属性。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>Which is mainly due to the nature of how decision tree growed using greedy algorithm and easily overfiting.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>可将划分点设为该属性在训练集中出现的不大于中位点的最大值。由此，决策树使用的划分点都出现在训练集中。&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5">
&lt;p>待补充。&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6">
&lt;p>[Mingers, 1989b]&amp;#160;&lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7">
&lt;p>[Raileanu and Stoffel, 2004]&amp;#160;&lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8">
&lt;p>[Mingers, 1989a]&amp;#160;&lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9">
&lt;p>[Mruthy et al., 1994]&amp;#160;&lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10">
&lt;p>[Brodley and Utgoff, 1995]&amp;#160;&lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:11">
&lt;p>[Utgoff, 1989b]&amp;#160;&lt;a href="#fnref:11" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:12">
&lt;p>[Guo and Gelfand, 1992]&amp;#160;&lt;a href="#fnref:12" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:13">
&lt;p>[Schlimmer and Fisher, 1986]&amp;#160;&lt;a href="#fnref:13" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:14">
&lt;p>[Utgoff, 1989a]&amp;#160;&lt;a href="#fnref:14" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:15">
&lt;p>[Utgoff et al., 1997]&amp;#160;&lt;a href="#fnref:15" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:16">
&lt;p>集成学习(ensemble learning，a.k.a, multi-classifier system, committee-based learning)通过构建并结合多个学习器来完成学习任务。集成学习一般结构是，先产生一组 “个体学习器(individual learner)”，再用某种策略将它们结合起来。个体学习器通常由一个现有学习算法从训练数据产生，例如 C4.5决策树算法或BP神经网络算法等，此时，如果集成中只包含同种类型的个体学习器，如 “决策树集成”、“神经网络集成”等，则这样的集成是 “同质” 的(homogeneous)集成，同质集成中的个体学习器也称为 “基学习器(base learner)”，相应的学习算法称为 “基学习算法(base learning algorithm)”；反之，则是 “异质” 的(heterogenous)集成，这时个体学习器常称为 &amp;ldquo;组件学习器(component learner)&amp;rdquo; 或直接称为个体学习器。&amp;#160;&lt;a href="#fnref:16" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:17">
&lt;p>Boosting 是一族可将弱学习器提升为强学习器的算法。这族算法的工作机制类似：先从初始训练集训练出一个机学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至学习器数目达到事先指定的值$T$，最终将这$T$个基学习器进行加权结合。&amp;#160;&lt;a href="#fnref:17" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:18">
&lt;p>bootstrapping 采样是有放回的随机重复采样，样本在$m$次采样中始终不被采到的概率是$(1 - {1 \over m})^m$，取极限得到$lim_{(m \rightarrow \infin)} (1 - {1 \over m})^m \rightarrow {1 \over e} \approx 0.368$，即通过自助采样，初始数据集中约有36.8%的样本未出现在自助采样集中。自助法能从初始数据集中产生多个不同训练集，这对集成学习有很大好处。然而，自助法产生的数据集改变了初始数据集的分布而引入估计偏差，因此，在初始数据量足够时，留出法和交叉验证法更常用一些。&amp;#160;&lt;a href="#fnref:18" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:19">
&lt;p>statistical mode: 众数。也就是频率最高的预测类别，与 hard voting classfifer 类似。&amp;#160;&lt;a href="#fnref:19" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:20">
&lt;p>The &lt;code>BaggingClassifier&lt;/code> class remains useful if you want a bag of something other than Decision Trees.&amp;#160;&lt;a href="#fnref:20" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:21">
&lt;p>Finding the best possible threshold for each feature at every node is one of the most time-consuming tasks of growing a tree.&amp;#160;&lt;a href="#fnref:21" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:22">
&lt;p>residual is the difference between the predicted and the ground true.&amp;#160;&lt;a href="#fnref:22" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title/><link>/posts/neuralnetworks/xgs_backprop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>1522009317@qq.com (fmh)</author><guid>/posts/neuralnetworks/xgs_backprop/</guid><description>&lt;h2 id="误差逆传播算法error-backpropagation-bp" >
&lt;div>
&lt;a href="#%e8%af%af%e5%b7%ae%e9%80%86%e4%bc%a0%e6%92%ad%e7%ae%97%e6%b3%95error-backpropagation-bp">
#
&lt;/a>
误差逆传播算法(error BackPropagation, BP)
&lt;/div>
&lt;/h2>
&lt;p>BP 算法是迄今最成功的神经网络学习算法。现实任务中使用神经网络时，大多是在使用 BP 算法进行训练。BP 算法不仅可用于多层前馈神经网络(multi-layer feedforward neural networks)&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> ，还可以用于其他类型的神经网络，例如训练递归神经网络。但通常说 “BP网络” 时，一般指用 BP 算法训练的多重前馈神经网络&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>。&lt;/p>
&lt;h3 id="bp网络及变量符号" >
&lt;div>
&lt;a href="#bp%e7%bd%91%e7%bb%9c%e5%8f%8a%e5%8f%98%e9%87%8f%e7%ac%a6%e5%8f%b7">
##
&lt;/a>
BP网络及变量符号
&lt;/div>
&lt;/h3>
&lt;p>给定训练集 $D = {(x_1, y_1), \ldots, (x_m, y_m)}, x_i \in \R^d, y_i \in \R^l$ ，即输入示例由 $d$ 个属性描述，输出 $l$ 维实值向量。为便于讨论，图5.7 给出了一个拥有 $d$ 个输入神经元、$l$ 个输出神经元、$q$ 个隐层神经元的多层前馈神经网络结构，其中&lt;/p>
&lt;ul>
&lt;li>
&lt;p>输出层第 $j$ 个神经元的阈值用 $\theta_j$ 表示，隐层第 $h$ 个神经元的阈值用 $\gamma_h$ 表示；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>输入层第 $i$ 个神经元与隐层第 $h$ 个神经元之间的连接权为 $v_{ih}$ ；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>隐层第 $h$ 个神经元与输出层第 $j$ 个神经元之间的连接权为 $w_hj$ ；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>记隐层第 $h$ 个神经元接收到的输入为 $\alpha_h = \sum^d_{i=1} v_{ih} x_i$ ；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>记输出层第 $j$ 个神经元接收到的输入为 $\beta_j = \sum^q_{h=1} w_{hj} b_h $ ，其中，$b_h$ 为隐层第 $h$ 个神经元的输出；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>假设隐层和输出层神经元都使用sigmoid函数&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> 作为激活函数&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> 。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img alt="BP network and notations" src="./images/xgs_BP_notations.png">&lt;/p>
&lt;p>对训练例 $(x_k, y_k)$ ，假定神经网络的输出为 $\hat{y}&lt;em>k = (\hat{y}^k_1, \ldots, \hat{y}^k_l)$ ，即
$$
\tag{5.3} \label{eq_y_hat}
\hat{y}^k_j = f(\beta_j - \theta_j),
$$
则网络在 $(x_k, y_k)$ 上均方误差为
$$
\tag{5.4}
E_k = {1 \over 2} \sum^l&lt;/em>{j=1} (\hat{y}^k_j - {y}^k_j)^2 .
$$
图5.7的网络中有 $(d + l + 1)q + l$ 个参数需确定：&lt;/p>
&lt;ul>
&lt;li>输入层到隐层的 $d \times q$ 个权值；&lt;/li>
&lt;li>隐层到输出层的 $q \times l$ 个权值;&lt;/li>
&lt;li>$q$ 个隐层神经元的阈值、$l$ 个输出层神经元的阈值。&lt;/li>
&lt;/ul>
&lt;p>BP 是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup> 对参数进行更新估计，即任意参数 $v$ 的更新估计式为
$$
\tag{5.5}
v \leftarrow v + \Delta v .
$$&lt;/p>
&lt;h3 id="参数的更新" >
&lt;div>
&lt;a href="#%e5%8f%82%e6%95%b0%e7%9a%84%e6%9b%b4%e6%96%b0">
##
&lt;/a>
参数的更新
&lt;/div>
&lt;/h3>
&lt;p>以下我们以图5.7中隐层到输出层的连接权 $w_{hj}$ 为例来进行推导。&lt;/p>
&lt;p>BP 算法基于梯度下降(gradient descent)策略，以目标的的负梯度方向对参数进行调整。对式(5.4)的误差 $E_k$ ，给定学习率 $\eta$ ，有
$$
\tag{5.6}
\Delta w_{hj} = - \eta {\partial E_k \over \partial w_{hj}}.
$$
注意&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>到 $w_{hj}$ 先影响到第 $j$ 个输出层神经元的输入值 $\beta_j$ ，再影响到其输出值 $\hat{y}^k_j$ ，然后影响到 $E_k$ ，有
$$
\tag{5.7}
\frac{\partial E_k}{\partial w_{hj}} =
\frac{\partial E_k}{\partial \hat{y}^k_j}
\cdot \frac{\partial \hat{y}^k_j}{\partial \beta_j}
\cdot \frac{\partial \beta_j}{\partial w_{hj}} .
$$
根据 $\beta_j$ 的&lt;a href="https://fgg100y.github.io/posts/neuralnetworks/xgs_backprop/###BP网络及变量符号">定义&lt;/a>，显然有
$$
\tag{5.8}
\frac{\partial \beta_j}{\partial w_{hj}} = b_h .
$$
sigmoid函数有一个很好的性质：
$$
\tag{5.9}
f&amp;rsquo;(x) = f(x)(1 - f(x)),
$$
于是，根据式(5.4)和式(5.3)，有
$$
\begin{eqnarray}
g_j
&amp;amp;=&amp;amp; - \frac{\partial E_k}{\partial \hat{y}^k_j} \cdot \frac{\partial \hat{y}^k_j}{\partial \beta_j} \
&amp;amp;=&amp;amp; - (\hat{y}^k_j - {y}^k_j) f&amp;rsquo;(\beta_j - \theta_j) \
\tag{5.10} \label{eq_output_gradient}
&amp;amp;=&amp;amp; \hat{y}^k_j(1 - \hat{y}^k_j) (\hat{y}^k_j - {y}^k_j) .
\end{eqnarray}
$$
将式(5.10)和(5.8)代入式(5.7)，再代入式(5.6)，就得到了 BP 算法中关于 $w_{hj}$ 的更新公式
$$
\tag{5.11} \label{eq_weights_hj}
\Delta w_{hj} = \eta g_j b_h .
$$
类似可得
$$
\begin{eqnarray}
\tag{5.12}
\Delta \theta_j &amp;amp;=&amp;amp; - \eta g_j, \
\tag{5.13}
\Delta v_{ih} &amp;amp;=&amp;amp; \eta e_h x_i, \
\tag{5.14} \label{eq_threshold_hidden}
\Delta \gamma_h &amp;amp;=&amp;amp; - \eta e_h, \
\end{eqnarray}
$$
其中
$$
\begin{eqnarray}
e_h
&amp;amp;=&amp;amp; - \frac{\partial E_k}{\partial b_h} \cdot \frac{\partial b_h}{\partial \alpha_h} \
&amp;amp;=&amp;amp; - \sum^l_{j=1} \frac{\partial E_k}{\partial \beta_j} \cdot \frac{\partial \beta_j}{\partial b_h} f&amp;rsquo;(\alpha_h - \gamma_h) \
&amp;amp;=&amp;amp; \sum^l_{j=1} w_{hj} g_j f&amp;rsquo;(\alpha_h - \gamma_h) \
\tag{5.15} \label{eq_hidden_gradient}
&amp;amp;=&amp;amp; b_h (1 - b_h) \sum^l_{j=1} w_{hj} g_j .
\end{eqnarray}
$$
学习率 $\eta \in (0, 1)$ 控制着算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛速度又会过慢。&lt;/p>
&lt;p>有时为了做精细调节，可令式(5.11)与(5.12)使用 $\eta_1$ ，式(5.13)与(5.14)使用 $\eta_2$ ，两者未必相等。&lt;/p>
&lt;h3 id="bp-算法的工作流程" >
&lt;div>
&lt;a href="#bp-%e7%ae%97%e6%b3%95%e7%9a%84%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b">
##
&lt;/a>
BP 算法的工作流程
&lt;/div>
&lt;/h3>
&lt;p>对每个训练样例，BP 算法执行以下操作：先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果；然后计算输出层的误差(第4-5行)，再将误差逆向传播至隐层神经元(第6行)，最后根据隐层神经元的误差来对连接权和阈值进行调整(第7行)。该迭代过程循环进行，直到达到某些停止条件为止。&lt;/p>
&lt;hr>
&lt;p>&lt;code>BP 算法工作流程&lt;/code>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>输入&lt;/strong>：训练集 $D = {(x_k, y_k)}^m_{k=1}$ ；&lt;/p>
&lt;p>​ 学习率 $\eta$ .&lt;/p>
&lt;p>&lt;strong>过程&lt;/strong>：&lt;/p>
&lt;p>1：在 $(0,1)$ 范围内随机初始化网络中所有连接权和阈值&lt;/p>
&lt;p>2：&lt;strong>repeat&lt;/strong>&lt;/p>
&lt;p>3: &lt;strong>for all&lt;/strong> $(x_k, y_k) \in D$ &lt;strong>do&lt;/strong>&lt;/p>
&lt;p>4: 根据当前参数和式($\ref{eq_y_hat}$)计算当前样本的输出 $\hat{y}_k$ ；&lt;/p>
&lt;p>5: 根据式($\ref{eq_output_gradient}$)计算输出层神经元的梯度项 $g_j$ ；&lt;/p>
&lt;p>6: 根据式($\ref{eq_hidden_gradient}$)计算隐层神经元的梯度项 $e_h$ ；&lt;/p>
&lt;p>7: 根据式($\ref{eq_weights_hj}$)-($\ref{eq_threshold_hidden}$)更新连接权 $w_{hj}, v_{ih}$ 与阈值 $\theta_j, \gamma_h$&lt;/p>
&lt;p>8: &lt;strong>end for&lt;/strong>&lt;/p>
&lt;p>9: &lt;strong>unitl&lt;/strong> 达到停止条件&lt;/p>
&lt;p>&lt;strong>输出&lt;/strong>：连接权与阈值确定的多层前馈神经网络&lt;/p>
&lt;hr>
&lt;p>&lt;strong>需要注意的是&lt;/strong>，BP 算法的目标是要最小化训练集 $D$ 上的累积误差
$$
\tag{5.16}
E = {1 \over m} \sum^m_{k=1} E_k ,
$$
但我们上面介绍的 “标准BP算法” 每次仅针对一个训练样例更新连接权和阈值，也就是说 &lt;code>BP 算法工作流程&lt;/code> 中算法的更新规则是基于单个的 $E_k$ 推导而得。如果类似地推导出基于累积误差最小化的更新规则，就得到了 “累积误差逆传播(accumulated error backpropagation)” 算法。累积BP算法与标准BP算法都很常用。一般来说，标准BP算法每次更新只针对单个样例，参数更新得非常频繁，而且对不同样例进行更新的效果可能出现 “抵消” 现象。因此，为了达到同样的累积误差极小点，标准BP算法往往需要进行更多次数的迭代。累积BP算法直接针对累积误差最小化，它在读取整个训练集 $D$ 一遍后才对参数进行更新，其参数更新频率低得多。但在很多任务中，累积误差下降到一定程度之后，进一步下降会非常缓慢，这时标准BP算法往往会更快获得较好的解，尤其是在训练集 $D$ 非常大时更为明显&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup> &lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup>。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>神经网络层级结构的一种，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。“前馈”并不意味着网络中信号不能向后传，而是指网络拓扑结构上不存在环或回路。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>The term back-propagation (BP) is often misunderstood as meaning the whole learning algorithm for multi layer neural networks. Actually, back-propagation refers only to the method for computing the gradient, while another algorithm, such SGD, is used to perform learning using this gradient.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>$\text{sigmoid}(x) = {1 \over 1 + e^{-x}}$ ，对数几率函数是典型的sigmoid函数，它把可能在较大范围内变化的输入值挤压到 $(0,1)$ 输出值范围内，因此有时也称为 “挤压函数(squashing function)”。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>激活函数也称为 “响应函数”，理想的激活函数是阶跃函数 $\text{sgn}(x)&lt;em>{x |x &amp;lt; 0} = 0; \text{sgn}(x)&lt;/em>{x |x \ge 0} =1$，它将输入值映射为输出值 &amp;ldquo;0&amp;rdquo; 或 “1”，显然 “1” 对应于神经元兴奋，“0” 对应于神经元兴奋。然而，阶跃函数具有不连续(在零点处)、不光滑等不太友好的性质，因此实际常用sigmoid函数作为激活函数。&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5">
&lt;p>感知机(Perceptron)由两层神经元组成，输入层接收外界输入信号后传递给输出层，输出层是 M-P 神经元，也称为 “阈值逻辑单元(threshold logic unit)”。感知机的学习规则非常简单，对训练样例 $(x, y)$ ，若当前感知机的输出为 $\hat{y}$ ，则感知机权重将这样调整：$w_i \leftarrow w_i + \Delta w_i$ ，其中 $\Delta w_i = \eta (y - \hat{y}) x_i$ ，其中 $\eta \in (0,1)$ 是学习率(learning rate)。可以看出，若感知机对训练样例 $(x, y)$ 预测正确，即 $\hat{y} = y$ ，则感知机不发生变化，否则将根据错误的程度进行权值调整。&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6">
&lt;p>这就是 “链式法则”。&amp;#160;&lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7">
&lt;p>标准BP算法和累积BP算法的区别类似于随机梯度下降(SGD)与标准梯度下降之间的区别。&amp;#160;&lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8">
&lt;p>感知机的参数更新规则和BP算法的参数更新规则式(5.11)-(5.14) 都是基于梯度下降。&amp;#160;&lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item></channel></rss>