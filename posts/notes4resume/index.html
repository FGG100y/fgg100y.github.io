<!doctype html><html lang=zh-cn data-theme><head><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><title>tech interview prepare (for my resume) - fgg blog</title>
<meta name=description content="简历中项目的技术要点"><link rel=icon type=image/x-icon href=https://fgg100y.github.io/favicon.ico><link rel=apple-touch-icon-precomposed href=https://fgg100y.github.io/favicon.png><link rel=stylesheet href=https://fgg100y.github.io/css/style.min.d1bfddb74ce95e21195c88c4dc9ddc29a7292837af9c174852caf9c3556f3987.css integrity="sha256-0b/dt0zpXiEZXIjE3J3cKacpKDevnBdIUsr5w1VvOYc="><link rel=stylesheet href=https://fgg100y.github.io/css/style.min.c4c04b3ef88e3d619ad4c7ee5e03048422bc55c4fefdc1f07657c1133670aa22.css integrity="sha256-xMBLPviOPWGa1MfuXgMEhCK8VcT+/cHwdlfBEzZwqiI="><link rel=stylesheet href=https://fgg100y.github.io/css/style.min.21c5d8fe0a79d623b0adc1ce4bd4f6dd2c05cd939c9aaaa966ba7186b1464f4d.css integrity="sha256-IcXY/gp51iOwrcHOS9T23SwFzZOcmqqpZrpxhrFGT00="><script src=https://fgg100y.github.io/js/script.min.08f04d96386c73c9bf4d160333f8f448c05a6e01c06770542ee0e013954ce930.js type=text/javascript integrity="sha256-CPBNljhsc8m/TRYDM/j0SMBabgHAZ3BULuDgE5VM6TA="></script></head><body><a class=skip-main href=#main>Skip to main content</a><div class=container><header class=common-header><div class=header-top><div class=header-top-left><h1 class="site-title noselect"><a href=/>fgg blog</a></h1><ul class=social-icons><li><a href=https://github.com/fgg100y title=Github rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-github"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></span></a></li></ul></div><div class=header-top-right></div></div><nav class=noselect><a href=https://fgg100y.github.io/ title>Home</a>
<a href=https://fgg100y.github.io/posts/ title>Posts</a></nav></header><main id=main tabindex=-1><article class="post h-entry"><div class=post-header><header><h1 class="p-name post-title">tech interview prepare (for my resume)</h1></header><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-04-27>2024-04-27</time></div><a class="post-hidden-url u-url" href=https://fgg100y.github.io/posts/notes4resume/>https://fgg100y.github.io/posts/notes4resume/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me></a><div class=post-taxonomies><ul class=post-tags><li><a href=https://fgg100y.github.io/tags/tech-interview/>#Tech Interview</a></li></ul></div></div></div><script>var toc=document.querySelector(".toc");toc&&toc.addEventListener("click",function(){event.target.tagName!=="A"&&(event.preventDefault(),this.open?(this.open=!1,this.classList.remove("expanded")):(this.open=!0,this.classList.add("expanded")))})</script><div class="content e-content"><h1 id=自我介绍><div><a href=#%e8%87%aa%e6%88%91%e4%bb%8b%e7%bb%8d>##
</a>自我介绍</div></h1><blockquote><p>在自我介绍时，确保你提到的项目和技能与你申请的职位紧密相关，这样可以更好地展示你的专业
能力和对职位的适应性。同时，保持自信和热情，让面试官感受到你对工作和团队的承诺。</p></blockquote><hr><p>尊敬的面试官，您好！</p><p>我叫范明华，拥有6年在机器学习领域的工作经验。我于2017年硕士毕业于中山大学，专业是生态学，
这为我在实验设计、统计分析以及数据挖掘方面打下了扎实的基础。在过去的6年中，我一直致力于
将机器学习技术应用于实际问题，并取得了一些的成果。</p><p>我在目前公司担任高级数据挖掘工程师，期间我主导了多个机器学习项目的开发和交付，包括时序预
测模型， 图像识别/目标检测模型，以及基于大数据挖掘的普通机器学习模型等，并预研NLP以及语
音识别方面的技术, 同时也取得了授权的发明专利、软件著作、地方标准等成果。在这些项目的实战
中，不仅提升了我的技术深度，也锻炼了代码管理和团队领导能力。</p><p>在技术层面，我比较擅长结合业务流程开展半监督学习，并且有丰富的实践经验（包括在普通机器学
习和NLP领域）。我熟悉整个机器学习项目的开发流程，从项目调研、数据预处理、特征工程到模型
训练和部署，我都有深入的理解和实践。</p><p>除了技术专长，我还是一个注重团队合作和务实负责的人。我相信，我的专业技能和丰富经验，能够为贵公司带来直接的价值。</p><p>我对贵公司在机器学习/大模型应用/自然语言处理方面等方面的工作非常感兴趣，并且我相信我的背景和技能可以为贵公司的发展做出贡献。
我期待能够加入贵公司，并与团队一起解决更多有趣的技术挑战。</p><p>感谢您给我这次面试的机会，我期待在接下来的讨论中分享更多我的经验和想法。谢谢！</p><hr><h1 id=project-01----nlp><div><a href=#project-01----nlp>##
</a>Project 01 &ndash; NLP</div></h1><h2 id=sklearn-randomforest-model><div><a href=#sklearn-randomforest-model>#
</a>sklearn randomforest model</div></h2><p>当谈到随机森林时，我们需要理解它的基础算法：决策树。随机森林是基于决策树的集成学习方法。所以，让我们首先来了解决策树的基本算法，然后再深入探讨随机森林。</p><h3 id=1-决策树算法><div><a href=#1-%e5%86%b3%e7%ad%96%e6%a0%91%e7%ae%97%e6%b3%95>##
</a>1. 决策树算法:</div></h3><h4 id=11-cart算法-classification-and-regression-trees><div><a href=#11-cart%e7%ae%97%e6%b3%95-classification-and-regression-trees>###
</a>1.1 CART算法 (Classification and Regression Trees):</div></h4><p>CART算法是一种用于构建分类和回归树的决策树算法。它通过对数据集递归地进行二分来构建决策树。具体步骤如下：</p><ol><li><p><strong>特征选择</strong>：对于分类问题，通常使用基尼指数（Gini index）或信息增益（Information Gain）来选择最佳的特征进行分裂；对于回归问题，通常使用平方误差来选择最佳的特征。</p></li><li><p><strong>节点分裂</strong>：根据选择的特征，将数据集分成两部分，使得每个子集的样本属于同一类别（对于分类问题）或具有相似的回归值（对于回归问题）。</p></li><li><p><strong>递归</strong>：对每个子集重复上述过程，直到满足停止条件，如达到最大深度、节点中样本数小于某个阈值或其他预定义条件。</p></li><li><p><strong>剪枝</strong>：为了避免过拟合，可以对生成的树进行剪枝，即移除一些节点来简化树的结构。</p></li></ol><h3 id=2-随机森林算法><div><a href=#2-%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97%e7%ae%97%e6%b3%95>##
</a>2. 随机森林算法:</div></h3><h4 id=21-构建随机森林><div><a href=#21-%e6%9e%84%e5%bb%ba%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97>###
</a>2.1 构建随机森林:</div></h4><p>随机森林是通过构建多棵决策树并将它们集成起来来完成的。具体步骤如下：</p><ol><li><p><strong>随机抽样</strong>：从原始训练集中随机选择一部分样本（有放回抽样）来构建每棵决策树的训练集。这样可以保证每棵树的训练集略有差异，增加了模型的多样性。</p></li><li><p><strong>随机特征选择</strong>：对于每棵树的每个节点，在选择分割特征时，随机选择一部分特征来进行评估。这样可以确保每棵树的分裂过程也有所差异。</p></li><li><p><strong>独立构建</strong>：每棵树都是独立构建的，没有任何关联。这意味着可以并行地构建多棵树，提高了训练效率。</p></li></ol><h4 id=22-集成决策树><div><a href=#22-%e9%9b%86%e6%88%90%e5%86%b3%e7%ad%96%e6%a0%91>###
</a>2.2 集成决策树:</div></h4><p>构建多棵决策树后，随机森林采用不同的方式来集成它们的预测结果：</p><ul><li><strong>分类任务</strong>：采用投票的方式，即每棵树投票选择最终的类别。</li><li><strong>回归任务</strong>：采用平均值的方式，即多棵树的预测结果取平均值。</li></ul><h3 id=总结><div><a href=#%e6%80%bb%e7%bb%93>##
</a>总结:</div></h3><p>随机森林是一种强大的机器学习方法，基于决策树的集成学习。通过利用决策树的随机性和集成策略，随机森林能够有效地应对分类和回归问题，并在许多实际应用中表现优异。</p><p>在 CART (Classification and Regression Trees) 算法中，节点的分裂依据是基于贪心算法。CART 算法通过贪心地选择每次分裂时能够最大程度减少不纯度（对于分类问题）或者最小化误差（对于回归问题）的特征来进行节点的分裂。这种贪心策略保证了在每个节点分裂时都选择了最优的特征来进行分裂。</p><h3 id=节点分裂的依据><div><a href=#%e8%8a%82%e7%82%b9%e5%88%86%e8%a3%82%e7%9a%84%e4%be%9d%e6%8d%ae>##
</a>节点分裂的依据：</div></h3><h4 id=对于分类问题><div><a href=#%e5%af%b9%e4%ba%8e%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98>###
</a>对于分类问题：</div></h4><p>在分类问题中，CART 算法通常使用以下两种方法作为节点分裂的依据：</p><ol><li><p><strong>基尼指数 (Gini index)</strong>：基尼指数衡量了从一个数据集中随机抽取两个样本，它们类别不一致的概率。具体地，对于一个节点 $t$，基尼指数可以计算为：</p><p>[ Gini(t) = 1 - \sum_{i=1}^{c} p(i|t)^2 ]</p><p>其中，$c$ 是类别的数量，$p(i|t)$ 是在节点 $t$ 中属于类别 $i$ 的样本的比例。选择能够最大程度降低基尼指数的特征来进行节点分裂。</p></li><li><p><strong>信息增益 (Information Gain)</strong>：信息增益衡量了在某个特征的条件下，将数据集分为不同类别后，带来的不确定性减少的程度。具体地，对于一个节点 $t$ 和一个特征 $A$，信息增益可以计算为：</p><p>[ IG(t, A) = H(t) - \sum_{v \in Values(A)} \frac{|t_v|}{|t|} \cdot H(t_v) ]</p><p>其中，$H(t)$ 是节点 $t$ 的熵，$Values(A)$ 是特征 $A$ 的取值集合，$t_v$ 是在特征 $A$ 上取值为 $v$ 的样本集合，$H(t_v)$ 是样本集合 $t_v$ 的熵。选择能够最大化信息增益的特征来进行节点分裂。</p></li></ol><h4 id=对于回归问题><div><a href=#%e5%af%b9%e4%ba%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98>###
</a>对于回归问题：</div></h4><p>在回归问题中，CART 算法通常使用平方误差 (Mean Squared Error, MSE) 作为节点分裂的依据。选择能够最小化节点分裂后样本的平方误差的特征来进行分裂。</p><h3 id=总结-1><div><a href=#%e6%80%bb%e7%bb%93-1>##
</a>总结：</div></h3><p>CART 算法在节点分裂时采用贪心算法，选择能够最大程度减少不纯度（分类问题）或者最小化误差（回归问题）的特征来进行分裂。这种贪心策略保证了每次分裂都选择了最优的特征，以构建出尽可能简单且有效的决策树。</p><p>当谈到基于决策树的集成学习时，除了随机森林，还有一种重要的方法是提升树（Boosting）。提升树是一种迭代的集成学习方法，通过串行地构建一系列决策树来逐步提升模型的性能。下面我会详细介绍提升树的原理和实现方式。</p><h3 id=提升树的原理><div><a href=#%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%8e%9f%e7%90%86>##
</a>提升树的原理：</div></h3><h4 id=1-基本思想><div><a href=#1-%e5%9f%ba%e6%9c%ac%e6%80%9d%e6%83%b3>###
</a>1. 基本思想：</div></h4><p>提升树的基本思想是通过训练一系列弱学习器（通常是决策树），然后将它们组合起来构成一个更强大的模型。每个弱学习器都专注于纠正之前模型的错误，因此在构建过程中会关注之前模型预测错误的样本。</p><h4 id=2-算法流程><div><a href=#2-%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b>###
</a>2. 算法流程：</div></h4><p>提升树的算法流程如下：</p><ol><li>初始化模型为一个常数值，通常为目标变量的均值（对于回归问题）或者是类别的先验概率（对于分类问题）。</li><li>迭代地训练决策树，每次训练都会生成一个新的弱学习器。在每次迭代中，算法会计算当前模型的残差（对于回归问题）或者梯度（对于分类问题），然后训练一个新的决策树来拟合这些残差或者梯度。</li><li>将新生成的决策树加到模型中，通常使用一个较小的学习率来缓解每棵树的影响。</li><li>重复迭代步骤2和步骤3，直到达到预先设定的迭代次数或者模型的性能达到某个阈值为止。</li></ol><h4 id=3-加法模型><div><a href=#3-%e5%8a%a0%e6%b3%95%e6%a8%a1%e5%9e%8b>###
</a>3. 加法模型：</div></h4><p>提升树的最终模型是一个加法模型，即多个弱学习器的加权求和。通过迭代训练，每个弱学习器都会对模型进行一定的修正，最终组合起来构成一个更强大的模型。</p><h3 id=实现><div><a href=#%e5%ae%9e%e7%8e%b0>##
</a>实现：</div></h3><p>提升树的实现通常采用梯度提升算法（Gradient Boosting），其中最常见的是梯度提升决策树（Gradient Boosting Decision Trees，GBDT）。</p><p>GBDT 算法的关键步骤包括计算残差或者梯度、训练决策树以拟合残差或者梯度、确定学习率等。GBDT 通过不断地迭代训练决策树来逐步优化模型，直到达到一定的迭代次数或者达到一定的性能指标。</p><h3 id=总结-2><div><a href=#%e6%80%bb%e7%bb%93-2>##
</a>总结：</div></h3><p>提升树是一种基于决策树的集成学习方法，通过迭代训练一系列决策树来逐步提升模型的性能。相较于随机森林，提升树通常会产生更加精确的预测，但需要更长的训练时间，并且对异常值和噪声数据更敏感。</p><h2 id=mlp-model><div><a href=#mlp-model>#
</a>MLP model</div></h2><p>MLP，即多层感知器（Multilayer Perceptron），是一种基本的人工神经网络模型。它由多层神经元组成，每一层都与下一层全连接。MLP是一种前馈神经网络，意味着信息只能从输入层向输出层传递，不会存在循环连接。</p><p>下面是MLP的一些基本原理：</p><ol><li><p><strong>神经元（Perceptron）</strong>：
在MLP中，每个神经元都是一个简单的计算单元。它接收来自前一层的输入信号，将这些信号加权求和，并通过激活函数产生输出。</p></li><li><p><strong>多层结构</strong>：
MLP由多个层组成，典型的MLP包括输入层、至少一个隐藏层和输出层。输入层接收原始数据，隐藏层对输入数据进行特征提取和转换，输出层生成最终的预测结果。</p></li><li><p><strong>权重和偏置</strong>：
在MLP中，每个连接都有一个相关联的权重，用于控制信号传递的强度和方向。此外，每个神经元还有一个偏置，用于调整神经元的激活阈值。</p></li><li><p><strong>激活函数</strong>：
在神经元中，激活函数决定了神经元输出的非线性关系。常用的激活函数包括Sigmoid、ReLU（Rectified Linear Unit）、tanh等，它们在不同情况下具有不同的优势。</p></li><li><p><strong>前向传播</strong>：
在MLP中，数据从输入层开始传播，经过一系列的加权求和和激活函数处理，一直传播到输出层，生成最终的预测结果。这个过程称为前向传播。</p></li><li><p><strong>反向传播</strong>：
反向传播是MLP中用于训练模型的关键步骤。它利用梯度下降算法，通过计算损失函数对每个参数（权重和偏置）的梯度，并沿着梯度的反方向更新参数，从而最小化损失函数。</p></li><li><p><strong>损失函数</strong>：
损失函数用于衡量模型预测结果与真实标签之间的差异。常见的损失函数包括均方误差（MSE）、交叉熵等，选择适当的损失函数取决于具体的问题类型。</p></li><li><p><strong>优化算法</strong>：
在反向传播过程中，需要选择合适的优化算法来更新模型参数。常用的优化算法包括随机梯度下降（SGD）、Adam、RMSprop等。</p></li></ol><p>总的来说，MLP通过多层的非线性变换来学习输入数据的复杂特征表示，通过反向传播算法不断调整模型参数以最小化损失函数，从而实现对数据的分类、回归等任务。</p><p>反向传播算法是用于训练神经网络的关键算法之一，它通过计算损失函数对每个参数的梯度来更新模型参数，从而使得模型能够逐渐优化以达到最佳性能。下面我将介绍反向传播算法的计算过程，以及链式法则如何用来计算梯度。</p><h3 id=反向传播算法的计算过程><div><a href=#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e7%ae%97%e6%b3%95%e7%9a%84%e8%ae%a1%e7%ae%97%e8%bf%87%e7%a8%8b>##
</a>反向传播算法的计算过程：</div></h3><ol><li><p><strong>前向传播</strong>：
首先，通过前向传播计算模型的输出。将输入数据输入到网络中，按照网络结构逐层计算每个神经元的输出，并将输出传递给下一层，直至生成最终的预测结果。</p></li><li><p><strong>计算损失</strong>：
使用损失函数计算模型的预测值与真实标签之间的差异，得到损失值。</p></li><li><p><strong>反向传播</strong>：
从输出层开始，利用链式法则逐层计算每个参数的梯度。梯度表示了损失函数对参数的变化率，它告诉我们如何调整参数才能使损失函数最小化。</p></li><li><p><strong>参数更新</strong>：
根据计算得到的梯度，利用优化算法（如随机梯度下降）来更新模型参数。通常，参数更新的步长（学习率）是一个超参数，需要根据实际情况进行调整。</p></li></ol><h3 id=链式法则如何用来计算梯度><div><a href=#%e9%93%be%e5%bc%8f%e6%b3%95%e5%88%99%e5%a6%82%e4%bd%95%e7%94%a8%e6%9d%a5%e8%ae%a1%e7%ae%97%e6%a2%af%e5%ba%a6>##
</a>链式法则如何用来计算梯度：</div></h3><p>链式法则是微积分中的基本原理，用于计算复合函数的导数。在反向传播算法中，我们利用链式法则来计算损失函数对模型参数的梯度，从而实现参数的更新。</p><p>假设有一个复合函数 (z = f(g(x)))，其中 (x) 是输入，(g(x)) 是一个函数，(f(x)) 是另一个函数。根据链式法则，(z) 对 (x) 的导数可以表示为：</p><p>[
\frac{dz}{dx} = \frac{dz}{dg} \cdot \frac{dg}{dx}
]</p><p>在神经网络中，我们可以将损失函数 (L) 视为 (z)，模型的参数视为 (x)，前向传播过程中的每一层输出视为 (g)，激活函数视为 (f)。利用链式法则，我们可以逐层计算损失函数对每个参数的梯度，然后根据优化算法更新参数，使得损失函数逐渐减小。</p><p>总的来说，反向传播算法通过利用链式法则计算损失函数对参数的梯度，实现了高效的神经网络训练过程，使得模型能够自动学习复杂的数据表示。</p><p>交叉熵（Cross-Entropy）是在分类任务中常用的损失函数，特别是在多分类任务中。它的原理和为什么有用可以通过以下几点进行详细解释：</p><h3 id=1-损失函数的作用><div><a href=#1-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e7%9a%84%e4%bd%9c%e7%94%a8>##
</a>1. 损失函数的作用：</div></h3><p>损失函数用于衡量模型预测结果与真实标签之间的差异。优化模型的目标是最小化损失函数，使得模型能够产生与真实标签相匹配的预测结果。</p><h3 id=2-交叉熵的定义><div><a href=#2-%e4%ba%a4%e5%8f%89%e7%86%b5%e7%9a%84%e5%ae%9a%e4%b9%89>##
</a>2. 交叉熵的定义：</div></h3><p>对于多分类任务，交叉熵损失函数的数学定义如下：</p><p>[
\text{Cross-Entropy}(y, \hat{y}) = -\sum_{i=1}^{N} y_i \log(\hat{y}_i)
]</p><p>其中，(y) 是真实标签的概率分布（通常是一个one-hot编码的向量），(\hat{y}) 是模型预测的概率分布，(N) 是类别的数量。该损失函数用于衡量真实标签与模型预测结果之间的差异。</p><h3 id=3-原理解释><div><a href=#3-%e5%8e%9f%e7%90%86%e8%a7%a3%e9%87%8a>##
</a>3. 原理解释：</div></h3><ul><li><p><strong>信息论角度</strong>：
交叉熵损失函数源自信息论中的信息熵概念。信息熵用于衡量一个随机变量的不确定性，而交叉熵则衡量两个概率分布之间的差异。当真实标签和模型预测的分布越接近时，交叉熵越小。</p></li><li><p><strong>梯度下降优化</strong>：
交叉熵损失函数在梯度下降优化过程中具有良好的性质。它的导数相对简单，计算起来更加高效，而且当模型的预测结果与真实标签的差异较大时，梯度也会变得更大，从而加速模型参数的更新。</p></li><li><p><strong>适用于多分类任务</strong>：
交叉熵损失函数特别适用于多分类任务，因为它能够有效地衡量多个类别之间的差异，并且在模型优化过程中能够引导模型更快地收敛到最优解。</p></li></ul><h3 id=4-为什么有用><div><a href=#4-%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e7%94%a8>##
</a>4. 为什么有用：</div></h3><ul><li><p><strong>梯度信息</strong>：
交叉熵损失函数提供了丰富的梯度信息，使得模型可以更快地学习到正确的预测结果。</p></li><li><p><strong>适用性广泛</strong>：
交叉熵损失函数适用于多分类任务，并且在实际应用中表现良好，因此成为了许多分类任务的首选损失函数。</p></li><li><p><strong>与概率相关</strong>：
交叉熵损失函数直接与概率分布相关，更符合任务的本质，能够更好地指导模型学习数据的分布情况。</p></li></ul><p>总的来说，交叉熵损失函数通过衡量模型预测结果与真实标签之间的差异，提供了有效的优化目标，并在梯度下降优化过程中起到重要作用，因此被广泛应用于分类任务中。</p><h2 id=bertroberta-model><div><a href=#bertroberta-model>#
</a>BERT/RoBERTa model</div></h2><p>BERT:</p><pre><code>BERT是一种双向的（Bidirectional）模型，这意味着它能够同时考虑到一个单词左边和右边的上下文信息。这使得BERT在理解句子语境时比之前的模型更为强大。
BERT模型的预训练过程是通过掩盖输入文本中的一部分词汇（Masked Language Model，MLM）和预测句子是否连续（Next Sentence Prediction，NSP）来完成的。
BERT以“transformer”为基础，这是一种自注意力（self-attention）机制的神经网络结构，它能够在考虑到输入序列的所有位置之间建立关联，从而更好地理解上下文。
</code></pre><p>RoBERTa是Facebook AI提出的一种改进的预训练自然语言处理（NLP）模型，它在很大程度上建立在BERT的基础上，但通过一系列的改进，使其在多个NLP任务上表现更优秀。</p><p>RoBERTa的主要改进包括：</p><pre><code>动态掩码策略（Dynamic Masking）：RoBERTa在预训练时采用了动态掩码策略，即在每个训练迭代中对输入句子进行随机化处理，而不是固定地在句子中随机掩码。这使得模型更好地学习句子中的上下文信息。

更长的训练时间和更大的批次大小：RoBERTa使用了更大的批次大小和更长的训练时间，以提高模型的泛化能力和性能。

去除NSP（Next Sentence Prediction）任务：RoBERTa不再使用BERT中的NSP任务，而是专注于MLM（Masked Language Model）任务，这使得模型更好地理解输入文本。

更多的训练数据：RoBERTa使用了更多的文本数据来进行预训练，这有助于提高模型的泛化能力。
</code></pre><p>总的来说，RoBERTa是对BERT模型的一种优化和改进，它在多个NLP任务上都取得了比BERT更好的性能。</p><h2 id=faiss-indexivfpq><div><a href=#faiss-indexivfpq>#
</a>FAISS (indexIVFPQ)</div></h2><h2 id=bertopic><div><a href=#bertopic>#
</a>BERTopic</div></h2><ul><li>clustering</li></ul><ul><li>UMAP/PCA</li></ul><ul><li>c-TF-IDF</li></ul><p>BERTopic 是一个基于BERT（Bidirectional Encoder Representations from Transformers）的自然语言处理工具，用于主题建模任务。BERTopic结合了BERT的强大表示学习能力和主题建模的思想，能够在大规模文本数据上快速、准确地提取主题信息。</p><p>BERTopic的工作原理如下：</p><ol><li><p><strong>文本向量化</strong>：首先，BERTopic使用预训练的BERT模型来将输入文本转换为高维向量表示。这些向量捕捉了输入文本的语义信息，并且通常能够更好地反映文本之间的语义相似度。</p></li><li><p><strong>主题发现</strong>：接下来，BERTopic使用聚类算法（例如DBSCAN或HDBSCAN）对文本向量进行聚类，以发现潜在的主题。聚类算法将文本向量分组为具有相似主题的簇。</p></li><li><p><strong>主题关键词提取</strong>：对于每个发现的主题簇，BERTopic还可以提取关键词来描述该主题。这些关键词通常是簇中最具代表性的词语，帮助用户理解主题的内容。</p></li><li><p><strong>主题可视化</strong>：最后，BERTopic可以将发现的主题可视化，使用户能够直观地了解文本数据中的主题结构。通常，可视化结果会以簇的形式展示，每个簇代表一个主题，簇内的文本则表示该主题的具体内容。</p></li></ol><p>关于最佳实践，以下是一些建议：</p><ol><li><p><strong>调整模型参数</strong>：根据任务需求和数据特点，调整BERTopic的参数，例如聚类算法的参数、主题数量等，以获得更好的结果。</p></li><li><p><strong>预处理文本数据</strong>：在使用BERTopic之前，对文本数据进行适当的预处理是很重要的，例如去除停用词、进行词干化或词形还原等，以减少噪音对主题建模的影响。</p></li><li><p><strong>理解主题结果</strong>：对于每个发现的主题，仔细查看主题簇中的文本，并考虑它们之间的相似性和共性，以确保主题的合理性和可解释性。</p></li><li><p><strong>与领域知识结合</strong>：在解释和利用主题结果时，结合领域知识会更有帮助。通过深入了解领域专业术语和相关概念，可以更准确地理解和解释主题的含义。</p></li></ol><p>通过合理地使用BERTopic工具，并结合适当的数据预处理和模型调优，可以有效地完成基于自然语言的主题建模任务。</p><p>当然，让我更详细地解释一下这些技术。</p><ol><li><p><strong>UMAP（Uniform Manifold Approximation and Projection）</strong>:</p><ul><li>UMAP是一种非线性降维算法，旨在将高维数据映射到低维空间以进行可视化或进一步分析。</li><li>UMAP相对于传统的降维技术（如t-SNE）具有更好的可扩展性和保持全局数据结构的能力。它能够保持更多的局部结构，同时在大规模数据上的计算效率更高。</li><li>在BERTopic中，UMAP常用于对BERT向量化的文本数据进行降维，以便进行更好的可视化或进一步的分析。降维后的数据可以更容易地被人类理解和解释。</li></ul></li><li><p><strong>c-TF-IDF（Class-based TF-IDF）</strong>:</p><ul><li>c-TF-IDF是一种改进的TF-IDF（Term Frequency-Inverse Document Frequency）方法，用于从文本数据中提取关键词。</li><li>与传统的TF-IDF相比，c-TF-IDF考虑了单词在不同主题中的重要性，而不仅仅是在整个文本集合中的重要性。这使得c-TF-IDF能够更好地捕捉文本中的主题相关信息。</li><li>在BERTopic中，c-TF-IDF常用于从每个发现的主题簇中提取关键词，以描述该主题的内容。这些关键词通常是簇中最具代表性的词语，帮助用户理解主题的含义和内容。</li></ul></li><li><p><strong>HDBSCAN（Hierarchical Density-Based Spatial Clustering of Applications with Noise）</strong>:</p><ul><li>HDBSCAN是一种密度聚类算法，旨在发现数据中的高密度区域，并将它们组合成簇。</li><li>与传统的基于距离的聚类算法（如K均值）不同，HDBSCAN不需要预先指定簇的数量，因此更适用于发现具有不同大小和形状的簇的数据。</li><li>在BERTopic中，HDBSCAN通常与UMAP一起使用，用于对BERT向量化的文本数据进行聚类。HDBSCAN能够识别出具有不同主题的文本簇，从而帮助用户发现文本数据中的主题结构。</li></ul></li></ol><p>综上所述，UMAP用于将高维文本向量降维到低维空间，以便于可视化和分析；c-TF-IDF用于从每个主题簇中提取关键词以描述主题内容；HDBSCAN用于发现文本数据中的潜在主题簇。这些技术的结合使得BERTopic能够有效地进行自然语言主题建模，并从文本数据中提取有意义的主题信息。</p><h1 id=project-02----ml><div><a href=#project-02----ml>##
</a>Project 02 &ndash; ML</div></h1><h2 id=self-training--gausianmixtruemodels><div><a href=#self-training--gausianmixtruemodels>#
</a>self-training & GausianMixtrueModels</div></h2><p>半监督学习是一种机器学习方法，它利用有标签和无标签的数据来进行模型训练。相比于只使用有标签数据进行训练，半监督学习可以利用更多的无标签数据，从而提高模型的性能。</p><p>self-training（自训练）是半监督学习中的一种常见技术，其基本思想是利用已经训练好的模型对无标签数据进行预测，然后将置信度较高的预测结果作为伪标签，将这些伪标签的数据与有标签数据一起重新训练模型。</p><p>具体来说，self-training的步骤如下：</p><ol><li><p>利用有标签数据训练一个初始模型。</p></li><li><p>使用该模型对无标签数据进行预测，并选取置信度较高的预测结果作为伪标签。</p></li><li><p>将伪标签的数据与原有的有标签数据合并，重新训练模型。</p></li><li><p>重复步骤2和步骤3，直到满足停止条件（比如达到最大迭代次数、模型性能不再提升等）。</p></li></ol><p>self-training的关键在于如何选择置信度较高的预测结果作为伪标签。一般来说，可以通过设置一个阈值来筛选置信度较高的预测结果，也可以使用模型的输出概率来作为置信度的度量。</p><p>使用self-training技术可以帮助扩充样本，提高模型的泛化能力，特别是在标记数据有限的情况下。但需要注意的是，自训练过程中可能会引入噪声，因此需要仔细调节参数和监控模型性能，以避免过拟合和性能下降的问题。</p><p>如果聚类簇内的标签并不一致，而且类别数目较为相同，这种情况可能会导致一些混乱，因为无法简单地选择一个代表性的标签来为整个聚类簇的样本打标签。在这种情况下，可以考虑以下几种处理方式：</p><ol><li><p><strong>投票机制</strong>：</p><ul><li>对于每个聚类簇，可以采用投票机制来选择标签。即，统计聚类簇中样本的真实标签或者已有的伪标签，选择出现频率最高的标签作为整个聚类簇的标签。</li><li>如果有多个标签出现频率相同，可以随机选择其中一个或者采用一些其他的策略来解决冲突。</li></ul></li><li><p><strong>标签融合</strong>：</p><ul><li>对于聚类簇内的样本，可以将其真实标签或者已有的伪标签进行融合。例如，可以计算聚类簇中每个类别的权重，然后根据权重对多个标签进行加权平均，得到一个综合的标签。</li><li>这种方法可以在一定程度上解决标签冲突的问题，但需要谨慎设计权重计算的方法，以避免给不太准确的标签过多的权重。</li></ul></li><li><p><strong>进一步分析</strong>：</p><ul><li>对于那些标签冲突较为严重的聚类簇，可以进一步分析其样本特征或者数据分布，尝试找到更合适的标签选择策略。</li><li>可以考虑使用一些数据挖掘技术或者领域知识来帮助解决这个问题。</li></ul></li><li><p><strong>半监督学习方法</strong>：</p><ul><li>除了高斯混合聚类，还可以尝试其他半监督学习方法，如图半监督学习（Graph-based Semi-Supervised Learning）、标签传播算法（Label Propagation）、自训练（Self-training）等。</li><li>这些方法可能会更有效地处理标签冲突的问题，因为它们可以更好地利用数据之间的相似性和关联性。</li></ul></li></ol><p>在实际应用中，可以根据具体情况选择适合的方法来处理标签冲突问题，同时需要注意监控模型的性能和效果，及时调整和优化算法。</p><h2 id=xgboost><div><a href=#xgboost>#
</a>XGBoost</div></h2><p>XGBoost，全称为“eXtreme Gradient Boosting”，是一种高效的集成学习算法，属于梯度提升树（Gradient Boosting Tree）的一种实现。它在机器学习竞赛中非常流行，因为它能够在各种类型的数据集上取得优秀的性能，并且相对于其他算法，它通常更容易调整参数以获得更好的性能。</p><p>以下是 XGBoost 模型的一些关键特点和优势：</p><ol><li><p><strong>集成学习</strong>：XGBoost 是一种集成学习算法，它通过组合多个弱学习器（通常是决策树）来构建一个强大的模型。每个决策树都是根据前一个树的错误进行训练，以逐步减少模型的残差。</p></li><li><p><strong>梯度提升算法</strong>：XGBoost 使用梯度提升算法来训练模型。该算法通过最小化损失函数的梯度来优化模型，从而使模型在每一步都更加贴近真实值。</p></li><li><p><strong>正则化</strong>：XGBoost 提供了对模型进行正则化的选项，包括 L1 和 L2 正则化，以及控制树的复杂度的参数。这有助于减少过拟合，提高模型的泛化能力。</p></li><li><p><strong>支持并行化</strong>：XGBoost 可以有效地利用并行计算资源进行训练，因此在大规模数据集上也能够快速地训练模型。</p></li><li><p><strong>特征重要性评估</strong>：XGBoost 可以计算特征的重要性，从而帮助用户了解哪些特征对模型的预测最为关键。</p></li><li><p><strong>灵活性</strong>：XGBoost 可以用于分类问题、回归问题以及排序问题，并且可以在不同类型的数据集上进行应用。</p></li></ol><p>总的来说，XGBoost 是一种强大且灵活的机器学习算法，适用于各种类型的问题，并且在实践中表现出色。</p><p>梯度提升算法（Gradient Boosting Algorithm）是一种集成学习方法，通过将多个弱学习器（通常是决策树）串联起来，逐步减少模型的残差来构建一个强大的预测模型。梯度提升算法通过梯度下降的思想，不断优化模型以最小化损失函数。</p><p>下面是梯度提升算法的基本步骤：</p><ol><li><p><strong>初始化模型</strong>：梯度提升算法通常从一个简单的模型开始，例如用一个常数来拟合数据的平均值。</p></li><li><p><strong>迭代优化</strong>：接下来，算法迭代地执行以下步骤：</p><ul><li>计算残差：使用当前模型对训练数据进行预测，并计算实际值与预测值之间的残差。</li><li>拟合残差：构建一个新的弱学习器（如决策树），以拟合残差。这意味着新的学习器会尝试纠正上一个模型的错误。</li><li>更新模型：将新的学习器与前面的模型组合起来，形成一个更强大的模型。</li></ul></li><li><p><strong>停止条件</strong>：当达到预先设定的迭代次数，或者当模型的性能满足某个特定的标准时，停止迭代。</p></li></ol><p>与梯度下降算法的关系在于，梯度提升算法也利用了梯度的信息来优化模型。但两者之间的关键区别在于优化的对象和优化方向。在梯度下降算法中，优化的对象是损失函数本身，而优化的方向是沿着损失函数梯度的反方向。而在梯度提升算法中，优化的对象是损失函数的残差，优化的方向是使残差最小化的方向。</p><p>总的来说，梯度提升算法是一种强大的集成学习方法，通过不断迭代优化模型以减少残差，从而构建一个强大的预测模型。它利用了梯度信息来指导优化过程，但与梯度下降算法相比，它的优化目标和优化方向有所不同。</p><h2 id=onnx-dockerpodman-and-restful-api><div><a href=#onnx-dockerpodman-and-restful-api>#
</a>ONNX, Docker/Podman, and restful-api</div></h2><p>当你希望使用 Docker 来部署服务，并且构建 Flask RESTful API 来提供对 ONNX 模型的推理服务时，你可以按照以下步骤进行：</p><h3 id=1-准备-flask-restful-api-代码><div><a href=#1-%e5%87%86%e5%a4%87-flask-restful-api-%e4%bb%a3%e7%a0%81>##
</a>1. 准备 Flask RESTful API 代码</div></h3><p>你需要创建一个 Flask 应用程序，编写代码以加载 ONNX 模型并提供 RESTful API 来进行推理。</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> flask <span style=color:#ff6ac1>import</span> Flask, request
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> flask_restful <span style=color:#ff6ac1>import</span> Api, Resource
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> onnxruntime
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>app <span style=color:#ff6ac1>=</span> Flask(__name__)
</span></span><span style=display:flex><span>api <span style=color:#ff6ac1>=</span> Api(app)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>class</span> <span style=color:#f3f99d>ModelInference</span>(Resource):
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>def</span> __init__(self):
</span></span><span style=display:flex><span>        <span style=color:#ff5c57>super</span>(ModelInference, self)<span style=color:#ff6ac1>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#ff6ac1>.</span>session <span style=color:#ff6ac1>=</span> onnxruntime<span style=color:#ff6ac1>.</span>InferenceSession(<span style=color:#5af78e>&#34;your_model.onnx&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>post</span>(self):
</span></span><span style=display:flex><span>        data <span style=color:#ff6ac1>=</span> request<span style=color:#ff6ac1>.</span>json
</span></span><span style=display:flex><span>        input_data <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>array(data[<span style=color:#5af78e>&#34;input&#34;</span>])<span style=color:#ff6ac1>.</span>astype(np<span style=color:#ff6ac1>.</span>float32)
</span></span><span style=display:flex><span>        output <span style=color:#ff6ac1>=</span> self<span style=color:#ff6ac1>.</span>session<span style=color:#ff6ac1>.</span>run([], {<span style=color:#5af78e>&#34;input&#34;</span>: input_data})
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> {<span style=color:#5af78e>&#34;output&#34;</span>: output<span style=color:#ff6ac1>.</span>tolist()}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>api<span style=color:#ff6ac1>.</span>add_resource(ModelInference, <span style=color:#5af78e>&#34;/predict&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>if</span> __name__ <span style=color:#ff6ac1>==</span> <span style=color:#5af78e>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    app<span style=color:#ff6ac1>.</span>run(debug<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>True</span>, host<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;0.0.0.0&#34;</span>)
</span></span></code></pre></div><h3 id=2-创建-dockerfile><div><a href=#2-%e5%88%9b%e5%bb%ba-dockerfile>##
</a>2. 创建 Dockerfile</div></h3><p>创建一个 Dockerfile 来构建 Docker 镜像。</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Dockerfile data-lang=Dockerfile><span style=display:flex><span><span style=color:#ff6ac1>FROM</span><span style=color:#5af78e> python:3.9-slim</span><span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57></span><span style=color:#ff6ac1>WORKDIR</span><span style=color:#5af78e> /app</span><span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57></span><span style=color:#ff6ac1>COPY</span> requirements.txt .<span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57></span><span style=color:#ff6ac1>RUN</span> pip install --no-cache-dir -r requirements.txt<span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57></span><span style=color:#ff6ac1>COPY</span> . .<span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57>
</span></span></span><span style=display:flex><span><span style=color:#ff5c57></span><span style=color:#ff6ac1>CMD</span> [ <span style=color:#5af78e>&#34;python&#34;</span>, <span style=color:#5af78e>&#34;app.py&#34;</span> ]<span style=color:#ff5c57>
</span></span></span></code></pre></div><h3 id=3-构建-docker-镜像><div><a href=#3-%e6%9e%84%e5%bb%ba-docker-%e9%95%9c%e5%83%8f>##
</a>3. 构建 Docker 镜像</div></h3><p>在包含 Dockerfile 的目录下执行以下命令来构建 Docker 镜像。</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker build -t your_image_name .
</span></span></code></pre></div><h3 id=4-运行-docker-容器><div><a href=#4-%e8%bf%90%e8%a1%8c-docker-%e5%ae%b9%e5%99%a8>##
</a>4. 运行 Docker 容器</div></h3><p>使用以下命令来运行你的 Docker 容器。</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker run -p 5000:5000 your_image_name
</span></span></code></pre></div><h3 id=5-测试-api><div><a href=#5-%e6%b5%8b%e8%af%95-api>##
</a>5. 测试 API</div></h3><p>使用任何 HTTP 客户端工具或 Python 应用程序来测试你的 API。</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>import</span> requests
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=color:#ff6ac1>=</span> {<span style=color:#5af78e>&#34;input&#34;</span>: [<span style=color:#ff9f43>1.0</span>, <span style=color:#ff9f43>2.0</span>, <span style=color:#ff9f43>3.0</span>]}  <span style=color:#78787e># 示例输入数据</span>
</span></span><span style=display:flex><span>response <span style=color:#ff6ac1>=</span> requests<span style=color:#ff6ac1>.</span>post(<span style=color:#5af78e>&#34;http://localhost:5000/predict&#34;</span>, json<span style=color:#ff6ac1>=</span>data)
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(response<span style=color:#ff6ac1>.</span>json())
</span></span></code></pre></div><h3 id=总结-3><div><a href=#%e6%80%bb%e7%bb%93-3>##
</a>总结</div></h3><p>这就是一个简单的部署流程。你可以根据你的具体需求进行调整和扩展，比如添加模型预处理、后处理逻辑，以及对 API 的身份验证和访问控制等功能。</p><h1 id=project-03----cv><div><a href=#project-03----cv>##
</a>Project 03 &ndash; CV</div></h1><h2 id=yolo-model><div><a href=#yolo-model>#
</a>YOLO model</div></h2><p>好的，让我来详细介绍一下YOLO（You Only Look Once）目标检测模型的原理和实现。</p><h3 id=1-yolo-模型的原理><div><a href=#1-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%8e%9f%e7%90%86>##
</a>1. YOLO 模型的原理：</div></h3><h4 id=11-单阶段检测><div><a href=#11-%e5%8d%95%e9%98%b6%e6%ae%b5%e6%a3%80%e6%b5%8b>###
</a>1.1 单阶段检测：</div></h4><p>YOLO 是一种单阶段目标检测模型，与传统的两阶段检测方法（如Faster R-CNN）不同，它将目标检测任务视为一个端到端的回归问题，直接从图像中预测目标的位置和类别。</p><h4 id=12-网络结构><div><a href=#12-%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84>###
</a>1.2 网络结构：</div></h4><p>YOLO 模型主要由卷积神经网络组成，通常采用类似于Darknet的深层卷积神经网络作为特征提取器。</p><h4 id=13-网络输出><div><a href=#13-%e7%bd%91%e7%bb%9c%e8%be%93%e5%87%ba>###
</a>1.3 网络输出：</div></h4><p>YOLO 将图像划分为固定大小的网格，并为每个网格预测多个边界框和对应的类别概率。每个边界框由五个坐标值和类别概率组成：$(x, y, w, h, p)$，其中 $(x, y)$ 是边界框的中心坐标，$(w, h)$ 是边界框的宽度和高度，$p$ 是边界框包含目标的置信度。</p><h4 id=14-损失函数><div><a href=#14-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0>###
</a>1.4 损失函数：</div></h4><p>YOLO 模型使用组合损失函数来同时优化边界框位置的准确性和类别的预测精度。该损失函数包括位置误差、置信度误差和类别误差。</p><h3 id=2-yolo-模型的实现><div><a href=#2-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%ae%9e%e7%8e%b0>##
</a>2. YOLO 模型的实现：</div></h3><h4 id=21-训练阶段><div><a href=#21-%e8%ae%ad%e7%bb%83%e9%98%b6%e6%ae%b5>###
</a>2.1 训练阶段：</div></h4><ul><li><strong>数据准备</strong>：收集和标记训练数据集，包括图像和对应的目标边界框。</li><li><strong>网络结构</strong>：选择适当的网络结构，通常使用预训练的Darknet网络或其变种。</li><li><strong>损失函数</strong>：定义和实现组合损失函数，用于优化网络参数。</li><li><strong>训练过程</strong>：使用训练数据集对模型进行训练，通过反向传播算法更新网络参数，以最小化损失函数。</li></ul><h4 id=22-推理阶段><div><a href=#22-%e6%8e%a8%e7%90%86%e9%98%b6%e6%ae%b5>###
</a>2.2 推理阶段：</div></h4><ul><li><strong>前向传播</strong>：将待检测的图像输入到训练好的模型中，通过前向传播算法获取每个边界框的预测结果。</li><li><strong>后处理</strong>：对网络输出进行后处理，包括非极大值抑制（NMS）和阈值筛选，以去除重叠的边界框和低置信度的边界框。</li><li><strong>目标框绘制</strong>：根据最终的边界框结果，将目标框绘制在原始图像上，并标记类别。</li></ul><h3 id=3-yolo-模型的优势><div><a href=#3-yolo-%e6%a8%a1%e5%9e%8b%e7%9a%84%e4%bc%98%e5%8a%bf>##
</a>3. YOLO 模型的优势：</div></h3><ul><li><strong>速度快</strong>：YOLO 是一种高效的目标检测模型，能够实时处理图像和视频流。</li><li><strong>端到端</strong>：YOLO 将目标检测视为一个端到端的回归问题，简化了检测流程。</li><li><strong>全局信息</strong>：YOLO 在整个图像上进行检测，能够同时考虑图像中的全局信息，从而更好地理解场景。</li></ul><h3 id=4-总结><div><a href=#4-%e6%80%bb%e7%bb%93>##
</a>4. 总结：</div></h3><p>YOLO 是一种高效的单阶段目标检测模型，通过将目标检测任务转化为回归问题，并结合有效的网络结构和损失函数，实现了在保持高准确率的同时实时进行目标检测的能力。</p><p>&ldquo;锚定点&rdquo;（Anchor Boxes）是YOLO模型中的一个重要概念，它用于解决目标检测中不同目标尺寸和比例的问题。在YOLO中，每个网格单元都负责预测一组固定数量和固定大小的边界框（即锚定点），以便检测不同尺寸和比例的目标。</p><h3 id=1-锚定点的概念><div><a href=#1-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%a6%82%e5%bf%b5>##
</a>1. 锚定点的概念：</div></h3><h4 id=11-问题><div><a href=#11-%e9%97%ae%e9%a2%98>###
</a>1.1 问题：</div></h4><p>传统的目标检测算法通常会将不同尺寸和比例的目标分配给不同的网络层来处理，这种方法不够灵活，无法很好地适应多样化的目标。</p><h4 id=12-解决方法><div><a href=#12-%e8%a7%a3%e5%86%b3%e6%96%b9%e6%b3%95>###
</a>1.2 解决方法：</div></h4><p>YOLO使用锚定点的思想，将不同尺寸和比例的目标统一分配给每个网格单元，并在每个网格单元中预测固定数量的边界框。这样可以增加模型的灵活性，使其能够检测不同尺寸和比例的目标。</p><h3 id=2-锚定点的思想><div><a href=#2-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%80%9d%e6%83%b3>##
</a>2. 锚定点的思想：</div></h3><h4 id=21-预定义大小和比例><div><a href=#21-%e9%a2%84%e5%ae%9a%e4%b9%89%e5%a4%a7%e5%b0%8f%e5%92%8c%e6%af%94%e4%be%8b>###
</a>2.1 预定义大小和比例：</div></h4><p>在YOLO中，锚定点是一组预定义的大小和比例的边界框。这些边界框通常是在训练数据集上通过聚类等方法得到的，以确保涵盖了大部分目标的大小和比例。</p><h4 id=22-单元格内多个边界框><div><a href=#22-%e5%8d%95%e5%85%83%e6%a0%bc%e5%86%85%e5%a4%9a%e4%b8%aa%e8%be%b9%e7%95%8c%e6%a1%86>###
</a>2.2 单元格内多个边界框：</div></h4><p>对于每个网格单元，YOLO模型预测固定数量的边界框，每个边界框的大小和比例与预定义的锚定点相对应。这样，每个网格单元可以同时检测多个不同尺寸和比例的目标。</p><h3 id=3-锚定点的技术实现><div><a href=#3-%e9%94%9a%e5%ae%9a%e7%82%b9%e7%9a%84%e6%8a%80%e6%9c%af%e5%ae%9e%e7%8e%b0>##
</a>3. 锚定点的技术实现：</div></h3><h4 id=31-预训练锚定点><div><a href=#31-%e9%a2%84%e8%ae%ad%e7%bb%83%e9%94%9a%e5%ae%9a%e7%82%b9>###
</a>3.1 预训练锚定点：</div></h4><p>在训练之前，通常会通过对训练数据集中的目标边界框进行聚类或者手动选择，来确定一组锚定点的大小和比例。</p><h4 id=32-模型预测><div><a href=#32-%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b>###
</a>3.2 模型预测：</div></h4><p>在模型推理阶段，每个网格单元通过回归预测固定数量的边界框，每个边界框的尺寸和比例由对应的锚定点确定。</p><h4 id=33-边界框调整><div><a href=#33-%e8%be%b9%e7%95%8c%e6%a1%86%e8%b0%83%e6%95%b4>###
</a>3.3 边界框调整：</div></h4><p>模型预测的边界框通常是相对于网格单元的偏移量和尺寸偏差，需要根据锚定点进行调整，得到最终的边界框位置。</p><h3 id=4-总结-1><div><a href=#4-%e6%80%bb%e7%bb%93-1>##
</a>4. 总结：</div></h3><p>锚定点是YOLO模型中用于解决不同尺寸和比例目标检测问题的关键概念，通过预定义一组大小和比例的边界框，并在每个网格单元中预测这些边界框的位置和类别，实现了模型对多样化目标的有效检测。</p><h2 id=transfer-learning><div><a href=#transfer-learning>#
</a>transfer-learning</div></h2><p>迁移学习是一种通过将已学习的知识从一个任务或领域应用到另一个任务或领域的机器学习技术。在目标检测任务中，迁移学习可以通过利用预训练的模型或特征来提升模型性能。以下是一些常用的迁移学习方法：</p><h3 id=1-微调fine-tuning><div><a href=#1-%e5%be%ae%e8%b0%83fine-tuning>##
</a>1. 微调（Fine-tuning）：</div></h3><p>微调是迁移学习中最常见的方法之一，它通常包括以下步骤：</p><ul><li><strong>预训练模型选择</strong>：选择一个在大规模数据集上预训练好的模型，例如 ImageNet 上的预训练模型。</li><li><strong>模型冻结</strong>：将预训练模型的部分或全部层冻结，即不更新它们的权重。</li><li><strong>顶层替换</strong>：替换预训练模型的顶层（通常是全连接层）或者添加新的全连接层，以适应新的目标检测任务。</li><li><strong>微调训练</strong>：在目标检测数据集上对整个模型进行训练，包括更新顶层和部分或全部解冻的层。</li></ul><h3 id=2-特征提取feature-extraction><div><a href=#2-%e7%89%b9%e5%be%81%e6%8f%90%e5%8f%96feature-extraction>##
</a>2. 特征提取（Feature Extraction）：</div></h3><p>特征提取是一种更轻量级的迁移学习方法，它不涉及到整个模型的重新训练，而是仅仅利用预训练模型的特征提取能力。</p><ul><li><strong>预训练模型选择</strong>：同样选择一个在大规模数据集上预训练好的模型。</li><li><strong>特征提取</strong>：将预训练模型的卷积层（通常是除了全连接层之外的所有层）作为特征提取器，并将提取到的特征作为输入，用于训练一个新的分类器或目标检测器。</li></ul><h3 id=3-领域自适应domain-adaptation><div><a href=#3-%e9%a2%86%e5%9f%9f%e8%87%aa%e9%80%82%e5%ba%94domain-adaptation>##
</a>3. 领域自适应（Domain Adaptation）：</div></h3><p>领域自适应是一种特殊的迁移学习方法，用于解决源域和目标域数据分布不匹配的问题。在目标检测任务中，可以通过在源域和目标域之间进行域适应来提高模型的泛化能力。</p><ul><li><strong>域适应方法</strong>：常见的域适应方法包括对抗训练、领域对齐等，通过调整模型的训练策略，使得模型在目标域上表现更好。</li></ul><h3 id=4-知识蒸馏knowledge-distillation><div><a href=#4-%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8fknowledge-distillation>##
</a>4. 知识蒸馏（Knowledge Distillation）：</div></h3><p>知识蒸馏是一种通过利用已训练好的模型的知识来训练一个更轻量级的模型的方法。在目标检测任务中，可以利用一个大型模型的知识来训练一个小型模型，以降低模型的复杂度和计算成本。</p><p>以上是一些常用的迁移学习方法，可以根据具体的任务需求和情况选择合适的方法来提升目标检测模型的性能。</p><h2 id=图像识别长尾分布问题><div><a href=#%e5%9b%be%e5%83%8f%e8%af%86%e5%88%ab%e9%95%bf%e5%b0%be%e5%88%86%e5%b8%83%e9%97%ae%e9%a2%98>#
</a>图像识别长尾分布问题</div></h2><p>处理训练数据集中的长尾分布是一个常见的问题，在目标检测任务中也同样存在。长尾分布意味着有些类别的样本数量非常少，而另一些类别的样本数量非常多。解决这个问题的方法包括：</p><h3 id=1-数据增强data-augmentation><div><a href=#1-%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%badata-augmentation>##
</a>1. 数据增强（Data Augmentation）：</div></h3><p>对于少样本类别，可以通过数据增强技术来生成更多的样本，以平衡不同类别之间的样本数量差异。常用的数据增强技术包括随机旋转、裁剪、缩放、平移、颜色变换等。</p><h3 id=2-类别加权class-weighting><div><a href=#2-%e7%b1%bb%e5%88%ab%e5%8a%a0%e6%9d%83class-weighting>##
</a>2. 类别加权（Class Weighting）：</div></h3><p>对于长尾分布的数据集，可以采用类别加权的方式来调整模型的损失函数，使得模型对少样本类别更加敏感。可以根据类别出现的频率来设置不同类别的权重，使得损失函数更平衡。</p><h3 id=3-重新采样resampling><div><a href=#3-%e9%87%8d%e6%96%b0%e9%87%87%e6%a0%b7resampling>##
</a>3. 重新采样（Resampling）：</div></h3><p>重新采样技术可以通过过采样或欠采样来调整数据集中不同类别的样本数量。对于少样本类别，可以采用过采样的方法增加样本数量，或者采用欠采样的方法减少样本数量。</p><h3 id=4-弱监督学习weakly-supervised-learning><div><a href=#4-%e5%bc%b1%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0weakly-supervised-learning>##
</a>4. 弱监督学习（Weakly Supervised Learning）：</div></h3><p>在长尾分布的数据集中，有些类别可能只有少量的有标签样本，而大部分样本是未标签的。可以利用弱监督学习的方法，例如使用无监督或半监督学习技术，从未标签的数据中学习有用的特征。</p><h3 id=5-多任务学习multi-task-learning><div><a href=#5-%e5%a4%9a%e4%bb%bb%e5%8a%a1%e5%ad%a6%e4%b9%a0multi-task-learning>##
</a>5. 多任务学习（Multi-Task Learning）：</div></h3><p>多任务学习可以将目标检测任务与其他相关任务结合起来训练模型，从而提升模型在长尾分布数据集上的性能。例如，可以将目标检测任务与图像分类、语义分割等任务结合起来进行训练，从而利用额外的信息来提升模型性能。</p><h3 id=6-异常检测anomaly-detection><div><a href=#6-%e5%bc%82%e5%b8%b8%e6%a3%80%e6%b5%8banomaly-detection>##
</a>6. 异常检测（Anomaly Detection）：</div></h3><p>针对长尾分布数据集中的少样本类别，可以采用异常检测的方法来识别并重点关注这些少样本类别，以便更好地调整模型和优化性能。</p><p>通过以上方法，可以有效地处理训练数据集中的长尾分布问题，并提升模型在不同类别上的性能。在实践中，通常需要根据具体的数据集和任务需求选择合适的方法进行处理。</p><h2 id=auto-encoder-model><div><a href=#auto-encoder-model>#
</a>Auto-encoder model</div></h2><p>领域自适应是一种将知识从一个域（源域）迁移到另一个域（目标域）的迁移学习方法，用于解决源域和目标域数据分布不匹配的问题。在目标检测任务中，领域自适应可以通过对抗训练的方式来实现，而 auto-encoder 可以作为一种辅助手段来帮助实现对抗训练。以下是具体的思路和细节：</p><h3 id=1-对抗训练的基本思路><div><a href=#1-%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%80%9d%e8%b7%af>##
</a>1. 对抗训练的基本思路：</div></h3><p>对抗训练是一种通过训练一个生成器和一个判别器的对抗过程，来使得生成器产生的数据分布与目标域的数据分布尽可能地接近。在目标检测任务中，可以通过对抗训练来调整模型，使得模型在目标域上表现更好。</p><h3 id=2-auto-encoder-在对抗训练中的作用><div><a href=#2-auto-encoder-%e5%9c%a8%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8>##
</a>2. auto-encoder 在对抗训练中的作用：</div></h3><p>auto-encoder 是一种无监督学习模型，它可以将输入数据编码成低维表示，并将其解码回原始数据。在对抗训练中，auto-encoder 可以作为一个生成器，用于生成与目标域数据分布相似的数据样本。通过训练 auto-encoder，可以学习到目标域数据的特征表示，从而帮助实现对抗训练。</p><h3 id=3-具体实现步骤><div><a href=#3-%e5%85%b7%e4%bd%93%e5%ae%9e%e7%8e%b0%e6%ad%a5%e9%aa%a4>##
</a>3. 具体实现步骤：</div></h3><h4 id=31-模型选择><div><a href=#31-%e6%a8%a1%e5%9e%8b%e9%80%89%e6%8b%a9>###
</a>3.1 模型选择：</div></h4><ul><li>选择一个预训练的模型作为基础模型，例如在源域上训练好的目标检测模型。</li></ul><h4 id=32-auto-encoder-训练><div><a href=#32-auto-encoder-%e8%ae%ad%e7%bb%83>###
</a>3.2 auto-encoder 训练：</div></h4><ul><li>在目标域上收集一部分数据，并使用这些数据来训练 auto-encoder。auto-encoder 的输入为目标域的图像数据，输出为重构的图像数据。通过训练 auto-encoder，可以学习到目标域数据的特征表示。</li></ul><h4 id=33-对抗训练><div><a href=#33-%e5%af%b9%e6%8a%97%e8%ae%ad%e7%bb%83>###
</a>3.3 对抗训练：</div></h4><ul><li>将训练好的 auto-encoder 作为生成器，将基础模型（源域上预训练的模型）作为判别器。</li><li>将源域和目标域的数据分别输入到 auto-encoder 和基础模型中，生成器尝试生成与目标域数据分布相似的数据样本，而判别器则尝试区分真实的目标域数据和生成器生成的数据。</li><li>通过对抗训练的过程，调整生成器和判别器的参数，使得生成器生成的数据分布与目标域的数据分布尽可能地接近。</li></ul><h3 id=4-进一步细化><div><a href=#4-%e8%bf%9b%e4%b8%80%e6%ad%a5%e7%bb%86%e5%8c%96>##
</a>4. 进一步细化：</div></h3><ul><li>可以考虑使用带有重建损失的对抗生成网络（Adversarial Auto-Encoder, AAE）来进行训练，以加强 auto-encoder 的特征学习能力和生成能力。</li><li>可以通过调整训练策略和超参数来进一步优化对抗训练的效果，例如学习率、训练轮数等。</li></ul><p>通过以上步骤，可以利用 auto-encoder 和对抗训练的方法来实现领域自适应，从而提升目标检测模型在目标域上的性能。</p><h2 id=目标检测的评估指标map_50><div><a href=#%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b%e7%9a%84%e8%af%84%e4%bc%b0%e6%8c%87%e6%a0%87map_50>#
</a>目标检测的评估指标（$mAP_{50}$）</div></h2><p>mAP_50 是目标检测任务中常用的评估指标之一，它表示在 IoU 阈值为 0.5 时的平均精确率（mAP，Mean Average Precision）。让我解释一下这个指标：</p><h3 id=1-平均精确率-average-precision-ap><div><a href=#1-%e5%b9%b3%e5%9d%87%e7%b2%be%e7%a1%ae%e7%8e%87-average-precision-ap>##
</a>1. 平均精确率 (Average Precision, AP)：</div></h3><ul><li>平均精确率是 Precision-Recall 曲线下的面积，用于衡量模型在不同 Recall 下的平均精确率。在目标检测任务中，AP 表示模型对单个类别的检测性能。</li></ul><h3 id=2-iou-阈值为-05><div><a href=#2-iou-%e9%98%88%e5%80%bc%e4%b8%ba-05>##
</a>2. IoU 阈值为 0.5：</div></h3><ul><li>IoU（Intersection over Union）是真实边界框和预测边界框的交集与并集之比。在计算 mAP 时，通常需要指定一个 IoU 阈值来判断一个检测结果是否是真正的检测结果。常用的 IoU 阈值之一是 0.5，表示当预测边界框与真实边界框的 IoU 大于等于 0.5 时，认为该预测边界框是正确的检测结果。</li></ul><h3 id=3-map_50-的含义><div><a href=#3-map_50-%e7%9a%84%e5%90%ab%e4%b9%89>##
</a>3. mAP_50 的含义：</div></h3><ul><li>mAP_50 表示在 IoU 阈值为 0.5 时的平均精确率，即模型在检测目标时，当预测边界框与真实边界框的 IoU 大于等于 0.5 时的平均精确率。</li></ul><h3 id=4-使用场景><div><a href=#4-%e4%bd%bf%e7%94%a8%e5%9c%ba%e6%99%af>##
</a>4. 使用场景：</div></h3><ul><li>mAP_50 是目标检测任务中常用的评估指标之一，它可以衡量模型在检测目标时的准确率和召回率，尤其在要求检测结果准确度较高的情况下，是一个重要的评价指标。</li></ul><h3 id=5-其他-iou-阈值><div><a href=#5-%e5%85%b6%e4%bb%96-iou-%e9%98%88%e5%80%bc>##
</a>5. 其他 IoU 阈值：</div></h3><p>除了常用的 IoU 阈值 0.5 外，还可以使用其他 IoU 阈值来计算不同阈值下的 mAP，比如 mAP_75 表示在 IoU 阈值为 0.75 时的平均精确率，以此类推。不同的 IoU 阈值反映了不同的检测精度要求，可以根据具体任务的需求选择合适的 IoU 阈值来评估模型性能。</p><h1 id=project-04----tsa><div><a href=#project-04----tsa>##
</a>Project 04 &ndash; TSA</div></h1><h2 id=k-means><div><a href=#k-means>#
</a>K-means</div></h2><h2 id=arima-model><div><a href=#arima-model>#
</a>ARIMA model</div></h2><h2 id=b-spline><div><a href=#b-spline>#
</a>B-spline</div></h2><h2 id=general-additive-models><div><a href=#general-additive-models>#
</a>General Additive Models</div></h2><h2 id=时序预测模型评估指标-apemape><div><a href=#%e6%97%b6%e5%ba%8f%e9%a2%84%e6%b5%8b%e6%a8%a1%e5%9e%8b%e8%af%84%e4%bc%b0%e6%8c%87%e6%a0%87-apemape>#
</a>时序预测模型评估指标 (APE/MAPE)</div></h2><h1 id=others><div><a href=#others>##
</a>Others</div></h1><h2 id=web-scraping><div><a href=#web-scraping>#
</a>web-scraping</div></h2><h2 id=bpewordpiecesentence-piece><div><a href=#bpewordpiecesentence-piece>#
</a>BPE/wordpiece/sentence-piece</div></h2></div></article></main><footer class="common-footer noselect"><div class=common-footer-bottom><div style=display:flex;align-items:center;gap:8px>© 2024</div><div>Powered by <a target=_blank rel="noopener noreferrer" href=https://gohugo.io/>Hugo</a>, theme <a target=_blank rel="noopener noreferrer" href=https://github.com/Junyi-99/hugo-theme-anubis2>Anubis2</a>.<br></div></div><p class="h-card vcard"><a href=https://fgg100y.github.io/ class="p-name u-url url fn" rel=me></a></p></footer></div></body></html>