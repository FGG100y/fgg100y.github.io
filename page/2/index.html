<!doctype html><html lang=en data-theme><head><meta name=generator content="Hugo 0.128.2"><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><title>fgg blog</title>
<meta name=description content><link rel=alternate type=application/rss+xml href=/index.xml title="fgg blog"><link rel=icon type=image/x-icon href=https://fgg100y.github.io/favicon.ico><link rel=apple-touch-icon-precomposed href=https://fgg100y.github.io/favicon.png><style>body{visibility:hidden;opacity:0}</style><noscript><style>body{visibility:visible;opacity:1}</style></noscript><link rel=stylesheet href=/css/style.min.184a655c5ad8596648622468e6696abf0cf0a2cf8266df17b4f7a36fe9c97551.css integrity="sha256-GEplXFrYWWZIYiRo5mlqvwzwos+CZt8XtPejb+nJdVE="><link rel=stylesheet href=/css/style.min.c4c04b3ef88e3d619ad4c7ee5e03048422bc55c4fefdc1f07657c1133670aa22.css integrity="sha256-xMBLPviOPWGa1MfuXgMEhCK8VcT+/cHwdlfBEzZwqiI="><link rel=stylesheet href=/css/style.min.21c5d8fe0a79d623b0adc1ce4bd4f6dd2c05cd939c9aaaa966ba7186b1464f4d.css integrity="sha256-IcXY/gp51iOwrcHOS9T23SwFzZOcmqqpZrpxhrFGT00="><link rel=stylesheet href=/css/style.min.863b4356f5ce53525ab2482f84c47476c4618984b9726e576c244225ebda1bcc.css integrity="sha256-hjtDVvXOU1JaskgvhMR0dsRhiYS5cm5XbCRCJevaG8w=" crossorigin=anonymous><script src=/js/script.min.08f04d96386c73c9bf4d160333f8f448c05a6e01c06770542ee0e013954ce930.js type=text/javascript integrity="sha256-CPBNljhsc8m/TRYDM/j0SMBabgHAZ3BULuDgE5VM6TA="></script><link rel=stylesheet href=/css/custom.css></head><body><a class=skip-main href=#main>Skip to main content</a><div class=container><header class=common-header><div class=header-top><div class=header-top-left><h1 class="site-title noselect"><a href=/>fgg blog</a></h1><div class=theme-switcher><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-sun-high"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14.828 14.828A4 4 0 109.172 9.172a4 4 0 005.656 5.656z"/><path d="M6.343 17.657l-1.414 1.414"/><path d="M6.343 6.343 4.929 4.929"/><path d="M17.657 6.343l1.414-1.414"/><path d="M17.657 17.657l1.414 1.414"/><path d="M4 12H2"/><path d="M12 4V2"/><path d="M20 12h2"/><path d="M12 20v2"/></svg></span></div><script>const STORAGE_KEY="user-color-scheme",defaultTheme="auto";let currentTheme,switchButton,autoDefinedScheme=window.matchMedia("(prefers-color-scheme: dark)");function switchTheme(){currentTheme=currentTheme==="dark"?"light":"dark",localStorage&&localStorage.setItem(STORAGE_KEY,currentTheme),document.documentElement.setAttribute("data-theme",currentTheme),changeGiscusTheme(currentTheme),document.body.dispatchEvent(new CustomEvent(currentTheme+"-theme-set"))}const autoChangeScheme=e=>{currentTheme=e.matches?"dark":"light",document.documentElement.setAttribute("data-theme",currentTheme),changeGiscusTheme(currentTheme),document.body.dispatchEvent(new CustomEvent(currentTheme+"-theme-set"))};document.addEventListener("DOMContentLoaded",function(){switchButton=document.querySelector(".theme-switcher"),currentTheme=detectCurrentScheme(),currentTheme==="auto"?(autoChangeScheme(autoDefinedScheme),autoDefinedScheme.addListener(autoChangeScheme)):document.documentElement.setAttribute("data-theme",currentTheme),switchButton&&switchButton.addEventListener("click",switchTheme,!1),showContent()});function detectCurrentScheme(){return localStorage!==null&&localStorage.getItem(STORAGE_KEY)?localStorage.getItem(STORAGE_KEY):defaultTheme?defaultTheme:window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"}function showContent(){document.body.style.visibility="visible",document.body.style.opacity=1}function changeGiscusTheme(e){function t(e){const t=document.querySelector("iframe.giscus-frame");if(!t)return;t.contentWindow.postMessage({giscus:e},"https://giscus.app")}t({setConfig:{theme:e}})}</script><ul class="social-icons noselect"><li><a href=https://github.com/fgg100y title=Github rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-github"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></span></a></li><li><a href=/index.xml title=RSS rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-rss"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 19m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></span></a></li></ul></div><div class=header-top-right></div></div><nav class=noselect><a class=active href=https://fgg100y.github.io/ title>Home</a>
<a href=https://fgg100y.github.io/posts/ title>Posts</a>
<a href=https://fgg100y.github.io/tags/ title>Tags</a>
<a href=https://fgg100y.github.io/about/ title>About</a></nav><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></header><main id=main tabindex=-1><div class=homepage-content></div><div class="articles h-feed"><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-28-knowledge_distillation2/>knowledge_distillation2</a></h1></header></div><div class="content post-summary p-summary"><h2 id=generalized-knowledge-distillation-gkd><div><a href=#generalized-knowledge-distillation-gkd>#
</a>Generalized Knowledge Distillation (GKD)</div></h2><p>泛化知识蒸馏是一种改进的知识蒸馏技术，旨在解决传统知识蒸馏方法在自回归序列模型中遇到的分
布不匹配问题，特别是在训练和推理阶段之间。传统的知识蒸馏方法通常基于固定的输出序列集进行，
这些序列或者是教师模型生成的，或者是基于真实数据的标签。然而，这导致学生模型在推理时生成
的序列可能与训练时见到的序列分布不同，从而影响了学生模型的泛化能力。</p><p>GKD 不再局限于固定输出序列的训练，而是允许学生模型在其自我生成的序列上进行学习，同时利用
教师模型提供的反馈。</p></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-28>2024-06-28</time></div><a class="post-hidden-url u-url" href=/posts/2024-06-28-knowledge_distillation2/>/posts/2024-06-28-knowledge_distillation2/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/generalized-kd/>#Generalized KD</a></li><li><a href=/tags/imitation-learning/>#Imitation Learning</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-27-knowledge_distillation/>knowledge_distillation</a></h1></header></div><div class="content post-summary p-summary"><p>知识蒸馏（Knowledge Distillation）是一种机器学习技术，它通过将大型、复杂的模型（称为教师
模型，Teacher Model）的知识“蒸馏”到小型、简洁的模型（称为学生模型，Student Model）中，从
而实现模型压缩和加速，同时尽可能保持原始模型的性能。这一技术使得模型可以在资源有限的设备
上高效运行，如手机或嵌入式设备。</p><blockquote><p>The method works by incorporating an additional loss into the traditional cross entropy
loss, which is based on the softmax output of the teacher network. The assumption is
that the output activations of a properly trained teacher network carry additional
information that can be leveraged by a student network during training.</p></blockquote></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-27>2024-06-27</time></div><a class="post-hidden-url u-url" href=/posts/2024-06-27-knowledge_distillation/>/posts/2024-06-27-knowledge_distillation/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/distillation/>#Distillation</a></li><li><a href=/tags/tearch/student-models/>#Tearch/Student Models</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-27-mixup_beyond_erm/>mixup_beyond_ERM</a></h1></header></div><div class="content post-summary p-summary"><h1 id=empirical-risk-minimazation-erm><div><a href=#empirical-risk-minimazation-erm>##
</a>Empirical Risk Minimazation (ERM)</div></h1><p>经验风险最小化, Empirical Risk Minimazation principle (Vapnik, 1998)</p><ol><li>基于ERM训练模型：亦即在训练数据集上学习以最小化其平均误差。</li><li>当前SOTA模型的参数量随着训练数据集规模增大而线性增加。</li></ol><p>而经典VC学习理论（learning theory, Vapnik & Chervonenkis, 1971）表明：只要学习器的参数量
不随着训练样本数量增加，则基于ERM学习一定会收敛(convergence, i.e., good generalization
to new data)。亦即：模型的复杂度（参数量规模）相对于训练数据规模应该是固定的或者变动不大。</p></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-27>2024-06-27</time></div><a class="post-hidden-url u-url" href=/posts/2024-06-27-mixup_beyond_erm/>/posts/2024-06-27-mixup_beyond_erm/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/mixup/>#Mixup</a></li><li><a href=/tags/erm/>#ERM</a></li><li><a href=/tags/vrm/>#VRM</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-16-wifi%E8%BF%9E%E4%B8%8D%E4%B8%8A_%E4%BD%86%E6%89%8B%E6%9C%BA%E6%B5%81%E9%87%8F%E5%8F%AF%E4%BB%A5/>路由器wifi连不上_但手机流量可以</a></h1></header></div><div class="content post-summary p-summary"><p>Q：请问Wifi无法翻墙或访问某些网站，但用手机流量却可以是什么原因？</p><p>A:
先说说你的wifi和5g环境下翻墙的问题，我猜测下你家里的宽带是不是移动的，手机流量用的是联通
或者电信，总之，家庭宽带和5g不是一家isp。 如果是的话，这个问题就比较好理解，不同isp不同
的地区都会有自己的一套黑名单机制。 所以可能你的家宽isp监测你的上网流量有不正常，或者大数
据认为你的翻墙服务器很可疑（未必是你造成的，因为有很多人在用），于是开启了屏蔽，但是另一
家手机isp并没有触发黑名单判定，所以未屏蔽。 移动的黑名单一般是最激进的，号称墙中墙，不过
不同地区的同一服务商政策也会有很大差别，不好说谁就一定好，谁就一定差。所以解决方法就是换
个翻墙服务器就可以了。</p></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-16>2024-06-16</time></div><a class="post-hidden-url u-url" href=/posts/2024-06-16-wifi%E8%BF%9E%E4%B8%8D%E4%B8%8A_%E4%BD%86%E6%89%8B%E6%9C%BA%E6%B5%81%E9%87%8F%E5%8F%AF%E4%BB%A5/>/posts/2024-06-16-wifi%E8%BF%9E%E4%B8%8D%E4%B8%8A_%E4%BD%86%E6%89%8B%E6%9C%BA%E6%B5%81%E9%87%8F%E5%8F%AF%E4%BB%A5/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/wifi/>#WIFI</a></li><li><a href=/tags/cellphone/>#Cellphone</a></li><li><a href>#isp网络访问屏蔽</a></li><li><a href>#生活点滴</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/2024-06-13-calculate_gpu_vram_for_llama3-70b/>calculate_gpu_vram_for_llama3-70B</a></h1></header></div><div class="content post-summary p-summary"><p>How many GPUs do I need to be able to serve Llama 70B? In order to answer that, you need
to know how much GPU memory will be required by the Large Language Model.</p><p>The formula is simple:</p><p>$$
M=\frac{(P * 4B)}{(32/Q)} * 1.2
$$</p></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-13>2024-06-13</time></div><a class="post-hidden-url u-url" href=/posts/2024-06-13-calculate_gpu_vram_for_llama3-70b/>/posts/2024-06-13-calculate_gpu_vram_for_llama3-70b/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/vram/>#VRAM</a></li><li><a href=/tags/llama3-70b/>#Llama3-70B</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/mlteam101/lean_principles/>lean_principles</a></h1></header></div><div class="content post-summary p-summary">精益之道</div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-03>2024-06-03</time></div><a class="post-hidden-url u-url" href=/posts/mlteam101/lean_principles/>/posts/mlteam101/lean_principles/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/lean-principle/>#Lean Principle</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/mlteam101/feedback_loops_and_times_to_feedback/>EffectiveML 01: Delivering successful ML projects</a></h1></header></div><div class="content post-summary p-summary">ML project feedback mechanisms and disciplines</div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-06-03>2024-06-03</time></div><a class="post-hidden-url u-url" href=/posts/mlteam101/feedback_loops_and_times_to_feedback/>/posts/mlteam101/feedback_loops_and_times_to_feedback/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/ml-teams/>#ML Teams</a></li><li><a href=/tags/task-feedback/>#Task Feedback</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/notes4resume/>tech interview prepare (for my resume)</a></h1></header></div><div class="content post-summary p-summary"><h1 id=自我介绍><div><a href=#%e8%87%aa%e6%88%91%e4%bb%8b%e7%bb%8d>##
</a>自我介绍</div></h1><blockquote><p>在自我介绍时，确保你提到的项目和技能与你申请的职位紧密相关，这样可以更好地展示你的专业
能力和对职位的适应性。同时，保持自信和热情，让面试官感受到你对工作和团队的承诺。</p></blockquote></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-05-27>2024-05-27</time></div><a class="post-hidden-url u-url" href=/posts/notes4resume/>/posts/notes4resume/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/tech-interview/>#Tech Interview</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/llm_prompt/>GPT-PROMPT</a></h1></header></div><div class="content post-summary p-summary"><p><a href="https://news.ycombinator.com/item?id=40474716">Ask HN: What is your ChatGPT customization prompt?</a></p><h2 id=system-prompt><div><a href=#system-prompt>#
</a>system prompt</div></h2><hr><p>You are an autoregressive language model that has been fine-tuned with
instruction-tuning and RLHF. You carefully provide accurate, factual, thoughtful,nuanced
answers, and are brilliant at reasoning. If you think there might not be a correct
answer, you say so.</p><p>Your users are experts in AI and ethics, so they already know you&rsquo;re a language model
and your capabilities and limitations, so don&rsquo;t remind them of that. They&rsquo;re familiar
with ethical issues in general so you don&rsquo;t need to remind them about those either.
Don&rsquo;t be verbose in your answers, but do provide details and examples where it might
help the explanation. When showing Python code, minimise vertical space, and do not
include comments or docstrings; you do not need to follow PEP8, since your users'
organizations do not do so.</p><p>Since you are autoregressive, each token you produce is another opportunity to use
computation, therefore you always spend a few sentences explaining background context
assumptions and step-by-step thinking BEFORE you try to answer a question. However: if
the request begins with the string &ldquo;vv&rdquo; then ignore the previous sentence and instead
make your response as concise as possible, with no introduction or background at the
start, no summary at the end, and outputting only code for answers where code is
appropriate.</p><hr></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-05-27>2024-05-27</time></div><a class="post-hidden-url u-url" href=/posts/llm_prompt/>/posts/llm_prompt/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/gpt/>#GPT</a></li><li><a href=/tags/system-prompt/>#System Prompt</a></li></ul></div></div></article><article class="post-list h-feed post-card"><div class=post-header><header><h1 class="p-name post-title"><a class=u-url href=/posts/faiss101/>FAISS-IVFPQ</a></h1></header></div><div class="content post-summary p-summary"><h2 id=plain-and-simple-indexflatl2><div><a href=#plain-and-simple-indexflatl2>#
</a>Plain and Simple: IndexFlatL2</div></h2><blockquote><p>Given a set of vectors, we can index them using Faiss — then using another vector (the query vector), we search for the most similar vectors within the index.
Now, Faiss not only allows us to build an index and search — but it also speeds up search times to ludicrous performance levels.</p></blockquote><p>IndexFlatL2 measures the L2 (or Euclidean) distance between all given points between our
query vector, and the vectors loaded into the index. It’s simple, very accurate, but not
too fast.</p><p><img alt=IMG:indexFlat2 src=/posts/faiss101/images/faiss-IndexFlat2.webp>
<em><p style=text-align:center>Image credit: <a href=https://www.pinecone.io/learn/series/faiss/faiss-tutorial/>pinecone.io</a></p></em></p></div><div class="post-info noselect"><div class="post-date dt-published"><time datetime=2024-05-22>2024-05-22</time></div><a class="post-hidden-url u-url" href=/posts/faiss101/>/posts/faiss101/</a>
<a href=https://fgg100y.github.io/ class="p-name p-author post-hidden-author h-card" rel=me>fmh</a><div class=post-taxonomies><ul class=post-tags><li><a href=/tags/faiss/>#FAISS</a></li><li><a href=/tags/ivf/>#IVF</a></li><li><a href>#乘积量化</a></li></ul></div></div></article><div class="pagination noselect"><div class="left pagination-item"><a href=/>to new posts</a></div><div class="right pagination-item"><a href=/page/3/>to old posts</a></div></div></div></main><footer class="common-footer noselect"><div class=common-footer-bottom><div style=display:flex;align-items:center;gap:8px>© fmh, 2024</div><div style=display:flex;align-items:center></div><div>Powered by <a target=_blank rel="noopener noreferrer" href=https://gohugo.io/>Hugo</a>, theme <a target=_blank rel="noopener noreferrer" href=https://github.com/Junyi-99/hugo-theme-anubis2>Anubis2</a>.<br></div></div><p class="h-card vcard"><a href=https://fgg100y.github.io/ class="p-name u-url url fn" rel=me>fmh</a></p></footer></div></body></html>